<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.8.11"/>
<title>Cambridge SMT System: Tutorial.070.rulextract.md Source File</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="navtree.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="resize.js"></script>
<script type="text/javascript" src="navtreedata.js"></script>
<script type="text/javascript" src="navtree.js"></script>
<script type="text/javascript">
  $(document).ready(initResizable);
  $(window).load(resizeHeight);
</script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td id="projectalign" style="padding-left: 0.5em;">
   <div id="projectname">Cambridge SMT System
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.8.11 -->
</div><!-- top -->
<div id="side-nav" class="ui-resizable side-nav-resizable">
  <div id="nav-tree">
    <div id="nav-tree-contents">
      <div id="nav-sync" class="sync"></div>
    </div>
  </div>
  <div id="splitbar" style="-moz-user-select:none;" 
       class="ui-resizable-handle">
  </div>
</div>
<script type="text/javascript">
$(document).ready(function(){initNavTree('Tutorial_8070_8rulextract_8md.html','');});
</script>
<div id="doc-content">
<div class="header">
  <div class="headertitle">
<div class="title">Tutorial.070.rulextract.md</div>  </div>
</div><!--header-->
<div class="contents">
<a href="Tutorial_8070_8rulextract_8md.html">Go to the documentation of this file.</a><div class="fragment"><div class="line"><a name="l00001"></a><span class="lineno">    1</span>&#160;Rule Extraction                {#rulextract}</div><div class="line"><a name="l00002"></a><span class="lineno">    2</span>&#160;=================</div><div class="line"><a name="l00003"></a><span class="lineno">    3</span>&#160;</div><div class="line"><a name="l00004"></a><span class="lineno">    4</span>&#160;The rule extractor is a Hadoop MapReduce tool written in Java and Scala. It is fast, flexible, and can handle large amounts of training data. </div><div class="line"><a name="l00005"></a><span class="lineno">    5</span>&#160;</div><div class="line"><a name="l00006"></a><span class="lineno">    6</span>&#160;\section rulextract_prerequisites Prerequisites</div><div class="line"><a name="l00007"></a><span class="lineno">    7</span>&#160;</div><div class="line"><a name="l00008"></a><span class="lineno">    8</span>&#160; + [A Hadoop 2 cluster](http://hadoop.apache.org/releases.html &quot;Download Hadoop&quot;)</div><div class="line"><a name="l00009"></a><span class="lineno">    9</span>&#160; + [Scala 2.11](http://www.scala-lang.org/download/)</div><div class="line"><a name="l00010"></a><span class="lineno">   10</span>&#160;</div><div class="line"><a name="l00011"></a><span class="lineno">   11</span>&#160;We assume that the Hadoop commands, including yarn and hdfs, are in your command path. If you do not have access to a Hadoop cluster, then a [single node cluster](http://hadoop.apache.org/docs/r2.6.0/hadoop-project-dist/hadoop-common/SingleCluster.html) is fine for the small amount of data in this tutorial.</div><div class="line"><a name="l00012"></a><span class="lineno">   12</span>&#160;</div><div class="line"><a name="l00013"></a><span class="lineno">   13</span>&#160;The jar located at $RULEXTRACTJAR is a &quot;fat jar&quot;, which means that all the dependences of the rule extractor are also included. A fat jar simplifies submission to the Hadoop cluster because dependencies do not need to be specified at job submission.</div><div class="line"><a name="l00014"></a><span class="lineno">   14</span>&#160;</div><div class="line"><a name="l00015"></a><span class="lineno">   15</span>&#160;\section rulextract_tutorial_overview Tutorial</div><div class="line"><a name="l00016"></a><span class="lineno">   16</span>&#160;</div><div class="line"><a name="l00017"></a><span class="lineno">   17</span>&#160;Rule extraction is split into two stages:</div><div class="line"><a name="l00018"></a><span class="lineno">   18</span>&#160;</div><div class="line"><a name="l00019"></a><span class="lineno">   19</span>&#160;**Extraction**: Rules are extracted from the entire training set, counted, and rule probabilities are computed. This stage uses MapReduce for fast aggregation of statistics. The output is the set of all rules for the language pair stored in a simple database based on the HFile format.</div><div class="line"><a name="l00020"></a><span class="lineno">   20</span>&#160;</div><div class="line"><a name="l00021"></a><span class="lineno">   21</span>&#160;**Retrieval**: For a given test set of parallel sentences the HFile is queried for constituent rules. Many of the features are computed as this stage, including lexical features. The retrieval stage does not require a Hadoop MapReduce cluster to run.</div><div class="line"><a name="l00022"></a><span class="lineno">   22</span>&#160;</div><div class="line"><a name="l00023"></a><span class="lineno">   23</span>&#160;\subsection rulextract_tutorial_extraction Extraction</div><div class="line"><a name="l00024"></a><span class="lineno">   24</span>&#160;</div><div class="line"><a name="l00025"></a><span class="lineno">   25</span>&#160;The extraction stage of the pipeline is modelled as a typical MapReduce batch process. Datasets are transformed into new datasets by Hadoop jobs, as shown in the following diagram:</div><div class="line"><a name="l00026"></a><span class="lineno">   26</span>&#160;</div><div class="line"><a name="l00027"></a><span class="lineno">   27</span>&#160;![Extraction Pipeline](rulextract.svg)</div><div class="line"><a name="l00028"></a><span class="lineno">   28</span>&#160;</div><div class="line"><a name="l00029"></a><span class="lineno">   29</span>&#160;For the remainder of this tutorial, it is assumed that commands are run from the `$DEMO` directory. Please change to that directory and ensure a log directory exists:</div><div class="line"><a name="l00030"></a><span class="lineno">   30</span>&#160;</div><div class="line"><a name="l00031"></a><span class="lineno">   31</span>&#160;    &gt; cd $DEMO</div><div class="line"><a name="l00032"></a><span class="lineno">   32</span>&#160;    &gt; mkdir -p logs</div><div class="line"><a name="l00033"></a><span class="lineno">   33</span>&#160;</div><div class="line"><a name="l00034"></a><span class="lineno">   34</span>&#160;Let us simplify the execution of the Hadoop commands by setting an environment variable:</div><div class="line"><a name="l00035"></a><span class="lineno">   35</span>&#160;</div><div class="line"><a name="l00036"></a><span class="lineno">   36</span>&#160;    &gt; RULEXTRACT=&quot;yarn jar $RULEXTRACTJAR&quot;</div><div class="line"><a name="l00037"></a><span class="lineno">   37</span>&#160;</div><div class="line"><a name="l00038"></a><span class="lineno">   38</span>&#160;The first step of the extraction pipeline is to load the training data on HDFS:</div><div class="line"><a name="l00039"></a><span class="lineno">   39</span>&#160;</div><div class="line"><a name="l00040"></a><span class="lineno">   40</span>&#160;     &gt; $RULEXTRACT \</div><div class="line"><a name="l00041"></a><span class="lineno">   41</span>&#160;         uk.ac.cam.eng.extraction.hadoop.util.ExtractorDataLoader \</div><div class="line"><a name="l00042"></a><span class="lineno">   42</span>&#160;         --hdfsout=RUEN-WMT13/training_data \</div><div class="line"><a name="l00043"></a><span class="lineno">   43</span>&#160;        @configs/CF.rulextract \</div><div class="line"><a name="l00044"></a><span class="lineno">   44</span>&#160;         &gt;&amp; logs/log.loaddata</div><div class="line"><a name="l00045"></a><span class="lineno">   45</span>&#160;</div><div class="line"><a name="l00046"></a><span class="lineno">   46</span>&#160;The extraction pipeline is driven by the configuration file `configs/CF.rulextract`. The configuration file specifies the source side of the training data (`--source=train/ru.sample.gz`), the target side (`--target=train/en.sample.gz`), and the alignments in the Berkeley format (`--alignment=train/align.berkeley.sample.gz`). The ExtractorDataLoader reads in the training data, and writes it in HDFS as a sequence file specified by the `--hdfsout` argument. </div><div class="line"><a name="l00047"></a><span class="lineno">   47</span>&#160;</div><div class="line"><a name="l00048"></a><span class="lineno">   48</span>&#160;The ExtractorDataLoader also requires a provenance file to be specified (`--provenance_file=train/provenance.sample.gz`). Provenances specify subsets of the training data for which to compute separate translation and lexical models. These models are treated as extra features in the linear model used by the decoder. </div><div class="line"><a name="l00049"></a><span class="lineno">   49</span>&#160;</div><div class="line"><a name="l00050"></a><span class="lineno">   50</span>&#160;The next step is to run the extractor:</div><div class="line"><a name="l00051"></a><span class="lineno">   51</span>&#160;</div><div class="line"><a name="l00052"></a><span class="lineno">   52</span>&#160;    &gt; $RULEXTRACT \</div><div class="line"><a name="l00053"></a><span class="lineno">   53</span>&#160;        uk.ac.cam.eng.extraction.hadoop.extraction.ExtractorJob \</div><div class="line"><a name="l00054"></a><span class="lineno">   54</span>&#160;        --input=RUEN-WMT13/training_data \</div><div class="line"><a name="l00055"></a><span class="lineno">   55</span>&#160;        --output=RUEN-WMT13/rules \</div><div class="line"><a name="l00056"></a><span class="lineno">   56</span>&#160;        @configs/CF.rulextract \</div><div class="line"><a name="l00057"></a><span class="lineno">   57</span>&#160;        &gt;&amp; logs/log.extract</div><div class="line"><a name="l00058"></a><span class="lineno">   58</span>&#160;</div><div class="line"><a name="l00059"></a><span class="lineno">   59</span>&#160;This command performs the first of transformations in the pipeline. It:</div><div class="line"><a name="l00060"></a><span class="lineno">   60</span>&#160;</div><div class="line"><a name="l00061"></a><span class="lineno">   61</span>&#160;+ extracts rules from parallel sentences.</div><div class="line"><a name="l00062"></a><span class="lineno">   62</span>&#160;+ aggregate the rules, such that the resulting dataset has 1 row per unique rule.</div><div class="line"><a name="l00063"></a><span class="lineno">   63</span>&#160;+ counts the occurrences of the rule in the training data according to provenance.</div><div class="line"><a name="l00064"></a><span class="lineno">   64</span>&#160;</div><div class="line"><a name="l00065"></a><span class="lineno">   65</span>&#160;The output of most of the tools in the pipeline is a sequence file, which is difficult to inspect. To help visualize the data stored in sequence files we supply a tool that converts the sequence file to a text representation. To inspect the output of the extractor execute the following command:</div><div class="line"><a name="l00066"></a><span class="lineno">   66</span>&#160;</div><div class="line"><a name="l00067"></a><span class="lineno">   67</span>&#160;    &gt; $RULEXTRACT \</div><div class="line"><a name="l00068"></a><span class="lineno">   68</span>&#160;        uk.ac.cam.eng.extraction.hadoop.util.SequenceFilePrint \</div><div class="line"><a name="l00069"></a><span class="lineno">   69</span>&#160;        RUEN-WMT13/rules/part-r-00000 2&gt;/dev/null \</div><div class="line"><a name="l00070"></a><span class="lineno">   70</span>&#160;        | head</div><div class="line"><a name="l00071"></a><span class="lineno">   71</span>&#160;</div><div class="line"><a name="l00072"></a><span class="lineno">   72</span>&#160;which prints the sequence file as tab-separated values:</div><div class="line"><a name="l00073"></a><span class="lineno">   73</span>&#160;</div><div class="line"><a name="l00074"></a><span class="lineno">   74</span>&#160;    3 6_18_4        {0=1, 1=1}      {0-2 =1}</div><div class="line"><a name="l00075"></a><span class="lineno">   75</span>&#160;    3_4_6002_6 4_5_2725_8   {0=1, 1=1}      {2-2 1-1 3-3 0-0 =1}</div><div class="line"><a name="l00076"></a><span class="lineno">   76</span>&#160;    3_5_64_266 370  {0=1, 1=1}      {2-0 3-0 =1}</div><div class="line"><a name="l00077"></a><span class="lineno">   77</span>&#160;    3_5_266_123_10557_63306_3 4_370_123776_21235_4_3        {0=1, 1=1}      {2-1 5-2 5-3 4-3 3-2 6-4 0-0 =1}</div><div class="line"><a name="l00078"></a><span class="lineno">   78</span>&#160;    3_5_399_1231_1940_24_3385_28107_3 4_171_10863_3334_6_16288_4089_4       {0=2, 1=2}      {8-7 2-2 5-4 4-2 4-3 7-5 1-1 3-1 3-2 6-6 0-0 =2}</div><div class="line"><a name="l00079"></a><span class="lineno">   79</span>&#160;    3_5_458_V 9_3_1552_6_V  {0=1, 1=1}      {2-2 1-0 =1}</div><div class="line"><a name="l00080"></a><span class="lineno">   80</span>&#160;    3_5_V_5291_V1 V_21498_6_V1      {0=1, 1=1}      {3-1 =1}</div><div class="line"><a name="l00081"></a><span class="lineno">   81</span>&#160;    3_5_V_130_3 9_V_14_226_4        {0=1, 1=1}      {4-4 1-0 3-2 3-3 =1}</div><div class="line"><a name="l00082"></a><span class="lineno">   82</span>&#160;    3_5_V_133_V1 8_9_V_206_10_V1    {0=1, 1=1}      {1-1 3-3 0-0 =1}</div><div class="line"><a name="l00083"></a><span class="lineno">   83</span>&#160;    3_6_27_706_3140 8_48_36_1414_3  {0=1, 1=1}      {2-1 4-3 1-0 3-2 =1}</div><div class="line"><a name="l00084"></a><span class="lineno">   84</span>&#160;</div><div class="line"><a name="l00085"></a><span class="lineno">   85</span>&#160;Note that you may see different results due to the partitioning of the data by MapReduce. The first field is the rule, with the source and target side separated by a space. The second field is the map of counts by provenance. In this example each rule has two provenances indexed by 0 and 1. The 0 indexed value is the count across the whole of the training data, which is called the global provenance. The 1 indexed value is the count across the common crawl corpus (cc), and because the rule only occurs in this corpus both counts are equal. In the third field we see a list of the alignments which yield this rule and their associated global counts. In this example all of the rules are yielded by a single alignment, and the counts are equal to the global provenance count. </div><div class="line"><a name="l00086"></a><span class="lineno">   86</span>&#160;</div><div class="line"><a name="l00087"></a><span class="lineno">   87</span>&#160;Once rules have been extracted, the next step is to compute the rule probabilities. Our approach is to use two jobs to compute the target given source (source2target) and source given target (target2source) probabilities. Here is a quick summary of how the source2target job computes the probabilities:</div><div class="line"><a name="l00088"></a><span class="lineno">   88</span>&#160;</div><div class="line"><a name="l00089"></a><span class="lineno">   89</span>&#160;+ Hadoop sorts the rules lexicographically by the source side first, then the target side.</div><div class="line"><a name="l00090"></a><span class="lineno">   90</span>&#160;    + The sort order is defined by a custom comparator.</div><div class="line"><a name="l00091"></a><span class="lineno">   91</span>&#160;    + To ensure that all rules with the same source side are sent to the same partition, only the source side of the rule is hashed.</div><div class="line"><a name="l00092"></a><span class="lineno">   92</span>&#160;+ Once sorted, all the rules with the same source side will be contiguous in the sequence file.</div><div class="line"><a name="l00093"></a><span class="lineno">   93</span>&#160;+ The reducer loads all the rules with the same source side in memory.</div><div class="line"><a name="l00094"></a><span class="lineno">   94</span>&#160;+ The reducer then computes the probabilities for all rules with the same source side.</div><div class="line"><a name="l00095"></a><span class="lineno">   95</span>&#160;</div><div class="line"><a name="l00096"></a><span class="lineno">   96</span>&#160;The target2source job uses the same approach, but the lexicographic sort order is reversed such that all the target sides are contiguous in the sorted data.</div><div class="line"><a name="l00097"></a><span class="lineno">   97</span>&#160;</div><div class="line"><a name="l00098"></a><span class="lineno">   98</span>&#160;The rule probability jobs are run using the following commands:</div><div class="line"><a name="l00099"></a><span class="lineno">   99</span>&#160;</div><div class="line"><a name="l00100"></a><span class="lineno">  100</span>&#160;    &gt; $RULEXTRACT \</div><div class="line"><a name="l00101"></a><span class="lineno">  101</span>&#160;        uk.ac.cam.eng.extraction.hadoop.features.phrase.Source2TargetJob \</div><div class="line"><a name="l00102"></a><span class="lineno">  102</span>&#160;        --input=RUEN-WMT13/rules \</div><div class="line"><a name="l00103"></a><span class="lineno">  103</span>&#160;        --output=RUEN-WMT13/s2t \</div><div class="line"><a name="l00104"></a><span class="lineno">  104</span>&#160;        &gt;&amp; logs/log.s2t </div><div class="line"><a name="l00105"></a><span class="lineno">  105</span>&#160;</div><div class="line"><a name="l00106"></a><span class="lineno">  106</span>&#160;    &gt; $RULEXTRACT \</div><div class="line"><a name="l00107"></a><span class="lineno">  107</span>&#160;        uk.ac.cam.eng.extraction.hadoop.features.phrase.Target2SourceJob \</div><div class="line"><a name="l00108"></a><span class="lineno">  108</span>&#160;        --input=RUEN-WMT13/rules \</div><div class="line"><a name="l00109"></a><span class="lineno">  109</span>&#160;        --output=RUEN-WMT13/t2s \</div><div class="line"><a name="l00110"></a><span class="lineno">  110</span>&#160;        &gt;&amp; logs/log.t2s</div><div class="line"><a name="l00111"></a><span class="lineno">  111</span>&#160;</div><div class="line"><a name="l00112"></a><span class="lineno">  112</span>&#160;We now have rule counts, and two sets of rule probabilities. The last step is to:</div><div class="line"><a name="l00113"></a><span class="lineno">  113</span>&#160;</div><div class="line"><a name="l00114"></a><span class="lineno">  114</span>&#160;+ Merge all the statistics.</div><div class="line"><a name="l00115"></a><span class="lineno">  115</span>&#160;+ Filter rules with low counts and probabilities.</div><div class="line"><a name="l00116"></a><span class="lineno">  116</span>&#160;+ Create the file based database (HFile).</div><div class="line"><a name="l00117"></a><span class="lineno">  117</span>&#160;</div><div class="line"><a name="l00118"></a><span class="lineno">  118</span>&#160;We do this with the MergeJob. Before we can run this job we need to edit the configuration file to set the location of files necessary for filtering. These files are specified by the following command line options in `configs/CF.rulextract`:</div><div class="line"><a name="l00119"></a><span class="lineno">  119</span>&#160;</div><div class="line"><a name="l00120"></a><span class="lineno">  120</span>&#160;+ `--allowed_patterns=file://$DEMO/configs/CF.rulextract.filter.allowedonly`</div><div class="line"><a name="l00121"></a><span class="lineno">  121</span>&#160;+ `--source_patterns=file://$DEMO/CF.rulextract.patterns`</div><div class="line"><a name="l00122"></a><span class="lineno">  122</span>&#160;</div><div class="line"><a name="l00123"></a><span class="lineno">  123</span>&#160;These files are specified by a full URI because they need to be accessible by every worker machine in the Hadoop cluster. For this tutorial we assume that the workers have access to a networked file system. If this is not the case, then you must load these files onto HDFS and use the `hdfs://` protocol in the configuration. Because the `file://` protocol does not allow for relative paths, the full path needs to added manually. For example:</div><div class="line"><a name="l00124"></a><span class="lineno">  124</span>&#160;</div><div class="line"><a name="l00125"></a><span class="lineno">  125</span>&#160;    &gt; sed &quot;s:\$DEMO:$DEMO:g&quot; configs/CF.rulextract &gt; configs/CF.rulextract.expanded</div><div class="line"><a name="l00126"></a><span class="lineno">  126</span>&#160;</div><div class="line"><a name="l00127"></a><span class="lineno">  127</span>&#160;The merge job can then be run as:</div><div class="line"><a name="l00128"></a><span class="lineno">  128</span>&#160;</div><div class="line"><a name="l00129"></a><span class="lineno">  129</span>&#160;    &gt; $RULEXTRACT \</div><div class="line"><a name="l00130"></a><span class="lineno">  130</span>&#160;        uk.ac.cam.eng.extraction.hadoop.merge.MergeJob \</div><div class="line"><a name="l00131"></a><span class="lineno">  131</span>&#160;        -D mapred.reduce.tasks=4 \</div><div class="line"><a name="l00132"></a><span class="lineno">  132</span>&#160;        --input_features=RUEN-WMT13/s2t,RUEN-WMT13/t2s \</div><div class="line"><a name="l00133"></a><span class="lineno">  133</span>&#160;        --input_rules=RUEN-WMT13/rules \</div><div class="line"><a name="l00134"></a><span class="lineno">  134</span>&#160;        --output=RUEN-WMT13/merge \</div><div class="line"><a name="l00135"></a><span class="lineno">  135</span>&#160;        @configs/CF.rulextract.expanded  \</div><div class="line"><a name="l00136"></a><span class="lineno">  136</span>&#160;        &gt;&amp; logs/log.merge</div><div class="line"><a name="l00137"></a><span class="lineno">  137</span>&#160;</div><div class="line"><a name="l00138"></a><span class="lineno">  138</span>&#160;The one unusual option here is ` -D mapred.reduce.tasks=4`. This option instructs Hadoop to use only 4 reducers when creating the HFile. The output directory `RUEN-WMT13/merge` will then contain the data partitioned into 4 files.</div><div class="line"><a name="l00139"></a><span class="lineno">  139</span>&#160;</div><div class="line"><a name="l00140"></a><span class="lineno">  140</span>&#160;It is useful to be able to fine tune `mapred.reduce.task` because the retriever queries each file in a separate thread. For the fastest retrieval times, the number of reducers should be set to be the same as number of threads as used in the retriever. Note that querying the HFile with a different number of threads does not change the results of the query. The query will just be slower.</div><div class="line"><a name="l00141"></a><span class="lineno">  141</span>&#160;</div><div class="line"><a name="l00142"></a><span class="lineno">  142</span>&#160;The HFile is a binary format, which can be viewed with the HFile print tool:</div><div class="line"><a name="l00143"></a><span class="lineno">  143</span>&#160;</div><div class="line"><a name="l00144"></a><span class="lineno">  144</span>&#160;          &gt; $RULEXTRACT \</div><div class="line"><a name="l00145"></a><span class="lineno">  145</span>&#160;              uk.ac.cam.eng.extraction.hadoop.util.HFilePrint \</div><div class="line"><a name="l00146"></a><span class="lineno">  146</span>&#160;              RUEN-WMT13/merge/part-r-00000.hfile 2&gt;/dev/null \</div><div class="line"><a name="l00147"></a><span class="lineno">  147</span>&#160;             | head</div><div class="line"><a name="l00148"></a><span class="lineno">  148</span>&#160;</div><div class="line"><a name="l00149"></a><span class="lineno">  149</span>&#160;which yields</div><div class="line"><a name="l00150"></a><span class="lineno">  150</span>&#160;</div><div class="line"><a name="l00151"></a><span class="lineno">  151</span>&#160;    3 4     RuleData [provCounts={0=8272, 1=8272}, alignments={0-0 =8272}, features={SOURCE2TARGET_PROBABILITY={0=-0.08468153736026644}, TARGET2SOURCE_PROBABILITY={0=-0.03958331665033461}, PROVENANCE_SOURCE2TARGET_PROBABILITY={1=-0.08468153736026644}, PROVENANCE_TARGET2SOURCE_PROBABILITY={1=-0.03958331665033461}}]</div><div class="line"><a name="l00152"></a><span class="lineno">  152</span>&#160;    3 8     RuleData [provCounts={0=287, 1=287}, alignments={0-0 =287}, features={SOURCE2TARGET_PROBABILITY={0=-3.4458309183488556}, TARGET2SOURCE_PROBABILITY={0=-1.7490483511350052}, PROVENANCE_SOURCE2TARGET_PROBABILITY={1=-3.4458309183488556}, PROVENANCE_TARGET2SOURCE_PROBABILITY={1=-1.7490483511350052}}]</div><div class="line"><a name="l00153"></a><span class="lineno">  153</span>&#160;    7 7_3   RuleData [provCounts={0=18, 1=18}, alignments={0-0 =8, 0-0 0-1 =9, 0-1 =1}, features={SOURCE2TARGET_PROBABILITY={0=-3.6535400876686275}, TARGET2SOURCE_PROBABILITY={0=-1.7346010553881064}, PROVENANCE_SOURCE2TARGET_PROBABILITY={1=-3.6535400876686275}, PROVENANCE_TARGET2SOURCE_PROBABILITY={1=-1.7346010553881064}}]</div><div class="line"><a name="l00154"></a><span class="lineno">  154</span>&#160;    7 17_11 RuleData [provCounts={0=10, 1=10}, alignments={0-0 =10}, features={SOURCE2TARGET_PROBABILITY={0=-4.241326752570746}, TARGET2SOURCE_PROBABILITY={0=-0.262364264467491}, PROVENANCE_SOURCE2TARGET_PROBABILITY={1=-4.241326752570746}, PROVENANCE_TARGET2SOURCE_PROBABILITY={1=-0.262364264467491}}]</div><div class="line"><a name="l00155"></a><span class="lineno">  155</span>&#160;    7 6     RuleData [provCounts={0=14, 1=14}, alignments={0-0 =14}, features={SOURCE2TARGET_PROBABILITY={0=-3.9048545159495336}, TARGET2SOURCE_PROBABILITY={0=-3.5326432677956565}, PROVENANCE_SOURCE2TARGET_PROBABILITY={1=-3.9048545159495336}, PROVENANCE_TARGET2SOURCE_PROBABILITY={1=-3.5326432677956565}}]</div><div class="line"><a name="l00156"></a><span class="lineno">  156</span>&#160;    7 9_3   RuleData [provCounts={0=11, 1=11}, alignments={0-0 =2, 0-0 0-1 =7, 0-1 =2}, features={SOURCE2TARGET_PROBABILITY={0=-4.146016572766421}, TARGET2SOURCE_PROBABILITY={0=-5.082533033275838}, PROVENANCE_SOURCE2TARGET_PROBABILITY={1=-4.146016572766421}, PROVENANCE_TARGET2SOURCE_PROBABILITY={1=-5.082533033275838}}]</div><div class="line"><a name="l00157"></a><span class="lineno">  157</span>&#160;    7 17    RuleData [provCounts={0=195, 1=195}, alignments={0-0 =195}, features={SOURCE2TARGET_PROBABILITY={0=-1.2709122870010454}, TARGET2SOURCE_PROBABILITY={0=-0.535142931416697}, PROVENANCE_SOURCE2TARGET_PROBABILITY={1=-1.2709122870010454}, PROVENANCE_TARGET2SOURCE_PROBABILITY={1=-0.535142931416697}}]</div><div class="line"><a name="l00158"></a><span class="lineno">  158</span>&#160;    7 7     RuleData [provCounts={0=53, 1=53}, alignments={0-0 =53}, features={SOURCE2TARGET_PROBABILITY={0=-2.5736199320126705}, TARGET2SOURCE_PROBABILITY={0=-2.741448481504058}, PROVENANCE_SOURCE2TARGET_PROBABILITY={1=-2.5736199320126705}, PROVENANCE_TARGET2SOURCE_PROBABILITY={1=-2.741448481504058}}]</div><div class="line"><a name="l00159"></a><span class="lineno">  159</span>&#160;    7 9_11  RuleData [provCounts={0=10, 1=10}, alignments={0-0 =1, 0-0 0-1 =9}, features={SOURCE2TARGET_PROBABILITY={0=-4.241326752570746}, TARGET2SOURCE_PROBABILITY={0=-1.9459101490553135}, PROVENANCE_SOURCE2TARGET_PROBABILITY={1=-4.241326752570746}, PROVENANCE_TARGET2SOURCE_PROBABILITY={1=-1.9459101490553135}}]</div><div class="line"><a name="l00160"></a><span class="lineno">  160</span>&#160;    7 17_3  RuleData [provCounts={0=67, 1=67}, alignments={0-0 =67}, features={SOURCE2TARGET_PROBABILITY={0=-2.3392192261738263}, TARGET2SOURCE_PROBABILITY={0=-0.5993284253422904}, PROVENANCE_SOURCE2TARGET_PROBABILITY={1=-2.3392192261738263}, PROVENANCE_TARGET2SOURCE_PROBABILITY={1=-0.5993284253422904}}]</div><div class="line"><a name="l00161"></a><span class="lineno">  161</span>&#160;</div><div class="line"><a name="l00162"></a><span class="lineno">  162</span>&#160;In practise the HFile is queried by the retriever tool, but it can be useful for debugging to be see the raw output. Finally we need to copy the merge directory to local disk. Execute the following:</div><div class="line"><a name="l00163"></a><span class="lineno">  163</span>&#160;</div><div class="line"><a name="l00164"></a><span class="lineno">  164</span>&#160;    &gt; hdfs dfs -copyToLocal RUEN-WMT13/merge hfile</div><div class="line"><a name="l00165"></a><span class="lineno">  165</span>&#160;</div><div class="line"><a name="l00166"></a><span class="lineno">  166</span>&#160;The Hadoop cluster is no longer needed, and can be shut down.</div><div class="line"><a name="l00167"></a><span class="lineno">  167</span>&#160;</div><div class="line"><a name="l00168"></a><span class="lineno">  168</span>&#160;\subsection rulextract_tutorial_retrieval Retrieval</div><div class="line"><a name="l00169"></a><span class="lineno">  169</span>&#160;</div><div class="line"><a name="l00170"></a><span class="lineno">  170</span>&#160;The HFile produced by the extraction stage contains all the rules extracted from the entire training data. In the retrieval stage the HFile is queried to produce a subset of the rules that can be applied to a test set. The retrieval tool also computes many of the features, including the lexical features, used in the decoder&#39;s linear model.</div><div class="line"><a name="l00171"></a><span class="lineno">  171</span>&#160;</div><div class="line"><a name="l00172"></a><span class="lineno">  172</span>&#160;Lexical features require IBM Model 1 probabilities in the [GIZA](http://www.statmt.org/moses/giza/GIZA++.html) format. Lexical models are available as a separate download as they take a fair amount of disk space. To get these models run the following commands:</div><div class="line"><a name="l00173"></a><span class="lineno">  173</span>&#160;</div><div class="line"><a name="l00174"></a><span class="lineno">  174</span>&#160;      &gt; wget http://mi.eng.cam.ac.uk/~jmp84/share/giza_ibm_model1_filtered.tar.gz</div><div class="line"><a name="l00175"></a><span class="lineno">  175</span>&#160;      &gt; tar -xvf giza_ibm_model1_filtered.tar.gz</div><div class="line"><a name="l00176"></a><span class="lineno">  176</span>&#160;</div><div class="line"><a name="l00177"></a><span class="lineno">  177</span>&#160;These lexical models were filtered with the source vocabulary and target vocabulary of the test set for this tutorial to obtain a reasonable size for these models (the source vocabulary is easily obtained from the test set, the target vocabulary is obtained by taking target words from relevant translation rules for that test set).</div><div class="line"><a name="l00178"></a><span class="lineno">  178</span>&#160;If you wish, you can also download the [full models](http://mi.eng.cam.ac.uk/~jmp84/share/giza_ibm_model1_filtered.tar.gz)  but you will require a machine with about 30G RAM to load the data. </div><div class="line"><a name="l00179"></a><span class="lineno">  179</span>&#160;</div><div class="line"><a name="l00180"></a><span class="lineno">  180</span>&#160;The retrieval tool assumes that the lexical models are stored in a directory structure that can be split by provenance and direction. This structure is reflected in the configuration option `--ttable_server_template=giza_ibm_model1_filtered/genres/$GENRE/align/$DIRECTION/$DIRECTION.mode1.final.gz`. The variables `$GENRE` and `$DIRECTION` are used internally by the retriever to formulate the correct path to a model. For example, to get the source-to-target direction for the cc provenance the retriever sets `GENRE=cc` and `DIRECTION=en2ru` to locate:</div><div class="line"><a name="l00181"></a><span class="lineno">  181</span>&#160;</div><div class="line"><a name="l00182"></a><span class="lineno">  182</span>&#160;    giza_ibm_model1_filtered/genres/cc/align/en2ru/en2ru.mode1.final.gz</div><div class="line"><a name="l00183"></a><span class="lineno">  183</span>&#160;</div><div class="line"><a name="l00184"></a><span class="lineno">  184</span>&#160;Here is a quick summary of what the retriever does:</div><div class="line"><a name="l00185"></a><span class="lineno">  185</span>&#160;</div><div class="line"><a name="l00186"></a><span class="lineno">  186</span>&#160;+ Generate all the possible source sides of a rule that can be found in a source sentence.</div><div class="line"><a name="l00187"></a><span class="lineno">  187</span>&#160;+ Partition the sets of source sides into queries for each file contained in the HFile directory.</div><div class="line"><a name="l00188"></a><span class="lineno">  188</span>&#160;+ Sort the queries.</div><div class="line"><a name="l00189"></a><span class="lineno">  189</span>&#160;+ Execute the queries and return rule counts, probabilities, and alignments for each rule found in the HFile.</div><div class="line"><a name="l00190"></a><span class="lineno">  190</span>&#160;+ Filter the rules for a second time.</div><div class="line"><a name="l00191"></a><span class="lineno">  191</span>&#160;+ Compute additional features, such as the lexical features.</div><div class="line"><a name="l00192"></a><span class="lineno">  192</span>&#160;+ Generate OOV, deletion rules, and pass-through rules based on the query results.</div><div class="line"><a name="l00193"></a><span class="lineno">  193</span>&#160;+ Write the results as shallow grammar.</div><div class="line"><a name="l00194"></a><span class="lineno">  194</span>&#160;</div><div class="line"><a name="l00195"></a><span class="lineno">  195</span>&#160;Let us now run the retriever. Because retrieval also performs filtering, we need to use the `CF.rulextract.expanded` configuration from the previous section. Run the following Scala script:</div><div class="line"><a name="l00196"></a><span class="lineno">  196</span>&#160;</div><div class="line"><a name="l00197"></a><span class="lineno">  197</span>&#160;    &gt; $HiFSTROOT/java/ruleXtract/scripts/retrieve.scala \</div><div class="line"><a name="l00198"></a><span class="lineno">  198</span>&#160;        --s2t_language_pair en2ru --t2s_language_pair ru2en \</div><div class="line"><a name="l00199"></a><span class="lineno">  199</span>&#160;        --test_file=RU/RU.tune.idx \</div><div class="line"><a name="l00200"></a><span class="lineno">  200</span>&#160;        --rules=G/rules.RU.tune.idx.gz \</div><div class="line"><a name="l00201"></a><span class="lineno">  201</span>&#160;        --vocab=RU.tune.idx.vocab \</div><div class="line"><a name="l00202"></a><span class="lineno">  202</span>&#160;        @configs/CF.rulextract.expanded \</div><div class="line"><a name="l00203"></a><span class="lineno">  203</span>&#160;        &gt;&amp; logs/log.retrieval</div><div class="line"><a name="l00204"></a><span class="lineno">  204</span>&#160;</div><div class="line"><a name="l00205"></a><span class="lineno">  205</span>&#160;The `s2t_language_pair` and `t2s_language_pair` options are used to set the `$DIRECTION` variable when locating lexical models. The `--test_file` option is the input file to translate and the output is stored in `--rules`. The output is stored as a gzipped shallow grammar, and can be used as input to HiFST:</div><div class="line"><a name="l00206"></a><span class="lineno">  206</span>&#160;</div><div class="line"><a name="l00207"></a><span class="lineno">  207</span>&#160;    &gt; /home/blue7/aaw35/tools/demo-files$ zcat G/rules.RU.tune.idx.gz | head</div><div class="line"><a name="l00208"></a><span class="lineno">  208</span>&#160;       V 542 2143 2.036882 0.980829 -1 -1 0 0 0 0 -1 0.841104 0.500422 2.036882 4.700000 4.700000 4.700000 0.980829 7 7 7 0.873349 0.652270 0.811145 40.001968 0.518248 0.367899 0.452543 40.001968</div><div class="line"><a name="l00209"></a><span class="lineno">  209</span>&#160;       V 435 7_3 2.197225 4.624973 -2 -1 0 0 -1 0 0 5.103256 5.981430 2.197225 4.700000 4.700000 4.700000 4.624973 7 7 7 7.014742 7.818437 5.184339 40.695116 6.225953 6.485531 6.219496 41.864230</div><div class="line"><a name="l00210"></a><span class="lineno">  210</span>&#160;       V 109 106 1.312186 1.189584 -1 -1 0 0 0 0 -1 1.206707 1.617768 1.312186 4.700000 4.700000 4.700000 1.189584 7 7 7 1.722831 1.505299 0.770817 40.001968 2.897182 0.356538 0.494034 40.001968</div><div class="line"><a name="l00211"></a><span class="lineno">  211</span>&#160;       V 298 12 2.302585 5.918894 -1 -1 0 0 -1 0 0 5.881671 8.218089 2.302585 4.700000 4.700000 4.700000 5.918894 7 7 7 6.500572 10.274702 7.688218 40.001968 7.903815 8.429022 8.320468 40.001968</div><div class="line"><a name="l00212"></a><span class="lineno">  212</span>&#160;       V 99 17_426 3.433987 0.693147 -2 -1 0 0 -1 0 0 1.033376 4.712400 3.433987 4.700000 4.700000 4.700000 0.693147 7 7 7 0.988207 0.782317 1.029978 1.290824 4.763535 5.242606 4.932181 45.396855</div><div class="line"><a name="l00213"></a><span class="lineno">  213</span>&#160;       V 79 40_83_13_27_180_19 3.433987 0.693147 -6 -1 0 0 -1 0 0 3.828080 24.055434 3.433987 4.700000 4.700000 4.700000 0.693147 7 7 7 3.752430 3.816584 3.814278 41.793728 26.486789 30.225935 26.563699 244.170694</div><div class="line"><a name="l00214"></a><span class="lineno">  214</span>&#160;       V 931 821_11 2.995732 1.945910 -2 -1 0 0 -1 0 0 1.060779 5.414462 2.995732 4.700000 4.700000 4.700000 1.945910 7 7 7 1.034481 0.940884 1.005978 40.695116 5.487767 5.069144 5.481220 48.615538</div><div class="line"><a name="l00215"></a><span class="lineno">  215</span>&#160;       V 454 21_499 3.401197 2.079442 -2 -1 0 0 -1 0 0 7.166555 10.007927 3.401197 4.700000 4.700000 4.700000 2.079442 7 7 7 6.709149 40.695116 9.531266 40.695116 10.229790 44.330405 12.247832 81.390231</div><div class="line"><a name="l00216"></a><span class="lineno">  216</span>&#160;       V 79 13_27_180 3.433987 0.693147 -3 -1 0 0 -1 0 0 3.172935 10.576585 3.433987 4.700000 4.700000 4.700000 0.693147 7 7 7 3.095097 3.152567 3.148776 41.100581 11.037732 14.379323 11.622925 122.085347</div><div class="line"><a name="l00217"></a><span class="lineno">  217</span>&#160;       V 735 7_603 2.772589 0 -2 -1 0 0 -1 0 0 1.801323 4.825997 2.772589 4.700000 4.700000 4.700000 0 7 7 7 1.909558 1.684512 1.756053 1.390172 5.103973 4.726153 4.772959 41.388263</div><div class="line"><a name="l00218"></a><span class="lineno">  218</span>&#160;</div><div class="line"><a name="l00219"></a><span class="lineno">  219</span>&#160;If the optional `--vocab` value is set then the retriever will write out the target side vocabulary for each sentence on separate lines. [KenLM](https://kheafield.com/code/kenlm/) can use files in this format to filter large language models. </div><div class="line"><a name="l00220"></a><span class="lineno">  220</span>&#160;</div><div class="line"><a name="l00221"></a><span class="lineno">  221</span>&#160;\subsection rulextract_pipeline_lexserve Lexical Servers</div><div class="line"><a name="l00222"></a><span class="lineno">  222</span>&#160;</div><div class="line"><a name="l00223"></a><span class="lineno">  223</span>&#160;As we have seen in the previous section, the lexical models can be very large. So large that they do not fit in memory of a single machine.  To deal with this problem the retriever uses a client-server model. The lexical models are stored in two servers, one for each direction, and the retriever requests probabilities from the servers as rules are read from the HFile. The Scala script in the previous section starts the two servers, waits for them to load the lexical models, and then starts the retriever.</div><div class="line"><a name="l00224"></a><span class="lineno">  224</span>&#160;</div><div class="line"><a name="l00225"></a><span class="lineno">  225</span>&#160;Starting the lexical servers separately is only necessary if the lexical models are very large. In most cases the Scala script is the recommended approach. For the sole purpose of demonstrating the lexical servers in action, we now quickly retrieve the rules for individual sentences. Although the retriever was designed for batch processing, we can still achieve respectable query speeds that are close to real time by preloading the lexical models. First we need to start the servers:</div><div class="line"><a name="l00226"></a><span class="lineno">  226</span>&#160;</div><div class="line"><a name="l00227"></a><span class="lineno">  227</span>&#160;    &gt; java -Xmx5G -server \</div><div class="line"><a name="l00228"></a><span class="lineno">  228</span>&#160;       -classpath $RULEXTRACTJAR \</div><div class="line"><a name="l00229"></a><span class="lineno">  229</span>&#160;       uk.ac.cam.eng.extraction.hadoop.features.lexical.TTableServer \</div><div class="line"><a name="l00230"></a><span class="lineno">  230</span>&#160;      @configs/CF.rulextract \</div><div class="line"><a name="l00231"></a><span class="lineno">  231</span>&#160;       --ttable_direction=s2t \</div><div class="line"><a name="l00232"></a><span class="lineno">  232</span>&#160;      --ttable_language_pair=en2ru \</div><div class="line"><a name="l00233"></a><span class="lineno">  233</span>&#160;      &gt;&amp; logs/log.s2t_server</div><div class="line"><a name="l00234"></a><span class="lineno">  234</span>&#160;</div><div class="line"><a name="l00235"></a><span class="lineno">  235</span>&#160;and</div><div class="line"><a name="l00236"></a><span class="lineno">  236</span>&#160;</div><div class="line"><a name="l00237"></a><span class="lineno">  237</span>&#160;    &gt; java -Xmx5G -server \</div><div class="line"><a name="l00238"></a><span class="lineno">  238</span>&#160;       -classpath $RULEXTRACTJAR \</div><div class="line"><a name="l00239"></a><span class="lineno">  239</span>&#160;       uk.ac.cam.eng.extraction.hadoop.features.lexical.TTableServer \</div><div class="line"><a name="l00240"></a><span class="lineno">  240</span>&#160;      @configs/CF.rulextract \</div><div class="line"><a name="l00241"></a><span class="lineno">  241</span>&#160;       --ttable_direction=t2s \</div><div class="line"><a name="l00242"></a><span class="lineno">  242</span>&#160;      --ttable_language_pair=ru2en \</div><div class="line"><a name="l00243"></a><span class="lineno">  243</span>&#160;      &gt;&amp; logs/log.t2s_server</div><div class="line"><a name="l00244"></a><span class="lineno">  244</span>&#160;</div><div class="line"><a name="l00245"></a><span class="lineno">  245</span>&#160;Inspect the logs and wait until the lexical servers report they are ready. Once the models are loaded this message will appear in the logs:</div><div class="line"><a name="l00246"></a><span class="lineno">  246</span>&#160;</div><div class="line"><a name="l00247"></a><span class="lineno">  247</span>&#160;    TTable server ready on port: ...</div><div class="line"><a name="l00248"></a><span class="lineno">  248</span>&#160;</div><div class="line"><a name="l00249"></a><span class="lineno">  249</span>&#160;Let us now create an input file of a single sentence. For this example let us use sentence 2 because it is a long sentence.</div><div class="line"><a name="l00250"></a><span class="lineno">  250</span>&#160;</div><div class="line"><a name="l00251"></a><span class="lineno">  251</span>&#160;    &gt; head -n2 RU/RU.tune.idx | tail -n1 &gt; 2.idx</div><div class="line"><a name="l00252"></a><span class="lineno">  252</span>&#160;</div><div class="line"><a name="l00253"></a><span class="lineno">  253</span>&#160;Now we run the retriever for this single sentence, using the time command to see how long it takes:</div><div class="line"><a name="l00254"></a><span class="lineno">  254</span>&#160;</div><div class="line"><a name="l00255"></a><span class="lineno">  255</span>&#160;    &gt; time java \</div><div class="line"><a name="l00256"></a><span class="lineno">  256</span>&#160;       -classpath $RULEXTRACTJAR \</div><div class="line"><a name="l00257"></a><span class="lineno">  257</span>&#160;       uk.ac.cam.eng.rule.retrieval.RuleRetriever \</div><div class="line"><a name="l00258"></a><span class="lineno">  258</span>&#160;        --test_file=2.idx \</div><div class="line"><a name="l00259"></a><span class="lineno">  259</span>&#160;        --rules=2.shallow.gz \</div><div class="line"><a name="l00260"></a><span class="lineno">  260</span>&#160;        --vocab=2.vocab \</div><div class="line"><a name="l00261"></a><span class="lineno">  261</span>&#160;        @configs/CF.rulextract.expanded \</div><div class="line"><a name="l00262"></a><span class="lineno">  262</span>&#160;        &gt;&amp; logs/log.2_retrieval</div><div class="line"><a name="l00263"></a><span class="lineno">  263</span>&#160;</div><div class="line"><a name="l00264"></a><span class="lineno">  264</span>&#160;and we can see the output that the grammar was generated in around 1.5 seconds:</div><div class="line"><a name="l00265"></a><span class="lineno">  265</span>&#160;</div><div class="line"><a name="l00266"></a><span class="lineno">  266</span>&#160;    real    0m1.644s</div><div class="line"><a name="l00267"></a><span class="lineno">  267</span>&#160;    user    0m6.816s</div><div class="line"><a name="l00268"></a><span class="lineno">  268</span>&#160;    sys     0m0.324s</div><div class="line"><a name="l00269"></a><span class="lineno">  269</span>&#160;</div><div class="line"><a name="l00270"></a><span class="lineno">  270</span>&#160;A respectable result considering that the pipeline is designed for batch processing.</div><div class="line"><a name="l00271"></a><span class="lineno">  271</span>&#160;</div><div class="line"><a name="l00272"></a><span class="lineno">  272</span>&#160;\section rulextract_filtering Filtering</div><div class="line"><a name="l00273"></a><span class="lineno">  273</span>&#160;</div><div class="line"><a name="l00274"></a><span class="lineno">  274</span>&#160;Most grammars will yield rules that are seen very infrequently in the training data. These rules cause the decoder search space to expand with very little benefit. To speed up decoding the low frequency rules are filtered out when generating grammars.</div><div class="line"><a name="l00275"></a><span class="lineno">  275</span>&#160;</div><div class="line"><a name="l00276"></a><span class="lineno">  276</span>&#160;The rule extraction pipeline allows for fine-grained control of how rules are filtered. Filtering is performed twice, once during extraction, and once during retrieval. The reason for performing filtering twice is to enable experiments that determine the correct level of filtering. A more generous threshold can be applied at extraction, and then tightened at retrieval time.</div><div class="line"><a name="l00277"></a><span class="lineno">  277</span>&#160;</div><div class="line"><a name="l00278"></a><span class="lineno">  278</span>&#160;Filtering is controlled by command line options, and two files:</div><div class="line"><a name="l00279"></a><span class="lineno">  279</span>&#160;</div><div class="line"><a name="l00280"></a><span class="lineno">  280</span>&#160;+ A list of allowed rule patterns (`--allowed_patterns`).</div><div class="line"><a name="l00281"></a><span class="lineno">  281</span>&#160;+ A list of allowed source side patterns, with extra filtering criteria (`--source_patterns`).</div><div class="line"><a name="l00282"></a><span class="lineno">  282</span>&#160;</div><div class="line"><a name="l00283"></a><span class="lineno">  283</span>&#160;The allowed rule patterns take the following form:</div><div class="line"><a name="l00284"></a><span class="lineno">  284</span>&#160;</div><div class="line"><a name="l00285"></a><span class="lineno">  285</span>&#160;    V1_W_V-W_V_W_V1</div><div class="line"><a name="l00286"></a><span class="lineno">  286</span>&#160;</div><div class="line"><a name="l00287"></a><span class="lineno">  287</span>&#160;The `W` symbol denotes any terminal symbol, and the `V` and `V1` symbols denote non-terminals. Any rules that do not fit these patterns are filtered from the final grammar.</div><div class="line"><a name="l00288"></a><span class="lineno">  288</span>&#160;</div><div class="line"><a name="l00289"></a><span class="lineno">  289</span>&#160;Lines in the source patterns file have the following format:</div><div class="line"><a name="l00290"></a><span class="lineno">  290</span>&#160;</div><div class="line"><a name="l00291"></a><span class="lineno">  291</span>&#160;    V_W_V1 2 10</div><div class="line"><a name="l00292"></a><span class="lineno">  292</span>&#160;</div><div class="line"><a name="l00293"></a><span class="lineno">  293</span>&#160;+ The first field is an acceptable source side pattern, and the symbols have the same meaning as the allowed rules patterns.</div><div class="line"><a name="l00294"></a><span class="lineno">  294</span>&#160;+ The second field is the minimum number of times a rule with this source pattern must occur to be accepted into the final grammar.</div><div class="line"><a name="l00295"></a><span class="lineno">  295</span>&#160;+ The third field is the maximum number of rules that share the same source side that can be in the final grammar. If more than the maximum number of rules are found, then only the rules with the highest frequency are chosen.</div><div class="line"><a name="l00296"></a><span class="lineno">  296</span>&#160;</div><div class="line"><a name="l00297"></a><span class="lineno">  297</span>&#160;We cover the rest of the filtering command line options in the next section.</div><div class="line"><a name="l00298"></a><span class="lineno">  298</span>&#160;</div><div class="line"><a name="l00299"></a><span class="lineno">  299</span>&#160;</div><div class="line"><a name="l00300"></a><span class="lineno">  300</span>&#160;\section rulextract_configuration_overview Configuration </div><div class="line"><a name="l00301"></a><span class="lineno">  301</span>&#160;</div><div class="line"><a name="l00302"></a><span class="lineno">  302</span>&#160;In the following table we list all possible command line options used in rule extraction. All options can be used either on the command line or specified in a configuration file. Configuration files are specified on the command line with the `@` symbol. Some tools share options and many tools specify `--input` and `--output` options, which we omit from the table. The tools also print help messages with a description of the required options.</div><div class="line"><a name="l00303"></a><span class="lineno">  303</span>&#160;</div><div class="line"><a name="l00304"></a><span class="lineno">  304</span>&#160;The Source2TargetJob and Target2SourceJob tools only require `--input` and `--output` options and have been omitted from this table.</div><div class="line"><a name="l00305"></a><span class="lineno">  305</span>&#160;</div><div class="line"><a name="l00306"></a><span class="lineno">  306</span>&#160;Note that the Scala script used for retrieval starts both lexical servers and then the retriever. Its command line options are a union of the lexical server and retriever options listed here.</div><div class="line"><a name="l00307"></a><span class="lineno">  307</span>&#160;</div><div class="line"><a name="l00308"></a><span class="lineno">  308</span>&#160;&lt;table&gt;</div><div class="line"><a name="l00309"></a><span class="lineno">  309</span>&#160;   &lt;tr&gt; &lt;th&gt;Option&lt;/th&gt; &lt;th&gt;Description&lt;/th&gt; &lt;th&gt;ExtractorJob&lt;/th&gt; &lt;th&gt;MergeJob&lt;/th&gt;&lt;th&gt;Lexical Server&lt;/th&gt;&lt;th&gt;Retrieval&lt;/th&gt;    &lt;/tr&gt;</div><div class="line"><a name="l00310"></a><span class="lineno">  310</span>&#160;   &lt;tr&gt;</div><div class="line"><a name="l00311"></a><span class="lineno">  311</span>&#160;           &lt;td&gt;remove_monotonic_repeats&lt;/td&gt;</div><div class="line"><a name="l00312"></a><span class="lineno">  312</span>&#160;           &lt;td&gt;Clips counts. For example, given a monotonically aligned phrase pair &lt;a b c, d e f&gt;, the hiero rule &lt;a X, d X&gt; can be extracted from &lt;a b, d e&gt; and from &lt;a b c, d e f&gt;, but the occurrence count is clipped to 1.&lt;/td&gt;</div><div class="line"><a name="l00313"></a><span class="lineno">  313</span>&#160;           &lt;td &gt; ✔ &lt;/td&gt;</div><div class="line"><a name="l00314"></a><span class="lineno">  314</span>&#160;           &lt;td&gt;  &lt;/td&gt;</div><div class="line"><a name="l00315"></a><span class="lineno">  315</span>&#160;           &lt;td&gt;  &lt;/td&gt;</div><div class="line"><a name="l00316"></a><span class="lineno">  316</span>&#160;           &lt;td&gt;  &lt;/td&gt;</div><div class="line"><a name="l00317"></a><span class="lineno">  317</span>&#160;   &lt;/tr&gt;</div><div class="line"><a name="l00318"></a><span class="lineno">  318</span>&#160;   &lt;tr&gt;</div><div class="line"><a name="l00319"></a><span class="lineno">  319</span>&#160;           &lt;td&gt;max_source_phrase&lt;/td&gt;</div><div class="line"><a name="l00320"></a><span class="lineno">  320</span>&#160;           &lt;td&gt;The maximum source phrase length for a phrase-based rule.&lt;/td&gt;</div><div class="line"><a name="l00321"></a><span class="lineno">  321</span>&#160;           &lt;td &gt; ✔ &lt;/td&gt;</div><div class="line"><a name="l00322"></a><span class="lineno">  322</span>&#160;           &lt;td&gt;  &lt;/td&gt;</div><div class="line"><a name="l00323"></a><span class="lineno">  323</span>&#160;           &lt;td&gt;  &lt;/td&gt;</div><div class="line"><a name="l00324"></a><span class="lineno">  324</span>&#160;           &lt;td&gt; ✔ &lt;/td&gt;</div><div class="line"><a name="l00325"></a><span class="lineno">  325</span>&#160;   &lt;/tr&gt;</div><div class="line"><a name="l00326"></a><span class="lineno">  326</span>&#160;   &lt;tr&gt;</div><div class="line"><a name="l00327"></a><span class="lineno">  327</span>&#160;           &lt;td&gt;max_source_elements&lt;/td&gt;</div><div class="line"><a name="l00328"></a><span class="lineno">  328</span>&#160;           &lt;td&gt; The maximum number of source elements (terminal or nonterminal)&lt;/td&gt;</div><div class="line"><a name="l00329"></a><span class="lineno">  329</span>&#160;           &lt;td &gt; ✔ &lt;/td&gt;</div><div class="line"><a name="l00330"></a><span class="lineno">  330</span>&#160;           &lt;td&gt;  &lt;/td&gt;</div><div class="line"><a name="l00331"></a><span class="lineno">  331</span>&#160;           &lt;td&gt;  &lt;/td&gt;</div><div class="line"><a name="l00332"></a><span class="lineno">  332</span>&#160;           &lt;td&gt; ✔ &lt;/td&gt;</div><div class="line"><a name="l00333"></a><span class="lineno">  333</span>&#160;   &lt;/tr&gt;</div><div class="line"><a name="l00334"></a><span class="lineno">  334</span>&#160;   &lt;tr&gt;</div><div class="line"><a name="l00335"></a><span class="lineno">  335</span>&#160;           &lt;td&gt;max_terminal_length&lt;/td&gt;</div><div class="line"><a name="l00336"></a><span class="lineno">  336</span>&#160;           &lt;td&gt; The maximum number of consecutive source terminals for a hiero rule.&lt;/td&gt;</div><div class="line"><a name="l00337"></a><span class="lineno">  337</span>&#160;           &lt;td &gt; ✔ &lt;/td&gt;</div><div class="line"><a name="l00338"></a><span class="lineno">  338</span>&#160;           &lt;td&gt;  &lt;/td&gt;</div><div class="line"><a name="l00339"></a><span class="lineno">  339</span>&#160;           &lt;td&gt;  &lt;/td&gt;</div><div class="line"><a name="l00340"></a><span class="lineno">  340</span>&#160;           &lt;td&gt; ✔ &lt;/td&gt;</div><div class="line"><a name="l00341"></a><span class="lineno">  341</span>&#160;   &lt;/tr&gt;</div><div class="line"><a name="l00342"></a><span class="lineno">  342</span>&#160;   &lt;tr&gt;</div><div class="line"><a name="l00343"></a><span class="lineno">  343</span>&#160;           &lt;td&gt;max_nonterminal_span&lt;/td&gt;</div><div class="line"><a name="l00344"></a><span class="lineno">  344</span>&#160;           &lt;td&gt; The maximum number of terminals covered by a source nonterminal.&lt;/td&gt;</div><div class="line"><a name="l00345"></a><span class="lineno">  345</span>&#160;           &lt;td &gt; ✔ &lt;/td&gt;</div><div class="line"><a name="l00346"></a><span class="lineno">  346</span>&#160;           &lt;td&gt;  &lt;/td&gt;</div><div class="line"><a name="l00347"></a><span class="lineno">  347</span>&#160;           &lt;td&gt;  &lt;/td&gt;</div><div class="line"><a name="l00348"></a><span class="lineno">  348</span>&#160;           &lt;td&gt; ✔ &lt;/td&gt;</div><div class="line"><a name="l00349"></a><span class="lineno">  349</span>&#160;   &lt;/tr&gt;</div><div class="line"><a name="l00350"></a><span class="lineno">  350</span>&#160;   &lt;tr&gt;</div><div class="line"><a name="l00351"></a><span class="lineno">  351</span>&#160;           &lt;td&gt;provenance&lt;/td&gt;</div><div class="line"><a name="l00352"></a><span class="lineno">  352</span>&#160;           &lt;td&gt; Comma-separated list of provenances.&lt;/td&gt;</div><div class="line"><a name="l00353"></a><span class="lineno">  353</span>&#160;           &lt;td &gt; ✔ &lt;/td&gt;</div><div class="line"><a name="l00354"></a><span class="lineno">  354</span>&#160;           &lt;td&gt;  &lt;/td&gt;</div><div class="line"><a name="l00355"></a><span class="lineno">  355</span>&#160;           &lt;td&gt; ✔&lt;/td&gt;</div><div class="line"><a name="l00356"></a><span class="lineno">  356</span>&#160;           &lt;td&gt; ✔ &lt;/td&gt;</div><div class="line"><a name="l00357"></a><span class="lineno">  357</span>&#160;   &lt;/tr&gt;</div><div class="line"><a name="l00358"></a><span class="lineno">  358</span>&#160;   &lt;tr&gt;</div><div class="line"><a name="l00359"></a><span class="lineno">  359</span>&#160;           &lt;td&gt;allowed_patterns&lt;/td&gt;</div><div class="line"><a name="l00360"></a><span class="lineno">  360</span>&#160;           &lt;td&gt; The location of the allowed patterns file. It must be specified as a URI.&lt;/td&gt;</div><div class="line"><a name="l00361"></a><span class="lineno">  361</span>&#160;           &lt;td &gt; &lt;/td&gt;</div><div class="line"><a name="l00362"></a><span class="lineno">  362</span>&#160;           &lt;td&gt; ✔  &lt;/td&gt;</div><div class="line"><a name="l00363"></a><span class="lineno">  363</span>&#160;           &lt;td&gt;  &lt;/td&gt;</div><div class="line"><a name="l00364"></a><span class="lineno">  364</span>&#160;           &lt;td&gt; ✔ &lt;/td&gt;</div><div class="line"><a name="l00365"></a><span class="lineno">  365</span>&#160;   &lt;/tr&gt;</div><div class="line"><a name="l00366"></a><span class="lineno">  366</span>&#160;   &lt;tr&gt;</div><div class="line"><a name="l00367"></a><span class="lineno">  367</span>&#160;           &lt;td&gt;source_patterns&lt;/td&gt;</div><div class="line"><a name="l00368"></a><span class="lineno">  368</span>&#160;           &lt;td&gt; The location of the source patterns file. It must be specified as a URI.&lt;/td&gt;</div><div class="line"><a name="l00369"></a><span class="lineno">  369</span>&#160;           &lt;td &gt; &lt;/td&gt;</div><div class="line"><a name="l00370"></a><span class="lineno">  370</span>&#160;           &lt;td&gt; ✔  &lt;/td&gt;</div><div class="line"><a name="l00371"></a><span class="lineno">  371</span>&#160;           &lt;td&gt;  &lt;/td&gt;</div><div class="line"><a name="l00372"></a><span class="lineno">  372</span>&#160;           &lt;td&gt; ✔ &lt;/td&gt;</div><div class="line"><a name="l00373"></a><span class="lineno">  373</span>&#160;   &lt;/tr&gt;</div><div class="line"><a name="l00374"></a><span class="lineno">  374</span>&#160;   &lt;tr&gt;</div><div class="line"><a name="l00375"></a><span class="lineno">  375</span>&#160;           &lt;td&gt;min_source2target_phrase&lt;/td&gt;</div><div class="line"><a name="l00376"></a><span class="lineno">  376</span>&#160;           &lt;td&gt; Minimum source-to-target probability for filtering phrase-based rules.&lt;/td&gt;</div><div class="line"><a name="l00377"></a><span class="lineno">  377</span>&#160;           &lt;td &gt; &lt;/td&gt;</div><div class="line"><a name="l00378"></a><span class="lineno">  378</span>&#160;           &lt;td&gt; ✔  &lt;/td&gt;</div><div class="line"><a name="l00379"></a><span class="lineno">  379</span>&#160;           &lt;td&gt;  &lt;/td&gt;</div><div class="line"><a name="l00380"></a><span class="lineno">  380</span>&#160;           &lt;td&gt; ✔ &lt;/td&gt;</div><div class="line"><a name="l00381"></a><span class="lineno">  381</span>&#160;   &lt;/tr&gt;</div><div class="line"><a name="l00382"></a><span class="lineno">  382</span>&#160;   &lt;tr&gt;</div><div class="line"><a name="l00383"></a><span class="lineno">  383</span>&#160;           &lt;td&gt;min_target2source_phrase&lt;/td&gt;</div><div class="line"><a name="l00384"></a><span class="lineno">  384</span>&#160;           &lt;td&gt; Minimum target-to-source probability for filtering phrase-based rules.&lt;/td&gt;</div><div class="line"><a name="l00385"></a><span class="lineno">  385</span>&#160;           &lt;td &gt; &lt;/td&gt;</div><div class="line"><a name="l00386"></a><span class="lineno">  386</span>&#160;           &lt;td&gt; ✔  &lt;/td&gt;</div><div class="line"><a name="l00387"></a><span class="lineno">  387</span>&#160;           &lt;td&gt;  &lt;/td&gt;</div><div class="line"><a name="l00388"></a><span class="lineno">  388</span>&#160;           &lt;td&gt; ✔ &lt;/td&gt;</div><div class="line"><a name="l00389"></a><span class="lineno">  389</span>&#160;   &lt;/tr&gt;</div><div class="line"><a name="l00390"></a><span class="lineno">  390</span>&#160;   &lt;tr&gt;</div><div class="line"><a name="l00391"></a><span class="lineno">  391</span>&#160;           &lt;td&gt;min_source2target_rule&lt;/td&gt;</div><div class="line"><a name="l00392"></a><span class="lineno">  392</span>&#160;           &lt;td&gt; Minimum source-to-target probability for filtering hierarchical rules.&lt;/td&gt;</div><div class="line"><a name="l00393"></a><span class="lineno">  393</span>&#160;           &lt;td &gt; &lt;/td&gt;</div><div class="line"><a name="l00394"></a><span class="lineno">  394</span>&#160;           &lt;td&gt; ✔  &lt;/td&gt;</div><div class="line"><a name="l00395"></a><span class="lineno">  395</span>&#160;           &lt;td&gt;  &lt;/td&gt;</div><div class="line"><a name="l00396"></a><span class="lineno">  396</span>&#160;           &lt;td&gt; ✔ &lt;/td&gt;</div><div class="line"><a name="l00397"></a><span class="lineno">  397</span>&#160;   &lt;/tr&gt;</div><div class="line"><a name="l00398"></a><span class="lineno">  398</span>&#160;   &lt;tr&gt;</div><div class="line"><a name="l00399"></a><span class="lineno">  399</span>&#160;           &lt;td&gt;min_target2source_rule&lt;/td&gt;</div><div class="line"><a name="l00400"></a><span class="lineno">  400</span>&#160;           &lt;td&gt; Minimum target-to-source probability for filtering hierarchical rules.&lt;/td&gt;</div><div class="line"><a name="l00401"></a><span class="lineno">  401</span>&#160;           &lt;td &gt; &lt;/td&gt;</div><div class="line"><a name="l00402"></a><span class="lineno">  402</span>&#160;           &lt;td&gt; ✔  &lt;/td&gt;</div><div class="line"><a name="l00403"></a><span class="lineno">  403</span>&#160;           &lt;td&gt;  &lt;/td&gt;</div><div class="line"><a name="l00404"></a><span class="lineno">  404</span>&#160;           &lt;td&gt; ✔ &lt;/td&gt;</div><div class="line"><a name="l00405"></a><span class="lineno">  405</span>&#160;   &lt;/tr&gt;</div><div class="line"><a name="l00406"></a><span class="lineno">  406</span>&#160;   &lt;tr&gt;</div><div class="line"><a name="l00407"></a><span class="lineno">  407</span>&#160;           &lt;td&gt;provenance_union&lt;/td&gt;</div><div class="line"><a name="l00408"></a><span class="lineno">  408</span>&#160;           &lt;td&gt; Some rules may have a low global probability that falls below the filtering threshold, but high enough in a particular provenance to pass the threshold. The provenance union option allows these rules to pass through into the final grammar.&lt;/td&gt;</div><div class="line"><a name="l00409"></a><span class="lineno">  409</span>&#160;           &lt;td &gt; &lt;/td&gt;</div><div class="line"><a name="l00410"></a><span class="lineno">  410</span>&#160;           &lt;td&gt; ✔  &lt;/td&gt;</div><div class="line"><a name="l00411"></a><span class="lineno">  411</span>&#160;           &lt;td&gt;  &lt;/td&gt;</div><div class="line"><a name="l00412"></a><span class="lineno">  412</span>&#160;           &lt;td&gt; ✔ &lt;/td&gt;</div><div class="line"><a name="l00413"></a><span class="lineno">  413</span>&#160;   &lt;/tr&gt;</div><div class="line"><a name="l00414"></a><span class="lineno">  414</span>&#160;   &lt;tr&gt;</div><div class="line"><a name="l00415"></a><span class="lineno">  415</span>&#160;           &lt;td&gt;input_features&lt;/td&gt;</div><div class="line"><a name="l00416"></a><span class="lineno">  416</span>&#160;           &lt;td&gt; A comma separated list of the output of the Source2TargetJob and Target2SourceJob.&lt;/td&gt;</div><div class="line"><a name="l00417"></a><span class="lineno">  417</span>&#160;           &lt;td &gt; &lt;/td&gt;</div><div class="line"><a name="l00418"></a><span class="lineno">  418</span>&#160;           &lt;td&gt; ✔  &lt;/td&gt;</div><div class="line"><a name="l00419"></a><span class="lineno">  419</span>&#160;           &lt;td&gt;  &lt;/td&gt;</div><div class="line"><a name="l00420"></a><span class="lineno">  420</span>&#160;           &lt;td&gt;  &lt;/td&gt;</div><div class="line"><a name="l00421"></a><span class="lineno">  421</span>&#160;   &lt;/tr&gt;</div><div class="line"><a name="l00422"></a><span class="lineno">  422</span>&#160;   &lt;tr&gt;</div><div class="line"><a name="l00423"></a><span class="lineno">  423</span>&#160;           &lt;td&gt;input_rules&lt;/td&gt;</div><div class="line"><a name="l00424"></a><span class="lineno">  424</span>&#160;           &lt;td&gt; The output of the extractor job.&lt;/td&gt;</div><div class="line"><a name="l00425"></a><span class="lineno">  425</span>&#160;           &lt;td &gt; &lt;/td&gt;</div><div class="line"><a name="l00426"></a><span class="lineno">  426</span>&#160;           &lt;td&gt; ✔  &lt;/td&gt;</div><div class="line"><a name="l00427"></a><span class="lineno">  427</span>&#160;           &lt;td&gt;  &lt;/td&gt;</div><div class="line"><a name="l00428"></a><span class="lineno">  428</span>&#160;           &lt;td&gt; &lt;/td&gt;</div><div class="line"><a name="l00429"></a><span class="lineno">  429</span>&#160;   &lt;/tr&gt;</div><div class="line"><a name="l00430"></a><span class="lineno">  430</span>&#160;   &lt;tr&gt;</div><div class="line"><a name="l00431"></a><span class="lineno">  431</span>&#160;           &lt;td&gt;ttable_s2t_server_port&lt;/td&gt;</div><div class="line"><a name="l00432"></a><span class="lineno">  432</span>&#160;           &lt;td&gt; Source-to-target lexical server port.&lt;/td&gt;</div><div class="line"><a name="l00433"></a><span class="lineno">  433</span>&#160;           &lt;td &gt; &lt;/td&gt;</div><div class="line"><a name="l00434"></a><span class="lineno">  434</span>&#160;           &lt;td&gt;  &lt;/td&gt;</div><div class="line"><a name="l00435"></a><span class="lineno">  435</span>&#160;           &lt;td&gt; ✔&lt;/td&gt;</div><div class="line"><a name="l00436"></a><span class="lineno">  436</span>&#160;           &lt;td&gt; ✔ &lt;/td&gt;</div><div class="line"><a name="l00437"></a><span class="lineno">  437</span>&#160;   &lt;/tr&gt;</div><div class="line"><a name="l00438"></a><span class="lineno">  438</span>&#160;   &lt;tr&gt;</div><div class="line"><a name="l00439"></a><span class="lineno">  439</span>&#160;           &lt;td&gt;ttable_t2s_server_port&lt;/td&gt;</div><div class="line"><a name="l00440"></a><span class="lineno">  440</span>&#160;           &lt;td&gt;Target-to-source lexical server port.&lt;/td&gt;</div><div class="line"><a name="l00441"></a><span class="lineno">  441</span>&#160;           &lt;td &gt; &lt;/td&gt;</div><div class="line"><a name="l00442"></a><span class="lineno">  442</span>&#160;           &lt;td&gt;  &lt;/td&gt;</div><div class="line"><a name="l00443"></a><span class="lineno">  443</span>&#160;           &lt;td&gt; ✔&lt;/td&gt;</div><div class="line"><a name="l00444"></a><span class="lineno">  444</span>&#160;           &lt;td&gt; ✔ &lt;/td&gt;</div><div class="line"><a name="l00445"></a><span class="lineno">  445</span>&#160;   &lt;/tr&gt;</div><div class="line"><a name="l00446"></a><span class="lineno">  446</span>&#160;   &lt;tr&gt;</div><div class="line"><a name="l00447"></a><span class="lineno">  447</span>&#160;           &lt;td&gt;ttable_s2t_host&lt;/td&gt;</div><div class="line"><a name="l00448"></a><span class="lineno">  448</span>&#160;           &lt;td&gt;Source-to-target lexical server hostname.&lt;/td&gt;</div><div class="line"><a name="l00449"></a><span class="lineno">  449</span>&#160;           &lt;td &gt; &lt;/td&gt;</div><div class="line"><a name="l00450"></a><span class="lineno">  450</span>&#160;           &lt;td&gt;  &lt;/td&gt;</div><div class="line"><a name="l00451"></a><span class="lineno">  451</span>&#160;           &lt;td&gt; ✔&lt;/td&gt;</div><div class="line"><a name="l00452"></a><span class="lineno">  452</span>&#160;           &lt;td&gt; ✔ &lt;/td&gt;</div><div class="line"><a name="l00453"></a><span class="lineno">  453</span>&#160;   &lt;/tr&gt;                   </div><div class="line"><a name="l00454"></a><span class="lineno">  454</span>&#160;   &lt;tr&gt;</div><div class="line"><a name="l00455"></a><span class="lineno">  455</span>&#160;           &lt;td&gt;ttable_t2s_host&lt;/td&gt;</div><div class="line"><a name="l00456"></a><span class="lineno">  456</span>&#160;           &lt;td&gt;Target-to-source lexical server hostname.&lt;/td&gt;</div><div class="line"><a name="l00457"></a><span class="lineno">  457</span>&#160;           &lt;td &gt; &lt;/td&gt;</div><div class="line"><a name="l00458"></a><span class="lineno">  458</span>&#160;           &lt;td&gt;  &lt;/td&gt;</div><div class="line"><a name="l00459"></a><span class="lineno">  459</span>&#160;           &lt;td&gt; ✔&lt;/td&gt;</div><div class="line"><a name="l00460"></a><span class="lineno">  460</span>&#160;           &lt;td&gt; ✔ &lt;/td&gt;</div><div class="line"><a name="l00461"></a><span class="lineno">  461</span>&#160;   &lt;/tr&gt;</div><div class="line"><a name="l00462"></a><span class="lineno">  462</span>&#160;   &lt;tr&gt;</div><div class="line"><a name="l00463"></a><span class="lineno">  463</span>&#160;           &lt;td&gt;ttable_server_template&lt;/td&gt;</div><div class="line"><a name="l00464"></a><span class="lineno">  464</span>&#160;           &lt;td&gt;Template string indicating the directory structure of the Giza lexical models. The template string can include $GENRE and $DIRECTION variables.&lt;/td&gt;</div><div class="line"><a name="l00465"></a><span class="lineno">  465</span>&#160;           &lt;td &gt; &lt;/td&gt;</div><div class="line"><a name="l00466"></a><span class="lineno">  466</span>&#160;           &lt;td&gt;  &lt;/td&gt;</div><div class="line"><a name="l00467"></a><span class="lineno">  467</span>&#160;           &lt;td&gt; ✔&lt;/td&gt;</div><div class="line"><a name="l00468"></a><span class="lineno">  468</span>&#160;           &lt;td&gt; &lt;/td&gt;</div><div class="line"><a name="l00469"></a><span class="lineno">  469</span>&#160;   &lt;/tr&gt;</div><div class="line"><a name="l00470"></a><span class="lineno">  470</span>&#160;   &lt;tr&gt;    </div><div class="line"><a name="l00471"></a><span class="lineno">  471</span>&#160;           &lt;td&gt;ttable_language_pair&lt;/td&gt;</div><div class="line"><a name="l00472"></a><span class="lineno">  472</span>&#160;           &lt;td&gt;String to substitute in the $DIRECTION variable.&lt;/td&gt;</div><div class="line"><a name="l00473"></a><span class="lineno">  473</span>&#160;           &lt;td &gt; &lt;/td&gt;</div><div class="line"><a name="l00474"></a><span class="lineno">  474</span>&#160;           &lt;td&gt;  &lt;/td&gt;</div><div class="line"><a name="l00475"></a><span class="lineno">  475</span>&#160;           &lt;td&gt; ✔&lt;/td&gt;</div><div class="line"><a name="l00476"></a><span class="lineno">  476</span>&#160;           &lt;td&gt; &lt;/td&gt;</div><div class="line"><a name="l00477"></a><span class="lineno">  477</span>&#160;   &lt;/tr&gt;</div><div class="line"><a name="l00478"></a><span class="lineno">  478</span>&#160;   &lt;tr&gt;    </div><div class="line"><a name="l00479"></a><span class="lineno">  479</span>&#160;   &lt;td&gt;ttable_direction&lt;/td&gt;</div><div class="line"><a name="l00480"></a><span class="lineno">  480</span>&#160;           &lt;td&gt;The direction of the ttable server. Valid values are &quot;s2t&quot; and &quot;t2s&quot;.&lt;/td&gt;</div><div class="line"><a name="l00481"></a><span class="lineno">  481</span>&#160;           &lt;td &gt; &lt;/td&gt;</div><div class="line"><a name="l00482"></a><span class="lineno">  482</span>&#160;           &lt;td&gt;  &lt;/td&gt;</div><div class="line"><a name="l00483"></a><span class="lineno">  483</span>&#160;           &lt;td&gt; ✔&lt;/td&gt;</div><div class="line"><a name="l00484"></a><span class="lineno">  484</span>&#160;           &lt;td&gt; &lt;/td&gt;</div><div class="line"><a name="l00485"></a><span class="lineno">  485</span>&#160;   &lt;/tr&gt;</div><div class="line"><a name="l00486"></a><span class="lineno">  486</span>&#160;   &lt;tr&gt;            </div><div class="line"><a name="l00487"></a><span class="lineno">  487</span>&#160;           &lt;td&gt;min_lex_prob&lt;/td&gt;</div><div class="line"><a name="l00488"></a><span class="lineno">  488</span>&#160;           &lt;td&gt;Minimum probability for a Model 1 entry. Entries with lower probability are discarded. Used for reducing the memory consumed by a lexical server.&lt;/td&gt;</div><div class="line"><a name="l00489"></a><span class="lineno">  489</span>&#160;           &lt;td &gt; &lt;/td&gt;</div><div class="line"><a name="l00490"></a><span class="lineno">  490</span>&#160;           &lt;td&gt;  &lt;/td&gt;</div><div class="line"><a name="l00491"></a><span class="lineno">  491</span>&#160;           &lt;td&gt; ✔&lt;/td&gt;</div><div class="line"><a name="l00492"></a><span class="lineno">  492</span>&#160;           &lt;td&gt; &lt;/td&gt;</div><div class="line"><a name="l00493"></a><span class="lineno">  493</span>&#160;   &lt;/tr&gt;</div><div class="line"><a name="l00494"></a><span class="lineno">  494</span>&#160;   &lt;tr&gt;            </div><div class="line"><a name="l00495"></a><span class="lineno">  495</span>&#160;           &lt;td&gt;hr_max_height&lt;/td&gt;</div><div class="line"><a name="l00496"></a><span class="lineno">  496</span>&#160;           &lt;td&gt;Maximum number of source terminals covered by the left-hand-side non-terminal in a hierarchical rule.&lt;/td&gt;</div><div class="line"><a name="l00497"></a><span class="lineno">  497</span>&#160;           &lt;td &gt; &lt;/td&gt;</div><div class="line"><a name="l00498"></a><span class="lineno">  498</span>&#160;           &lt;td&gt;  &lt;/td&gt;</div><div class="line"><a name="l00499"></a><span class="lineno">  499</span>&#160;           &lt;td&gt; &lt;/td&gt;</div><div class="line"><a name="l00500"></a><span class="lineno">  500</span>&#160;           &lt;td&gt; ✔&lt;/td&gt;</div><div class="line"><a name="l00501"></a><span class="lineno">  501</span>&#160;   &lt;/tr&gt;</div><div class="line"><a name="l00502"></a><span class="lineno">  502</span>&#160;   &lt;tr&gt;    </div><div class="line"><a name="l00503"></a><span class="lineno">  503</span>&#160;           &lt;td&gt;features&lt;/td&gt;</div><div class="line"><a name="l00504"></a><span class="lineno">  504</span>&#160;           &lt;td&gt;Comma separated list of features to include in the final grammar.&lt;/td&gt;</div><div class="line"><a name="l00505"></a><span class="lineno">  505</span>&#160;           &lt;td &gt; &lt;/td&gt;</div><div class="line"><a name="l00506"></a><span class="lineno">  506</span>&#160;           &lt;td&gt;  &lt;/td&gt;</div><div class="line"><a name="l00507"></a><span class="lineno">  507</span>&#160;           &lt;td&gt; &lt;/td&gt;</div><div class="line"><a name="l00508"></a><span class="lineno">  508</span>&#160;           &lt;td&gt; ✔&lt;/td&gt;</div><div class="line"><a name="l00509"></a><span class="lineno">  509</span>&#160;   &lt;/tr&gt;</div><div class="line"><a name="l00510"></a><span class="lineno">  510</span>&#160;   &lt;tr&gt;</div><div class="line"><a name="l00511"></a><span class="lineno">  511</span>&#160;           &lt;td&gt;pass_through_rules&lt;/td&gt;</div><div class="line"><a name="l00512"></a><span class="lineno">  512</span>&#160;           &lt;td&gt;File containing pass-through rules.&lt;/td&gt;</div><div class="line"><a name="l00513"></a><span class="lineno">  513</span>&#160;           &lt;td &gt; &lt;/td&gt;</div><div class="line"><a name="l00514"></a><span class="lineno">  514</span>&#160;           &lt;td&gt;  &lt;/td&gt;</div><div class="line"><a name="l00515"></a><span class="lineno">  515</span>&#160;           &lt;td&gt; &lt;/td&gt;</div><div class="line"><a name="l00516"></a><span class="lineno">  516</span>&#160;           &lt;td&gt; ✔&lt;/td&gt;</div><div class="line"><a name="l00517"></a><span class="lineno">  517</span>&#160;   &lt;/tr&gt;</div><div class="line"><a name="l00518"></a><span class="lineno">  518</span>&#160;   &lt;tr&gt;</div><div class="line"><a name="l00519"></a><span class="lineno">  519</span>&#160;           &lt;td&gt;retrieval_threads&lt;/td&gt;</div><div class="line"><a name="l00520"></a><span class="lineno">  520</span>&#160;           &lt;td&gt;The number of threads used to query the HFile. &lt;/td&gt;</div><div class="line"><a name="l00521"></a><span class="lineno">  521</span>&#160;           &lt;td &gt; &lt;/td&gt;</div><div class="line"><a name="l00522"></a><span class="lineno">  522</span>&#160;           &lt;td&gt;  &lt;/td&gt;</div><div class="line"><a name="l00523"></a><span class="lineno">  523</span>&#160;           &lt;td&gt; &lt;/td&gt;</div><div class="line"><a name="l00524"></a><span class="lineno">  524</span>&#160;           &lt;td&gt; ✔&lt;/td&gt;</div><div class="line"><a name="l00525"></a><span class="lineno">  525</span>&#160;   &lt;/tr&gt;</div><div class="line"><a name="l00526"></a><span class="lineno">  526</span>&#160;   &lt;tr&gt;</div><div class="line"><a name="l00527"></a><span class="lineno">  527</span>&#160;           &lt;td&gt;hfile&lt;/td&gt;</div><div class="line"><a name="l00528"></a><span class="lineno">  528</span>&#160;           &lt;td&gt;Directory containing the HFile. &lt;/td&gt;</div><div class="line"><a name="l00529"></a><span class="lineno">  529</span>&#160;           &lt;td &gt; &lt;/td&gt;</div><div class="line"><a name="l00530"></a><span class="lineno">  530</span>&#160;           &lt;td&gt;  &lt;/td&gt;</div><div class="line"><a name="l00531"></a><span class="lineno">  531</span>&#160;           &lt;td&gt; &lt;/td&gt;</div><div class="line"><a name="l00532"></a><span class="lineno">  532</span>&#160;           &lt;td&gt; ✔&lt;/td&gt;</div><div class="line"><a name="l00533"></a><span class="lineno">  533</span>&#160;   &lt;/tr&gt;</div><div class="line"><a name="l00534"></a><span class="lineno">  534</span>&#160;   &lt;tr&gt;</div><div class="line"><a name="l00535"></a><span class="lineno">  535</span>&#160;           &lt;td&gt;test_file&lt;/td&gt;</div><div class="line"><a name="l00536"></a><span class="lineno">  536</span>&#160;           &lt;td&gt;File containing the sentences to be translated. &lt;/td&gt;</div><div class="line"><a name="l00537"></a><span class="lineno">  537</span>&#160;           &lt;td &gt; &lt;/td&gt;</div><div class="line"><a name="l00538"></a><span class="lineno">  538</span>&#160;           &lt;td&gt;  &lt;/td&gt;</div><div class="line"><a name="l00539"></a><span class="lineno">  539</span>&#160;           &lt;td&gt; &lt;/td&gt;</div><div class="line"><a name="l00540"></a><span class="lineno">  540</span>&#160;           &lt;td&gt; ✔&lt;/td&gt;</div><div class="line"><a name="l00541"></a><span class="lineno">  541</span>&#160;   &lt;/tr&gt;</div><div class="line"><a name="l00542"></a><span class="lineno">  542</span>&#160;   &lt;tr&gt;</div><div class="line"><a name="l00543"></a><span class="lineno">  543</span>&#160;           &lt;td&gt;rules&lt;/td&gt;</div><div class="line"><a name="l00544"></a><span class="lineno">  544</span>&#160;           &lt;td&gt;Gzipped output file containing the shallow grammar. &lt;/td&gt;</div><div class="line"><a name="l00545"></a><span class="lineno">  545</span>&#160;           &lt;td &gt; &lt;/td&gt;</div><div class="line"><a name="l00546"></a><span class="lineno">  546</span>&#160;           &lt;td&gt;  &lt;/td&gt;</div><div class="line"><a name="l00547"></a><span class="lineno">  547</span>&#160;           &lt;td&gt; &lt;/td&gt;</div><div class="line"><a name="l00548"></a><span class="lineno">  548</span>&#160;           &lt;td&gt; ✔&lt;/td&gt;</div><div class="line"><a name="l00549"></a><span class="lineno">  549</span>&#160;   &lt;/tr&gt;</div><div class="line"><a name="l00550"></a><span class="lineno">  550</span>&#160;   &lt;tr&gt;</div><div class="line"><a name="l00551"></a><span class="lineno">  551</span>&#160;           &lt;td&gt;vocab&lt;/td&gt;</div><div class="line"><a name="l00552"></a><span class="lineno">  552</span>&#160;           &lt;td&gt;File containing target side vocabulary for KENLM filtering. &lt;/td&gt;</div><div class="line"><a name="l00553"></a><span class="lineno">  553</span>&#160;           &lt;td &gt; &lt;/td&gt;</div><div class="line"><a name="l00554"></a><span class="lineno">  554</span>&#160;           &lt;td&gt;  &lt;/td&gt;</div><div class="line"><a name="l00555"></a><span class="lineno">  555</span>&#160;           &lt;td&gt; &lt;/td&gt;</div><div class="line"><a name="l00556"></a><span class="lineno">  556</span>&#160;           &lt;td&gt; ✔&lt;/td&gt;</div><div class="line"><a name="l00557"></a><span class="lineno">  557</span>&#160;   &lt;/tr&gt;           </div><div class="line"><a name="l00558"></a><span class="lineno">  558</span>&#160;&lt;/table&gt;</div><div class="line"><a name="l00559"></a><span class="lineno">  559</span>&#160;</div></div><!-- fragment --></div><!-- contents -->
</div><!-- doc-content -->
<!-- start footer part -->
<div id="nav-path" class="navpath"><!-- id is needed for treeview function! -->
  <ul>
    <li class="navelem"><a class="el" href="Tutorial_8070_8rulextract_8md.html">Tutorial.070.rulextract.md</a></li>
    <li class="footer">Generated on Thu May 19 2016 11:21:36 for Cambridge SMT System by
    <a href="http://www.doxygen.org/index.html">
    <img class="footer" src="doxygen.png" alt="doxygen"/></a> 1.8.11 </li>
  </ul>
</div>
</body>
</html>
