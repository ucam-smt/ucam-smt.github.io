<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.8.3"/>
<title>Cambridge SMT System: Rescoring Procedures</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="navtree.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="resize.js"></script>
<script type="text/javascript" src="navtree.js"></script>
<script type="text/javascript">
  $(document).ready(initResizable);
  $(window).load(resizeHeight);
</script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td style="padding-left: 0.5em;">
   <div id="projectname">Cambridge SMT System
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.8.3 -->
</div><!-- top -->
<div id="side-nav" class="ui-resizable side-nav-resizable">
  <div id="nav-tree">
    <div id="nav-tree-contents">
      <div id="nav-sync" class="sync"></div>
    </div>
  </div>
  <div id="splitbar" style="-moz-user-select:none;" 
       class="ui-resizable-handle">
  </div>
</div>
<script type="text/javascript">
$(document).ready(function(){initNavTree('rescoring.html','');});
</script>
<div id="doc-content">
<div class="header">
  <div class="headertitle">
<div class="title">Rescoring Procedures </div>  </div>
</div><!--header-->
<div class="contents">
<div class="textblock"><h1><a class="anchor" id="rescoring_lm"></a>
Efficient Language Model Rescoring</h1>
<p>As discussed above, HiFST uses a lexicographic semiring (<a class="el" href="basic.html#basic_scores">Scores, Costs, and Semirings</a>, [<a class="el" href="index.html#Roark2011">Roark2011</a>]) of two tropical weights. In each arc of a lattice generated by HiFST, the first weight (G+M) contains the correct score (translation grammar score + language model score). The second weight G only contains the translation grammar score. An example is repeated here: </p>
<pre class="fragment"> &gt; zcat output/exp.baseline/LATS/1.fst.gz | fstprint | head -n 10
 0 1    1                            1             -2.609375,-2.609375
 1 36   999999999                    999999999      29.5185547,29.5185547
 1 35   12198                        12198          19.6816635,7.27929688
 1 34   12198                        12198          17.9902573,5.58789062
 1 33   9227                         9227           16.845089,2.56347656
 1 32   9121                         9121           9.55193996,-1.04199219
 1 31   9121                         9121           7.86053371,-2.73339844
 1 30   9121                         9121           9.33318996,-1.26074219
 1 29   8559                         8559           14.9520674,4.25878906
 1 28   4608                         4608           17.6058693,4.88671875
</pre><p>The advantage of using the lexicographic semiring to represent (G+M,G) weights is that the language model score can be substracted very efficiently. HiFST binaries do this mapping internally with an <a href="http://www.openfst.org/twiki/bin/view/FST/ArcMapDoc">fstmap</a> operation. The result is a WFSA whose weights contain only the translation grammar scores (G,G). The lexmap tool can be used to do this mapping, as follows, yielding lexicographic weights (G,G): </p>
<pre class="fragment">  &gt; zcat output/exp.baseline.outputnoprune/LATS/1.fst.gz | lexmap.O2  | fstprint | head -n 10
  0  1 1    1                                               -2.609375,-2.609375
  1  36     999999999                                       999999999       29.5185547,29.5185547
  1  35     12198                                           12198           7.27929688,7.27929688
  1  34     12198                                           12198           5.58789062,5.58789062
  1  33     9227                                            9227            2.56347656,2.56347656
  1  32     9121                                            9121            -1.04199219,-1.04199219
  1  31     9121                                            9121            -2.73339844,-2.73339844
  1  30     9121                                            9121            -1.26074219,-1.26074219
  1  29     8559                                            8559            4.25878906,4.25878906
  1  28     4608                                            4608            4.88671875,4.88671875
</pre><p>Using this facility to remove language model scores, the HiFST applylm tool can be used to rescore lattices under a different language model than was used in first-pass translation. Operations are as follows:</p>
<ol type="1">
<li>A lattice with lexicographic (G+M,G) weights is loaded</li>
<li>Weights are converted to (G,G) via fstmap</li>
<li>The new language model(s) are applied via composition under the lexicographic semiring, with optional scale factors and word insertion penalties. The new WFSAs weights are of the form (G+M',G), where M' are the new language model weights.</li>
<li>The reweighted WFSA is written to disk, with either lexicographic or standard tropical weights</li>
</ol>
<p>The following example uses applylm to rescore lattices generated with almost no pruning (<code>output/exp.baseline.outputnoprune/LATS</code>). Rescoring uses the same 4-gram language model originally used to generate the lattice, but with a different scale factor (<code>lm.scale=0.9</code>). </p>
<pre class="fragment"> &gt; applylm.O2 --config=configs/CF.baseline.outputnoprune.lmrescore  &amp;&gt; log/log.lmrescore
</pre><p>For the first sentence, the original 1-best hypothesis was: </p>
<pre class="fragment">&gt; zcat output/exp.baseline.outputnoprune/LATS/1.fst.gz | printstrings.O2 --semiring=lexstdarc -m wmaps/wmt13.en.wmap -w 2&gt;/dev/null
&lt;s&gt; republican strategy of resistance to the renewal of obamas election &lt;/s&gt;        57.4707,-8.03809
</pre><p>Rescoring yields a slightly different 1-best: </p>
<pre class="fragment">&gt; zcat output/exp.baseline.lmrescore/LATS/1.fst.gz | printstrings.O2 --semiring=lexstdarc -m wmaps/wmt13.en.wmap -w 2&gt;/dev/null
&lt;s&gt; the republican strategy of resistance to the renewal of obamas election &lt;/s&gt;    50.9163,-8.66992
</pre><p>Note the "load.deletelmcost" option in the configuration file, which instructs the tool to subtract old lm scores first.</p>
<p>If the scaling is not changed, both lattices should be identical (<code>applylm.O2 --config=configs/CF.baseline.outputnoprune.lmrescore --lm.featureweights=1</code>).</p>
<h1><a class="anchor" id="lmbr"></a>
Lattice Minimum Bayes Risk Decoding</h1>
<p>For a detailed discussion of LMBR, see Chapters 7 and 8 in [<a class="el" href="index.html#BlackwoodPhD">BlackwoodPhD</a>].</p>
<p>LMBR is a decoding procedure, based on the following:</p>
<ul>
<li>Evidence space: a lattice (WFSA) containing weighted translations produced by the SMT system.<ul>
<li>N-gram posterior distributions, with pathwise posteriors, are extracted from this WFSA.</li>
</ul>
</li>
<li>The hypotheses space: an unweighted lattice (FSA) containing hypotheses to be rescored.</li>
</ul>
<p>The following steps are carried out in LMBR decoding:</p>
<ol type="1">
<li>The evidence space is normalised after applying a grammar scale factor (<code>--alpha=</code>). Scaling is done by the <a class="el" href="index.html#OpenFst">OpenFst</a> <a href="http://www.openfst.org/twiki/bin/view/FST/PushDoc">Push</a> towards final states, and setting the final state probability to 1.0.</li>
<li>N-grams are extracted from the hypothesis space.</li>
<li>N-gram path-posterior probabilities are computed over the evidence space using a modified Forward procedure (see <a class="el" href="index.html#Blackwood2010">Blackwood2010</a>)</li>
<li>Cyclic WFSAs are built to represent posterior probability distribution of each n-gram order and compose with the original hypotheses space. A word insertion penalty (<code>--wps=</code>) is also included in the costs of the cyclic WFSAs.</li>
<li>Risk is computed through a sequence of compositions.</li>
<li>The result for LMBR decoding is a WFSA; each weighted path represents a hypothesis and its risk.</li>
</ol>
<p>The weighted hypothesis space can be save as a WFSA, or the minimum risk hypothesis can be generated via the <a class="el" href="index.html#OpenFst">OpenFst</a> <a href="http://www.openfst.org/twiki/bin/view/FST/ShortestPathDoc">ShortestPath</a> operation.</p>
<p>The following example applies LMBR decoding to the baseline lattices </p>
<pre class="fragment">&gt; lmbr.O2 --config=configs/CF.baseline.lmbr &amp;&gt; log/log.baseline.lmbr
</pre><p>The LMBR output hyppthesis file keeps the scale factor, word penalty, and sentence id at the start of the file; the hypothesis follows the colon </p>
<pre class="fragment">&gt; cat output/exp.baseline.lmbr/HYPS/0.40_0.02.hyp
0.4 0.02 1:1 3 9121 384 6 2756 7 3 4144 6 159312 42 1341 2
0.4 0.02 2:1 3 1119 6 3 9121 1711 54 79 6 3 85 7 525 3 13907 17 3 628 5 2
</pre><p>LMBR can be optimised by tuning the grammar scale factor and word insertion penalty. Once lattices are loaded into memory and n-grams are extracted (steps 1 - 5), rescoring is fast enough that it is practical and efficient to perform a grid search over a range of parameter values (see config file).</p>
<p>Hypotheses are written to different files, with names based on parameter values (e.g. as <code>--writeonebest=output/exp.baseline.lmbr/HYPS/%alpha%_%wps%%.hyp</code> ). The best set of values can be selected based on BLEU score, after mapping each integer mapped output back to words, detokenizing, and scoring on against references.</p>
<p>LMBR relies on a unigram precision (p) and precision ratio (r) that are computed over a development set, e.g. with verbose logs of a BLEU scorer such as NIST mteval1. The script <code>$HiFSTROOT/scripts/lmbr/compute-testset-precisions.pl</code> is included for this purpose.</p>
<p>If the option <code>--preprune=</code> is specified, the evidence space is pruned prior to computing posterior probabilities (i.e. pruning is done at threshold 7 in this example). If this option is not defined, the full evidence space will be passed through. </p>
</div></div><!-- contents -->
</div><!-- doc-content -->
<!-- start footer part -->
<div id="nav-path" class="navpath"><!-- id is needed for treeview function! -->
  <ul>
    <li class="footer">Generated on Tue May 27 2014 21:16:47 for Cambridge SMT System by
    <a href="http://www.doxygen.org/index.html">
    <img class="footer" src="doxygen.png" alt="doxygen"/></a> 1.8.3 </li>
  </ul>
</div>
</body>
</html>
