<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.8.3"/>
<title>Cambridge SMT System: Lattice MERT</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="navtree.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="resize.js"></script>
<script type="text/javascript" src="navtree.js"></script>
<script type="text/javascript">
  $(document).ready(initResizable);
  $(window).load(resizeHeight);
</script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td style="padding-left: 0.5em;">
   <div id="projectname">Cambridge SMT System
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.8.3 -->
</div><!-- top -->
<div id="side-nav" class="ui-resizable side-nav-resizable">
  <div id="nav-tree">
    <div id="nav-tree-contents">
      <div id="nav-sync" class="sync"></div>
    </div>
  </div>
  <div id="splitbar" style="-moz-user-select:none;" 
       class="ui-resizable-handle">
  </div>
</div>
<script type="text/javascript">
$(document).ready(function(){initNavTree('lmert.html','');});
</script>
<div id="doc-content">
<div class="header">
  <div class="headertitle">
<div class="title">Lattice MERT </div>  </div>
</div><!--header-->
<div class="contents">
<div class="textblock"><p>This section describes how to:</p>
<ul>
<li>generate lattices for use with LMERT [<a class="el" href="index.html#Macherey2008">Macherey2008</a>]</li>
<li>run the HiFST implementations of LMERT for iterative parameter estimation [<a class="el" href="index.html#Waite2012">Waite2012</a>]</li>
</ul>
<h1><a class="anchor" id="lmert_run"></a>
HiFST_lmert</h1>
<p>This HiFST release includes an implementation of LMERT [<a class="el" href="index.html#Waite2012">Waite2012</a>]. The script <code>HiFST_lmert</code> runs several iterations of lattice generation and parameter estimation using the <code>lmert</code> tool.</p>
<p>Prior to running the script, make sure to download and uncompress the LM <code>interp.4g.arpa.newstest2012.tune.corenlp.ru.idx.withoptions.mmap</code> into the <code>M/</code> directory (see <a class="el" href="start.html#Setup_files">Tutorial Files</a>). </p>
<pre class="fragment">&gt; scripts/HiFST_lmert
</pre><p>This script runs 4 iterations of LMERT, with each iteration consisting of the four steps that follow in the sections below. In our experience, on a X86_64 Linux computer with 4 2.8GHz CPUs and 24GB RAM, each iteration takes ca. 3 hours.</p>
<p>Output from each iteration is written to files <code>log/log.lmert.[1,2,3,4]</code>. For example, </p>
<pre class="fragment">&gt; tail -8 log/log.lmert.bak/log.lmert.1
Thu May 15 14:33:52 2014 optimization result:
Thu May 15 14:33:52 2014   start: 0.310724 0.996479
Thu May 15 14:33:52 2014   final: 0.316637
Thu May 15 14:33:52 2014 writing final parameters to file: output/exp.lmert/params.1
Thu May 15 14:33:52 2014   1.000000,1.080643,0.516691,1.694245,0.096786,-0.436836,24.789537,-4.856992,-3.419495,0.488006,0.121445,-0.064946
==Params
Thu May 15 14:33:52 BST 2014
1.000000,1.080643,0.516691,1.694245,0.096786,-0.436836,24.789537,-4.856992,-3.419495,0.488006,0.121445,-0.064946

&gt; tail -8 log/log.lmert.bak/log.lmert.2
Thu May 15 19:08:00 2014 optimization result:
Thu May 15 19:08:00 2014   start: 0.316392 0.968629
Thu May 15 19:08:00 2014   final: 0.322178
Thu May 15 19:08:00 2014 writing final parameters to file: output/exp.lmert/params.2
Thu May 15 19:08:00 2014   1.000000,1.471600,0.534356,2.443535,-1.373008,0.631498,27.626422,-5.952960,-2.638954,0.699155,0.182260,-0.018291
==Params
Thu May 15 19:08:00 BST 2014
1.000000,1.471600,0.534356,2.443535,-1.373008,0.631498,27.626422,-5.952960,-2.638954,0.699155,0.182260,-0.018291
</pre><p>This indicates:</p>
<ul>
<li>The initial set of parameters yields a tuning set BLEU score of 0.310724, with brevity penalty 0.996479</li>
<li>The first iteration of LMERT improves the tuning set BLEU score to 0.316637 over the tuning set lattices generated with the initial parameters</li>
<li>Retranslation with the parameters found at iteration 1 yields a tuning set BLEU score of 0.316392, with brevity penalty 0.968629</li>
<li>The second iteration of LMERT improves the tuning set BLEU score to 0.322178 over the tuning set lattices generated with the parameters from iteration 1</li>
</ul>
<p>Note that the n-gram language model is set by default to <code>M/interp.4g.arpa.newstest2012.tune.corenlp.ru.idx.withoptions.mmap</code>. This is a quantized version of <code>M/interp.4g.arpa.newstest2012.tune.corenlp.ru.idx.union.mmap</code>. Slightly higher tuning set BLEU scores can be gotten with the unquantized LM, although memory use in tuning will be higher.</p>
<p>Note also that the script <code>HiFST_lmert</code> can be modified to perform LMERT over only the first (e.g.) 100 tuning set sentences. This can be done for debugging / demonstration, in that processing will be much faster, although the estimated parameters will not be as robust.</p>
<h1><a class="anchor" id="lmert_hyps"></a>
1. Hypotheses for LMERT</h1>
<p>Note that this step is also done in MERT (<a class="el" href="mert.html">MERT - Features Only</a>), although the settings here are slightly different.</p>
<p>The following command is run at iteration <code>$it</code> , and will generate lattices for <code>$M</code> files.</p>
<ul>
<li>Input:<ul>
<li><code>$it</code> &ndash; lmert iteration (1, 2, ...)</li>
<li><code>$M</code> &ndash; number of sentences to process</li>
<li><code>RU/RU.tune.idx</code> &ndash; tuning set source language sentences</li>
<li><code>G/rules.shallow.vecfea.all.gz</code> &ndash; translation grammar</li>
<li><code>M/interp.4g.arpa.newstest2012.tune.corenlp.ru.idx.union.mmap</code> &ndash; target language model</li>
<li>language model and translation grammar feature weights, provided via command line option</li>
</ul>
</li>
<li>Output<ul>
<li><code>output/exp.lmert/$it/LATS/?.fst.gz</code> &ndash; word lattices (WFSAs), determinized and minimized</li>
<li><code>output/exp.lmert/$it/hyps</code> &ndash; translation hyps (discarded)</li>
</ul>
</li>
</ul>
<p>The feature weights are gathered into a single vector, and set via the <code>--featureweights</code> command line option</p>
<ul>
<li>The first parameter is the grammar scale factor (in the MERT demo, this is set via <code>lm.featureweights</code>)</li>
<li>The remaining parameters are weights for the grammar features (in the MERT demo, these are set via <code>grammar.featureweights</code>)</li>
</ul>
<p>The initial parameters are </p>
<pre class="fragment">FW=1.0,0.697263,0.396540,2.270819,-0.145200,0.038503,29.518480,-3.411896,-3.732196,0.217455,0.041551,0.060136
</pre><p>HiFST is run in translation mode as </p>
<pre class="fragment">&gt; hifst.O2 --config=configs/CF.lmert.hyps --range=1:$M --featureweights=$FW --target.store=output/exp.lmert/$it/hyps --hifst.lattice.store=output/exp.lmert/$it/LATS/?.fst.gz
</pre><h1><a class="anchor" id="lmert_veclats"></a>
2. Guided Translation / Forced Alignment</h1>
<ul>
<li>Input:<ul>
<li><code>$it</code> &ndash; lmert iteration (1, 2, ...)</li>
<li><code>$M</code> &ndash; number of sentences to process</li>
<li><code>output/exp.lmert/$it/LATS/?.fst.gz</code> &ndash; word lattices (WFSAs), determinized and minimized (from <a class="el" href="lmert.html#lmert_hyps">1. Hypotheses for LMERT</a>)</li>
</ul>
</li>
<li>Output:<ul>
<li><code>output/exp.lmert/$it/ALILATS/?.fst.gz</code> &ndash; transducers mapping derivations to translations (e.g. Fig. 7, [<a class="el" href="index.html#deGispert2010">deGispert2010</a>])</li>
<li><code>output/exp.lmert/$it/hyps</code> &ndash; translation hyps (discarded)</li>
</ul>
</li>
</ul>
<p>HiFST is run in alignment mode. Lattices (from <code>output/exp.lmert/$it/LATS/?.fst.gz</code>) read and transformed into substring acceptors used to constrain the space of alignments </p>
<pre class="fragment">&gt; hifst.O2 --config=configs/CF.lmert.alilats --range=1:$M --referencefilter.load=output/exp.lmert/$it/LATS/?.fst.gz --target.store=output/exp.lmert/$it/hyps --hifst.lattice.store=output/exp.lmert/$it/ALILATS/?.fst.gz
</pre><p>Note the following parameters in the configuration file: </p>
<pre class="fragment">[referencefilter]
prunereferenceweight=4
# pruning threshold to be applied to input lattice prior to alignment
prunereferenceshortestpath=10000
# extract n-best list from input lattice to use as hypotheses
</pre><p>Reference lattices are read from <code>output/exp.lmert/$it/LATS/?.fst.gz</code>. For each lattice:</p>
<ul>
<li>an N-Best list of depth 10000 is extracted using <code>fstshortestpath</code></li>
<li>the lattices are pruned with threshold <code>prunereferenceweight=4</code></li>
<li>the pruned lattice is unioned with the N-Best list</li>
<li>the resulting WFSA is transformed (after removing weights, minimization and determinization) into a substring acceptor to be used in alignment</li>
</ul>
<p>A simpler approach could be simply to prune the reference lattices. However in practice it can be difficult to find a global pruning threshold that always yields a reference lattice that is big enough, but not too big. Including the n-best list ensures that there will always be a rich set of candidate hypotheses.</p>
<h1><a class="anchor" id="lmert_alilats"></a>
3. WFSAs with Unweighted Feature Vectors</h1>
<ul>
<li>Input:<ul>
<li><code>$it</code> &ndash; lmert iteration (1, 2, ...)</li>
<li><code>$M</code> &ndash; number of sentences to process</li>
<li>language model and translation grammar feature weights, provided via command line options</li>
<li><code>output/exp.lmert/$it/ALILATS/?.fst.gz</code> &ndash; transducers mapping derivations to translations</li>
</ul>
</li>
<li>Output:<ul>
<li>output/exp.lmert/$it/VECFEA/?.fst.gz &ndash; translation lattices (WFSAs) with unweighted feature vectors</li>
</ul>
</li>
</ul>
<p><code>alilats2splats</code> transforms ALILATS alignment lattices to sparse vector weight lattices; see Section 2.3.1, [<a class="el" href="index.html#deGispert2010">deGispert2010</a>] for a detailed explanation. A single output WFSA with sparse vector weights is written for each translation. Note that this is different from the MERT case, where two N-best lists of hypotheses and features are written for each translation.</p>
<p>The HiFST <code>alilats2splats</code> command is </p>
<pre class="fragment">&gt; alilats2splats.O2 --config=configs/CF.lmert.vecfea --range=1:$M --featureweights=$FW --sparseweightvectorlattice.loadalilats=output/exp.lmert/$it/ALILATS/?.fst.gz --sparseweightvectorlattice.store=output/exp.lmert/$it/VECFEA/?.fst.gz
</pre><h1><a class="anchor" id="lmert_lmert"></a>
4. LMERT</h1>
<ul>
<li>Input:<ul>
<li><code>$it</code> &ndash; lmert iteration (1, 2, ...)</li>
<li><code>$M</code> &ndash; number of sentences to process</li>
<li><code>output/exp.lmert/$it/VECFEA/?.fst.gz</code> &ndash; translation lattices (WFSAs) with unweighted feature vectors (from <a class="el" href="lmert.html#lmert_alilats">3. WFSAs with Unweighted Feature Vectors</a>)</li>
<li><code>EN/EN.tune.idx</code> &ndash; target language references in integer format</li>
</ul>
</li>
<li>Output:<ul>
<li><code>output/exp.lmert/params.$it</code> &ndash; reestimated feature vector under LMERT with BLEU</li>
</ul>
</li>
</ul>
<p><code>latmert</code> runs as follows </p>
<pre class="fragment">&gt; latmert.O2 --search=random --random_axes --random_directions=28 --direction=axes --threads=24 --cache_lattices --error_function=bleu --algorithm=lmert --idxlimits=1:$M --print_precision=6 --lats=output/exp.lmert/$it/VECFEA/%idx%.fst.gz --lambda=$FW --write_parameters=output/exp.lmert/params.$it  EN/EN.tune.idx
</pre><h1><a class="anchor" id="lmert_veclats_tst"></a>
Notes on Tropical Sparse Tuple Vector Weights</h1>
<p>The output lattices in <code>output/exp.lmert/$it/lats/VECFEA</code> are <code>tropicalsparsetuple</code> vector weight lattices. </p>
<pre class="fragment">&gt; zcat output/exp.mert/1/lats/VECFEA/1.fst.gz | fstinfo | head -n 2
fst type                                          vector
arc type                                          tropicalsparsetuple
</pre><p>The scores in these lattices are unweighted by the feature vector weights, i.e. they are the raw feature scores against which L/MERT finds the optimal parameter vector values. Distances under these unweighted vectors do not agree with the initial translation hypotheses, e.g. the shortest-path does not agree with the best translation: </p>
<pre class="fragment">&gt; unset TUPLEARC_WEIGHT_VECTOR
&gt; zcat output/exp.mert/1/lats/VECFEA/1.fst.gz | fstshortestpath | fsttopsort | fstpush --to_final --push_weights | fstprint -isymbols=wmaps/wmt13.en.all.wmap
Warning: cannot find parameter vector. Defaulting to flat parameters
Warning: cannot find parameter vector. Defaulting to flat parameters
0       1       &lt;s&gt;     1
1       2       parliament      50
2       3       not     20
3       4       supports        1463
4       5       amendment       245
5       6       ,       4
6       7       gives   1145
7       8       freedom 425
8       9       tymoshenko      23899
9       10      &lt;/s&gt;    2
10      0,10,1,35.6919899,2,6.59277344,3,14.2285156,4,-10,5,-10,6,-6,8,-1,10,-9,11,8.2109375,12,13.7412109,
</pre><p>The sparse vector weight format is </p>
<pre class="fragment">0,N,idx_1,fea_1,...,idx_N,fea_N
</pre><p>where N is the number of non-zero elements in that weight vector.</p>
<p>To compute semiring costs correctly, the <code>TUPLEARC_WEIGHT_VECTOR</code> environment variable should be set to contain the correct feature vector weight; this should be the same feature vector weight applied in translation in steps 1 and 2: </p>
<pre class="fragment">TUPLEARC_WEIGHT_VECTOR=[s_1 ... s_m w_1 ... w_n]
</pre><p>which in this particular example is </p>
<pre class="fragment">&gt; export TUPLEARC_WEIGHT_VECTOR="1,0.697263,0.396540,2.270819,-0.145200,0.038503,29.518480,-3.411896,-3.732196,0.217455,0.041551,0.060136"
</pre><p>The shortest path found through the vector lattice is then the same hypothesis produced under the initial parameter settings: </p>
<pre class="fragment">&gt; zcat output/exp.mert/1/lats/VECFEA/1.fst.gz | fstshortestpath | fsttopsort | fstpush --to_final --push_weights | fstprint -isymbols=wmaps/wmt13.en.all.wmap
0       1       &lt;s&gt;     1
1       2       parliament      50
2       3       supports        1463
3       4       amendment       245
4       5       giving  803
5       6       freedom 425
6       7       tymoshenko      23899
7       8       &lt;/s&gt;    2
8       0,10,1,20.7773838,2,7.80957031,3,17.8671875,4,-8,5,-8,6,-5,9,-1,10,-7,11,20.0175781,12,18.2978516,
</pre><p>Note that printstrings can be used to extract n-best lists from the vector lattices, if the TUPLEARC_WEIGHT_VECTOR is correctly set: </p>
<pre class="fragment">&gt; zcat output/exp.mert/1/lats/VECFEA/1.fst.gz | printstrings.O2 --semiring=tuplearc --nbest=10 --unique -w -m wmaps/wmt13.en.all.wmap --tuplearc.weights=$TUPLEARC_WEIGHT_VECTOR 2&gt;/dev/null
&lt;s&gt; parliament supports amendment giving freedom tymoshenko &lt;/s&gt;        20.7778,7.80957,17.8672,-8,-8,-5,0,0,-1,-7,20.0176,18.2979
&lt;s&gt; parliament supports amendment gives freedom tymoshenko &lt;/s&gt;         20.7773,8.48828,20.9248,-8,-8,-4,0,-1,0,-7,14.1162,14.1016
&lt;s&gt; parliament supports amendment giving freedom timoshenko &lt;/s&gt;        20.7778,9.70703,17.7393,-8,-8,-5,0,0,-1,-7,22.166,18.2529
&lt;s&gt; parliament supports correction giving freedom tymoshenko &lt;/s&gt;       20.7768,9.15527,18.6689,-8,-8,-4,0,0,-1,-7,22.4062,20.7334
&lt;s&gt; parliament supports amendment giving liberty tymoshenko &lt;/s&gt;        20.7768,10.2051,18.3838,-8,-8,-5,0,0,-1,-7,22.6582,19.4707
&lt;s&gt; parliament supports amendment gives freedom timoshenko &lt;/s&gt;         20.7773,10.1602,21.0596,-8,-8,-4,0,-1,0,-7,16.2646,14.0566
&lt;s&gt; parliament supports amendment enables freedom tymoshenko &lt;/s&gt;       20.7768,8.48828,20.0742,-8,-8,-4,0,-1,0,-7,50.2627,17.0137
&lt;s&gt; parliament supports amendment enable freedom tymoshenko &lt;/s&gt;        20.7768,8.48828,20.6904,-8,-8,-4,0,-1,0,-7,50.2627,15.3457
&lt;s&gt; parliament not supports amendment giving freedom tymoshenko &lt;/s&gt;    29.3873,5.82324,12.8096,-9,-9,-6,0,0,-1,-8,16.1914,17.9443
&lt;s&gt; parliament supports amendment providing freedom tymoshenko &lt;/s&gt;     20.7769,8.48828,21.1689,-8,-8,-4,0,-1,0,-7,50.2627,17.3027
</pre><p>These should agree with n-best lists generated directly by alilats2splats</p>
<ul>
<li>N.B. There can be significant numerical differences between computations under the tropical lexicographic semiring vs the tuplearc semiring: printstrings and alilats2splats might not give exactly the same results. In such cases, the alilats2splats result is probably the better choice. </li>
</ul>
</div></div><!-- contents -->
</div><!-- doc-content -->
<!-- start footer part -->
<div id="nav-path" class="navpath"><!-- id is needed for treeview function! -->
  <ul>
    <li class="footer">Generated on Mon May 26 2014 02:37:40 for Cambridge SMT System by
    <a href="http://www.doxygen.org/index.html">
    <img class="footer" src="doxygen.png" alt="doxygen"/></a> 1.8.3 </li>
  </ul>
</div>
</body>
</html>
