<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.8.3"/>
<title>Cambridge SMT System: Getting Started</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="navtree.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="resize.js"></script>
<script type="text/javascript" src="navtree.js"></script>
<script type="text/javascript">
  $(document).ready(initResizable);
  $(window).load(resizeHeight);
</script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td style="padding-left: 0.5em;">
   <div id="projectname">Cambridge SMT System
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.8.3 -->
</div><!-- top -->
<div id="side-nav" class="ui-resizable side-nav-resizable">
  <div id="nav-tree">
    <div id="nav-tree-contents">
      <div id="nav-sync" class="sync"></div>
    </div>
  </div>
  <div id="splitbar" style="-moz-user-select:none;" 
       class="ui-resizable-handle">
  </div>
</div>
<script type="text/javascript">
$(document).ready(function(){initNavTree('start.html','');});
</script>
<div id="doc-content">
<div class="header">
  <div class="headertitle">
<div class="title">Getting Started </div>  </div>
</div><!--header-->
<div class="contents">
<div class="textblock"><h1><a class="anchor" id="build"></a>
Installation of UCAM-SMT package</h1>
<p>The code can be cloned from the following GitHub address: </p>
<pre class="fragment">&gt; git clone https://github.com/ucam-smt/ucam-smt.git
</pre><p>Once downloaded, go into the cloned directory and run this command: </p>
<pre class="fragment">&gt; ./build-tests.sh
</pre><p>This should download and install necessary dependencies, compile the code and run tests. The <code>README.md</code> in the cloned directory also contains useful information for the installation.</p>
<h1><a class="anchor" id="paths"></a>
Paths and Environment Variables</h1>
<p>The following instructions are for the Bash shell.</p>
<p>In the following, <code>HiFSTROOT</code> designates the cloned directory, i.e. the following should be a complete path to the cloned directory </p>
<pre class="fragment">&gt; export HiFSTROOT=complete_path_to_hifst_cloned_directory
</pre><p>After HiFST is successfully built and tested, the file $HiFSTROOT/Makefile.inc will contain environment variable settings needed to run the HiFST binaries and the OpenFST tools using the HiFST libraries. To set these, simply run </p>
<pre class="fragment">&gt; source $HiFSTROOT/Makefile.inc
&gt; export PATH=$HiFSTROOT/bin:$OPENFST_BIN:$PATH
&gt; export LD_LIBRARY_PATH=$HiFSTROOT/bin:$OPENFST_LIB
</pre><p>You should make sure that $HiFSTBINDIR is added first on the path and the library path and that it preceeds the OpenFst directories. If the LD_LIBRARY_PATH variable is not set correctly, you will see the message </p>
<pre class="fragment">ERROR: GenericRegister::GetEntry : tropical_LT_tropical-arc.so: cannot open shared object file: No such file or directory
ERROR: ReadFst : unknown arc type "tropical_LT_tropical" : standard input
</pre><h1><a class="anchor" id="Setup_files"></a>
Tutorial Files</h1>
<p>Files for this tutorial can be downloaded from the following GitHub address: </p>
<pre class="fragment">&gt; git clone https://github.com/ucam-smt/demo-files.git
&gt; cd demo-files; gunzip wmaps/*.gz  ## Uncompress big wordmap files.
</pre><p>The following directories contain the data files, configuration files, and model files needed for this tutorial. </p>
<pre class="fragment"> ./
 |-configs/ # Configuration files
 |-EN/      # English reference text
 |-G/       # Translation grammars
 |-M/       # Language models
 |-RU/      # Russian input text
 |-scripts/ # Scripts for these demonstration exercises
 |-wmaps/   # Word maps, to map English and Russian text to integers
</pre><p>The following directories will be created after running this tutorial. </p>
<pre class="fragment"> ./
 |-log/     # Translation process log files
 |-output/  # Translation output, as 1-best hypotheses and lattices
</pre><p>There are additional Supplementary Files which can be downloaded from <a href="http://mi.eng.cam.ac.uk/~wjb31/data/hifst.release.May14/">http://mi.eng.cam.ac.uk/~wjb31/data/hifst.release.May14/</a> .</p>
<h2><a class="anchor" id="Setup_configs"></a>
Configuration Files and Command Line Options</h2>
<p>As you work through the tutorial, please read the comments in the config files which explain some of the processing options. The following configuration files are provided for the tutorial. </p>
<pre class="fragment"> # baseline configuration: 4-gram LM and Shallow-1 translation grammar
 configs/CF.baseline : HiFST with 4-gram language model and a Shallow-1 grammar
 configs/CF.baseline.lmbr : lattice Minimum Bayes' Risk (LMBR) rescoring on top of baseline system
 configs/CF.baseline.outputnoprune : lattice output without pruning
 configs/CF.baseline.outputnoprune.lmrescore : lattice rescoring with language models
 # full Hiero grammar with 4-gram LM
 configs/CF.hiero : full Hiero grammar without pruning in search
 configs/CF.hiero.chopping : methods for dealing with long source sentences
 configs/CF.hiero.localprune  : full Hiero grammar with pruning in search
 configs/CF.hiero.pdt : full Hiero grammar, decoding with push-down automata (HiPDT)
 # full, iterative lattice MERT script
 configs/CF.lmert.alilats : Lattice MERT example, alignment lattices
 configs/CF.lmert.hyps : Lattice MERT example, initial hypotheses
 configs/CF.lmert.vecfea : Lattice MERT example, vector feature lattices
 # example feature generation for MERT and LMERT
 configs/CF.mert.alilats.nbest : MERT features, derivation-to-translation transducers, restricted to N-Best lists
 configs/CF.mert.hyps : MERT features, initial hypotheses
 configs/CF.mert.vecfea.nbest  : MERT features, N-Best feature lists for MERT
 # misc
 configs/CF.recaser : recasing examples
 configs/CF.baseline.client : HiFST client-server example, client
 configs/CF.baseline.server : HiFST client-server example, server
</pre><p>HiFST uses the Boost libraries which provide support for <a href="http://www.boost.org/doc/libs/1_55_0/doc/html/program_options/overview.html">configuration files</a>.</p>
<p>Parameters can be supplied either on the command line or in the config files. For example, the following options could be provided on the command line: </p>
<pre class="fragment"> --hifst.prune=9 --hifst.replacefstbyarc.nonterminals=X,V
</pre><p>Alternatively, they could be specified in a configuration file either as </p>
<pre class="fragment"> hifst.prune=9
 hifst.replacefstbyarc.nonterminals=X,V
</pre><p>or as </p>
<pre class="fragment"> [hifst]
 prune=9
 replacefstbyarc.nonterminals=X,V
</pre><h2><a class="anchor" id="wmaps"></a>
Word Maps and Integer Mapped Files</h2>
<p>HiFST uses <a href="http://www.openfst.org/twiki/bin/view/FST/FstAdvancedUsage#Symbol_Tables">symbol tables</a> as provided by <a class="el" href="index.html#OpenFst">OpenFst</a> to map between source and target language text and the integer representation used internally by the decoder. See the <a class="el" href="index.html#OpenFst">OpenFst</a> <a href="http://www.openfst.org/twiki/bin/view/FST/FstQuickTour">Quick Tour</a> for a discussion of the use of symbol tables.</p>
<p>Integer mappings for English and Russian are in the directory wmaps/ : </p>
<pre class="fragment"> wmaps/wmt13.en.wmap
 wmaps/wmt13.en.all.wmap (a much larger version of wmaps/wmt13.en.wmap)
 wmaps/wmt13.ru.wmap
 wmaps/wmt13.ru.all.wmap (a much larger version of wmaps/wmt13.ru.wmap)
</pre><p>Note that HiFST reserves the integers 1 and 2 for the sentence-start and sentence-end symbols. 0 is the OpenFST epsilon symbol.</p>
<p>The format of the wordmap files is straightforward, e.g. </p>
<pre class="fragment"> &gt; head wmaps/wmt13.en.wmap
 &lt;epsilon&gt;                0
 &lt;s&gt;                      1
 &lt;/s&gt;                     2
 the                      3
 ,                        4
 .                        5
 of                       6
 to                       7
 and                      8
 in                       9
</pre><p>Source text files are provided in integer format : </p>
<pre class="fragment"> RU/RU.set1.idx : integer mapped Russian text

 &gt; head -2 RU/RU.set1.idx
 1 20870 2447 5443 50916 78159 3621 2
 1 1716 20196 95123 154 1049 6778 996 9 239837 7 1799 4 2
</pre><p>The <a href="http://openfst.org/twiki/bin/view/FST/FstExtensions">FAR</a> tools can be used to generate Russian text from the integer mapped files (see the discussion on <a class="el" href="basic.html#basic_latshyps">Translation Lattices and 1-Best Hypotheses</a>). </p>
<pre class="fragment"> &gt; farcompilestrings --entry_type=line RU/RU.set1.idx | farprintstrings --symbols=wmaps/wmt13.ru.wmap | head -2
 &lt;s&gt; республиканская стратегия сопротивления повторному избранию обамы &lt;/s&gt;
 &lt;s&gt; лидеры республиканцев оправдывали свою политику необходимостью борьбы с фальсификациями на выборах . &lt;/s&gt;
</pre><h2><a class="anchor" id="lms"></a>
Language Models</h2>
<p>English 3-gram and 4-gram language models are provided in both <a href="http://kheafield.com/code/kenlm/">KenLM</a> and <a href="http://www.speech.sri.com/projects/srilm/manpages/ngram-format.5.html">ARPA</a> formats . See [<a class="el" href="index.html#Pino2013">Pino2013</a>] for a description of how these LMs are built.</p>
<p>The following language models have restricted vocabulary corresponding to the target side of the rules that apply to the first few sentences of the tuning set RU.set1.idx . This is done so that the LMs are small and quickly and easily loaded into memory. <em>Do not use these models except for the first few sentences in this tutorial.</em> </p>
<pre class="fragment"> M/lm.3g.arpa.gz : Kneser-Ney 3-gram language model in ARPA format
 M/lm.3g.mmap : Kneser-Ney 3-gram language model in KenLM format
 M/lm.4g.arpa.gz : Kneser-Ney 4-gram language model in ARPA format
 M/lm.4g.mmap : Kneser-Ney 4-gram language model in KenLM format
 M/lm.4g.eprnd.mmap : entropy pruned KN 4-gram LM in KenLM format
 M/lm.tc.gz : true-casing language model
</pre><p>The following large LMs are available from a separate download site (see <a class="el" href="start.html#build">Installation of UCAM-SMT package</a>). It covers the target-side vocabulary for the large translation grammars, and is suitable for running on the complete tune and test set included in this tutorial. In particular, this second LM must be downloaded and uncompressed into the M/ directory prior to running the MERT and LMERT scripts and examples (see <a class="el" href="mert.html">MERT - Features Only</a> and <a class="el" href="lmert.html">Lattice MERT</a>). </p>
<pre class="fragment"> M/interp.4g.arpa.newstest2012.tune.corenlp.ru.idx.union.mmap : KN 4gram LM in KenLM format
 M/interp.4g.arpa.newstest2012.tune.corenlp.ru.idx.withoptions.mmap : quantized KN 4gram LM in KenLM format
</pre><p>Language models are in integer mapped format, e.g. for the ARPA files: </p>
<pre class="fragment"> &gt; zcat M/lm.3g.arpa.gz | grep . | head -15
 \data\
 ngram 1=1348
 ngram 2=130054
 ngram 3=785733
 \1-grams:
 -1.0615243 &lt;unk&gt;
 -inf               &lt;s&gt;     -1.0853117
 -1.5690455 &lt;/s&gt;
 -2.2388144 12      -1.0949439
 -2.682596  11      -0.872226
 -4.0860014 1547    -0.66412055
 -2.4807615 14      -0.8686333
 -2.9167347 25      -0.7014704
 -2.599824  22      -0.6987488
 -2.6652465 26      -0.7175091
</pre><p>We also provide an <em>entropy pruned</em> [<a class="el" href="index.html#SRILM">SRILM</a>] version of the 4-gram language model as used for decoding with Push-Down Automata [<a class="el" href="index.html#Allauzen2014">Allauzen2014</a>] ; this is described below in <a class="el" href="md_Tutorial.html#pda">Translation with Push-Down Automata</a> . </p>
<pre class="fragment"> M/lm.4g.eprnd.arpa.gz : Entropy-pruned Kneser-Ney 4-gram language model in ARPA format
 M/lm.4g.eprnd.mmap : Entropy-pruned Kneser-Ney 4-gram language model in KenLM format
</pre><h2><a class="anchor" id="tgrammars"></a>
Translation Grammars</h2>
<p>HiFST uses Synchronous Context-Free Grammars (SCFGs) for translation. A full Hiero and a Shallow-1 translation grammar are provided in the <code>G/</code> directory: </p>
<pre class="fragment"> G/rules.hiero.gz : full hiero grammar with scalar translation scores
 G/rules.shallow.gz : Shallow-1 hiero grammar with scalar translation scores
</pre><p>We also provide versions of these grammars with raw, unweighted feature scores: </p>
<pre class="fragment"> G/rules.hiero.vecfea.gz : full hiero grammar with feature vectors
 G/rules.shallow.vecfea.gz : Shallow-1 hiero grammar with feature vectors
</pre><p>For the tutorial on optimization (<a class="el" href="mert.html">MERT - Features Only</a>), larger grammars corresponding to the entire <code>RU/RU.tune.idx</code> tune set are provided: </p>
<pre class="fragment"> G/rules.shallow.all.gz : larger Shallow-1 hiero grammar with scalar translation scores
 G/rules.shallow.vecfea.allgz : larger Shallow-1 hiero grammar with feature vectors
</pre><p>There is also a grammar provided for the true-casing example (<a class="el" href="md_Tutorial.html#true_casing">Fst-based True casing</a>) </p>
<pre class="fragment">  G/tc.unimap
</pre><h3><a class="anchor" id="rules"></a>
Grammar File Formats</h3>
<p>In the grammar file, each line represents a rule. The rule format is: </p>
<pre class="fragment"> LHS RHS_SOURCE RHS_TARGET FEA_1 [FEA_2 FEA_3 FEA_4 ...]
</pre><p>where </p>
<pre class="fragment"> LHS = the left hand side of the rule
 RHS_SOURCE = the source-language part of the right hand side of the rule
 RHS_TARGET = the target-language part of the right hand side of the rule
 FEA_i = the i-th component of the feature vector associated with the rule
</pre><p>The left hand side of a rule is a non-terminal symbol (in uppercase). The right hand side is a pair of terminal and non-terminal symbol sequences in the source and target languages.</p>
<h4><a class="anchor" id="tgrammars_formats_fea"></a>
Feature Vectors</h4>
<p>Scores are assigned to rules as the dot product of a rule-specific feature vector and a weight vector (see the discussion in <a class="el" href="mert.html">MERT - Features Only</a>). This computation can be done offline, in which case the feature for every rule in the grammar is a 1-dimensional scalar. Alternatively, the decoder can be provided with a weight vector which is applied to the feature vectors while loading the grammar.</p>
<p>For example, the grammar <code>G/rules.shallow.gz</code> provided in this tutorial the following set of weights was found via LMERT tuning (see <a class="el" href="mert.html">MERT - Features Only</a> ): </p>
<pre class="fragment">0.697263,0.396540,2.270819,-0.145200,0.038503,29.518480,-3.411896,-3.732196,0.217455,0.041551,0.060136
</pre><p>These can be applied to the Shallow-1 grammar, as follows: </p>
<pre class="fragment">&gt; WV=0.697263,0.396540,2.270819,-0.145200,0.038503,29.518480,-3.411896,-3.732196,0.217455,0.041551,0.060136
&gt; zcat G/rules.shallow.vecfea.gz | scripts/weightgrammar -w=$WV | head -3
V 3 4 -2.046860955276
V 3 4_3 -1.884009085882
V 3 8 1.857985226112
</pre><p>and this should agree with the scalar-valued version of the grammar: </p>
<pre class="fragment">&gt; zcat G/rules.shallow.gz | head -3
V 3 4 -2.046860955276
V 3 4_3 -1.884009085882
V 3 8 1.857985226112
</pre><h4><a class="anchor" id="tgrammars_formats_nt"></a>
Non-Terminals</h4>
<p>In translation, a non-terminal <code>X</code> on the right hand side can be rewritten by any rule whose left hand side is <code>X</code>. HiFST places no restrictions on the definition of terminal and non-terminal sequences in an SCFG rule; similarly, there are no constraints on how many non-terminal symbols can be used in a rule (i.e. there are no constraints on order of the SCFG). However using a full Hiero grammar can lead to slow translation, and this tutorial discusses several strategies for pruning in translation and for translation grammar pruning.</p>
<p>Here is a small sample translation grammar </p>
<pre class="fragment"> M 434_M 1462_8_M -1.81842
 M 7_M 9_3_M -0.735445
 M V V -0
 S S_X S_X 0.05768
 S X X -0
 V 10806 1411 1.16623
 V 164_M_60 78_M_8 -0.226464
 V 164_M2_60_M1 78_M1_8_M2 -0.226464
 V 21_591 39_258_8 -0.510102
 V 24 3_54 -2.50252
 V 274_M_4 709_9_3_M -0.589246
 V 5 6 -1.81729
 V 7_1689 9_741_8 0.438945
 V 8 23 -1.46604
 X 1 1 -2.5598
 X 2 2 -2.5598
 X V V -0
 D 1775 &lt;dr&gt; 10.4327
 S S_D_X S_D_X 0.11536
</pre><p>This grammar has four non-terminal symbols: <code>S</code>, <code>M</code>, <code>V</code> and <code>D</code>, and a 1-dimensional weight. The terminal symbols are integers, corresponding to words in the source and target language word maps (<a class="el" href="start.html#wmaps">Word Maps and Integer Mapped Files</a>). The symbol <code>&lt;dr&gt;</code> is a special symbol used by HiFST to represent an empty word, to indicate deletion.</p>
<p>As an example, for rule </p>
<pre class="fragment"> V 164_M_60 78_M_8 -0.226464
</pre><p>we have </p>
<pre class="fragment"> LHS        = V
 RHS_SOURCE = 164_M_60
 RHS_TARGET = 78_M_8
 WEIGHT_1   = -0.226464
</pre><p>With this rule the decoder can rewrite the non-terminal <code>V</code> by replacing it by <code>164_M_60</code> in the source language and by <code>78_M_8</code> in the target language; the rule is applied with a score of -0.226464. Similarly, rule <code>V 5 6 -1.81729</code> replaces <code>V</code> by the word "5" in the source-language and with the word "6" in the target-language, with a score of -1.81729.</p>
<p>Indices on non-terminals indicate alignment within rules with more than one non-terminal. For example, for rule </p>
<pre class="fragment">V 164_M2_6_M1 78_M1_8_M2 -0.226464
</pre><p>the <code>M</code> non-terminals on both language sides are indexed by 1 or 2; that is, <code>M1</code> in the source language is linked with <code>M1</code> in the target language, and <code>M2</code> in the source language is linked with <code>M2</code> in the target. Strictly speaking, <code>M2</code> is not a non-terminal in the above example: it is the second instance of the non-terminal <code>M</code> in the rule. Obviously this is a reordering rule.</p>
<p>In general we use different types of rule to distinguish different translation cases and obtain a finer-grained model. In this example, the <code>S</code> rules are doing something rather similar to the glue rules used in Hiero-style systems; the <code>M</code> rules can be regarded as monotonic translation rules; the <code>V</code> rules can be regarded as reordering translation rules and phrasal translation rules; and the <code>D</code> rule can be regarded as an explicit operation of word deletion.</p>
<p>Note that there is a straight-forward correspondence between the Hiero-style rule notation introduced by [<a class="el" href="index.html#Chiang2007">Chiang2007</a>] and the HiFST rule file format (for rules with one-dimensional weights). For example, the HiFST grammar file entries </p>
<pre class="fragment">V 164_M2_6_M1 78_M1_8_M2 -0.226464
S S_X S_X 0.05768
</pre><p>can be written as </p>
<pre class="fragment">V -&gt; &lt; 164 M2 6 M1 ,  78 M1 8 M2 &gt; / -0.226464
S -&gt; &lt; S X , S X &gt; / 0.05768
</pre><h3><a class="anchor" id="tgrammars_shallow"></a>
Shallow-N Translation Grammars</h3>
<p>Shallow grammars [<a class="el" href="index.html#deGispert2010">deGispert2010</a>] can be used to control the degree of nesting allowed within an hierarchical grammar. For example, for a Shallow-1 Grammar, variables in a rule can be substituted only by phrases. That is, hierarchical rules can be used only once to generate words; once a hierarchical rule is used, translation relies on glue rules to cover longer source spans.</p>
<p>Formally, we use W to denote the set of terminals, and S and X to denote two non-terminals. A simple Hiero-style grammar can be defined to be: </p>
<pre class="fragment"> S -&gt; X, X
 S -&gt; S X, S X
 X -&gt; a, b        where a, b \in ({X} union W)^+
</pre><p>We can transform this into a Shallow-1 grammar as </p>
<pre class="fragment"> S -&gt; X, X
 S -&gt; S X, S X
 Y -&gt; a, b        where a, b \in {W}^+
 X -&gt; u, v        where u, v \in {{Y} union W}^+
</pre><p>Here <code>Y</code> is introduced to handle phrasal translations. The variables in rule <code>X -&gt; u, v</code> can only be substituted with the <code>Y</code> rules.</p>
<p>In some cases it is desirable to allow more complex movement in translation, such as complex structure movements in Chinese-English translation. For this we can use a generalisation of the simple Shallow-1 grammar, called Shallow-N grammars. These grammars allow hierarchical rules to be applied up to N times. For example, below is the form of a Shallow-2 grammar. </p>
<pre class="fragment"> S -&gt; X, X
 S -&gt; S X, S X
 Y^0 -&gt; a^0, b^0  where a^0, b^0 \in {W}^+
 Y^1 -&gt; a^1, b^1  where a^1, b^1 \in {{Y^0} union W}^+
 X -&gt; u, v        where u, v \in {{Y^1} union W}^+
</pre><p>The Shallow-2 grammar introduces <code>Y^0</code> and <code>Y^1</code> to handle hierarchical rule application at two levels within a derivation. For more detailed description of Shallow-n grammars, please refer to the HiFST paper [<a class="el" href="index.html#deGispert2010">deGispert2010</a>]. </p>
</div></div><!-- contents -->
</div><!-- doc-content -->
<!-- start footer part -->
<div id="nav-path" class="navpath"><!-- id is needed for treeview function! -->
  <ul>
    <li class="footer">Generated on Mon May 26 2014 02:37:40 for Cambridge SMT System by
    <a href="http://www.doxygen.org/index.html">
    <img class="footer" src="doxygen.png" alt="doxygen"/></a> 1.8.3 </li>
  </ul>
</div>
</body>
</html>
