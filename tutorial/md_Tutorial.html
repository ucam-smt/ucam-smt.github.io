<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.8.3"/>
<title>Cambridge SMT System: Pruning</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="navtree.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="resize.js"></script>
<script type="text/javascript" src="navtree.js"></script>
<script type="text/javascript">
  $(document).ready(initResizable);
  $(window).load(resizeHeight);
</script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td style="padding-left: 0.5em;">
   <div id="projectname">Cambridge SMT System
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.8.3 -->
</div><!-- top -->
<div id="side-nav" class="ui-resizable side-nav-resizable">
  <div id="nav-tree">
    <div id="nav-tree-contents">
      <div id="nav-sync" class="sync"></div>
    </div>
  </div>
  <div id="splitbar" style="-moz-user-select:none;" 
       class="ui-resizable-handle">
  </div>
</div>
<script type="text/javascript">
$(document).ready(function(){initNavTree('md_Tutorial.html','');});
</script>
<div id="doc-content">
<div class="header">
  <div class="headertitle">
<div class="title">Pruning </div>  </div>
</div><!--header-->
<div class="contents">
<div class="textblock"><h1><a class="anchor" id="lpruning"></a>
Local pruning / pruning in search</h1>
<p>Local pruning controls processing speed and memory use during translation. Only enough details are reviewed here to describe how HiFST performs pruning in search; for a detailed discussion of local pruning and pruning in search, see Section 2.2.2 of [<a class="el" href="index.html#deGispert2010">deGispert2010</a>].</p>
<p>Given a translation grammar and a source language sentence, HiFST first constructs a Recursive Transition Network (RTN) representing the translation hypotheses [<a class="el" href="index.html#Iglesias2009">Iglesias2009</a>, <a class="el" href="index.html#Iglesias2011">Iglesias2011</a>]. This is done as part of a modified CYK algorithm used to parse the source sentence under the translation grammar. The RTN is then <em>expanded</em> to an equivalent WFSA via the <a class="el" href="index.html#OpenFst">OpenFst</a> <a href="http://openfst.cs.nyu.edu/twiki/bin/view/FST/ReplaceDoc">Replace</a> operation. This WFSA contains the translation hypotheses along with their scores under the translation grammar. We refer to this as the `top-level' WFSA, because it is associated with the top-most cell in the CYK grid. This top-level WFSA can be pruned after composition with the language model, as described in the discussion of <a class="el" href="basic.html#basic_toplevelpruning">Admissible pruning / top-level pruning</a>. We refer to this as <em>exact search</em> or <em>exact translation</em>. In exact translation, no translation hypotheses are discarded prior to applying the complete translation and language model scores.</p>
<p>Exact translation can be done under some combinations of translation grammars, language models, and language pairs. In particular, the <a class="el" href="start.html#tgrammars_shallow">Shallow-N Translation Grammars</a> were designed for exact search. However attempting exact translation under many translation grammars would cause either the <a href="http://openfst.cs.nyu.edu/twiki/bin/view/FST/ReplaceDoc">Replace</a> operation or the subsequent language model composition to become computationally intractable. We therefore have developed a pruning strategy that prunes the RTN during its construction.</p>
<p>The RTN created by HiFST can be described as follows:</p>
<ul>
<li><img class="formulaInl" alt="$X$" src="form_0.png"/> is the set of non-terminals in the translation grammar, with <img class="formulaInl" alt="$S$" src="form_1.png"/> as the root</li>
<li><img class="formulaInl" alt="$\Sigma$" src="form_2.png"/> is the target language vocabulary, i.e. the terminals in the target language</li>
<li><img class="formulaInl" alt="$I$" src="form_3.png"/> is the length of the source sentence <img class="formulaInl" alt="$s$" src="form_4.png"/>, i.e. <img class="formulaInl" alt="$s = s_0...s_{I - 1}$" src="form_5.png"/></li>
<li>A new set of non-terminals is defined as <img class="formulaInl" alt="$N = \{ (x,i,j) : x \in X , 0 <= i <= j < I \}$" src="form_6.png"/><ul>
<li>Note that <img class="formulaInl" alt="$(S,0,I-1) \in N$" src="form_7.png"/></li>
</ul>
</li>
<li><img class="formulaInl" alt="$(T_u)_{u \in N}$" src="form_8.png"/>, is a family of WFSAs with input alphabet <img class="formulaInl" alt="$\Sigma \cup N$" src="form_9.png"/><ul>
<li>Each <img class="formulaInl" alt="$T_u$" src="form_10.png"/> with <img class="formulaInl" alt="$u = (x, i, j)$" src="form_11.png"/>, is a WFSA that describes all applications of translation rules with left-hand side non-terminal <img class="formulaInl" alt="$x$" src="form_12.png"/> that span the substring <img class="formulaInl" alt="$s_i ... s_j$" src="form_13.png"/></li>
<li><img class="formulaInl" alt="$T_u$" src="form_10.png"/> is associated with the CYK grid cell associated with source space <img class="formulaInl" alt="$[i,j]$" src="form_14.png"/> and headed by non-terminal <img class="formulaInl" alt="$x$" src="form_12.png"/></li>
</ul>
</li>
<li>The top-level RTN is defined as <img class="formulaInl" alt="$R_{(S,0,I-1)} = (N, \Sigma, (T_u)_{u \in N}, (S,0,I-1))$" src="form_15.png"/>.<ul>
<li>The root symbol of this RTN is <img class="formulaInl" alt="$(S,0,I-1)$" src="form_16.png"/>.</li>
<li>The WFSA <img class="formulaInl" alt="$T_{(S,0,I-1)}$" src="form_17.png"/> represents all applications of translation rules that span the entire sentence and are rooted with non-terminal <img class="formulaInl" alt="$S$" src="form_1.png"/>.</li>
</ul>
</li>
</ul>
<p>Exact translation is achieved if every <img class="formulaInl" alt="$T_u$" src="form_10.png"/> is complete (i.e. if no pruning is done) prior to the <a class="el" href="index.html#OpenFst">OpenFst</a> <a href="http://openfst.org/twiki/bin/view/FST/ReplaceDoc">Replace</a> operation on the RTN <img class="formulaInl" alt="$R_{(S,0,I-1)}$" src="form_18.png"/>. This produces a WFSA that contains all translations that can be produced under the translation grammar.</p>
<p>The RTN pruning strategy relies on noting that each of the WFSAs <img class="formulaInl" alt="$T_{u'}$" src="form_19.png"/>, <img class="formulaInl" alt="$u' = (x', i', j')$" src="form_20.png"/>, also defines an RTN <img class="formulaInl" alt="$R_{u'}$" src="form_21.png"/>, as follows:</p>
<ul>
<li>Define a subset of non-terminals <img class="formulaInl" alt="$N' = \{ (x,i,j) : x \in X , i' <= i <=j < j' \}$" src="form_22.png"/> , i.e. <img class="formulaInl" alt="$N' \subset N$" src="form_23.png"/></li>
<li><img class="formulaInl" alt="$R_{u'} = (N', (T_u)_{u \in N'}, (x', i', j') )$" src="form_24.png"/><ul>
<li>The root symbol of this RTN is <img class="formulaInl" alt="$(x', i', j')$" src="form_25.png"/></li>
</ul>
</li>
</ul>
<p>The <a href="http://openfst.cs.nyu.edu/twiki/bin/view/FST/ReplaceDoc">Replace</a> operation can be applied to the RTNs <img class="formulaInl" alt="$R_{u'}$" src="form_21.png"/> to produce an WFSA containing all translations of the source string <img class="formulaInl" alt="$S_{i'} ... S_{j'}$" src="form_26.png"/> using derivations rooted in the non-terminal <img class="formulaInl" alt="$x'$" src="form_27.png"/>. This WFSA can be pruned and used in place of the original <img class="formulaInl" alt="$T_{u'}$" src="form_19.png"/>.</p>
<p>Because of the possibility of search errors we refer to this as 'local pruning' or inadmissible pruning. There is the possibility that pruning any of the <img class="formulaInl" alt="$T_u$" src="form_10.png"/> may possibly cause some good translations to be discarded. For this reason it is important to tune the pruning strategy for the translation grammar and language model. Once pruning has been set, the benefits are</p>
<ul>
<li>faster creation of the top-level WFSA via the <a href="http://openfst.cs.nyu.edu/twiki/bin/view/FST/ReplaceDoc">Replace</a> operation</li>
<li>faster composition of the translation WFSA with the language model</li>
<li>less memory used in RTN construction and language model composition</li>
</ul>
<p>Local pruning should be done under the combined translation and the language model scores, rather than under the translation grammar scores alone alone. However, the LM used in local pruning can be relatively weak. For example, if the main language model used in translation is a 4-gram, perhaps a 3-gram or even a bigram language model could be used in local pruning. Using a smaller language model will make pruning faster, as will an efficient scheme to remove the scores of the language models used in pruning. The lexicographic semiring, see <a class="el" href="basic.html#basic_scores">Scores, Costs, and Semirings</a>, makes this last operation easy.</p>
<h1><a class="anchor" id="local_prune"></a>
Local Pruning Algorithm</h1>
<p>HiFST monitors the size of the <img class="formulaInl" alt="$T_u$" src="form_10.png"/> during translation. Any of these automata that exceed specified thresholds are converted to WFSAs and pruned. Subsequent expansion of the RTN <img class="formulaInl" alt="$R_{(S,0,I-1)}$" src="form_18.png"/> is then done with respect to the pruned versions of <img class="formulaInl" alt="$T_u$" src="form_10.png"/>.</p>
<p>Local pruning is controlled via the following HiFST parameters: </p>
<pre class="fragment">hifst.localprune.enable=yes # must be set to activate local pruning
hifst.localprune.conditions=NT_1,span_1,size_1,threshold_1,...,NT_N,span_N,size_N,threshold_N
hifst.localprune.lm.load=lm_1,...lm_K
hifst.localprune.lm.featureweights=scale_1,...,scale_K
hifst.localprune.lm.wps=wp_1,...,wp_K
</pre><p>In the above, an arbitrary number N of tuples (<code>NT_n</code>, <code>span_n</code>, <code>size_n</code>, <code>threshold_n</code>) can be provided; similarly, an arbitrary number K of language model parameters (<code>lm_k</code>, <code>scale_k</code>, <code>wp_k</code>) can also be used in pruning.</p>
<p>Pruning is applied during construction of the RTN, as follows:</p>
<ul>
<li>If any <img class="formulaInl" alt="$T_u$" src="form_10.png"/> satisfies the following conditions for any parameter set (<code>NT_n</code>, <code>span_n</code>, <code>size_n</code>, <code>threshold_n</code>), n=1,...,N<ul>
<li>NT_n = X</li>
<li>span_n &lt;= j-i</li>
<li>size_n &lt;= number of states of <img class="formulaInl" alt="$T_u$" src="form_10.png"/>, computed via <a class="el" href="index.html#OpenFst">OpenFst</a> <code>NumStates()</code></li>
</ul>
</li>
<li>then <img class="formulaInl" alt="$T_u$" src="form_10.png"/> is pruned as follows:<ul>
<li>OpenFst <a href="http://openfst.cs.nyu.edu/twiki/bin/view/FST/ReplaceDoc">Replace</a> converts <img class="formulaInl" alt="$R_u$" src="form_28.png"/> to a WFSA</li>
<li><a href="http://www.openfst.org/twiki/bin/view/FST/RmEpsilonDoc">RmEpsilon</a>,<a href="http://www.openfst.org/twiki/bin/view/FST/DeterminizeDoc">Deteminize</a>, and <a href="http://www.openfst.org/twiki/bin/view/FST/MinimizeDoc">Minimize</a> generate a compacted WFSA</li>
<li><a href="http://www.openfst.org/twiki/bin/view/FST/ComposeDoc">Composition</a> with K language model(s) WFSAs<ul>
<li>The parameters (<code>lm_k</code>, <code>scale_k</code>, <code>wp_k</code>) specify the language models, language model scale factors, and word penalties to be applied</li>
</ul>
</li>
<li>OpenFst <a href="http://www.openfst.org/twiki/bin/view/FST/PruneDoc">Prune</a> is applied with threshold <code>threshold_n</code></li>
<li>Language model scores are removed by copying component weights in the lexicographic semiring, see <a class="el" href="basic.html#basic_scores">Scores, Costs, and Semirings</a></li>
<li><a href="http://www.openfst.org/twiki/bin/view/FST/RmEpsilonDoc">RmEpsilon</a>,<a href="http://www.openfst.org/twiki/bin/view/FST/DeterminizeDoc">Deteminize</a>, and <a href="http://www.openfst.org/twiki/bin/view/FST/MinimizeDoc">Minimize</a>, yielding a pruned WFSA <img class="formulaInl" alt="$T_u$" src="form_10.png"/> with only translation scores and target language symbols</li>
</ul>
</li>
<li>The pruned version of <img class="formulaInl" alt="$T_u$" src="form_10.png"/> is then used in place of the original version in the RTN</li>
</ul>
<h1><a class="anchor" id="lpruning_effects"></a>
Effect on Speed, Memory, Scores</h1>
<p>Pruning in search is particularly important when running HiFST with grammars that are more powerful than the shallow grammar used in earlier examples.</p>
<p>For example, HiFST can be run with a full Hiero grammar, while monitoring memory consumption via the UNIX top command: </p>
<pre class="fragment"> &gt; (time hifst.O2 --config=configs/CF.hiero) &amp;&gt; log/log.hiero
</pre><p>The memory use is approximately 2GB and translation takes approximately 1m45s. (The resource consumption may vary depending on your hardware, we provide these numbers to illustrate the effect of local pruning.)</p>
<p>If translation is performed with the same grammar and language model, but with local pruning, </p>
<pre class="fragment"> &gt; (time hifst.O2 --config=configs/CF.hiero.localprune) &amp;&gt; log/log.hiero.localprune
</pre><p>then the memory consumption is reduced to under 300MB and the processing time to approximately 25s. Inspecting the log file indicates that local pruning was applied to 18 sublattices for the second sentence: </p>
<pre class="fragment"> &gt; tail -n 16 log/log.hiero.localprune | head -n 12
 Fri May  9 15:20:38 2014: run.INF:=====Translate sentence 1:1 20870 2447 5443 50916 78159 3621 2
 Fri May  9 15:20:38 2014: run.INF:Loading hierarchical grammar: G/rules.hiero.gz
 Fri May  9 15:20:38 2014: run.INF:loading LM=M/lm.4g.mmap
 Fri May  9 15:20:38 2014: run.INF:loading LM=M/lm.3g.mmap
 Fri May  9 15:20:38 2014: run.INF:Stats for Sentence 1: local pruning, number of times=0
 Fri May  9 15:20:38 2014: run.INF:End Sentence ******************************************************
 Fri May  9 15:20:38 2014: run.INF:Translation 1best is: 1 3 9121 384 6 2756 7 3 4144 6 159312 42 1341 2
 Fri May  9 15:20:38 2014: run.INF:=====Translate sentence 2:1 1716 20196 95123 154 1049 6778 996 9 239837 7 1799 4 2
 Fri May  9 15:20:47 2014: run.INF:Stats for Sentence 2: local pruning, number of times=18
 Fri May  9 15:20:55 2014: run.INF:End Sentence ******************************************************
 Fri May  9 15:20:56 2014: run.INF:Translation 1best is: 1 3 1119 6 3 9121 1711 63 355 85 7 369 24 3 13907 17 3 628 5 2
 Fri May  9 15:20:56 2014: main.INF:hifst.O2 ends!
</pre><p>In this case, local pruning has no effect on the translations produced: </p>
<pre class="fragment"> &gt; head output/exp.hiero.localprune/hyps output/exp.hiero/hyps
 ==&gt; output/exp.hiero.localprune/hyps &lt;==
 1 3 9121 384 6 2756 7 3 4144 6 159312 42 1341 2
 1 3 1119 6 3 9121 1711 63 355 85 7 369 24 3 13907 17 3 628 5 2

 ==&gt; output/exp.hiero/hyps &lt;==
 1 3 9121 384 6 2756 7 3 4144 6 159312 42 1341 2
 1 3 1119 6 3 9121 1711 63 355 85 7 369 24 3 13907 17 3 628 5 2
</pre><p>The effect of pruning can be more dramatic on longer, more difficult to translate sentences. For example, the third sentence in this set is difficult to translate under the full Hiero grammar without pruning, although it can be translated using local pruning as </p>
<pre class="fragment"> &gt; (time hifst.O2 --config=configs/CF.hiero.localprune --range=3:3) &amp;&gt; log/log.hiero.localprune2
</pre><p>Even with local pruning, the processing time for this one sentence is over 4 minutes.</p>
<p>By comparison, translation is much faster with much more aggressive local pruning, which we introduce via command line options to override the settings in the configuration file: </p>
<pre class="fragment"> &gt; (time hifst.O2 --config=configs/CF.hiero.localprune --range=3:3 --hifst.lattice.store=output/exp.hiero.localprunemore/LATS/?.fst.gz --target.store=output/exp.hiero.localprunemore/hyps --hifst.localprune.conditions=X,3,10,1,V,3,10,1) &amp;&gt; log/log.hiero.localprune3
</pre><p>Translation finishes in less than 6 seconds, but this more aggressive local pruning changes the translation hypothesis: </p>
<pre class="fragment"> &gt; zcat output/exp.hiero.localprune/LATS/3.fst.gz | printstrings.O2 -w --semiring=lexstdarc -m wmaps/wmt13.en.wmap 2&gt;/dev/null
 &lt;s&gt; however , in the heart of the take the last myth , arguing that the rare cases of fraud in elections in the united states , the deaths of a lightning strike . &lt;/s&gt;  128.842,-0.150391

 &gt; zcat output/exp.hiero.localprunemore/LATS/3.fst.gz | printstrings.O2 -w --semiring=lexstdarc -m wmaps/wmt13.en.wmap 2&gt;/dev/null
 &lt;s&gt; however , in the heart of the take the last myth , arguing that a rare cases of fraud in elections in the united states , the deaths of a lightning strike . &lt;/s&gt;  130.054,-0.943359
</pre><p>The best hypothesis generated with less local pruning in <code>exp.hiero.localprune/</code> has a combined translation and language model score of 128.842 . This hypothesis does not survive more local pruning in <code>exp.hiero.localprunemore/</code> , where the best hypothesis has a higher combined score of 130.054 .</p>
<h1><a class="anchor" id="chopping"></a>
Source Sentence Chopping</h1>
<p>Long source sentences make the translation process slow and expensive in memory consumption; see [<a class="el" href="index.html#Allauzen2014">Allauzen2014</a>] for a discussion of how source sentence length affects computational complexity and memory use by HiFST and HiPDT. There are various strategies for controlling translation complexity; pruning has been discussed (<a class="el" href="md_Tutorial.html#lpruning">Local pruning / pruning in search</a>), and it is also possible to set the maximum span and gap spans allowed in translation so as to control computational complexity. However translation quality can be affected if pruning is too heavy or if span constraints are set too aggressively.</p>
<p>An alternative approach is to 'chop' long sentences into shorter segements which can then be translated separately. If the sentence chopping is done carefully, the impact on the translation quality can be minimized. The benefits to chopping are faster translation that consumes less memory. The potential drawbacks are twofold: chopping can prevent the search procedure from finding good hypothesis under the grammar, and care must be taken to correctly apply the target language model at the sentence level.</p>
<h1><a class="anchor" id="chopping_gb"></a>
Grammar-based Sentence Chopping</h1>
<p>Chopping can be done by inserting the special 'chop' symbol '0' in the source sentence, and then translating with a modified grammar. The chopping grammar is constructed so that translation rules are not applied across the chopping points, thus limiting the space of translation that are generated. Conceptually, translation proceeds as:</p>
<ol type="1">
<li>the translation grammar is applied separately to source sentence segments demarcated by chop symbols</li>
<li>local pruning can be applied to the translations of these segments</li>
<li>the resulting WFSAs containing translations of the segments are concatenated under the chopping grammar, possibly with local pruning</li>
<li>the language model is applied</li>
<li>top-level, admissible pruning is done under the translation and languaage model scores</li>
</ol>
<p>In this way the FSTs produced by translating the segments are concatenated prior to application of the target language model; in this way the language model context is not broken by the source sentence chopping.</p>
<p>As an example, a grammar modified for chopping contains the following rules (without weights): </p>
<pre class="fragment"> R 1 1
 R R_D_X R_D_X
 R R_X R_X

 T 0 0
 T T_D_X T_D_X
 T T_X T_X

 S S_U S_U
 S Q Q
 Q R R
 U T T
</pre><p>The rules in the first block above are similar to those used in the usual Hiero grammar, with the original '<code>S</code>' changed to '<code>R</code>'. These rules are responsible for concatenating the partial translations of the source sentence, starting from the sentence-start symbol '1', up to but not including the first instance of the chopping symbol '0'.</p>
<p>Each subsequent sequence of source words starting with symbol '0', is handled in a similar way by the second block of rules above. Note that the only rule that can be applied to the input symbol '0' is '<code>T 0 0</code>', making the translation of each chopped segment independent. This makes use of the OpenFST convention of mapping 0 to epsilon: the 0's in the input are parsed as regular symbols by HiFST, while 0's on the output side are mapped to epsilons and ignored in composition with the language model.</p>
<p>The third block of rules above will join together the results obtained for each chopped segment. As with the glue rule '<code>S</code>' in the usual Hiero grammar, it is necessary to allow this new set of rules to be applied to any span. This is done by setting </p>
<pre class="fragment">  cykparser.ntexceptionsmaxspan=S,Q,R,T,U
</pre><p>The additional mapping provided by the last two rules controls the pruning applied to the top CYK cell relative to each chopped segment: </p>
<pre class="fragment">  hifst.localprune.conditions=Q,1,100,12,U,1,100,12,X,5,10000,9,V,3,20000,9
</pre><p>In the above example tighter parameters are chosen for '<code>Q</code>' and '<code>U</code>' to force pruning. In this way the final lattice obtained by concatenation is prevented from growing too large. However a wider beam (12) with respect to the other cell types is used, to avoid discarding too many potentially useful hypotheses.</p>
<p>It is possible to specify explicitly that FSTs generated for rules with LHS '<code>X</code>' or '<code>V</code>' can be kept as pointers rather then expanded in the FST (RTN) that is built for a higher CYK cell. This is achieved setting </p>
<pre class="fragment">  hifst.replacefstbyarc=X,V
  hifst.replacefstbyarc.exceptions=S,R,T
</pre><p>The second line above prevents substitution for rules with LHS '<code>S</code>', '<code>R</code>' and '<code>T</code>'. It is better to have a fully expanded FST for these rules for more effective optimisation (Determinization and Minimisation).</p>
<h1><a class="anchor" id="chopping_eg"></a>
Converting Grammars and Input Text for Chopping</h1>
<p>The usual Hiero grammar can be converted for chopping, as follows; note that no-cost, 0 valued, weights are added to rules :</p>
<p>First, create the chopping and glue rules: </p>
<pre class="fragment"> &gt; (echo "T T_D_X T_D_X 0" ; echo "T T_X T_X 0" ; echo "T 0 0 0") &gt; G/rules.hiero.chop
 &gt; (echo "S S_U S_U 0" ; echo "U T T 0" ; echo "Q R R 0" ; echo "S Q Q 0") &gt;&gt; G/rules.hiero.chop
 &gt; cat G/rules.hiero.chop
 T T_D_X T_D_X 0
 T T_X T_X 0
 T 0 0 0
 S S_U S_U 0
 U T T 0
 Q R R 0
 S Q Q 0
</pre><p>Next, append all rules, mapping glue rules with LHS S to LHS R: </p>
<pre class="fragment"> &gt; zcat G/rules.hiero.gz | sed 's,S,R,g' &gt;&gt; G/rules.hiero.chop
 &gt; gzip G/rules.hiero.chop
</pre><p>The source text (<code>RU/RU.set1.chop.idx</code>) will be chopped simply inserting the chopping marker '0' after each comma (integer mapped to 3 in the Russian wordmap); this is a simplistic approach that is easily implemented for this demonstration: </p>
<pre class="fragment"> &gt; sed 's, 3 , 3 0 ,g' RU/RU.set1.idx &gt; RU/RU.set1.chopping.idx

 &gt; diff RU/RU.set1.idx RU/RU.set1.chopping.idx | head -n4
 3c3
 &lt; 1 109 5 458 756435 1225 1358 60145 3 12725 3 11 3678 66369 7 1799 5 1317 2946 45 32023 3 75 3678 1102 24 10272 28960 4 2
 ---
 &gt; 1 109 5 458 756435 1225 1358 60145 3 0 12725 3 0 11 3678 66369 7 1799 5 1317 2946 45 32023 3 0 75 3678 1102 24 10272 28960 4 2
</pre><p>The following command will translate lines 3,12,19 in the Russian integer-mapped file RU/RU.set1.chop.idx : </p>
<pre class="fragment"> # Run HiFST, with chopping.  Input is the chopped source RU/RU.set1.chopping.idx.
 # hypotheses are written to output/exp.chopping/chop/hyps and lattices to output/exp.chopping/chop/LATS/
 &gt; (time hifst.O2 --config=configs/CF.hiero.chopping) &amp;&gt; log/log.chopping.chop
</pre><p>Now we decode again keeping the same configuration (same grammar and language model), but with the non-chopped version of the input: </p>
<pre class="fragment"> # Run HiFST, without chopping.  Input is the original, unchopped source RU/RU.set1.idx
 # hypotheses are written to output/exp.chopping/nochop/hyps and lattices to output/exp.chopping/nochop/LATS/
 &gt; (time hifst.O2 --config=configs/CF.hiero.chopping --source.load=RU/RU.set1.idx --target.store=output/exp.chopping/nochop/hyps --hifst.lattice.store=output/exp.chopping/nochop/LATS/?.fst.gz) &amp;&gt; log/log.chopping.nochop
</pre><p>Comparing the time and memory consumption of the two experiments shows that source-sentence chopping is significantly faster and uses far less memory; in particular, local pruning is required less often under the chopping grammar: </p>
<pre class="fragment">                                         Number of local prunings
 Input      Tot time      Max memory    Sent 3    Sent 12   Sent 19
 --------   --------      ----------    ------    -------   -------
 Unchopped  22m 37s         5.4Gb        92        106       168
 Chopped     3m 57s         0.8Gb        34         46        20
</pre><p>However, chopping restricts the space of translations. Looking at the scores of the best translation hypotheses, chopping the source sentence prevents the decoder from finding the best scoring hypothesis under the grammar; for the third sentence, the hypothesis produced without chopping has a lower (i.e. better) combined cost (128.842) than the hypothesis produced with chopping (130.309): </p>
<pre class="fragment"> # find the score of the best hypothesis for the 3rd sentence, without chopping
 &gt; zcat output/exp.chopping/nochop/LATS/3.fst.gz | printstrings.O2 --semiring=lexstdarc
 1 106 4 9 3 1552 6 3 96 3 200 8072 4 5452 10 3 4143 535 6 1206 9 628 9 3 232 56 4 3 2723 6 11 21441 2645 5 2       128.842,-0.150391
 # find the score of the best hypothesis for the 3rd sentence, with chopping
 &gt; zcat output/exp.chopping/chop/LATS/3.fst.gz | printstrings.O2 --semiring=lexstdarc
 1 106 4 9 3 1552 6 3 96 3 200 8072 4 5452 10 3 4143 535 6 1206 9 628 9 3 232 56 4 3 2723 6 11 21441 2645 5 2       130.309,1.31641
</pre><h1><a class="anchor" id="chopping_sseg"></a>
Chopping by Explicit Source Sentence Segmentation</h1>
<p>It is also possible to segment and translate each segment completely independently, as shown in this example for sentence 3. Here, the original Russian sentence is chopped into three shorter sentences which are to be translated independently, as follows: </p>
<pre class="fragment"> # split sentence 3 into 4 separate sentences
 &gt; awk 'NR==3' RU/RU.set1.idx | sed 's, 3 , 3 2\n1 ,g'  &gt; RU/RU.sent3.chopped
 &gt; cat RU/RU.sent3.chopped
 1 109 5 458 756435 1225 1358 60145 3 2
 1 12725 3 2
 1 11 3678 66369 7 1799 5 1317 2946 45 32023 3 2
 1 75 3678 1102 24 10272 28960 4 2

 # run HiFST over all segments
 &gt; hifst.O2 --config=configs/CF.hiero.chopping --source.load=RU/RU.sent3.chopped --target.store=output/exp.chopping/sent3/hyps --hifst.lattice.store=output/exp.chopping/sent3/LATS/seg.?.fst --range=1:4

 # concatenate output lattices
 &gt; fstconcat output/exp.chopping/sent3/LATS/seg.1.fst output/exp.chopping/sent3/LATS/seg.2.fst | fstconcat - output/exp.chopping/sent3/LATS/seg.3.fst | fstconcat - output/exp.chopping/sent3/LATS/seg.4.fst &gt; output/exp.chopping/sent3/LATS/sent.fst

 # print output string
 &gt; cat output/exp.chopping/sent3/LATS/sent.fst | printstrings.O2 --semiring=lexstdarc -m wmaps/wmt13.en.wmap -w 2&gt;/dev/null
 &lt;s&gt; however , in the middle of the last myth , believe &lt;/s&gt; &lt;s&gt; by saying , &lt;/s&gt; &lt;s&gt; the cases of fraud in elections in the united states , a rare &lt;/s&gt; &lt;s&gt; the deaths of a lightning strike . &lt;/s&gt;  141.166,-12.5742
</pre><p>In the above example, the language model is applied separately to the translations of each segment leading to the substrings "&lt;/s&gt; &lt;s&gt;" in the hypothesis. A transducer can be built to remove these from the output lattice, as follows </p>
<pre class="fragment"> &gt; mkdir tmp
 &gt; echo -e "0\t1\t1\t1" &gt; tmp/strip_1_2.txt
 &gt; echo -e "1\t2\t2\t0" &gt;&gt; tmp/strip_1_2.txt
 &gt; echo -e "2\t1\t1\t0" &gt;&gt; tmp/strip_1_2.txt
 &gt; echo -e "2\t2\t0\t0" &gt;&gt; tmp/strip_1_2.txt
 &gt; echo -e "1\t3\t2\t2" &gt;&gt; tmp/strip_1_2.txt
 &gt; echo -e "3" &gt;&gt; tmp/strip_1_2.txt
 &gt; awk '$2 != 1 &amp;&amp; $2 != 2 {printf "1\t1\t%d\t%d\n", $2,$2}' wmaps/wmt13.en.wmap &gt;&gt; tmp/strip_1_2.txt
 &gt; fstcompile  --arc_type=tropical_LT_tropical tmp/strip_1_2.txt | fstarcsort &gt; tmp/strip_1_2.fst

 # apply the strip_1_2.fst transducer to the fst for sentence 3
 &gt; fstcompose output/exp.chopping/sent3/LATS/sent.fst tmp/strip_1_2.fst | fstproject --project_output | fstrmepsilon &gt; output/exp.chopping/sent3/LATS/sent_no12.fst

 # look at output
 &gt; cat output/exp.chopping/sent3/LATS/sent_no12.fst | printstrings.O2 --semiring=lexstdarc -m wmaps/wmt13.en.wmap -w 2&gt;/dev/null
 &lt;s&gt; however , in the middle of the last myth , believe by saying , the cases of fraud in elections in the united states , a rare the deaths of a lightning strike . &lt;/s&gt;  141.166,-12.5742
</pre><p>Note however that the language model score for this hypothesis are not correct, since the language model histories cannot span translations across the chopped segments.</p>
<p>To fix this, the applylm tool (see <a class="el" href="rescoring.html#rescoring_lm">Efficient Language Model Rescoring</a>) can be used to remove and reapply the language model so that it spans the source segment translations. The following example simply removes the language model scores from output/exp.chopping/sent3/LATS/sent_no12.fst and then reapplies them via composition </p>
<pre class="fragment"> &gt; applylm.O2 --lm.load=M/lm.4g.mmap --lm.featureweights=1 --lm.wps=0.0 --semiring=lexstdarc --lattice.load=output/exp.chopping/sent3/LATS/sent_no12.fst --lattice.store=output/exp.chopping/sent?/LATS/sent_no12_rescore.fst --lattice.load.deletelmcost --range=3:3
</pre><p>The rescored output is written to <code>output/exp.chopping/sent3/LATS/sent_no12_rescore.fst</code> with correctly applied language model scores. The total translation cost is much lower (better) than when segment hypotheses are simply combined (i.e. 115.855 vs. 141.166): </p>
<pre class="fragment"> &gt; cat output/exp.chopping/sent3/LATS/sent_no12_rescore.fst | printstrings.O2 --semiring=lexstdarc -m wmaps/wmt13.en.wmap -w 2&gt;/dev/null
 &lt;s&gt; however , in the heart of the take the last myth , arguing that the rare cases of fraud in elections in the united states , the deaths of a lightning strike . &lt;/s&gt;       115.855,-13.1377</pre><h1><a class="anchor" id="pda"></a>
Translation with Push-Down Automata</h1>
<p>This HiFST package can also perform decoding using Push-Down Automata (PDA) as described in [<a class="el" href="index.html#Iglesias2011">Iglesias2011</a>, <a class="el" href="index.html#Allauzen2014">Allauzen2014</a>]. We call this the HiPDT decoder. A brief overview of it and an example on how to use it is given next.</p>
<p>In this framework, the RTN at the top-most cell of the CYK grid is converted into a PDA (via the Replace operation in the <a class="el" href="index.html#OpenFst">OpenFst</a> Extensions) and efficiently composed with a language model to produce another PDA. To obtain the final output FSA, the PDA is expanded to an FSA either entirely (if memory is sufficient and the language model is small enough) or via pruned expansion (for larger language models). This is useful in exploring large and complex translation grammars where HiFST requires a lot of local pruning. However, it requires the language model to be 'small' (for example, entropy-pruned as in [<a class="el" href="index.html#Iglesias2011">Iglesias2011</a>, <a class="el" href="index.html#Allauzen2014">Allauzen2014</a>]). Therefore, we then typically rescore the pruned output FSA with a stronger language model.</p>
<p>This whole setup can be accomplished in one single command as follows: </p>
<pre class="fragment">&gt; hifst.O2 --config=configs/CF.hiero.pdt &amp;&gt; log/log.hiero.pdt
</pre><p>Please see the config file for the parameters needed, along with explanatory comments.</p>
<p>In this particular example, the output 1-best for the first two sentences is identical to the baseline Hiero case (with translation via RTN replacement followed by composition). However, the output lattices differ as they contain different hypotheses (due to the different pruning strategy).</p>
<h2><a class="anchor" id="pda_rtns"></a>
Recursive Transition Networks</h2>
<p>As already discussed with respect to <a class="el" href="md_Tutorial.html#lpruning">Local pruning / pruning in search</a>, HiFST generates an initial representation of the space of translation in the form of an RTN, which is then transformed either to WFSAs or to PDAs using the <a class="el" href="index.html#OpenFst">OpenFst</a> <a href="http://openfst.org/twiki/bin/view/FST/ReplaceDoc">Replace</a> operation prior to application of the language model.</p>
<p>HiFST can save the RTNs to disk, and the language model application and shortest path operations can be carried out using the <a class="el" href="index.html#OpenFst">OpenFst</a> command line tools.</p>
<p>For example, consider generation of the baseline lattices with the Shallow-1 translation grammar and the 4-gram language model. The command can be re-run, but with added instructions to save the RTNs to disk: </p>
<pre class="fragment">&gt; hifst.O2 --config=configs/CF.baseline --hifst.writertn=output/exp.baseline/rtn/?/%%rtn_label%%.fst --grammar.storentorder=output/exp.baseline/rtn/ntmap  --hifst.rtnopt=yes &amp;&gt; log/log.baseline.rtn
</pre><p>The RTNs are written to the directory <code>output/exp.baseline/rtn/*</code> as </p>
<pre class="fragment">&gt; ls output/exp.baseline/rtn/1/
1001000007.fst  1003001002.fst  1003003000.fst  1003004001.fst  1003006000.fst  1004002000.fst  1004005000.fst
1003001000.fst  1003002000.fst  1003003001.fst  1003005000.fst  1003007000.fst  1004003000.fst  1004006000.fst
1003001001.fst  1003002001.fst  1003004000.fst  1003005001.fst  1004001000.fst  1004004000.fst
</pre><p>and the non-terminal mapping is written to output/exp.baseline/rtn/ntmap : </p>
<pre class="fragment">&gt; cat output/exp.baseline/rtn/ntmap
S   1
D   2
X   3
V   4
</pre><p>Each RTN name is of the form 1ABC.fst , where A, B, and C are 3-digit strings.</p>
<ul>
<li>A is the numerical code for a non-terminal in the grammar; in this case, 001 corresponds to S.</li>
<li>B indicates a position in the source sentence: 0 &lt;= B &lt; I, where I is the source sentence length</li>
<li>C indicates the offset to the end of a span, 0 &lt;= C and B+C &lt; I</li>
<li>The automata 1ABC.fst corresponds to T_(A,B,B+C) in the formulation of <a class="el" href="md_Tutorial.html#lpruning">Local pruning / pruning in search</a></li>
</ul>
<p>In this example, the automata 1003001002.fst contains all derivations headed by X, the third non-terminal, and spanning source positions 1 to 3 (=1+2).</p>
<p>The root automata is 1001000007.fst, since A=001 (the S non-terminal), B=0 (the first source position), and C=7 (the sentence has 8 words). This automata is a representation of all possible translations of the source sentence under this grammar, as can be seen by printing its paths (here the first 2): </p>
<pre class="fragment">&gt; cat output/exp.baseline/rtn/1/1001000007.fst | printstrings.O2 --semiring=lexstdarc -u --nbest=2 2&gt;/dev/null
1 1004001000 11 384 1004003000 1004004000 1004005000 1004006000 2
1 1004001000 11 384 1003003001 1004005000 1004006000 2
</pre><p>As can be seen, the symbols are a mix of target language symbols (1,2,11,384,...) and pointers to other automata (1004001000, 1004003000, ...). Conversion of the RTN is done by recursive substitution of these symbols by the FSTs to which they point, starting from the root automata.</p>
<h2><a class="anchor" id="pda_replace"></a>
Replacement: Translation by Converting RTNs to WFSAs</h2>
<pre class="fragment"> &gt; fstreplace | head -n 3
 Recursively replaces FST arcs with other FST(s).

 Usage: fstreplace root.fst rootlabel [rule1.fst label1 ...] [out.fst]
</pre><p>Note that the root FST and root label are always of the form 1001000C, where C = I - 1 , where I is the source sentence length.</p>
<p>HiFST uses the same names for rules and labels, so we get get the filenames and labels in the right form by, e.g. </p>
<pre class="fragment"> &gt; ls output/exp.baseline/rtn/1/1*.fst | sed 's,\(.*\)/\(.*\).fst,\1/\2.fst \2,' | head -n 5
 output/exp.baseline/rtn/1/1001000007.fst 1001000007
 output/exp.baseline/rtn/1/1003001000.fst 1003001000
 output/exp.baseline/rtn/1/1003001001.fst 1003001001
 output/exp.baseline/rtn/1/1003001002.fst 1003001002
 output/exp.baseline/rtn/1/1003002000.fst 1003002000
</pre><p>The following will expand the RTN into an FSA: </p>
<pre class="fragment"> &gt; fstreplace `ls output/exp.baseline/rtn/1/1*.fst | sed 's,\(.*\)/\(.*\).fst,\1/\2.fst \2,'` &gt; output/exp.baseline/rtn/1/T.fst
</pre><p>The WFSA T is the replacement of the RTN that was generated in translation.</p>
<h3><a class="anchor" id="rtn_lm_app"></a>
Composition and Shortest Path</h3>
<p>The applylm tool can be used to apply the baseline 4-gram language model to T via composition. This generates a new WFSA containing both translation and language model scores:</p>
<ul>
<li>Input<ul>
<li>M/lm.4g.mmap : n-gram LM</li>
<li>output/exp.baseline/rtn/1/T.fst : WFSA containing translation scores</li>
</ul>
</li>
<li>Output<ul>
<li>output/exp.baseline/rtn/1/TG.fst.gz : WFSA containing translation grammar and LM scores</li>
</ul>
</li>
</ul>
<p>The output is written in the form of a transducer, with the RTN labels as the input symbols and the target language words on the output symbols: </p>
<pre class="fragment"> &gt; applylm.O2 --lm.load=M/lm.4g.mmap --semiring=lexstdarc --lattice.load=output/exp.baseline/rtn/1/T.fst --lattice.store=output/exp.baseline/rtn/1/TG.fst.gz

 &gt; zcat output/exp.baseline/rtn/1/TG.fst.gz | fstshortestpath | fstrmepsilon | fsttopsort | fstprint
 0    1     1               1       -2.609375,-2.609375
 1    2     9121            9121    9.33318996,-1.26074219
 2    3     1004002000      0
 3    4     384             384     7.13530731,-2.609375
 4    5     1004003000      0       1.28222656,1.28222656
 5    6     6               6       -0.390115976,-3.328125
 6    7     2756            2756    9.45967484,0.288085938
 7    8     7               7       1.79730964,0
 8    9     1004004000      0
 9    10    3               3       -0.395056069,-1.23925781
 10   11    4144            4144    9.78138161,0
 11   12    6               6       0.201819927,0
 12   13    1003005001      0       3.29199219,3.29199219
 13   14    1458528         1458528 10.2062063,-1.0703125
 14   15    1004005000      0
 15   16    1341            1341    6.04568958,1.55957031
 16   17    2               2       2.33047056,-2.34277344
 17
</pre><p>To see the translation alone, we project to the output symbols: </p>
<pre class="fragment">&gt; zcat output/exp.baseline/rtn/1/TG.fst.gz | fstproject --project_output | printstrings.O2 --semiring=lexstdarc -w -m wmaps/wmt13.en.wmap 2&gt;/dev/null
&lt;s&gt; republican strategy of resistance to the renewal of obamas election &lt;/s&gt;                        57.4707,-8.03809
</pre><p>which should agree with the previously generated contents of output/exp.baseline/LATS/1.fst.gz produced by the baseline system: </p>
<pre class="fragment">&gt; zcat output/exp.baseline/LATS/1.fst.gz | printstrings.O2 --semiring=lexstdarc -w -m wmaps/wmt13.en.wmap 2&gt;/dev/null
&lt;s&gt; republican strategy of resistance to the renewal of obamas election &lt;/s&gt;             57.4707,-8.03809
</pre><h2><a class="anchor" id="pda_expand"></a>
Expansion: Translation by Composition of PDAs and WFSAs followed by Pruned Expansion</h2>
<p>When using PDTs, the decoding process differs from the above in that the RTN is not expanded to an FSA prior to composition with the LM. Instead, HiPDT replaces the RTN by a PDA, which is efficiently composed with the LM to produce another PDA. Finally, this resulting PDA is converted to the final translation FSA via pruned expansion.</p>
<p>As explained in the example of <a class="el" href="md_Tutorial.html#pda">Translation with Push-Down Automata</a>, this process is done by the decoder in one go. For explanatory reasons, here we reproduce it externally for one sentence via the command line.</p>
<p>(Note: as of March 2014 we have not managed to make the OpenFST PDT command line operations work well with our lexicographic library, so the standard tropical semirring must be used in this example. This makes it slightly more complex than it should be, but we believe it is useful to understand HiPDT anyway)</p>
<p>First, we dump the RTN for the full hiero grammar as follows: </p>
<pre class="fragment">&gt; hifst.O2 --config=configs/CF.hiero --hifst.writertn=output/exp.hiero/rtn/?/%%rtn_label%%.fst --grammar.storentorder=output/exp.hiero/rtn/ntmap --hifst.rtnopt=yes &amp;&gt; log/log.hiero.rtn
</pre><p>Then, we ensure that the RTN files are in the tropical semiring: </p>
<pre class="fragment">&gt; mkdir -p output/exp.hiero/rtn-tp/1 output/exp.hiero/rtn-tp/2
&gt; pushd output/exp.hiero/rtn/ ; for f in ?/100*.fst; do cat $f | lexmap.O2 --action=lex2std &gt; ../rtn-tp/$f; done; popd
</pre><p>The PDT is then created as follows: </p>
<pre class="fragment">&gt; for f in 1 2; do pdtreplace --pdt_parentheses=output/exp.hiero/rtn-tp/$f/parens.txt `ls output/exp.hiero/rtn-tp/$f/1*.fst | sed 's,\(.*\)/\(.*\).fst,\1/\2.fst \2,'` &gt; output/exp.hiero/rtn-tp/$f/T.pdt; done
</pre><p>where the `pdt_parentheses' option indicates that the open/close parentheses symbols are to be stored into a file. This is used later in order to expand the PDA to an FSA.</p>
<p>Then the PDA is composed with the weak language model. This is done via the standard composition algorithm, but making sure that open/close parentheses symbols are treated as epsilons by the composition algorithm. To accomplish this, their respective output symbols need to be relabel to 0 before applying the LM: </p>
<pre class="fragment">&gt; for f in 1 2; do cat output/exp.hiero/rtn-tp/1/parens.txt | tr '\t' '\n' | sed 's/$/\t0/' &gt; output/exp.hiero/rtn-tp/$f/parens-to-epsilon.txt ;
&gt; cat output/exp.hiero/rtn-tp/$f/T.pdt | fstrelabel -relabel_opairs=output/exp.hiero/rtn-tp/$f/parens-to-epsilon.txt &gt; output/exp.hiero/rtn-tp/$f/Tb.pdt
&gt; applylm.O2 --lm.load=M/lm.4g.eprnd.mmap --lattice.load=output/exp.hiero/rtn-tp/$f/Tb.pdt --lattice.store=output/exp.hiero/rtn-tp/$f/TG.pdt ;
&gt; done
</pre><p>Then the resulting PDT is expanded into an FSA while applying a pruning weight of 9: </p>
<pre class="fragment">&gt; for f in 1 2; do fstproject output/exp.hiero/rtn-tp/$f/TG.pdt | pdtexpand --pdt_parentheses=output/exp.hiero/rtn-tp/$f/parens.txt --weight=9 &gt; output/exp.hiero/rtn-tp/$f/TG.fst ; done
</pre><p>Finally, the weak LM is removed and the full LM is applied: </p>
<pre class="fragment">&gt; for f in 1 2; do applylm.O2 --lm.load=M/lm.4g.eprnd.mmap --lm.featureweights=-1 --lattice.load=output/exp.hiero/rtn-tp/$f/TG.fst --lattice.store=output/exp.hiero/rtn-tp/$f/TG-nolm.fst ; applylm.O2 --lm.load=M/lm.4g.mmap --lattice.load=output/exp.hiero/rtn-tp/$f/TG-nolm.fst --lattice.store=output/exp.hiero/rtn-tp/$f/TG-final.fst ; done
</pre><p>The final FSA that results from this process (<code>output/exp.hiero/rtn-tp/1/TG-final.fst</code>) should be equivalent to the one obtained by HiPDT (<code>output/exp.hiero.pdt/LATS/1.fst.gz</code>) except for numerical differences. Their 1-best hypothesis can be obtained as follows: </p>
<pre class="fragment">&gt; zcat output/exp.hiero.pdt/LATS/1.fst.gz | printstrings.O2 --semiring=lexstdarc -w -m wmaps/wmt13.en.wmap 2&gt;/dev/null
&lt;s&gt; the republican strategy of resistance to the renewal of obama 's election &lt;/s&gt;  55.2515,-11.6445

&gt; cat output/exp.hiero/rtn-tp/1/TG-final.fst | printstrings.O2 -w -m wmaps/wmt13.en.wmap 2&gt;/dev/null
    &lt;s&gt; the republican strategy of resistance to the renewal of obama 's election &lt;/s&gt;      55.2515</pre><h1><a class="anchor" id="true_casing"></a>
Fst-based True casing</h1>
<p>HiFST includes a tool typically used for true casing the output. It relies on two models:</p>
<ul>
<li>A true-case integer-mapped language model in ARPA or KenLM format.</li>
<li>A flower transducer that transduces uncased words to every true case alternative. This model is loaded from a file with the following format per line, one for each uncased word:<ul>
<li>uncased-case-word true-case-word1 prob1 true-case-word2 prob2 ...</li>
<li>This format is compatible with the unigram model for <a class="el" href="index.html#SRILM">SRILM</a> <a href="http://www.speech.sri.com/projects/srilm/manpages/disambig.1.html">disambig</a> tool (see <code>--map</code> option).</li>
</ul>
</li>
</ul>
<p>Words must be integer-mapped. A file with this model is available: </p>
<pre class="fragment">&gt; head  G/tc.unimap
1 1 1.0
2 2 1.0
3 5943350 0.00002 3 0.86370 5943349 0.13628
4 4 1.00000
5 5 1.00000
6 5942623 0.00452 5942624 0.00002 6 0.99546
7 5943397 0.00000 5943398 0.01875 7 0.98121 5943399 0.00004
8 5941239 0.00003 8 0.99494 5941238 0.00502
9 5942238 0.06269 9 0.93729 5942239 0.00002
10 5943348 0.00001 10 0.99498 5943347 0.00501
</pre><p>For example, under this model word 4 (comma ",") transduces to itself with probability 1. The uncased word 3 ("the") has three upper-case alternatives: "the", "THE", and "The", with the following probabilities </p>
<pre class="fragment"> P(the | the) = 0.86
 P(THE | the) = 0.00002
 P(The | the) = 0.13628
</pre><p>To generate these probabilities, you just need counts of truecased words. You can extract these unigrams with <a class="el" href="index.html#SRILM">SRILM</a> <a href="http://www.speech.sri.com/projects/srilm/manpages/ngram-count.1.html">ngram-count</a> tool, and calculate the probability of each particular true-cased form given the aggregated number of lower-cased instances.</p>
<p>These models are provided to the recaser module via the following configuration options </p>
<pre class="fragment">&gt; cat configs/CF.recaser
[recaser]
lm.load=M/lm.tc.gz
unimap.load=G/tc.unimap
</pre><p>The true casing procedure is very similar to that of <a class="el" href="index.html#SRILM">SRILM</a> <a href="http://www.speech.sri.com/projects/srilm/manpages/disambig.1.html">disambig</a> tool. In our case this is accomplished with two subsequent compositions, followed by exact pruning. An acceptable performance vs speed/memory trade-off can be achieved e.g. with offline entropy pruning of the language model.</p>
<p>A range of input lattices can be true-cased in the following way with our fst-based disambig tool: </p>
<pre class="fragment">&gt; disambig.O2 configs/CF.recaser --recaser.input=output/exp.hiero.pdt/LATS/?.fst.gz --recaser.output=output/exp.recasing/LATS/?.fst.gz --range=1:2 -s lexstdarc
</pre><p>The result can be printed as so: </p>
<pre class="fragment">&gt; printstrings.O2 --range=1:2 --input=output/exp.recasing/LATS/?.fst.gz --semiring=lexstdarc --label-map=wmaps/wmt13.en.wmap 2&gt;/dev/null
&lt;s&gt; The Republican strategy of resistance to the renewal of Obama 's election &lt;/s&gt;
&lt;s&gt; The leaders of the Republican justified their policies need to deal with the spin on the elections . &lt;/s&gt;
</pre><p>Note that both models need to be integer-mapped, hence the external target wordmap (&ndash;label-map) must also map true case words.</p>
<p>HiFST can include truecasing as subsequent step following decoding, prior to writing the output hypotheses. For instance: </p>
<pre class="fragment">&gt; hifst.O2 --config=configs/CF.hiero.pdt.recaser --target.store=output/exp.hiero.pdt/recased/hyps &amp;&gt; log/log.hiero.pdt.recase

&gt; farcompilestrings --entry_type=line output/exp.hiero.pdt/recased/hyps | farprintstrings --symbols=wmaps/wmt13.en.wmap
&lt;s&gt; The Republican strategy of resistance to the renewal of Obama 's election &lt;/s&gt;
&lt;s&gt; The leaders of the Republican justified their policies need to deal with the spin on the elections . &lt;/s&gt;
</pre><p>However, the output lattices are left in uncased form: </p>
<pre class="fragment">&gt; zcat output/exp.hiero.pdt/LATS/1.fst.gz | printstrings.O2 --semiring=lexstdarc --label-map=wmaps/wmt13.en.wmap -w 2&gt;/dev/null
&lt;s&gt; the republican strategy of resistance to the renewal of obama 's election &lt;/s&gt;               55.2515,-11.6445</pre> </div></div><!-- contents -->
</div><!-- doc-content -->
<!-- start footer part -->
<div id="nav-path" class="navpath"><!-- id is needed for treeview function! -->
  <ul>
    <li class="footer">Generated on Mon May 26 2014 02:52:17 for Cambridge SMT System by
    <a href="http://www.doxygen.org/index.html">
    <img class="footer" src="doxygen.png" alt="doxygen"/></a> 1.8.3 </li>
  </ul>
</div>
</body>
</html>
