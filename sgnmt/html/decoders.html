

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Decoders &mdash; SGNMT 0.3.2 documentation</title>
  

  
  

  

  
  
    

  

  
  
    <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  

  
    <link rel="stylesheet" href="_static/custom.css" type="text/css" />
  

  
    <link rel="top" title="SGNMT 0.3.2 documentation" href="index.html"/>
        <link rel="next" title="Examples" href="examples.html"/>
        <link rel="prev" title="Predictors" href="predictors.html"/> 

  
  <script src="_static/js/modernizr.min.js"></script>

</head>

<body class="wy-body-for-nav" role="document">

  <div class="wy-grid-for-nav">

    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search">
          

          
            <a href="index.html" class="icon icon-home"> SGNMT
          

          
          </a>

          
            
            
              <div class="version">
                0.3.2
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
                <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="setup.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="tutorial.html">Tutorial</a></li>
<li class="toctree-l1"><a class="reference internal" href="adding_components.html">Tutorial: Adding new components</a></li>
<li class="toctree-l1"><a class="reference internal" href="command_line.html">Command-line reference</a></li>
<li class="toctree-l1"><a class="reference internal" href="predictors.html">Predictors</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Decoders</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#available-decoders">Available decoders</a></li>
<li class="toctree-l2"><a class="reference internal" href="#relevant-modules">Relevant modules</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#cam-sgnmt-decoding-astar-module">cam.sgnmt.decoding.astar module</a></li>
<li class="toctree-l3"><a class="reference internal" href="#cam-sgnmt-decoding-beam-module">cam.sgnmt.decoding.beam module</a></li>
<li class="toctree-l3"><a class="reference internal" href="#cam-sgnmt-decoding-bigramgreedy-module">cam.sgnmt.decoding.bigramgreedy module</a></li>
<li class="toctree-l3"><a class="reference internal" href="#cam-sgnmt-decoding-bow-module">cam.sgnmt.decoding.bow module</a></li>
<li class="toctree-l3"><a class="reference internal" href="#cam-sgnmt-decoding-bucket-module">cam.sgnmt.decoding.bucket module</a></li>
<li class="toctree-l3"><a class="reference internal" href="#cam-sgnmt-decoding-combibeam-module">cam.sgnmt.decoding.combibeam module</a></li>
<li class="toctree-l3"><a class="reference internal" href="#cam-sgnmt-decoding-core-module">cam.sgnmt.decoding.core module</a></li>
<li class="toctree-l3"><a class="reference internal" href="#cam-sgnmt-decoding-decoder-module">cam.sgnmt.decoding.decoder module</a></li>
<li class="toctree-l3"><a class="reference internal" href="#cam-sgnmt-decoding-dfs-module">cam.sgnmt.decoding.dfs module</a></li>
<li class="toctree-l3"><a class="reference internal" href="#cam-sgnmt-decoding-flip-module">cam.sgnmt.decoding.flip module</a></li>
<li class="toctree-l3"><a class="reference internal" href="#cam-sgnmt-decoding-greedy-module">cam.sgnmt.decoding.greedy module</a></li>
<li class="toctree-l3"><a class="reference internal" href="#cam-sgnmt-decoding-heuristics-module">cam.sgnmt.decoding.heuristics module</a></li>
<li class="toctree-l3"><a class="reference internal" href="#cam-sgnmt-decoding-multisegbeam-module">cam.sgnmt.decoding.multisegbeam module</a></li>
<li class="toctree-l3"><a class="reference internal" href="#cam-sgnmt-decoding-restarting-module">cam.sgnmt.decoding.restarting module</a></li>
<li class="toctree-l3"><a class="reference internal" href="#cam-sgnmt-decoding-sepbeam-module">cam.sgnmt.decoding.sepbeam module</a></li>
<li class="toctree-l3"><a class="reference internal" href="#cam-sgnmt-decoding-syncbeam-module">cam.sgnmt.decoding.syncbeam module</a></li>
<li class="toctree-l3"><a class="reference internal" href="#cam-sgnmt-decoding-syntaxbeam-module">cam.sgnmt.decoding.syntaxbeam module</a></li>
<li class="toctree-l3"><a class="reference internal" href="#module-contents">Module contents</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="examples.html">Examples</a></li>
<li class="toctree-l1"><a class="reference internal" href="faq.html">Common issues</a></li>
<li class="toctree-l1"><a class="reference internal" href="publications.html">Publications</a></li>
<li class="toctree-l1"><a class="reference internal" href="cam.sgnmt.html">All modules</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" role="navigation" aria-label="top navigation">
        <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
        <a href="index.html">SGNMT</a>
      </nav>


      
      <div class="wy-nav-content">
        <div class="rst-content">
          

 



<div role="navigation" aria-label="breadcrumbs navigation">
  <ul class="wy-breadcrumbs">
    <li><a href="index.html">Docs</a> &raquo;</li>
      
    <li>Decoders</li>
      <li class="wy-breadcrumbs-aside">
        
          
            <a href="_sources/decoders.txt" rel="nofollow"> View page source</a>
          
        
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="decoders">
<h1>Decoders<a class="headerlink" href="#decoders" title="Permalink to this headline">¶</a></h1>
<p>Decoders are search strategies for traversing the search space which is spanned by the predictors.
Decoders are specified using the <code class="docutils literal"><span class="pre">--decoder</span></code> arguments.</p>
<div class="section" id="available-decoders">
<h2>Available decoders<a class="headerlink" href="#available-decoders" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><strong>greedy</strong>: Greedy decoding (similar to beam=1)</li>
<li><strong>beam</strong>: Beam search like in Bahdanau et al, 2015 .</li>
<li><strong>sepbeam</strong>: Associates predictors with hypos in beam search and applies only one predictor instead of all for hypo expansion.</li>
<li><strong>syncbeam</strong>: Beam search which compares after consuming a special synchronization symbol instead of after each iteration.</li>
<li><strong>syntaxbeam</strong>: Beam search which ensures diversity amongst terminal symbol histories.</li>
<li><strong>combibeam</strong>: Beam search which applies <code class="docutils literal"><span class="pre">--combination_scheme</span></code> at each time step.</li>
<li><strong>multisegbeam</strong>: Beam search with multiple segmentations.</li>
<li><strong>dfs</strong>: Depth-first search. This should be used for exact decoding or the complete enumeration of the search space.
but it cannot be used if the search space is too large (like for unrestricted NMT) as it performs exhaustive search.
If you have not only negative predictor scores, set <code class="docutils literal"><span class="pre">--early_stopping</span></code> to false.</li>
<li><strong>restarting</strong>: Like DFS but with better admissible pruning behavior.</li>
<li><strong>astar</strong>: A* search. The heuristic function is configured using the <code class="docutils literal"><span class="pre">--heuristics</span> <span class="pre">options</span></code>.</li>
<li><strong>bucket</strong>: Works best for bag problems. Maintains buckets for each hypo length and extends a hypo in a bucket by one before selecting the next bucket.</li>
<li><strong>flip</strong>: This decoder works only for bag problems. It traverses the search space by switching two words in the hypothesis. Do not use bow predictor.</li>
<li><strong>bow</strong>: Restarting decoder optimized for bag-of-words problems.</li>
<li><strong>bigramgreedy</strong>: Works best for bag problems. Collects bigram statistics and constructs hypos to score by greedily selecting high scoring bigrams. Do not use bow predictor with this search strategy.</li>
<li><strong>vanilla</strong>: Original Blocks beam decoder. This bypasses the predictor framework and directly performs pure NMT beam
decoding on the GPU. Use this when you do pure NMT decoding as this is usually faster then using a single nmt predictor
as the search can be parallelized on the GPU.</li>
</ul>
<p>Detailed descriptions are available below in the modules.</p>
</div>
<div class="section" id="relevant-modules">
<h2>Relevant modules<a class="headerlink" href="#relevant-modules" title="Permalink to this headline">¶</a></h2>
<div class="section" id="cam-sgnmt-decoding-astar-module">
<h3>cam.sgnmt.decoding.astar module<a class="headerlink" href="#cam-sgnmt-decoding-astar-module" title="Permalink to this headline">¶</a></h3>
<p>Implementation of the A* search strategy</p>
<dl class="class">
<dt>
<em class="property">class </em><code class="descclassname">cam.sgnmt.decoding.astar.</code><code class="descname">AstarDecoder</code><span class="sig-paren">(</span><em>decoder_args</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/decoding/astar.html#AstarDecoder"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Bases: <a class="reference internal" href="cam.sgnmt.decoding.html#cam.sgnmt.decoding.core.Decoder" title="cam.sgnmt.decoding.core.Decoder"><code class="xref py py-class docutils literal"><span class="pre">cam.sgnmt.decoding.core.Decoder</span></code></a></p>
<p>This decoder implements A*. For heuristics, see the the
<code class="docutils literal"><span class="pre">decoding.core</span></code> module for interfaces and the general handling of
heuristics, and the <code class="docutils literal"><span class="pre">decoding.heuristics</span></code> package for heuristic
implementations. This A* implementation does not have a &#8216;closed
set&#8217;, i.e. we do not keep track of already visited states. Make
sure that your search space is acyclic (normally it is unless you
decode on cyclic lattices with the fst predictor.</p>
<dl class="method">
<dt>
<code class="descname">decode</code><span class="sig-paren">(</span><em>src_sentence</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/decoding/astar.html#AstarDecoder.decode"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Decodes a single source sentence using A* search.</p>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="cam-sgnmt-decoding-beam-module">
<h3>cam.sgnmt.decoding.beam module<a class="headerlink" href="#cam-sgnmt-decoding-beam-module" title="Permalink to this headline">¶</a></h3>
<p>Implementation of the beam search strategy</p>
<dl class="class">
<dt>
<em class="property">class </em><code class="descclassname">cam.sgnmt.decoding.beam.</code><code class="descname">BeamDecoder</code><span class="sig-paren">(</span><em>decoder_args</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/decoding/beam.html#BeamDecoder"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Bases: <a class="reference internal" href="cam.sgnmt.decoding.html#cam.sgnmt.decoding.core.Decoder" title="cam.sgnmt.decoding.core.Decoder"><code class="xref py py-class docutils literal"><span class="pre">cam.sgnmt.decoding.core.Decoder</span></code></a></p>
<p>This decoder implements standard beam search and several
variants of it such as diversity promoting beam search and beam
search with heuristic future cost estimates. This implementation
supports risk-free pruning and hypotheses recombination.</p>
<dl class="method">
<dt>
<code class="descname">decode</code><span class="sig-paren">(</span><em>src_sentence</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/decoding/beam.html#BeamDecoder.decode"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Decodes a single source sentence using beam search.</p>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="cam-sgnmt-decoding-bigramgreedy-module">
<h3>cam.sgnmt.decoding.bigramgreedy module<a class="headerlink" href="#cam-sgnmt-decoding-bigramgreedy-module" title="Permalink to this headline">¶</a></h3>
<p>Implementation of the bigram greedy search strategy</p>
<dl class="class">
<dt>
<em class="property">class </em><code class="descclassname">cam.sgnmt.decoding.bigramgreedy.</code><code class="descname">BigramGreedyDecoder</code><span class="sig-paren">(</span><em>decoder_args</em>, <em>trg_test_file</em>, <em>max_expansions=0</em>, <em>early_stopping=True</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/decoding/bigramgreedy.html#BigramGreedyDecoder"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Bases: <a class="reference internal" href="cam.sgnmt.decoding.html#cam.sgnmt.decoding.core.Decoder" title="cam.sgnmt.decoding.core.Decoder"><code class="xref py py-class docutils literal"><span class="pre">cam.sgnmt.decoding.core.Decoder</span></code></a></p>
<p>The bigram greedy decoder collects bigram statistics at each
node expansions. After each decoding pass, it constructs a new
hypothesis to rescore by greedily selecting bigrams and gluing
them together. Afterwards, the new hypothesis is rescored and new
bigram statistics are collected.</p>
<p>Note that this decoder does not support the <code class="docutils literal"><span class="pre">max_length</span></code>
parameter as it is designed for fixed length decoding problems.</p>
<p>Also note that this decoder works only for bag-of-words problems.
Do not use the bow predictor in combination with this decoder as
it will hide the EOS scores which are important to estimate bigram
scores.</p>
<dl class="method">
<dt>
<code class="descname">decode</code><span class="sig-paren">(</span><em>src_sentence</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/decoding/bigramgreedy.html#BigramGreedyDecoder.decode"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Decodes a single source sentence with the flip decoder</p>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="cam-sgnmt-decoding-bow-module">
<h3>cam.sgnmt.decoding.bow module<a class="headerlink" href="#cam-sgnmt-decoding-bow-module" title="Permalink to this headline">¶</a></h3>
<p>Implementation of the bow search strategy</p>
<dl class="class">
<dt>
<em class="property">class </em><code class="descclassname">cam.sgnmt.decoding.bow.</code><code class="descname">BOWDecoder</code><span class="sig-paren">(</span><em>decoder_args</em>, <em>hypo_recombination</em>, <em>max_expansions=0</em>, <em>stochastic=False</em>, <em>early_stopping=True</em>, <em>always_single_step=False</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/decoding/bow.html#BOWDecoder"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Bases: <a class="reference internal" href="cam.sgnmt.decoding.html#cam.sgnmt.decoding.core.Decoder" title="cam.sgnmt.decoding.core.Decoder"><code class="xref py py-class docutils literal"><span class="pre">cam.sgnmt.decoding.core.Decoder</span></code></a></p>
<p>This decoder is designed to work well for bag-of-words decoding
experiments. It is similar to the restarting decoder as it back-
traces to a node in the search tree and does greedy decoding from
that point. However, the strategy to select the node from which to
restart differs: we select the node with the highest expected total
score, which is estimated by taking the score of a full hypothesis
with the same prefix plus the score in the posterior in the
corresponding decoding run of the first deviating token. This
heuristic assumes that the score of the full hypothesis will be
the same as the previous one, just using the better score at the
deviating node in place. This assumption is more likely to hold in
fixed length decoding problems, e.g. bag-of-words tasks.</p>
<p>Note that this decoder does not support the <code class="docutils literal"><span class="pre">max_length</span></code>
parameter as it is designed for fixed length decoding problems.</p>
<p>Also note that even if this decoder is designed for bag problems,
it can be used even in case of variable length hypotheses.
Therefore, you still need to use the bow predictor.</p>
<dl class="method">
<dt>
<code class="descname">create_initial_node</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/decoding/bow.html#BOWDecoder.create_initial_node"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Create the root node for the search tree.</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">decode</code><span class="sig-paren">(</span><em>src_sentence</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/decoding/bow.html#BOWDecoder.decode"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Decodes a single source sentence using BOW search.</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">greedy_decode</code><span class="sig-paren">(</span><em>node</em>, <em>word</em>, <em>single_step</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/decoding/bow.html#BOWDecoder.greedy_decode"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Helper function for greedy decoding from a certain point in
the search tree.</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt>
<em class="property">class </em><code class="descclassname">cam.sgnmt.decoding.bow.</code><code class="descname">BOWNode</code><span class="sig-paren">(</span><em>hypo</em>, <em>posterior</em>, <em>score_breakdown</em>, <em>prev_nodes</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/decoding/bow.html#BOWNode"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal"><span class="pre">object</span></code></p>
<p>Helper class for <code class="docutils literal"><span class="pre">BOWDecoder`</span></code> representing a child
object in the search tree.</p>
<dl class="attribute">
<dt id="cam.sgnmt.decoding.bow.BOWNode.hypo">
<code class="descname">hypo</code><a class="headerlink" href="#cam.sgnmt.decoding.bow.BOWNode.hypo" title="Permalink to this definition">¶</a></dt>
<dd><p><em>PartialHypothesis</em> &#8211; Hypothesis corresponding to this node</p>
</dd></dl>

<dl class="attribute">
<dt id="cam.sgnmt.decoding.bow.BOWNode.posterior">
<code class="descname">posterior</code><a class="headerlink" href="#cam.sgnmt.decoding.bow.BOWNode.posterior" title="Permalink to this definition">¶</a></dt>
<dd><p><em>dict</em> &#8211; Scores on outgoing arcs</p>
</dd></dl>

<dl class="attribute">
<dt id="cam.sgnmt.decoding.bow.BOWNode.score_breakdown">
<code class="descname">score_breakdown</code><a class="headerlink" href="#cam.sgnmt.decoding.bow.BOWNode.score_breakdown" title="Permalink to this definition">¶</a></dt>
<dd><p><em>dict</em> &#8211; Score breakdowns for outgoing arcs</p>
</dd></dl>

<dl class="attribute">
<dt id="cam.sgnmt.decoding.bow.BOWNode.prev_nodes">
<code class="descname">prev_nodes</code><a class="headerlink" href="#cam.sgnmt.decoding.bow.BOWNode.prev_nodes" title="Permalink to this definition">¶</a></dt>
<dd><p><em>list</em> &#8211; Path from the root to this node</p>
</dd></dl>

<dl class="attribute">
<dt id="cam.sgnmt.decoding.bow.BOWNode.active_arcs">
<code class="descname">active_arcs</code><a class="headerlink" href="#cam.sgnmt.decoding.bow.BOWNode.active_arcs" title="Permalink to this definition">¶</a></dt>
<dd><p><em>dict</em> &#8211; Dictionary of unexplored outgoing arcs</p>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="cam-sgnmt-decoding-bucket-module">
<h3>cam.sgnmt.decoding.bucket module<a class="headerlink" href="#cam-sgnmt-decoding-bucket-module" title="Permalink to this headline">¶</a></h3>
<p>Implementation of the bucket search strategy</p>
<dl class="class">
<dt>
<em class="property">class </em><code class="descclassname">cam.sgnmt.decoding.bucket.</code><code class="descname">BucketDecoder</code><span class="sig-paren">(</span><em>decoder_args</em>, <em>hypo_recombination</em>, <em>max_expansions=0</em>, <em>low_memory_mode=True</em>, <em>beam=1</em>, <em>pure_heuristic_scores=False</em>, <em>diversity_factor=-1.0</em>, <em>early_stopping=True</em>, <em>stochastic=False</em>, <em>bucket_selector='maxscore'</em>, <em>bucket_score_strategy='difference'</em>, <em>collect_stats_strategy='best'</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/decoding/bucket.html#BucketDecoder"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Bases: <a class="reference internal" href="cam.sgnmt.decoding.html#cam.sgnmt.decoding.core.Decoder" title="cam.sgnmt.decoding.core.Decoder"><code class="xref py py-class docutils literal"><span class="pre">cam.sgnmt.decoding.core.Decoder</span></code></a></p>
<p>The bucket decoder maintains separate buckets for each sentence
length. The buckets contain partial hypotheses. In each iteration,
the decoder selects a bucket, and expands the best hypothesis in
this bucket by one token. The core of the bucket decoder is the
bucket selection strategy. The following strategies are available:</p>
<ul>
<li><dl class="first docutils">
<dt>&#8216;iter&#8217;: Puts all buckets in a big loop and iterates through it.</dt>
<dd><p class="first last">With this strategy, the number of hypothesis expansions
is equally distributed over the buckets</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt>&#8216;random&#8217;: (with stochastic=true and bucket_selecto!=difference)</dt>
<dd><p class="first last">Randomly select a non-empty bucket</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt>&#8216;difference&#8217;: Similar to the heuristic used by the restarting</dt>
<dd><p class="first last">decoder. Select the bucket in which the difference
between best and second best hypothesis is minimal</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt>&#8216;maxdiff&#8217;: Like &#8216;iter&#8217;, but filters buckets in which the</dt>
<dd><p class="first last">difference between first and second hypo is larger
than epsilon. If no such buckets exist, increase
epsilon</p>
</dd>
</dl>
</li>
</ul>
<dl class="method">
<dt>
<code class="descname">decode</code><span class="sig-paren">(</span><em>src_sentence</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/decoding/bucket.html#BucketDecoder.decode"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Decodes a single source sentence.</p>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="cam-sgnmt-decoding-combibeam-module">
<h3>cam.sgnmt.decoding.combibeam module<a class="headerlink" href="#cam-sgnmt-decoding-combibeam-module" title="Permalink to this headline">¶</a></h3>
<p>Implementation of beam search which applies combination_sheme at
each timestep.</p>
<dl class="class">
<dt>
<em class="property">class </em><code class="descclassname">cam.sgnmt.decoding.combibeam.</code><code class="descname">CombiBeamDecoder</code><span class="sig-paren">(</span><em>decoder_args</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/decoding/combibeam.html#CombiBeamDecoder"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Bases: <a class="reference internal" href="cam.sgnmt.decoding.html#cam.sgnmt.decoding.beam.BeamDecoder" title="cam.sgnmt.decoding.beam.BeamDecoder"><code class="xref py py-class docutils literal"><span class="pre">cam.sgnmt.decoding.beam.BeamDecoder</span></code></a></p>
<p>This beam search implementation is a modification to the hypo
expansion strategy. Rather than selecting hypotheses based on
the sum of the previous hypo scores and the current one, we
apply combination_scheme in each time step. This makes it possible
to use schemes like Bayesian combination on the word rather than
the full sentence level.</p>
</dd></dl>

</div>
<div class="section" id="cam-sgnmt-decoding-core-module">
<h3>cam.sgnmt.decoding.core module<a class="headerlink" href="#cam-sgnmt-decoding-core-module" title="Permalink to this headline">¶</a></h3>
<p>Contains all the basic interfaces and abstract classes for decoding.
This is mainly <code class="docutils literal"><span class="pre">Predictor</span></code> and <code class="docutils literal"><span class="pre">Decoder</span></code>. Functionality should be
implemented mainly in the <code class="docutils literal"><span class="pre">predictors</span></code> package for predictors and in
the <code class="docutils literal"><span class="pre">decoding.decoder</span></code> module for decoders.</p>
<dl class="data">
<dt>
<code class="descclassname">cam.sgnmt.decoding.core.</code><code class="descname">CLOSED_VOCAB_SCORE_NORM_EXACT</code><em class="property"> = 2</em></dt>
<dd><p><em>Exact</em> &#8211; Normalize by 1 plus the number of words outside the
vocabulary to make it a valid distribution again</p>
</dd></dl>

<dl class="data">
<dt>
<code class="descclassname">cam.sgnmt.decoding.core.</code><code class="descname">CLOSED_VOCAB_SCORE_NORM_NONE</code><em class="property"> = 1</em></dt>
<dd><p><em>None</em> &#8211; Do not apply any normalization.</p>
</dd></dl>

<dl class="data">
<dt>
<code class="descclassname">cam.sgnmt.decoding.core.</code><code class="descname">CLOSED_VOCAB_SCORE_NORM_REDUCED</code><em class="property"> = 3</em></dt>
<dd><p><em>Reduced</em> &#8211; Always normalize the closed vocabulary scores to the
vocabulary which is defined by the open vocabulary predictors at each
time step.</p>
</dd></dl>

<dl class="data">
<dt>
<code class="descclassname">cam.sgnmt.decoding.core.</code><code class="descname">CLOSED_VOCAB_SCORE_NORM_RESCALE_UNK</code><em class="property"> = 4</em></dt>
<dd><p><em>Rescale UNK</em> &#8211; Divide the UNK scores by the number of words outside the
vocabulary. Results in a valid distribution if predictor scores are
stochastic.</p>
</dd></dl>

<dl class="class">
<dt>
<em class="property">class </em><code class="descclassname">cam.sgnmt.decoding.core.</code><code class="descname">Decoder</code><span class="sig-paren">(</span><em>decoder_args</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/decoding/core.html#Decoder"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Bases: <a class="reference internal" href="cam.sgnmt.html#cam.sgnmt.utils.Observable" title="cam.sgnmt.utils.Observable"><code class="xref py py-class docutils literal"><span class="pre">cam.sgnmt.utils.Observable</span></code></a></p>
<p>A <code class="docutils literal"><span class="pre">Decoder</span></code> instance represents a particular search strategy
such as A*, beam search, greedy search etc. Decisions are made
based on the outputs of one or many predictors, which are
maintained by the <code class="docutils literal"><span class="pre">Decoder</span></code> instance.</p>
<p>Decoders are observable. They fire notifications after
apply_predictors has been called. All heuristics
are observing the decoder by default.</p>
<dl class="method">
<dt>
<code class="descname">add_full_hypo</code><span class="sig-paren">(</span><em>hypo</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/decoding/core.html#Decoder.add_full_hypo"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Adds a new full hypothesis to <code class="docutils literal"><span class="pre">full_hypos</span></code>. This can be
used by implementing subclasses to add a new hypothesis to the
result set. This method also notifies observers.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>hypo</strong> (<a class="reference internal" href="cam.sgnmt.decoding.html#cam.sgnmt.decoding.core.Hypothesis" title="cam.sgnmt.decoding.core.Hypothesis"><em>Hypothesis</em></a>) &#8211; New complete hypothesis</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">add_heuristic</code><span class="sig-paren">(</span><em>heuristic</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/decoding/core.html#Decoder.add_heuristic"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Add a heuristic to the decoder. For future cost estimates,
the sum of the estimates from all heuristics added so far will
be used. The predictors used in this heuristic have to be set
before via <code class="docutils literal"><span class="pre">set_heuristic_predictors()</span></code></p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>heuristic</strong> (<a class="reference internal" href="cam.sgnmt.decoding.html#cam.sgnmt.decoding.core.Heuristic" title="cam.sgnmt.decoding.core.Heuristic"><em>Heuristic</em></a>) &#8211; A heuristic to use for future cost
estimates</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">add_predictor</code><span class="sig-paren">(</span><em>name</em>, <em>predictor</em>, <em>weight=1.0</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/decoding/core.html#Decoder.add_predictor"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Adds a predictor to the decoder. This means that this
predictor is going to be used to predict the next target word
(see <code class="docutils literal"><span class="pre">predict_next</span></code>)</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>name</strong> (<em>string</em>) &#8211; Predictor name like &#8216;nmt&#8217; or &#8216;fst&#8217;</li>
<li><strong>predictor</strong> (<a class="reference internal" href="cam.sgnmt.predictors.html#cam.sgnmt.predictors.core.Predictor" title="cam.sgnmt.predictors.core.Predictor"><em>Predictor</em></a>) &#8211; Predictor instance</li>
<li><strong>weight</strong> (<em>float</em>) &#8211; Predictor weight</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">apply_predictors</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/decoding/core.html#Decoder.apply_predictors"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Get the distribution over the next word by combining the
predictor scores.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body">Two dicts. <code class="docutils literal"><span class="pre">combined</span></code> maps
target word ids to the combined score, <code class="docutils literal"><span class="pre">score_breakdown</span></code>
contains the scores for each predictor separately
represented as tuples (unweighted_score, predictor_weight)</td>
</tr>
<tr class="field-even field"><th class="field-name">Return type:</th><td class="field-body">combined,score_breakdown</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">are_equal_predictor_states</code><span class="sig-paren">(</span><em>states1</em>, <em>states2</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/decoding/core.html#Decoder.are_equal_predictor_states"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>This method applies <code class="docutils literal"><span class="pre">is_equal</span></code> on all predictors. It
returns true if all predictor states are equal.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>states1</strong> (<em>list</em>) &#8211; First predictor states as returned by
<code class="docutils literal"><span class="pre">get_predictor_states</span></code></li>
<li><strong>states2</strong> (<em>list</em>) &#8211; Second predictor states as returned by
<code class="docutils literal"><span class="pre">get_predictor_states</span></code></li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first last">boolean. True if all predictor states are equal, False
otherwise</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="staticmethod">
<dt>
<em class="property">static </em><code class="descname">combi_arithmetic_unnormalized</code><span class="sig-paren">(</span><em>x</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/decoding/core.html#Decoder.combi_arithmetic_unnormalized"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Calculates the weighted sum (or geometric mean of log
values). Do not use with empty lists.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>x</strong> (<em>list</em>) &#8211; List of tuples [(out1, weight1), ...]</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body">float. Weighted sum out1*weight1+out2*weight2...</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="staticmethod">
<dt>
<em class="property">static </em><code class="descname">combi_geometric_unnormalized</code><span class="sig-paren">(</span><em>x</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/decoding/core.html#Decoder.combi_geometric_unnormalized"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Calculates the weighted geometric mean. Do not use empty
lists.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>x</strong> (<em>list</em>) &#8211; List of tuples [(out1, weight1), ...]</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body">out1^weight1*out2^weight2...</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body">float. Weighted geo. mean</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">consume</code><span class="sig-paren">(</span><em>word</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/decoding/core.html#Decoder.consume"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Calls <code class="docutils literal"><span class="pre">consume()</span></code> on all predictors.</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">decode</code><span class="sig-paren">(</span><em>src_sentence</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/decoding/core.html#Decoder.decode"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Decodes a single source sentence. This method has to be
implemented by subclasses. It contains the core of the
implemented search strategy <code class="docutils literal"><span class="pre">src_sentence</span></code> is a list of
source word ids representing the source sentence without
&lt;S&gt; or &lt;/S&gt; symbols. This method returns a list of hypotheses,
order descending by score such that the first entry is the best
decoding result. Implementations should delegate the scoring of
hypotheses to the predictors via <code class="docutils literal"><span class="pre">apply_predictors()</span></code>, and
organize predictor states with the methods <code class="docutils literal"><span class="pre">consume()</span></code>,
<code class="docutils literal"><span class="pre">get_predictor_states()</span></code> and <code class="docutils literal"><span class="pre">set_predictor_states()</span></code>. In
this way, the decoder is decoupled from the scoring modules.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>src_sentence</strong> (<em>list</em>) &#8211; List of source word ids without &lt;S&gt; or
&lt;/S&gt; which make up the source sentence</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body">list. A list of <code class="docutils literal"><span class="pre">Hypothesis</span></code> instances ordered by their
score.</td>
</tr>
<tr class="field-odd field"><th class="field-name">Raises:</th><td class="field-body"><code class="docutils literal"><span class="pre">NotImplementedError</span></code> &#8211; if the method is not implemented</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">estimate_future_cost</code><span class="sig-paren">(</span><em>hypo</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/decoding/core.html#Decoder.estimate_future_cost"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Uses all heuristics which have been added with
<code class="docutils literal"><span class="pre">add_heuristic</span></code> to estimate the future cost for a given
partial hypothesis. The estimates are used in heuristic based
searches like A*. This function returns the future log <em>cost</em>
(i.e. the lower the better), assuming that the last word in the
partial hypothesis <code class="docutils literal"><span class="pre">hypo</span></code> is consumed next.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>hypo</strong> (<a class="reference internal" href="cam.sgnmt.decoding.html#cam.sgnmt.decoding.core.PartialHypothesis" title="cam.sgnmt.decoding.core.PartialHypothesis"><em>PartialHypothesis</em></a>) &#8211; Hypothesis for which to estimate
the future cost given the current
predictor state</td>
</tr>
</tbody>
</table>
<dl class="docutils">
<dt>Returns</dt>
<dd>float. Future cost</dd>
</dl>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">get_full_hypos_sorted</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/decoding/core.html#Decoder.get_full_hypos_sorted"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Returns <code class="docutils literal"><span class="pre">full_hypos</span></code> sorted by the total score. Can be
used by implementing subclasses as return value of
<code class="docutils literal"><span class="pre">decode</span></code></p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body">list. <code class="docutils literal"><span class="pre">full_hypos</span></code> sorted by <code class="docutils literal"><span class="pre">total_score</span></code>.</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">get_lower_score_bound</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/decoding/core.html#Decoder.get_lower_score_bound"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Intended to be called by implementing subclasses. Returns a
lower bound on the best score of the current sentence. This is
either read from the lower bounds file (if provided) or set to
negative infinity.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body">float. Lower bound on the best score for current sentence</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">get_max_expansions</code><span class="sig-paren">(</span><em>max_expansions_param</em>, <em>src_sentence</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/decoding/core.html#Decoder.get_max_expansions"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>This is a helper for decoders which support the
<code class="docutils literal"><span class="pre">max_node_expansions</span></code> parameter. It returns the maximum
number of node expansions for the given sentence.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>max_expansions_param</strong> (<em>int</em>) &#8211; max_node_expansions parameter
passed through from the config</li>
<li><strong>src_sentence</strong> (<em>list</em>) &#8211; Current source sentence</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first last">int. Maximum number of node expansions for this decoding
task.</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">get_predictor_states</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/decoding/core.html#Decoder.get_predictor_states"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Calls <code class="docutils literal"><span class="pre">get_state()</span></code> on all predictors.</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">has_predictors</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/decoding/core.html#Decoder.has_predictors"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Returns true if predictors have been added to the decoder.</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">initialize_predictors</code><span class="sig-paren">(</span><em>src_sentence</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/decoding/core.html#Decoder.initialize_predictors"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>First, increases the sentence id counter and calls
<code class="docutils literal"><span class="pre">initialize()</span></code> on all predictors. Then, <code class="docutils literal"><span class="pre">initialize()</span></code> is
called for all heuristics.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>src_sentence</strong> (<em>list</em>) &#8211; List of source word ids without &lt;S&gt; or
&lt;/S&gt; which make up the source sentence</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">remove_predictors</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/decoding/core.html#Decoder.remove_predictors"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Removes all predictors of this decoder.</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">reset_predictors</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/decoding/core.html#Decoder.reset_predictors"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Calls <code class="docutils literal"><span class="pre">reset()</span></code> on all predictors and resets the sentence
id counter <code class="docutils literal"><span class="pre">self.current_sen_id</span></code>.</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">set_heuristic_predictors</code><span class="sig-paren">(</span><em>heuristic_predictors</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/decoding/core.html#Decoder.set_heuristic_predictors"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Define the list of predictors used by heuristics. This needs
to be called before adding heuristics with <code class="docutils literal"><span class="pre">add_heuristic()</span></code></p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>heuristic_predictors</strong> (<em>list</em>) &#8211; Predictors and their weights
to be used with heuristics.
Should be in the same form
as <code class="docutils literal"><span class="pre">Decoder.predictors</span></code>,
i.e. a list of
(predictor, weight) tuples</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">set_predictor_combi_method</code><span class="sig-paren">(</span><em>method</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/decoding/core.html#Decoder.set_predictor_combi_method"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Defines how to accumulate scores over the sequence. Should
be one of the <code class="docutils literal"><span class="pre">combi_</span></code> methods defined below</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>method</strong> (<em>function</em>) &#8211; A function which accepts a list of
tuples [(out1, weight1), ...] and
calculates a combined score, e.g.
one of the <code class="docutils literal"><span class="pre">combi_*</span></code> methods</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">set_predictor_states</code><span class="sig-paren">(</span><em>states</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/decoding/core.html#Decoder.set_predictor_states"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Calls <code class="docutils literal"><span class="pre">set_state()</span></code> on all predictors.</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">set_start_sen_id</code><span class="sig-paren">(</span><em>start_sen_id</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/decoding/core.html#Decoder.set_start_sen_id"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Set the internal sentence id counter <cite>self.current_sen_id`</cite>
to <code class="docutils literal"><span class="pre">start_sen_id</span></code> and resets all predictors.</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt>
<em class="property">class </em><code class="descclassname">cam.sgnmt.decoding.core.</code><code class="descname">Heuristic</code><a class="reference internal" href="_modules/cam/sgnmt/decoding/core.html#Heuristic"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Bases: <a class="reference internal" href="cam.sgnmt.html#cam.sgnmt.utils.Observer" title="cam.sgnmt.utils.Observer"><code class="xref py py-class docutils literal"><span class="pre">cam.sgnmt.utils.Observer</span></code></a></p>
<p>A <code class="docutils literal"><span class="pre">Heuristic</span></code> instance can be used to estimate the future
costs for a given word in a given state. See the <code class="docutils literal"><span class="pre">heuristics</span></code>
module for implementations.</p>
<dl class="method">
<dt>
<code class="descname">estimate_future_cost</code><span class="sig-paren">(</span><em>hypo</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/decoding/core.html#Heuristic.estimate_future_cost"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Estimate the future cost (i.e. negative score) given the
states of the predictors set by <code class="docutils literal"><span class="pre">set_predictors</span></code> for a
partial hypothesis <code class="docutils literal"><span class="pre">hypo</span></code>. Note that this function is not
supposed to change predictor states. If (e.g. for the greedy
heuristic) this is not possible, the predictor states must be
changed back after execution by the implementing method.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>hypo</strong> (<em>PartialHypo</em>) &#8211; Hypothesis for which to estimate the
future cost</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body">float. The future cost estimate for this heuristic</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">initialize</code><span class="sig-paren">(</span><em>src_sentence</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/decoding/core.html#Heuristic.initialize"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Initialize the heuristic with the given source sentence.
This is not passed through to the heuristic predictors
automatically but handles initialization outside the
predictors.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>src_sentence</strong> (<em>list</em>) &#8211; List of source word ids without &lt;S&gt; or
&lt;/S&gt; which make up the source sentence</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">notify</code><span class="sig-paren">(</span><em>message</em>, <em>message_type=1</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/decoding/core.html#Heuristic.notify"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>This is the notification method from the <code class="docutils literal"><span class="pre">Observer</span></code>
super class. We implement it with an empty method here, but
implementing sub classes can override this method to get
notifications from the decoder instance about generated
posterior distributions.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>message</strong> (<em>object</em>) &#8211; The posterior sent by the decoder</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">set_predictors</code><span class="sig-paren">(</span><em>predictors</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/decoding/core.html#Heuristic.set_predictors"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Set the predictors used by this heuristic.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>predictors</strong> (<em>list</em>) &#8211; Predictors and their weights to be
used with this heuristic. Should be in
the same form as <code class="docutils literal"><span class="pre">Decoder.predictors</span></code>,
i.e. a list of (predictor, weight)
tuples</td>
</tr>
</tbody>
</table>
</dd></dl>

</dd></dl>

<dl class="class">
<dt>
<em class="property">class </em><code class="descclassname">cam.sgnmt.decoding.core.</code><code class="descname">Hypothesis</code><span class="sig-paren">(</span><em>trgt_sentence</em>, <em>total_score</em>, <em>score_breakdown=[]</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/decoding/core.html#Hypothesis"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Complete translation hypotheses are represented by an instance
of this class. We store the produced sentence, the combined score,
and a score breakdown to the separate predictor scores.</p>
<dl class="method">
<dt>
<code class="descname">convert_to_char_level</code><span class="sig-paren">(</span><em>cmap</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/decoding/core.html#Hypothesis.convert_to_char_level"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Creates a new hypothesis on the character level from a
hypothesis on the word level. Both objects will have the same
total score, but the word tokens in trgt_sentence are replaced
by characters and score_breakdown adds word scores on the first
character of the word. The mapping from word ID to character ID
sequence is realized by using <code class="docutils literal"><span class="pre">utils.trg_wmap</span></code> and the char-
to-id map <code class="docutils literal"><span class="pre">cmap</span></code>.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>cmap</strong> (<em>dict</em>) &#8211; Mapping from character to character ID</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body">Hypothesis. New hypo which corresponds to this hypo but is
tokenized on the character instead of the word level.</td>
</tr>
</tbody>
</table>
</dd></dl>

</dd></dl>

<dl class="class">
<dt>
<em class="property">class </em><code class="descclassname">cam.sgnmt.decoding.core.</code><code class="descname">PartialHypothesis</code><span class="sig-paren">(</span><em>initial_states=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/decoding/core.html#PartialHypothesis"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Represents a partial hypothesis in various decoders.</p>
<dl class="method">
<dt>
<code class="descname">cheap_expand</code><span class="sig-paren">(</span><em>word</em>, <em>score</em>, <em>score_breakdown</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/decoding/core.html#PartialHypothesis.cheap_expand"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Creates a new partial hypothesis adding a new word to the
translation prefix with given probability. Does NOT update the
predictor states but adds a flag which signals that the last
word in this hypothesis has not been consumed yet by the
predictors. This can save memory because we can reuse the
current state for many hypothesis. It also saves computation
as we do not consume words which are then discarded anyway by
the search procedure.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>word</strong> (<em>int</em>) &#8211; New word to add to the translation prefix</li>
<li><strong>score</strong> (<em>float</em>) &#8211; Word log probability which is to be added
to the total hypothesis score</li>
<li><strong>score_breakdown</strong> (<em>list</em>) &#8211; Predictor score breakdown for
the new word</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">expand</code><span class="sig-paren">(</span><em>word</em>, <em>new_states</em>, <em>score</em>, <em>score_breakdown</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/decoding/core.html#PartialHypothesis.expand"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Creates a new partial hypothesis adding a new word to the
translation prefix with given probability and updates the
stored predictor states.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>word</strong> (<em>int</em>) &#8211; New word to add to the translation prefix</li>
<li><strong>new_states</strong> (<em>object</em>) &#8211; Predictor states after consuming
<code class="docutils literal"><span class="pre">word</span></code></li>
<li><strong>score</strong> (<em>float</em>) &#8211; Word log probability which is to be added
to the total hypothesis score</li>
<li><strong>score_breakdown</strong> (<em>list</em>) &#8211; Predictor score breakdown for
the new word</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">generate_full_hypothesis</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/decoding/core.html#PartialHypothesis.generate_full_hypothesis"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Create a <code class="docutils literal"><span class="pre">Hypothesis</span></code> instance from this hypothesis.</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">get_last_word</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/decoding/core.html#PartialHypothesis.get_last_word"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Get the last word in the translation prefix.</p>
</dd></dl>

</dd></dl>

<dl class="function">
<dt>
<code class="descclassname">cam.sgnmt.decoding.core.</code><code class="descname">breakdown2score_bayesian</code><span class="sig-paren">(</span><em>working_score</em>, <em>score_breakdown</em>, <em>full=False</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/decoding/core.html#breakdown2score_bayesian"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>This realizes score combination following the Bayesian LM
interpolation scheme from (Allauzen and Riley, 2011)</p>
<blockquote>
<div>Bayesian Language Model Interpolation for Mobile Speech Input</div></blockquote>
<p>By setting K=T we define the predictor weights according the score
the predictors give to the current partial hypothesis. The initial
predictor weights are used as priors. This function is designed to
be assigned to the globals <code class="docutils literal"><span class="pre">breakdown2score_partial</span></code> or
<code class="docutils literal"><span class="pre">breakdown2score_full</span></code>.
TODO could make more efficient use of <code class="docutils literal"><span class="pre">working_score</span></code></p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>working_score</strong> (<em>float</em>) &#8211; Working combined score, which is the
weighted sum of the scores in
<code class="docutils literal"><span class="pre">score_breakdown</span></code>. Not used.</li>
<li><strong>score_breakdown</strong> (<em>list</em>) &#8211; Breakdown of the combined score into
predictor scores</li>
<li><strong>full</strong> (<em>bool</em>) &#8211; <p>If True, reevaluate all time steps. If False,
assume that this function has been called in the</p>
<blockquote>
<div>previous time step.</div></blockquote>
</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first last">float. Bayesian interpolated predictor scores</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt>
<code class="descclassname">cam.sgnmt.decoding.core.</code><code class="descname">breakdown2score_bayesian_loglin</code><span class="sig-paren">(</span><em>working_score</em>, <em>score_breakdown</em>, <em>full=False</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/decoding/core.html#breakdown2score_bayesian_loglin"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Like bayesian combination scheme, but uses loglinear model
combination rather than linear interpolation weights</p>
<p>TODO: Implement incremental version of it, write weights into breakdowns.</p>
</dd></dl>

<dl class="function">
<dt>
<code class="descclassname">cam.sgnmt.decoding.core.</code><code class="descname">breakdown2score_full</code><span class="sig-paren">(</span><em>working_score</em>, <em>score_breakdown</em>, <em>full=False</em><span class="sig-paren">)</span></dt>
<dd><p>Implements the combination scheme &#8216;sum&#8217; by always returning
<code class="docutils literal"><span class="pre">working_score</span></code>. This function is designed to be assigned to
the globals <code class="docutils literal"><span class="pre">breakdown2score_partial</span></code> or <code class="docutils literal"><span class="pre">breakdown2score_full</span></code></p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>working_score</strong> (<em>float</em>) &#8211; Working combined score, which is the
weighted sum of the scores in
<code class="docutils literal"><span class="pre">score_breakdown</span></code></li>
<li><strong>score_breakdown</strong> (<em>list</em>) &#8211; Breakdown of the combined score into
predictor scores (not used).</li>
<li><strong>full</strong> (<em>bool</em>) &#8211; <p>If True, reevaluate all time steps. If False,
assume that this function has been called in the</p>
<blockquote>
<div>previous time step (not used).</div></blockquote>
</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first last">float. Returns <code class="docutils literal"><span class="pre">working_score</span></code></p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt>
<code class="descclassname">cam.sgnmt.decoding.core.</code><code class="descname">breakdown2score_length_norm</code><span class="sig-paren">(</span><em>working_score</em>, <em>score_breakdown</em>, <em>full=False</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/decoding/core.html#breakdown2score_length_norm"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Implements the combination scheme &#8216;length_norm&#8217; by normalizing
the sum of the predictor scores by the length of the current
sequence (i.e. the length of <code class="docutils literal"><span class="pre">score_breakdown</span></code>. This function is
designed to be assigned to the globals <code class="docutils literal"><span class="pre">breakdown2score_partial</span></code>
or <code class="docutils literal"><span class="pre">breakdown2score_full</span></code>.
TODO could make more efficient use of <code class="docutils literal"><span class="pre">working_score</span></code></p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>working_score</strong> (<em>float</em>) &#8211; Working combined score, which is the
weighted sum of the scores in
<code class="docutils literal"><span class="pre">score_breakdown</span></code>. Not used.</li>
<li><strong>score_breakdown</strong> (<em>list</em>) &#8211; Breakdown of the combined score into
predictor scores</li>
<li><strong>full</strong> (<em>bool</em>) &#8211; <p>If True, reevaluate all time steps. If False,
assume that this function has been called in the</p>
<blockquote>
<div>previous time step (not used).</div></blockquote>
</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first last">float. Returns a length normalized <code class="docutils literal"><span class="pre">working_score</span></code></p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt>
<code class="descclassname">cam.sgnmt.decoding.core.</code><code class="descname">breakdown2score_sum</code><span class="sig-paren">(</span><em>working_score</em>, <em>score_breakdown</em>, <em>full=False</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/decoding/core.html#breakdown2score_sum"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Implements the combination scheme &#8216;sum&#8217; by always returning
<code class="docutils literal"><span class="pre">working_score</span></code>. This function is designed to be assigned to
the globals <code class="docutils literal"><span class="pre">breakdown2score_partial</span></code> or <code class="docutils literal"><span class="pre">breakdown2score_full</span></code></p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>working_score</strong> (<em>float</em>) &#8211; Working combined score, which is the
weighted sum of the scores in
<code class="docutils literal"><span class="pre">score_breakdown</span></code></li>
<li><strong>score_breakdown</strong> (<em>list</em>) &#8211; Breakdown of the combined score into
predictor scores (not used).</li>
<li><strong>full</strong> (<em>bool</em>) &#8211; <p>If True, reevaluate all time steps. If False,
assume that this function has been called in the</p>
<blockquote>
<div>previous time step (not used).</div></blockquote>
</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first last">float. Returns <code class="docutils literal"><span class="pre">working_score</span></code></p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

</div>
<div class="section" id="cam-sgnmt-decoding-decoder-module">
<h3>cam.sgnmt.decoding.decoder module<a class="headerlink" href="#cam-sgnmt-decoding-decoder-module" title="Permalink to this headline">¶</a></h3>
</div>
<div class="section" id="cam-sgnmt-decoding-dfs-module">
<h3>cam.sgnmt.decoding.dfs module<a class="headerlink" href="#cam-sgnmt-decoding-dfs-module" title="Permalink to this headline">¶</a></h3>
<p>Implementation of the dfs search strategy</p>
<dl class="class">
<dt>
<em class="property">class </em><code class="descclassname">cam.sgnmt.decoding.dfs.</code><code class="descname">DFSDecoder</code><span class="sig-paren">(</span><em>decoder_args</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/decoding/dfs.html#DFSDecoder"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Bases: <a class="reference internal" href="cam.sgnmt.decoding.html#cam.sgnmt.decoding.core.Decoder" title="cam.sgnmt.decoding.core.Decoder"><code class="xref py py-class docutils literal"><span class="pre">cam.sgnmt.decoding.core.Decoder</span></code></a></p>
<p>This decoder implements depth first search without using
heuristics. This is the most efficient search algorithm for
complete enumeration of the search space as it minimizes the
number of <code class="docutils literal"><span class="pre">get_state()</span></code> and <code class="docutils literal"><span class="pre">set_state()</span></code> calls. Note that
this DFS implementation has no cycle detection, i.e. if the search
space has cycles this decoder may run into an infinite loop.</p>
<dl class="method">
<dt>
<code class="descname">decode</code><span class="sig-paren">(</span><em>src_sentence</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/decoding/dfs.html#DFSDecoder.decode"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Decodes a single source sentence using depth first search.
If <code class="docutils literal"><span class="pre">max_expansions</span></code> equals 0, this corresponds to exhaustive
search for the globally best scoring hypothesis. Note that with
<code class="docutils literal"><span class="pre">early_stopping</span></code> enabled, the returned set of hypothesis are
not necessarily the global n-best hypotheses. To create an
exact n-best list, disable both <code class="docutils literal"><span class="pre">max_expansions</span></code> and
<code class="docutils literal"><span class="pre">early_stopping</span></code> in the constructor.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>src_sentence</strong> (<em>list</em>) &#8211; List of source word ids without &lt;S&gt; or
&lt;/S&gt; which make up the source sentence</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body">list. A list of <code class="docutils literal"><span class="pre">Hypothesis</span></code> instances ordered by their
score. If <code class="docutils literal"><span class="pre">max_expansions</span></code> equals 0, the first element
holds the global best scoring hypothesis</td>
</tr>
</tbody>
</table>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="cam-sgnmt-decoding-flip-module">
<h3>cam.sgnmt.decoding.flip module<a class="headerlink" href="#cam-sgnmt-decoding-flip-module" title="Permalink to this headline">¶</a></h3>
<p>Implementation of the flip search strategy</p>
<dl class="class">
<dt>
<em class="property">class </em><code class="descclassname">cam.sgnmt.decoding.flip.</code><code class="descname">FlipCandidate</code><span class="sig-paren">(</span><em>trgt_sentence</em>, <em>scores</em>, <em>bigram_scores</em>, <em>max_score</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/decoding/flip.html#FlipCandidate"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal"><span class="pre">object</span></code></p>
<p>Helper class for <code class="docutils literal"><span class="pre">FlipDecoder</span></code>. Represents a full but yet
unscored hypothesis which differs from an explored hypo by one
flip or move operation.</p>
</dd></dl>

<dl class="class">
<dt>
<em class="property">class </em><code class="descclassname">cam.sgnmt.decoding.flip.</code><code class="descname">FlipDecoder</code><span class="sig-paren">(</span><em>decoder_args</em>, <em>trg_test_file</em>, <em>max_expansions=0</em>, <em>early_stopping=True</em>, <em>flip_strategy='move'</em>, <em>always_greedy=False</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/decoding/flip.html#FlipDecoder"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Bases: <a class="reference internal" href="cam.sgnmt.decoding.html#cam.sgnmt.decoding.core.Decoder" title="cam.sgnmt.decoding.core.Decoder"><code class="xref py py-class docutils literal"><span class="pre">cam.sgnmt.decoding.core.Decoder</span></code></a></p>
<p>The flip decoder explores the search space by permutating
already explored hypotheses with a single permutation operation. We
support two operations: &#8216;flip&#8217; flips the position of two target
tokens. &#8216;move&#8217; moves one target token to another location in the
sentence.</p>
<p>Note that this decoder does not support the <code class="docutils literal"><span class="pre">max_length</span></code>
parameter as it is designed for fixed length decoding problems.</p>
<p>Also note that this decoder works only for bag-of-words problems.
Do not use the bow predictor in combination with this decoder as
it will hide the EOS scores which are important to estimate bigram
scores.</p>
<dl class="method">
<dt>
<code class="descname">decode</code><span class="sig-paren">(</span><em>src_sentence</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/decoding/flip.html#FlipDecoder.decode"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Decodes a single source sentence with the flip decoder</p>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="cam-sgnmt-decoding-greedy-module">
<h3>cam.sgnmt.decoding.greedy module<a class="headerlink" href="#cam-sgnmt-decoding-greedy-module" title="Permalink to this headline">¶</a></h3>
<p>Implementation of the greedy search strategy</p>
<dl class="class">
<dt>
<em class="property">class </em><code class="descclassname">cam.sgnmt.decoding.greedy.</code><code class="descname">GreedyDecoder</code><span class="sig-paren">(</span><em>decoder_args</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/decoding/greedy.html#GreedyDecoder"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Bases: <a class="reference internal" href="cam.sgnmt.decoding.html#cam.sgnmt.decoding.core.Decoder" title="cam.sgnmt.decoding.core.Decoder"><code class="xref py py-class docutils literal"><span class="pre">cam.sgnmt.decoding.core.Decoder</span></code></a></p>
<p>The greedy decoder does not revise decisions and therefore does
not have to maintain predictor states. Therefore, this
implementation is particularly simple and can be used as template
for more complex decoders. The greedy decoder can be imitated with
the <code class="docutils literal"><span class="pre">BeamDecoder</span></code> with beam size 1.</p>
<dl class="method">
<dt>
<code class="descname">decode</code><span class="sig-paren">(</span><em>src_sentence</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/decoding/greedy.html#GreedyDecoder.decode"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Decode a single source sentence in a greedy way: Always take
the highest scoring word as next word and proceed to the next
position. This makes it possible to decode without using the
predictors <code class="docutils literal"><span class="pre">get_state()</span></code> and <code class="docutils literal"><span class="pre">set_state()</span></code> methods as we
do not have to keep track of predictor states.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>src_sentence</strong> (<em>list</em>) &#8211; List of source word ids without &lt;S&gt; or
&lt;/S&gt; which make up the source sentence</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body">list. A list of a single best <code class="docutils literal"><span class="pre">Hypothesis</span></code> instance.</td>
</tr>
</tbody>
</table>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="cam-sgnmt-decoding-heuristics-module">
<h3>cam.sgnmt.decoding.heuristics module<a class="headerlink" href="#cam-sgnmt-decoding-heuristics-module" title="Permalink to this headline">¶</a></h3>
<p>Heuristics are used during A* decoding and are called to compose the
estimated look ahead costs. The <code class="docutils literal"><span class="pre">Heuristic</span></code> super class is defined
in the <code class="docutils literal"><span class="pre">core</span></code> module.</p>
<dl class="class">
<dt>
<em class="property">class </em><code class="descclassname">cam.sgnmt.decoding.heuristics.</code><code class="descname">GreedyHeuristic</code><span class="sig-paren">(</span><em>decoder_args</em>, <em>cache_estimates=True</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/decoding/heuristics.html#GreedyHeuristic"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Bases: <a class="reference internal" href="cam.sgnmt.decoding.html#cam.sgnmt.decoding.core.Heuristic" title="cam.sgnmt.decoding.core.Heuristic"><code class="xref py py-class docutils literal"><span class="pre">cam.sgnmt.decoding.core.Heuristic</span></code></a></p>
<p>This heuristic performs greedy decoding to get future cost
estimates. This is expensive but can lead to very close estimates.</p>
<dl class="method">
<dt>
<code class="descname">estimate_future_cost</code><span class="sig-paren">(</span><em>hypo</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/decoding/heuristics.html#GreedyHeuristic.estimate_future_cost"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Estimate the future cost by full greedy decoding. If
<code class="docutils literal"><span class="pre">self.cache_estimates</span></code> is enabled, check cache first</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">estimate_future_cost_with_cache</code><span class="sig-paren">(</span><em>hypo</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/decoding/heuristics.html#GreedyHeuristic.estimate_future_cost_with_cache"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Enabled cache...</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">estimate_future_cost_without_cache</code><span class="sig-paren">(</span><em>hypo</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/decoding/heuristics.html#GreedyHeuristic.estimate_future_cost_without_cache"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Disabled cache...</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">initialize</code><span class="sig-paren">(</span><em>src_sentence</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/decoding/heuristics.html#GreedyHeuristic.initialize"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Initialize the cache.</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">set_predictors</code><span class="sig-paren">(</span><em>predictors</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/decoding/heuristics.html#GreedyHeuristic.set_predictors"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Override <code class="docutils literal"><span class="pre">Decoder.set_predictors</span></code> to redirect the
predictors to <code class="docutils literal"><span class="pre">self.decoder</span></code></p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt>
<em class="property">class </em><code class="descclassname">cam.sgnmt.decoding.heuristics.</code><code class="descname">LastTokenHeuristic</code><a class="reference internal" href="_modules/cam/sgnmt/decoding/heuristics.html#LastTokenHeuristic"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Bases: <a class="reference internal" href="cam.sgnmt.decoding.html#cam.sgnmt.decoding.core.Heuristic" title="cam.sgnmt.decoding.core.Heuristic"><code class="xref py py-class docutils literal"><span class="pre">cam.sgnmt.decoding.core.Heuristic</span></code></a></p>
<p>This heuristic reflects the score of the last token in the
translation prefix only, ie. not the accumulated score. Using this
with pure_heuristic_estimates leads to expanding the partial
hypothesis with the end token with the best individual score. This
can be useful in search spaces in which bad translation prefixes
imply low individual scores later.</p>
<dl class="method">
<dt>
<code class="descname">estimate_future_cost</code><span class="sig-paren">(</span><em>hypo</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/decoding/heuristics.html#LastTokenHeuristic.estimate_future_cost"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Returns the negative score of the last token in hypo.</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">initialize</code><span class="sig-paren">(</span><em>src_sentence</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/decoding/heuristics.html#LastTokenHeuristic.initialize"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Empty method.</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt>
<em class="property">class </em><code class="descclassname">cam.sgnmt.decoding.heuristics.</code><code class="descname">PredictorHeuristic</code><a class="reference internal" href="_modules/cam/sgnmt/decoding/heuristics.html#PredictorHeuristic"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Bases: <a class="reference internal" href="cam.sgnmt.decoding.html#cam.sgnmt.decoding.core.Heuristic" title="cam.sgnmt.decoding.core.Heuristic"><code class="xref py py-class docutils literal"><span class="pre">cam.sgnmt.decoding.core.Heuristic</span></code></a></p>
<p>The predictor heuristic relies on the
<code class="docutils literal"><span class="pre">estimate_future_costs()</span></code> implementation of the predictors. Use
this heuristic to access predictor specific future cost functions,
e.g. shortest path for the fst predictor.</p>
<dl class="method">
<dt>
<code class="descname">estimate_future_cost</code><span class="sig-paren">(</span><em>hypo</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/decoding/heuristics.html#PredictorHeuristic.estimate_future_cost"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Returns the weighted sum of predictor estimates.</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">initialize</code><span class="sig-paren">(</span><em>src_sentence</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/decoding/heuristics.html#PredictorHeuristic.initialize"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Calls <code class="docutils literal"><span class="pre">initialize_heuristic()</span></code> on all predictors.</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">notify</code><span class="sig-paren">(</span><em>message</em>, <em>message_type=1</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/decoding/heuristics.html#PredictorHeuristic.notify"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>This heuristic passes through notifications to the
predictors.</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt>
<em class="property">class </em><code class="descclassname">cam.sgnmt.decoding.heuristics.</code><code class="descname">ScorePerWordHeuristic</code><a class="reference internal" href="_modules/cam/sgnmt/decoding/heuristics.html#ScorePerWordHeuristic"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Bases: <a class="reference internal" href="cam.sgnmt.decoding.html#cam.sgnmt.decoding.core.Heuristic" title="cam.sgnmt.decoding.core.Heuristic"><code class="xref py py-class docutils literal"><span class="pre">cam.sgnmt.decoding.core.Heuristic</span></code></a></p>
<p>Using this heuristic results in length normalized scores instead
of the pure sum of predictor scores for a partial hypothesis.
Therefore, it is not a heuristic like in the classical A* sense.
Instead, using the A* decoder with this heuristic simulates beam
search which always keeps the hypotheses with the best per word
scores.</p>
<dl class="method">
<dt>
<code class="descname">estimate_future_cost</code><span class="sig-paren">(</span><em>hypo</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/decoding/heuristics.html#ScorePerWordHeuristic.estimate_future_cost"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>A* will put <code class="docutils literal"><span class="pre">cost-score</span></code> on the heap. In order to simulate
length normalized beam search, we want to use <code class="docutils literal"><span class="pre">-score/length</span></code>
as partial hypothesis score. Therefore, this method returns
<code class="docutils literal"><span class="pre">-score/length</span> <span class="pre">+</span> <span class="pre">score</span></code></p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">initialize</code><span class="sig-paren">(</span><em>src_sentence</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/decoding/heuristics.html#ScorePerWordHeuristic.initialize"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Empty method.</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt>
<em class="property">class </em><code class="descclassname">cam.sgnmt.decoding.heuristics.</code><code class="descname">StatsHeuristic</code><span class="sig-paren">(</span><em>heuristic_scores_file=''</em>, <em>collect_stats_strategy='best'</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/decoding/heuristics.html#StatsHeuristic"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Bases: <a class="reference internal" href="cam.sgnmt.decoding.html#cam.sgnmt.decoding.core.Heuristic" title="cam.sgnmt.decoding.core.Heuristic"><code class="xref py py-class docutils literal"><span class="pre">cam.sgnmt.decoding.core.Heuristic</span></code></a></p>
<p>This heuristic is based on the sum of unigram costs of consumed
words. Unigram statistics are collected via a <code class="docutils literal"><span class="pre">UnigramTable</span></code>.</p>
<dl class="method">
<dt>
<code class="descname">estimate_future_cost</code><span class="sig-paren">(</span><em>hypo</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/decoding/heuristics.html#StatsHeuristic.estimate_future_cost"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Returns the sum of heuristic unigram estimates of the words
in the translation prefix of <code class="docutils literal"><span class="pre">hypo</span></code>. Combined with the hypo
score, this leads to using the ratio between actual hypo score
and an idealistic score (product of unigrams) to discriminate
partial hypotheses.</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">initialize</code><span class="sig-paren">(</span><em>src_sentence</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/decoding/heuristics.html#StatsHeuristic.initialize"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Calls <code class="docutils literal"><span class="pre">reset</span></code> to reset collected statistics from previous
sentences</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>src_sentence</strong> (<em>list</em>) &#8211; Not used</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">notify</code><span class="sig-paren">(</span><em>message</em>, <em>message_type=1</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/decoding/heuristics.html#StatsHeuristic.notify"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Passing through to the unigram table <code class="docutils literal"><span class="pre">self.estimates</span></code>.</p>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="cam-sgnmt-decoding-multisegbeam-module">
<h3>cam.sgnmt.decoding.multisegbeam module<a class="headerlink" href="#cam-sgnmt-decoding-multisegbeam-module" title="Permalink to this headline">¶</a></h3>
<p>Implementation of beam search for predictors with multiple
tokenizations.</p>
<dl class="class">
<dt>
<em class="property">class </em><code class="descclassname">cam.sgnmt.decoding.multisegbeam.</code><code class="descname">Continuation</code><span class="sig-paren">(</span><em>parent_hypo</em>, <em>pred_stubs</em>, <em>key=''</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/decoding/multisegbeam.html#Continuation"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal"><span class="pre">object</span></code></p>
<p>A continuation is a partial hypothesis plus the next word. A
continuation can be incomplete if predictors use finer grained
tokenization and the score is not final yet.</p>
<dl class="method">
<dt>
<code class="descname">calculate_score</code><span class="sig-paren">(</span><em>pred_weights</em>, <em>defaults=[]</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/decoding/multisegbeam.html#Continuation.calculate_score"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Calculates the full word score for this continuation using
the predictor stub scores.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>pred_weights</strong> (<em>list</em>) &#8211; Predictor weights. Length of this list
must match the number of stubs</li>
<li><strong>defaults</strong> (<em>list</em>) &#8211; Score which should be used if a predictor
stub is set to None</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first last">float. Full score of this continuation, or an optimistic
estimate if the continuation is not complete.</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">expand</code><span class="sig-paren">(</span><em>decoder</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/decoding/multisegbeam.html#Continuation.expand"><span class="viewcode-link">[source]</span></a></dt>
<dd></dd></dl>

<dl class="method">
<dt>
<code class="descname">generate_expanded_hypo</code><span class="sig-paren">(</span><em>decoder</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/decoding/multisegbeam.html#Continuation.generate_expanded_hypo"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>This can be used to create a new <code class="docutils literal"><span class="pre">PartialHypothesis</span></code> which
reflects the state after this continuation. This involves
expanding the history by <code class="docutils literal"><span class="pre">word</span></code>, updating score and <a href="#id1"><span class="problematic" id="id2">score_</span></a>
breakdown, and consuming the last tokens in the stub to save
the final predictor states. If the continuation is complete,
this will result in a new word level hypothesis. If not, the
generated hypo will indicate an incomplete word at the last
position by using the word ID -1.</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">is_complete</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/decoding/multisegbeam.html#Continuation.is_complete"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Returns true if all predictor stubs are completed, i.e.
the continuation can be mapped unambiguously to a word and the
score is final.</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt>
<em class="property">class </em><code class="descclassname">cam.sgnmt.decoding.multisegbeam.</code><code class="descname">EOWTokenizer</code><span class="sig-paren">(</span><em>path</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/decoding/multisegbeam.html#EOWTokenizer"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Bases: <a class="reference internal" href="cam.sgnmt.decoding.html#cam.sgnmt.decoding.multisegbeam.Tokenizer" title="cam.sgnmt.decoding.multisegbeam.Tokenizer"><code class="xref py py-class docutils literal"><span class="pre">cam.sgnmt.decoding.multisegbeam.Tokenizer</span></code></a></p>
<p>This tokenizer reads word maps with explicit &lt;/w&gt; endings. This
can be used for subword unit based tokenizers.</p>
<dl class="method">
<dt>
<code class="descname">is_word_begin_token</code><span class="sig-paren">(</span><em>token</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/decoding/multisegbeam.html#EOWTokenizer.is_word_begin_token"><span class="viewcode-link">[source]</span></a></dt>
<dd></dd></dl>

<dl class="method">
<dt>
<code class="descname">key2tokens</code><span class="sig-paren">(</span><em>key</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/decoding/multisegbeam.html#EOWTokenizer.key2tokens"><span class="viewcode-link">[source]</span></a></dt>
<dd></dd></dl>

<dl class="method">
<dt>
<code class="descname">tokens2key</code><span class="sig-paren">(</span><em>tokens</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/decoding/multisegbeam.html#EOWTokenizer.tokens2key"><span class="viewcode-link">[source]</span></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="class">
<dt>
<em class="property">class </em><code class="descclassname">cam.sgnmt.decoding.multisegbeam.</code><code class="descname">FSTTokenizer</code><span class="sig-paren">(</span><em>path</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/decoding/multisegbeam.html#FSTTokenizer"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Bases: <a class="reference internal" href="cam.sgnmt.decoding.html#cam.sgnmt.decoding.multisegbeam.Tokenizer" title="cam.sgnmt.decoding.multisegbeam.Tokenizer"><code class="xref py py-class docutils literal"><span class="pre">cam.sgnmt.decoding.multisegbeam.Tokenizer</span></code></a></p>
<p>This tokenizer reads in an FST which transduces a sequence
of subword units to a sequence of characters which constitute
the key. The characters must used the global target cmap.</p>
<dl class="attribute">
<dt>
<code class="descname">EPS_ID</code><em class="property"> = 0</em></dt>
<dd><p>OpenFST&#8217;s reserved ID for epsilon arcs.</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">is_word_begin_token</code><span class="sig-paren">(</span><em>token</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/decoding/multisegbeam.html#FSTTokenizer.is_word_begin_token"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Returns true if there is an arc labeled with <code class="docutils literal"><span class="pre">token</span></code> from
the start state in the token2char FST.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>token</strong> (<em>int</em>) &#8211; token ID</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body">bool. True if a word can start with <code class="docutils literal"><span class="pre">token</span></code></td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">key2tokens</code><span class="sig-paren">(</span><em>key</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/decoding/multisegbeam.html#FSTTokenizer.key2tokens"><span class="viewcode-link">[source]</span></a></dt>
<dd></dd></dl>

<dl class="method">
<dt>
<code class="descname">tokens2key</code><span class="sig-paren">(</span><em>tokens</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/decoding/multisegbeam.html#FSTTokenizer.tokens2key"><span class="viewcode-link">[source]</span></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="class">
<dt>
<em class="property">class </em><code class="descclassname">cam.sgnmt.decoding.multisegbeam.</code><code class="descname">MixedTokenizer</code><span class="sig-paren">(</span><em>path</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/decoding/multisegbeam.html#MixedTokenizer"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Bases: <a class="reference internal" href="cam.sgnmt.decoding.html#cam.sgnmt.decoding.multisegbeam.Tokenizer" title="cam.sgnmt.decoding.multisegbeam.Tokenizer"><code class="xref py py-class docutils literal"><span class="pre">cam.sgnmt.decoding.multisegbeam.Tokenizer</span></code></a></p>
<p>This tokenizer allows to mix word- and character-level
tokenizations like proposed by Wu et al. (2016). Words with
&lt;b&gt;, &lt;m&gt;, and &lt;e&gt; prefixes are treated as character-level
tokens, all others are completed word-level tokens</p>
<dl class="method">
<dt>
<code class="descname">is_word_begin_token</code><span class="sig-paren">(</span><em>token</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/decoding/multisegbeam.html#MixedTokenizer.is_word_begin_token"><span class="viewcode-link">[source]</span></a></dt>
<dd></dd></dl>

<dl class="method">
<dt>
<code class="descname">key2tokens</code><span class="sig-paren">(</span><em>key</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/decoding/multisegbeam.html#MixedTokenizer.key2tokens"><span class="viewcode-link">[source]</span></a></dt>
<dd></dd></dl>

<dl class="method">
<dt>
<code class="descname">tokens2key</code><span class="sig-paren">(</span><em>tokens</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/decoding/multisegbeam.html#MixedTokenizer.tokens2key"><span class="viewcode-link">[source]</span></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="class">
<dt>
<em class="property">class </em><code class="descclassname">cam.sgnmt.decoding.multisegbeam.</code><code class="descname">MultisegBeamDecoder</code><span class="sig-paren">(</span><em>decoder_args</em>, <em>hypo_recombination</em>, <em>beam_size</em>, <em>tokenizations</em>, <em>early_stopping=True</em>, <em>max_word_len=25</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/decoding/multisegbeam.html#MultisegBeamDecoder"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Bases: <a class="reference internal" href="cam.sgnmt.decoding.html#cam.sgnmt.decoding.core.Decoder" title="cam.sgnmt.decoding.core.Decoder"><code class="xref py py-class docutils literal"><span class="pre">cam.sgnmt.decoding.core.Decoder</span></code></a></p>
<p>This is a version of beam search which can handle predictors
with differing tokenizations. We assume that all tokenizations are
consistent with words, i.e. no token crosses word boundaries. The
search simulates beam search on the word level. At each time step,
we keep the n best hypotheses on the word level. Predictor scores
on finer-grained tokens are collapsed into a single score s.t. they
can be combined with scores from other predictors. This decoder can
produce words without entry in the word map. In this case, words
are added to <code class="docutils literal"><span class="pre">utils.trg_wmap</span></code>. Consider using the <code class="docutils literal"><span class="pre">output_chars</span></code>
option to avoid dealing with the updated word map in the output.</p>
<dl class="method">
<dt>
<code class="descname">decode</code><span class="sig-paren">(</span><em>src_sentence</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/decoding/multisegbeam.html#MultisegBeamDecoder.decode"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Decodes a single source sentence using beam search.</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt>
<em class="property">class </em><code class="descclassname">cam.sgnmt.decoding.multisegbeam.</code><code class="descname">PredictorStub</code><span class="sig-paren">(</span><em>tokens</em>, <em>pred_state</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/decoding/multisegbeam.html#PredictorStub"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal"><span class="pre">object</span></code></p>
<p>A predictor stub models the state of a predictor given a
continuation.</p>
<dl class="method">
<dt>
<code class="descname">expand</code><span class="sig-paren">(</span><em>token</em>, <em>token_score</em>, <em>pred_state</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/decoding/multisegbeam.html#PredictorStub.expand"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Creates a new predictor stub by adding a (scored) token.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>token</strong> (<em>int</em>) &#8211; Token ID to add</li>
<li><strong>token_score</strong> (<em>float</em>) &#8211; Token score of the added token</li>
<li><strong>pred_state</strong> (<em>object</em>) &#8211; predictor state before consuming
the added token</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">has_full_score</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/decoding/multisegbeam.html#PredictorStub.has_full_score"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Returns true if the full token sequence has been scored with
the predictor, i.e. <code class="docutils literal"><span class="pre">self.score</span></code> is the final predictor
score.</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">score_next</code><span class="sig-paren">(</span><em>token_score</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/decoding/multisegbeam.html#PredictorStub.score_next"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Can be called when the continuation is expanded and the
score of the next token is available</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>token_score</strong> (<em>float</em>) &#8211; Predictor score of
self.tokens[self.score_pos]</td>
</tr>
</tbody>
</table>
</dd></dl>

</dd></dl>

<dl class="class">
<dt>
<em class="property">class </em><code class="descclassname">cam.sgnmt.decoding.multisegbeam.</code><code class="descname">Tokenizer</code><a class="reference internal" href="_modules/cam/sgnmt/decoding/multisegbeam.html#Tokenizer"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal"><span class="pre">object</span></code></p>
<p>A tokenizer translates between token sequences and string keys.
It is mainly responsible for matching token sequences from
different predictors together.</p>
<dl class="method">
<dt>
<code class="descname">is_word_begin_token</code><span class="sig-paren">(</span><em>token</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/decoding/multisegbeam.html#Tokenizer.is_word_begin_token"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Returns true if <code class="docutils literal"><span class="pre">token</span></code> is only allowed at word begins.</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">key2tokens</code><span class="sig-paren">(</span><em>key</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/decoding/multisegbeam.html#Tokenizer.key2tokens"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Convert a key to a sequence of tokens. If this mapping is
ambiguous, return one of the shortest mappings. Use UNK to
match any (sub)string without token correspondence.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>key</strong> (<em>string</em>) &#8211; key to look up</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body">list. List of token IDs</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">tokens2key</code><span class="sig-paren">(</span><em>tokens</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/decoding/multisegbeam.html#Tokenizer.tokens2key"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Convert a token sequence to a string key.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>tokens</strong> (<em>list</em>) &#8211; List of token IDs</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body">String. The key for the token sequence</td>
</tr>
</tbody>
</table>
</dd></dl>

</dd></dl>

<dl class="class">
<dt>
<em class="property">class </em><code class="descclassname">cam.sgnmt.decoding.multisegbeam.</code><code class="descname">WordMapper</code><a class="reference internal" href="_modules/cam/sgnmt/decoding/multisegbeam.html#WordMapper"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal"><span class="pre">object</span></code></p>
<dl class="docutils">
<dt>This class is responsible for the mapping between keys and word</dt>
<dd>IDs. The multiseg beam search can produce words which are not in
the original word map. This mapper adds these words to</dd>
</dl>
<p><code class="docutils literal"><span class="pre">utils.trg_wmap</span></code>.</p>
<blockquote>
<div>This class uses the GoF design pattern singleton.</div></blockquote>
<dl class="staticmethod">
<dt>
<em class="property">static </em><code class="descname">get_singleton</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/decoding/multisegbeam.html#WordMapper.get_singleton"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Get singleton instance of the word mapper. This method
implements lazy initialization.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body">WordMapper. Singleton <code class="docutils literal"><span class="pre">WordMapper</span></code> instance.</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">get_word_id</code><span class="sig-paren">(</span><em>key</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/decoding/multisegbeam.html#WordMapper.get_word_id"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Finds a word ID for the given key. If no such key is in the
current word map, create a new entry in <code class="docutils literal"><span class="pre">utils.trg_wmap</span></code>.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>key</strong> (<em>string</em>) &#8211; key to look up</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body">int. Word ID corresponding to <code class="docutils literal"><span class="pre">key</span></code>. Add new word ID if
the key cannot be found in <code class="docutils literal"><span class="pre">utils.trg_wmap</span></code></td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="attribute">
<dt>
<code class="descname">singleton</code><em class="property"> = None</em></dt>
<dd><p>Singleton instance. Access via <code class="docutils literal"><span class="pre">get_singleton()</span></code>.</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">synchronize</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/decoding/multisegbeam.html#WordMapper.synchronize"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Synchronizes the internal state of this mapper with
<code class="docutils literal"><span class="pre">utils.trg_wmap</span></code>. This includes updating the reverse lookup
table and finding the lowest free word ID which can be assigned
to new words.</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt>
<em class="property">class </em><code class="descclassname">cam.sgnmt.decoding.multisegbeam.</code><code class="descname">WordTokenizer</code><span class="sig-paren">(</span><em>path</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/decoding/multisegbeam.html#WordTokenizer"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Bases: <a class="reference internal" href="cam.sgnmt.decoding.html#cam.sgnmt.decoding.multisegbeam.Tokenizer" title="cam.sgnmt.decoding.multisegbeam.Tokenizer"><code class="xref py py-class docutils literal"><span class="pre">cam.sgnmt.decoding.multisegbeam.Tokenizer</span></code></a></p>
<p>This tokenizer implements a purly word-level tokenization.
Keys are generated according a standard word map.</p>
<dl class="method">
<dt>
<code class="descname">is_word_begin_token</code><span class="sig-paren">(</span><em>token</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/decoding/multisegbeam.html#WordTokenizer.is_word_begin_token"><span class="viewcode-link">[source]</span></a></dt>
<dd></dd></dl>

<dl class="method">
<dt>
<code class="descname">key2tokens</code><span class="sig-paren">(</span><em>key</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/decoding/multisegbeam.html#WordTokenizer.key2tokens"><span class="viewcode-link">[source]</span></a></dt>
<dd></dd></dl>

<dl class="method">
<dt>
<code class="descname">tokens2key</code><span class="sig-paren">(</span><em>tokens</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/decoding/multisegbeam.html#WordTokenizer.tokens2key"><span class="viewcode-link">[source]</span></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="function">
<dt>
<code class="descclassname">cam.sgnmt.decoding.multisegbeam.</code><code class="descname">is_key_complete</code><span class="sig-paren">(</span><em>key</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/decoding/multisegbeam.html#is_key_complete"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Returns true if the key is complete. Complete keys are marked
with a blank symbol at the end of the string. A complete key
corresponds to a full word, incomplete keys cannot be mapped to
word IDs.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>key</strong> (<em>string</em>) &#8211; The key</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body">bool. Return true if the last character in <code class="docutils literal"><span class="pre">key</span></code> is blank.</td>
</tr>
</tbody>
</table>
</dd></dl>

</div>
<div class="section" id="cam-sgnmt-decoding-restarting-module">
<h3>cam.sgnmt.decoding.restarting module<a class="headerlink" href="#cam-sgnmt-decoding-restarting-module" title="Permalink to this headline">¶</a></h3>
<p>Implementation of the restarting search strategy</p>
<dl class="class">
<dt>
<em class="property">class </em><code class="descclassname">cam.sgnmt.decoding.restarting.</code><code class="descname">RestartingChild</code><span class="sig-paren">(</span><em>word</em>, <em>score</em>, <em>score_breakdown</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/decoding/restarting.html#RestartingChild"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal"><span class="pre">object</span></code></p>
<p>Helper class for <code class="docutils literal"><span class="pre">RestartingDecoder`</span></code> representing a child
object in the search tree.</p>
</dd></dl>

<dl class="class">
<dt>
<em class="property">class </em><code class="descclassname">cam.sgnmt.decoding.restarting.</code><code class="descname">RestartingDecoder</code><span class="sig-paren">(</span><em>decoder_args</em>, <em>hypo_recombination</em>, <em>max_expansions=0</em>, <em>low_memory_mode=True</em>, <em>node_cost_strategy='difference'</em>, <em>stochastic=False</em>, <em>always_single_step=False</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/decoding/restarting.html#RestartingDecoder"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Bases: <a class="reference internal" href="cam.sgnmt.decoding.html#cam.sgnmt.decoding.core.Decoder" title="cam.sgnmt.decoding.core.Decoder"><code class="xref py py-class docutils literal"><span class="pre">cam.sgnmt.decoding.core.Decoder</span></code></a></p>
<p>This decoder first creates a path to the final node greedily.
Then, it looks for the node on this path with the smallest
difference between best and second best child, and restarts greedy
decoding from this point. In order to do so, it maintains a
priority queue of all visited nodes, which is ordered by the
difference between the worst expanded child and the best unexpanded
one. If this queue is empty, we have visited the best path. This
algorithm is similar to DFS but does not backtrace to the last call
of the recursive function but to the one which is most promising.</p>
<p>Note that this algorithm is exact. It tries to exploit the problem
characteristics of NMT search: Reloading predictor states can be
expensive, node expansion is even more expensive but for free from
visited nodes, and there is no good admissible heuristic.</p>
<p>Note2: Does not work properly if predictor scores can be positive
because of admissible pruning</p>
<dl class="method">
<dt>
<code class="descname">create_initial_node</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/decoding/restarting.html#RestartingDecoder.create_initial_node"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Create the root node for the search tree.</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">decode</code><span class="sig-paren">(</span><em>src_sentence</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/decoding/restarting.html#RestartingDecoder.decode"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Decodes a single source sentence using Restarting search.</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">greedy_decode</code><span class="sig-paren">(</span><em>hypo</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/decoding/restarting.html#RestartingDecoder.greedy_decode"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Helper function for greedy decoding from a certain point in
the search tree.</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt>
<em class="property">class </em><code class="descclassname">cam.sgnmt.decoding.restarting.</code><code class="descname">RestartingNode</code><span class="sig-paren">(</span><em>hypo</em>, <em>children</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/decoding/restarting.html#RestartingNode"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal"><span class="pre">object</span></code></p>
<p>Helper class for <code class="docutils literal"><span class="pre">RestartingDecoder`</span></code> representing a node
in the search tree.</p>
</dd></dl>

</div>
<div class="section" id="cam-sgnmt-decoding-sepbeam-module">
<h3>cam.sgnmt.decoding.sepbeam module<a class="headerlink" href="#cam-sgnmt-decoding-sepbeam-module" title="Permalink to this headline">¶</a></h3>
<p>Implementation of beam search which does not combine all predictor
scores but keeps only one predictor alive for each hypo in the
beam. Good for approximate and efficient ensembling.</p>
<dl class="class">
<dt>
<em class="property">class </em><code class="descclassname">cam.sgnmt.decoding.sepbeam.</code><code class="descname">SepBeamDecoder</code><span class="sig-paren">(</span><em>decoder_args</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/decoding/sepbeam.html#SepBeamDecoder"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Bases: <a class="reference internal" href="cam.sgnmt.decoding.html#cam.sgnmt.decoding.beam.BeamDecoder" title="cam.sgnmt.decoding.beam.BeamDecoder"><code class="xref py py-class docutils literal"><span class="pre">cam.sgnmt.decoding.beam.BeamDecoder</span></code></a></p>
<p>This beam search implementation breaks with the predictor
abstraction via the <code class="docutils literal"><span class="pre">Decoder.apply_predictors()</span></code> and
<code class="docutils literal"><span class="pre">Decoder.consume()</span></code> interfaces. We do not use combined scores
of all predictors, but link single predictors to hypotheses in
the beam. On hypo expansion, we call <code class="docutils literal"><span class="pre">predict_next()</span></code> only on
this predictor. This is suitable for approximated ensembling as
it reduces the runtime nearly to a single system run.</p>
<p>Note that <code class="docutils literal"><span class="pre">PartialHypothesis.predictor_states</span></code> holds a list
with <code class="docutils literal"><span class="pre">None</span></code> objects except for one position.</p>
<p>Also note that predictor weights are ignored for this decoding
strategy.</p>
</dd></dl>

</div>
<div class="section" id="cam-sgnmt-decoding-syncbeam-module">
<h3>cam.sgnmt.decoding.syncbeam module<a class="headerlink" href="#cam-sgnmt-decoding-syncbeam-module" title="Permalink to this headline">¶</a></h3>
<p>Implementation of beam search with explicit synchronization symbol</p>
<dl class="class">
<dt>
<em class="property">class </em><code class="descclassname">cam.sgnmt.decoding.syncbeam.</code><code class="descname">SyncBeamDecoder</code><span class="sig-paren">(</span><em>decoder_args</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/decoding/syncbeam.html#SyncBeamDecoder"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Bases: <a class="reference internal" href="cam.sgnmt.decoding.html#cam.sgnmt.decoding.beam.BeamDecoder" title="cam.sgnmt.decoding.beam.BeamDecoder"><code class="xref py py-class docutils literal"><span class="pre">cam.sgnmt.decoding.beam.BeamDecoder</span></code></a></p>
<p>This beam search implementation is a two level approach.
Hypotheses are not compared after each iteration, but after
consuming an explicit synchronization symbol. This is useful
when SGNMT runs on the character level, but it makes more sense
to compare hypos with same lengths in terms of number of words
and not characters. The end-of-word symbol &lt;/w&gt; can be used as
synchronization symbol.</p>
</dd></dl>

</div>
<div class="section" id="cam-sgnmt-decoding-syntaxbeam-module">
<h3>cam.sgnmt.decoding.syntaxbeam module<a class="headerlink" href="#cam-sgnmt-decoding-syntaxbeam-module" title="Permalink to this headline">¶</a></h3>
<p>The syntax beam secoding strategy ensures diversity in the terminals.</p>
<dl class="class">
<dt>
<em class="property">class </em><code class="descclassname">cam.sgnmt.decoding.syntaxbeam.</code><code class="descname">SyntaxBeamDecoder</code><span class="sig-paren">(</span><em>decoder_args</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/decoding/syntaxbeam.html#SyntaxBeamDecoder"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Bases: <a class="reference internal" href="cam.sgnmt.decoding.html#cam.sgnmt.decoding.beam.BeamDecoder" title="cam.sgnmt.decoding.beam.BeamDecoder"><code class="xref py py-class docutils literal"><span class="pre">cam.sgnmt.decoding.beam.BeamDecoder</span></code></a></p>
<p>The syntax beam search strategy is an extension of beam search
which ensures diversity amongst the terminals in the active
hypotheses. The decoder clusters hypotheses by their terminal
history. Each cluster cannot have more than beam_size hypos, and
the number of clusters is topped by beam_size. This means that
the effective beam size varies between beam_size and beam_size^2,
and there are always beam_size different terminal histories in the
active beam.</p>
<dl class="method">
<dt>
<code class="descname">decode</code><span class="sig-paren">(</span><em>src_sentence</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/decoding/syntaxbeam.html#SyntaxBeamDecoder.decode"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Decodes a single source sentence using beam search.</p>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="module-contents">
<h3>Module contents<a class="headerlink" href="#module-contents" title="Permalink to this headline">¶</a></h3>
<p>This package contains the central interfaces for the decoder (in the
<code class="docutils literal"><span class="pre">core</span></code> module ), and the implementations of search strategies
(<code class="docutils literal"><span class="pre">Decoder</span></code>).</p>
</div>
</div>
</div>


           </div>
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="examples.html" class="btn btn-neutral float-right" title="Examples" accesskey="n">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="predictors.html" class="btn btn-neutral" title="Predictors" accesskey="p"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2018, University of Cambridge.

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/snide/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  

    <script type="text/javascript">
        var DOCUMENTATION_OPTIONS = {
            URL_ROOT:'./',
            VERSION:'0.3.2',
            COLLAPSE_INDEX:false,
            FILE_SUFFIX:'.html',
            HAS_SOURCE:  true
        };
    </script>
      <script type="text/javascript" src="_static/jquery.js"></script>
      <script type="text/javascript" src="_static/underscore.js"></script>
      <script type="text/javascript" src="_static/doctools.js"></script>

  

  
  
    <script type="text/javascript" src="_static/js/theme.js"></script>
  

  
  
  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.StickyNav.enable();
      });
  </script>
   

</body>
</html>