

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>cam.sgnmt.decoding.core &mdash; SGNMT 0.1 documentation</title>
  

  
  

  

  
  
    

  

  
  
    <link rel="stylesheet" href="../../../../_static/css/theme.css" type="text/css" />
  

  
    <link rel="stylesheet" href="../../../../_static/custom.css" type="text/css" />
  

  
    <link rel="top" title="SGNMT 0.1 documentation" href="../../../../index.html"/>
        <link rel="up" title="Module code" href="../../../index.html"/> 

  
  <script src="../../../../_static/js/modernizr.min.js"></script>

</head>

<body class="wy-body-for-nav" role="document">

  <div class="wy-grid-for-nav">

    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search">
          

          
            <a href="../../../../index.html" class="icon icon-home"> SGNMT
          

          
          </a>

          
            
            
              <div class="version">
                0.1
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
                <ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../setup.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../tutorial.html">Tutorial</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../command_line.html">Command-line reference</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../cam.sgnmt.predictors.html">Predictors</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../cam.sgnmt.decoding.html">Decoders</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../cam.sgnmt.html">All modules</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../publications.html">Publications</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" role="navigation" aria-label="top navigation">
        <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
        <a href="../../../../index.html">SGNMT</a>
      </nav>


      
      <div class="wy-nav-content">
        <div class="rst-content">
          





<div role="navigation" aria-label="breadcrumbs navigation">
  <ul class="wy-breadcrumbs">
    <li><a href="../../../../index.html">Docs</a> &raquo;</li>
      
          <li><a href="../../../index.html">Module code</a> &raquo;</li>
      
    <li>cam.sgnmt.decoding.core</li>
      <li class="wy-breadcrumbs-aside">
        
          
        
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <h1>Source code for cam.sgnmt.decoding.core</h1><div class="highlight"><pre>
<span></span><span class="sd">&quot;&quot;&quot;Contains all the basic interfaces and abstract classes for decoding.</span>
<span class="sd">This is mainly ``Predictor`` and ``Decoder``. Functionality should be</span>
<span class="sd">implemented mainly in the ``predictors`` package for predictors and in</span>
<span class="sd">the ``decoding.decoder`` module for decoders.</span>
<span class="sd">&quot;&quot;&quot;</span>

<span class="kn">from</span> <span class="nn">abc</span> <span class="kn">import</span> <span class="n">abstractmethod</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">cam.sgnmt</span> <span class="kn">import</span> <span class="n">utils</span>

<span class="n">NEG_INF</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="s2">&quot;-inf&quot;</span><span class="p">)</span>

<span class="sd">&quot;&quot;&quot;The ``CLOSED_VOCAB_SCORE_NORM_*`` constants define the normalization</span>
<span class="sd">behavior for closed vocabulary predictor scores. Closed vocabulary </span>
<span class="sd">predictors (e.g. NMT) have a predefined (and normally very limited) </span>
<span class="sd">vocabulary. In contrast, open vocabulary predictors (see </span>
<span class="sd">``UnboundedPredictor``) are defined over a much larger vocabulary </span>
<span class="sd">(e.g. FST) s.t. it is easier to consider them as having an open </span>
<span class="sd">vocabulary. When combining open and closed vocabulary predictors, we use</span>
<span class="sd">the UNK probability of closed vocabulary predictors for words outside </span>
<span class="sd">their vocabulary. The following flags decide (as argument to </span>
<span class="sd">``Decoder``) what to do with the closed vocabulary predictor scores</span>
<span class="sd">when combining them with open vocabulary predictors in that way. This</span>
<span class="sd">can be changed with the --closed_vocab_norm argument &quot;&quot;&quot;</span>


<span class="n">CLOSED_VOCAB_SCORE_NORM_NONE</span> <span class="o">=</span> <span class="mi">1</span>
<span class="sd">&quot;&quot;&quot;None: Do not apply any normalization. &quot;&quot;&quot;</span>


<span class="n">CLOSED_VOCAB_SCORE_NORM_EXACT</span> <span class="o">=</span> <span class="mi">2</span>
<span class="sd">&quot;&quot;&quot;Exact: Normalize by 1 plus the number of words outside the </span>
<span class="sd">vocabulary to make it a valid distribution again&quot;&quot;&quot;</span>


<span class="n">CLOSED_VOCAB_SCORE_NORM_REDUCED</span> <span class="o">=</span> <span class="mi">3</span>
<span class="sd">&quot;&quot;&quot;Reduced: Always normalize the closed vocabulary scores to the </span>
<span class="sd">vocabulary which is defined by the open vocabulary predictors at each</span>
<span class="sd">time step. &quot;&quot;&quot;</span>


<div class="viewcode-block" id="Predictor"><a class="viewcode-back" href="../../../../cam.sgnmt.decoding.html#cam.sgnmt.decoding.core.Predictor">[docs]</a><span class="k">class</span> <span class="nc">Predictor</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;A predictor produces the predictive probability distribution of</span>
<span class="sd">    the next word given the state of the predictor. The state may </span>
<span class="sd">    change during ``predict_next()`` and ``consume()``. The functions</span>
<span class="sd">    ``get_state()`` and ``set_state()`` can be used for non-greedy </span>
<span class="sd">    decoding. Note: The state describes the predictor with the current</span>
<span class="sd">    history. It does not encapsulate the current source sentence, i.e. </span>
<span class="sd">    you cannot recover a predictor state if ``initialize()`` was called</span>
<span class="sd">    in between. ``predict_next()`` and ``consume()`` must be called </span>
<span class="sd">    alternately. This holds even when using ``get_state()`` and </span>
<span class="sd">    ``set_state()``: Loading/saving states is transparent to the</span>
<span class="sd">    predictor instance.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Initializes ``current_sen_id`` with 0. &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">current_sen_id</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">pass</span>

<div class="viewcode-block" id="Predictor.set_current_sen_id"><a class="viewcode-back" href="../../../../cam.sgnmt.decoding.html#cam.sgnmt.decoding.core.Predictor.set_current_sen_id">[docs]</a>    <span class="k">def</span> <span class="nf">set_current_sen_id</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">cur_sen_id</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;This function is called between ``initialize()`` calls to </span>
<span class="sd">        increment the sentence id counter. It can also be used to skip </span>
<span class="sd">        sentences for the --range argument.</span>
<span class="sd">        </span>
<span class="sd">        Args:</span>
<span class="sd">            cur_sen_id (int):  Sentence id for the next call of</span>
<span class="sd">                               ``initialize()``</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">current_sen_id</span> <span class="o">=</span> <span class="n">cur_sen_id</span></div>
    
    <span class="nd">@abstractmethod</span>
<div class="viewcode-block" id="Predictor.predict_next"><a class="viewcode-back" href="../../../../cam.sgnmt.decoding.html#cam.sgnmt.decoding.core.Predictor.predict_next">[docs]</a>    <span class="k">def</span> <span class="nf">predict_next</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Returns the predictive distribution over the target </span>
<span class="sd">        vocabulary for the next word given the predictor state. Note </span>
<span class="sd">        that the prediction itself can change the state of the </span>
<span class="sd">        predictor. For example, the neural predictor updates the </span>
<span class="sd">        decoder network state and its attention to predict the next </span>
<span class="sd">        word. Two calls of ``predict_next()`` must be separated by a </span>
<span class="sd">        ``consume()`` call.</span>
<span class="sd">        </span>
<span class="sd">        Returns:</span>
<span class="sd">            dictionary,array,list. Word log probabilities for the next </span>
<span class="sd">            target token. All ids which are not set are assumed to have</span>
<span class="sd">            probability ``get_unk_probability()``</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span></div>
    
    <span class="nd">@abstractmethod</span>
<div class="viewcode-block" id="Predictor.consume"><a class="viewcode-back" href="../../../../cam.sgnmt.decoding.html#cam.sgnmt.decoding.core.Predictor.consume">[docs]</a>    <span class="k">def</span> <span class="nf">consume</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">word</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Expand the current history by ``word`` and update the </span>
<span class="sd">        internal predictor state accordingly. Two calls of ``consume()``</span>
<span class="sd">        must be separated by a ``predict_next()`` call.</span>
<span class="sd">        </span>
<span class="sd">        Args:</span>
<span class="sd">            word (int):  Word to add to the current history</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span></div>
    
    <span class="nd">@abstractmethod</span>
<div class="viewcode-block" id="Predictor.get_state"><a class="viewcode-back" href="../../../../cam.sgnmt.decoding.html#cam.sgnmt.decoding.core.Predictor.get_state">[docs]</a>    <span class="k">def</span> <span class="nf">get_state</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Get the current predictor state. The state can be any object</span>
<span class="sd">        or tuple of objects which makes it possible to return to the</span>
<span class="sd">        predictor state with the current history.</span>
<span class="sd">        </span>
<span class="sd">        Returns:</span>
<span class="sd">          object. Predictor state</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span></div>
    
    <span class="nd">@abstractmethod</span>
<div class="viewcode-block" id="Predictor.set_state"><a class="viewcode-back" href="../../../../cam.sgnmt.decoding.html#cam.sgnmt.decoding.core.Predictor.set_state">[docs]</a>    <span class="k">def</span> <span class="nf">set_state</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">state</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Loads a predictor state from an object created with </span>
<span class="sd">        ``get_state()``. Note that this does not copy the argument but</span>
<span class="sd">        just references the given state. If ``state`` is going to be</span>
<span class="sd">        used in the future to return to that point again, you should</span>
<span class="sd">        copy the state with ``copy.deepcopy()`` before.</span>
<span class="sd">        </span>
<span class="sd">        Args:</span>
<span class="sd">           state (object): Predictor state as returned by </span>
<span class="sd">                           ``get_state()``</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span></div>
    
    <span class="nd">@abstractmethod</span>
<div class="viewcode-block" id="Predictor.reset"><a class="viewcode-back" href="../../../../cam.sgnmt.decoding.html#cam.sgnmt.decoding.core.Predictor.reset">[docs]</a>    <span class="k">def</span> <span class="nf">reset</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Reset the predictor state to the initial configuration. This</span>
<span class="sd">        is required when a new set of sentences is to be decoded, e.g.</span>
<span class="sd">        to reset the sentence counter in the fst predictor to load the</span>
<span class="sd">        correct lattice. This function is NOT called each time before</span>
<span class="sd">        decoding a single sentence. See ``initialize()`` for this.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span></div>
    
<div class="viewcode-block" id="Predictor.estimate_future_cost"><a class="viewcode-back" href="../../../../cam.sgnmt.decoding.html#cam.sgnmt.decoding.core.Predictor.estimate_future_cost">[docs]</a>    <span class="k">def</span> <span class="nf">estimate_future_cost</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">hypo</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Predictors can implement their own look-ahead cost functions.</span>
<span class="sd">        They are used in A* if the --heuristics parameter is set to </span>
<span class="sd">        predictor. This function should return the future log *cost* </span>
<span class="sd">        (i.e. the lower the better) given the current predictor state, </span>
<span class="sd">        assuming that the last word in the partial hypothesis &#39;hypo&#39; is</span>
<span class="sd">        consumed next. This function must not change the internal </span>
<span class="sd">        predictor state.</span>
<span class="sd">        </span>
<span class="sd">        Args:</span>
<span class="sd">            hypo (PartialHypothesis): Hypothesis for which to estimate</span>
<span class="sd">                                      the future cost given the current</span>
<span class="sd">                                      predictor state</span>
<span class="sd">        </span>
<span class="sd">        Returns</span>
<span class="sd">            float. Future cost</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="mf">0.0</span></div>
    
<div class="viewcode-block" id="Predictor.get_unk_probability"><a class="viewcode-back" href="../../../../cam.sgnmt.decoding.html#cam.sgnmt.decoding.core.Predictor.get_unk_probability">[docs]</a>    <span class="k">def</span> <span class="nf">get_unk_probability</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">posterior</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;This function defines the probability of all words which are</span>
<span class="sd">        not in ``posterior``. This is usually used to combine open and</span>
<span class="sd">        closed vocabulary predictors. The argument ``posterior`` should </span>
<span class="sd">        have been produced with ``predict_next()``</span>
<span class="sd">        </span>
<span class="sd">        Args:</span>
<span class="sd">            posterior (list,array,dict): Return value of the last call</span>
<span class="sd">                                         of ``predict_next``</span>
<span class="sd">        </span>
<span class="sd">        Returns:</span>
<span class="sd">            float: Score to use for words outside ``posterior``</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">NEG_INF</span></div>
    
<div class="viewcode-block" id="Predictor.initialize"><a class="viewcode-back" href="../../../../cam.sgnmt.decoding.html#cam.sgnmt.decoding.core.Predictor.initialize">[docs]</a>    <span class="k">def</span> <span class="nf">initialize</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">src_sentence</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Initialize the predictor with the given source sentence. </span>
<span class="sd">        This resets the internal predictor state and loads everything </span>
<span class="sd">        which is constant throughout the processing of a single source</span>
<span class="sd">        sentence. For example, the NMT decoder runs the encoder network</span>
<span class="sd">        and stores the source annotations.</span>
<span class="sd">        </span>
<span class="sd">        Args:</span>
<span class="sd">            src_sentence (list): List of word IDs which form the source</span>
<span class="sd">                                 sentence without &lt;S&gt; or &lt;/S&gt;</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">pass</span></div>
    
<div class="viewcode-block" id="Predictor.initialize_heuristic"><a class="viewcode-back" href="../../../../cam.sgnmt.decoding.html#cam.sgnmt.decoding.core.Predictor.initialize_heuristic">[docs]</a>    <span class="k">def</span> <span class="nf">initialize_heuristic</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">src_sentence</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;This is called after ``initialize()`` if the predictor is</span>
<span class="sd">        registered as heuristic predictor (i.e. </span>
<span class="sd">        ``estimate_future_cost()`` will be called in the future).</span>
<span class="sd">        Predictors can implement this function for initialization of </span>
<span class="sd">        their own heuristic mechanisms.</span>
<span class="sd">        </span>
<span class="sd">        Args:</span>
<span class="sd">            src_sentence (list): List of word IDs which form the source</span>
<span class="sd">                                 sentence without &lt;S&gt; or &lt;/S&gt;</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">pass</span></div>
    
<div class="viewcode-block" id="Predictor.finalize_posterior"><a class="viewcode-back" href="../../../../cam.sgnmt.decoding.html#cam.sgnmt.decoding.core.Predictor.finalize_posterior">[docs]</a>    <span class="k">def</span> <span class="nf">finalize_posterior</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">scores</span><span class="p">,</span> <span class="n">use_weights</span><span class="p">,</span> <span class="n">normalize_scores</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;This method can be used to enforce the parameters use_weights</span>
<span class="sd">        normalize_scores in predictors with dict posteriors.</span>
<span class="sd">        </span>
<span class="sd">        Args:</span>
<span class="sd">            scores (dict): unnormalized log valued scores</span>
<span class="sd">            use_weights (bool): Set to false to replace all values in </span>
<span class="sd">                                ``scores`` with 0 (= log 1)</span>
<span class="sd">            normalize_scores: Set to true to make the exp of elements </span>
<span class="sd">                              in ``scores`` sum up to 1&quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">scores</span><span class="p">:</span> <span class="c1"># empty scores -&gt; pass through</span>
            <span class="k">return</span> <span class="n">scores</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">use_weights</span><span class="p">:</span>
            <span class="n">scores</span> <span class="o">=</span> <span class="nb">dict</span><span class="o">.</span><span class="n">fromkeys</span><span class="p">(</span><span class="n">scores</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">normalize_scores</span><span class="p">:</span>
            <span class="n">log_sum</span> <span class="o">=</span> <span class="n">utils</span><span class="o">.</span><span class="n">log_sum</span><span class="p">(</span><span class="n">scores</span><span class="o">.</span><span class="n">itervalues</span><span class="p">())</span>
            <span class="n">ret</span> <span class="o">=</span> <span class="p">{</span><span class="n">k</span><span class="p">:</span> <span class="n">v</span> <span class="o">-</span> <span class="n">log_sum</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">scores</span><span class="o">.</span><span class="n">iteritems</span><span class="p">()}</span>
            <span class="k">return</span> <span class="n">ret</span>
        <span class="k">return</span> <span class="n">scores</span></div></div>


<div class="viewcode-block" id="UnboundedVocabularyPredictor"><a class="viewcode-back" href="../../../../cam.sgnmt.decoding.html#cam.sgnmt.decoding.core.UnboundedVocabularyPredictor">[docs]</a><span class="k">class</span> <span class="nc">UnboundedVocabularyPredictor</span><span class="p">(</span><span class="n">Predictor</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Predictors under this class implement models with very large </span>
<span class="sd">    target vocabularies, for which it is too inefficient to list the </span>
<span class="sd">    entire posterior. Instead, they are evaluated only for a given list</span>
<span class="sd">    of target words. This list is usually created by taking all non-zero</span>
<span class="sd">    probability words from the bounded vocabulary predictors. An </span>
<span class="sd">    example of a unbounded vocabulary predictor is the ngram predictor:</span>
<span class="sd">    Instead of listing the entire ngram vocabulary, we run srilm only</span>
<span class="sd">    on the words which are possible according other predictor (e.g. fst</span>
<span class="sd">    or nmt). This is realized by introducing the ``trgt_words``</span>
<span class="sd">    argument to ``predict_next``. &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot; Initializes ``current_sen_id`` with 0. &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">UnboundedVocabularyPredictor</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="n">__init__</span><span class="p">()</span>

    <span class="nd">@abstractmethod</span>
<div class="viewcode-block" id="UnboundedVocabularyPredictor.predict_next"><a class="viewcode-back" href="../../../../cam.sgnmt.decoding.html#cam.sgnmt.decoding.core.UnboundedVocabularyPredictor.predict_next">[docs]</a>    <span class="k">def</span> <span class="nf">predict_next</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">trgt_words</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Like in ``Predictor``, returns the predictive distribution</span>
<span class="sd">        over target words given the predictor state. Note </span>
<span class="sd">        that the prediction itself can change the state of the </span>
<span class="sd">        predictor. For example, the neural predictor updates the </span>
<span class="sd">        decoder network state and its attention to predict the next </span>
<span class="sd">        word. Two calls of ``predict_next()`` must be separated by a </span>
<span class="sd">        ``consume()`` call.</span>
<span class="sd">        </span>
<span class="sd">        Args:</span>
<span class="sd">            trgt_words (list): List of target word ids.</span>
<span class="sd">        </span>
<span class="sd">        Returns:</span>
<span class="sd">            dictionary,array,list. Word log probabilities for the next </span>
<span class="sd">            target token. All ids which are not set are assumed to have</span>
<span class="sd">            probability ``get_unk_probability(). The returned set should</span>
<span class="sd">            not contain any ids which are not in ``trgt_words``, but it</span>
<span class="sd">            does not have to score all of them</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span></div></div>


<div class="viewcode-block" id="Heuristic"><a class="viewcode-back" href="../../../../cam.sgnmt.decoding.html#cam.sgnmt.decoding.core.Heuristic">[docs]</a><span class="k">class</span> <span class="nc">Heuristic</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;A ``Heuristic`` instance can be used to estimate the future </span>
<span class="sd">    costs for a given word in a given state. See the ``heuristics``</span>
<span class="sd">    module for implementations.&quot;&quot;&quot;</span>
    
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Creates a heuristic without predictors. &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Heuristic</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="n">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">predictors</span> <span class="o">=</span> <span class="p">[]</span>

<div class="viewcode-block" id="Heuristic.set_predictors"><a class="viewcode-back" href="../../../../cam.sgnmt.decoding.html#cam.sgnmt.decoding.core.Heuristic.set_predictors">[docs]</a>    <span class="k">def</span> <span class="nf">set_predictors</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">predictors</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Set the predictors used by this heuristic. </span>
<span class="sd">        </span>
<span class="sd">        Args:</span>
<span class="sd">            predictors (list):  Predictors and their weights to be</span>
<span class="sd">                                used with this heuristic. Should be in</span>
<span class="sd">                                the same form as ``Decoder.predictors``,</span>
<span class="sd">                                i.e. a list of (predictor, weight)</span>
<span class="sd">                                tuples</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">predictors</span> <span class="o">=</span> <span class="n">predictors</span></div>
    
<div class="viewcode-block" id="Heuristic.initialize"><a class="viewcode-back" href="../../../../cam.sgnmt.decoding.html#cam.sgnmt.decoding.core.Heuristic.initialize">[docs]</a>    <span class="k">def</span> <span class="nf">initialize</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">src_sentence</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Initialize the heuristic with the given source sentence.</span>
<span class="sd">        This is not passed through to the heuristic predictors</span>
<span class="sd">        automatically but handles initialization outside the</span>
<span class="sd">        predictors.</span>
<span class="sd">        </span>
<span class="sd">        Args:</span>
<span class="sd">            src_sentence (list): List of source word ids without &lt;S&gt; or</span>
<span class="sd">                                 &lt;/S&gt; which make up the source sentence</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">pass</span></div>

    <span class="nd">@abstractmethod</span>
<div class="viewcode-block" id="Heuristic.estimate_future_cost"><a class="viewcode-back" href="../../../../cam.sgnmt.decoding.html#cam.sgnmt.decoding.core.Heuristic.estimate_future_cost">[docs]</a>    <span class="k">def</span> <span class="nf">estimate_future_cost</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">hypo</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Estimate the future cost (i.e. negative score) given the </span>
<span class="sd">        states of the predictors set by ``set_predictors`` for a</span>
<span class="sd">        partial hypothesis ``hypo``. Note that this function is not </span>
<span class="sd">        supposed to change predictor states. If (e.g. for the greedy </span>
<span class="sd">        heuristic) this is not possible, the predictor states must be</span>
<span class="sd">        changed back after execution by the implementing method.</span>
<span class="sd">        </span>
<span class="sd">        Args:</span>
<span class="sd">            hypo (PartialHypo): Hypothesis for which to estimate the</span>
<span class="sd">                                future cost</span>
<span class="sd">        </span>
<span class="sd">        Returns:</span>
<span class="sd">            float. The future cost estimate for this heuristic</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span></div></div>
    

<div class="viewcode-block" id="breakdown2score_sum"><a class="viewcode-back" href="../../../../cam.sgnmt.decoding.html#cam.sgnmt.decoding.core.breakdown2score_sum">[docs]</a><span class="k">def</span> <span class="nf">breakdown2score_sum</span><span class="p">(</span><span class="n">working_score</span><span class="p">,</span> <span class="n">score_breakdown</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Implements the combination scheme &#39;sum&#39; by always returning</span>
<span class="sd">    ``working_score``. This function is designed to be assigned to</span>
<span class="sd">    the globals ``breakdown2score_partial`` or ``breakdown2score_full``</span>
<span class="sd">    </span>
<span class="sd">    Args:</span>
<span class="sd">        working_score (float): Working combined score, which is the </span>
<span class="sd">                               weighted sum of the scores in</span>
<span class="sd">                               ``score_breakdown``</span>
<span class="sd">        score_breakdown (list): Breakdown of the combined score into</span>
<span class="sd">                                predictor scores</span>
<span class="sd">    </span>
<span class="sd">    Returns:</span>
<span class="sd">        float. Returns ``working_score``</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">working_score</span></div>


<div class="viewcode-block" id="breakdown2score_length_norm"><a class="viewcode-back" href="../../../../cam.sgnmt.decoding.html#cam.sgnmt.decoding.core.breakdown2score_length_norm">[docs]</a><span class="k">def</span> <span class="nf">breakdown2score_length_norm</span><span class="p">(</span><span class="n">working_score</span><span class="p">,</span> <span class="n">score_breakdown</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Implements the combination scheme &#39;length_norm&#39; by normalizing</span>
<span class="sd">    the sum of the predictor scores by the length of the current </span>
<span class="sd">    sequence (i.e. the length of ``score_breakdown``. This function is</span>
<span class="sd">    designed to be assigned to the globals ``breakdown2score_partial``</span>
<span class="sd">    or ``breakdown2score_full``. </span>
<span class="sd">    TODO could make more efficient use of ``working_score``</span>
<span class="sd">    </span>
<span class="sd">    Args:</span>
<span class="sd">        working_score (float): Working combined score, which is the </span>
<span class="sd">                               weighted sum of the scores in</span>
<span class="sd">                               ``score_breakdown``. Not used.</span>
<span class="sd">        score_breakdown (list): Breakdown of the combined score into</span>
<span class="sd">                                predictor scores</span>
<span class="sd">    </span>
<span class="sd">    Returns:</span>
<span class="sd">        float. Returns a length normalized ``working_score``</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">score</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">([</span><span class="n">Decoder</span><span class="o">.</span><span class="n">combi_arithmetic_unnormalized</span><span class="p">(</span><span class="n">s</span><span class="p">)</span> 
                        <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="n">score_breakdown</span><span class="p">])</span>
    <span class="k">return</span> <span class="n">score</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">score_breakdown</span><span class="p">)</span></div>


<div class="viewcode-block" id="breakdown2score_bayesian"><a class="viewcode-back" href="../../../../cam.sgnmt.decoding.html#cam.sgnmt.decoding.core.breakdown2score_bayesian">[docs]</a><span class="k">def</span> <span class="nf">breakdown2score_bayesian</span><span class="p">(</span><span class="n">working_score</span><span class="p">,</span> <span class="n">score_breakdown</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;This realizes score combination following the Bayesian LM </span>
<span class="sd">    interpolation scheme from (Allauzen and Riley, 2011)</span>
<span class="sd">    </span>
<span class="sd">      Bayesian Language Model Interpolation for Mobile Speech Input</span>
<span class="sd">    </span>
<span class="sd">    By setting K=T we define the predictor weights according the score</span>
<span class="sd">    the predictors give to the current partial hypothesis. The initial</span>
<span class="sd">    predictor weights are used as priors. This function is designed to </span>
<span class="sd">    be assigned to the globals ``breakdown2score_partial`` or </span>
<span class="sd">    ``breakdown2score_full``. </span>
<span class="sd">    TODO could make more efficient use of ``working_score``</span>
<span class="sd">    </span>
<span class="sd">    Args:</span>
<span class="sd">        working_score (float): Working combined score, which is the </span>
<span class="sd">                               weighted sum of the scores in</span>
<span class="sd">                               ``score_breakdown``. Not used.</span>
<span class="sd">        score_breakdown (list): Breakdown of the combined score into</span>
<span class="sd">                                predictor scores</span>
<span class="sd">    </span>
<span class="sd">    Returns:</span>
<span class="sd">        float. Bayesian interpolated predictor scores</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">score_breakdown</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">working_score</span>
    <span class="n">acc</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">prev_alphas</span> <span class="o">=</span> <span class="p">[]</span> <span class="c1"># list of all alpha_i,k</span>
    <span class="c1"># Write priors to alphas</span>
    <span class="k">for</span> <span class="p">(</span><span class="n">p</span><span class="p">,</span><span class="n">w</span><span class="p">)</span> <span class="ow">in</span> <span class="n">score_breakdown</span><span class="p">[</span><span class="mi">0</span><span class="p">]:</span>
        <span class="n">prev_alphas</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">w</span><span class="p">))</span>
    <span class="k">for</span> <span class="n">pos</span> <span class="ow">in</span> <span class="n">score_breakdown</span><span class="p">:</span> <span class="c1"># for each position in the hypothesis</span>
        <span class="n">alphas</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">sub_acc</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="c1"># for each predictor (p: p_k(w_i|h_i), w: prior p(k))</span>
        <span class="k">for</span> <span class="n">k</span><span class="p">,(</span><span class="n">p</span><span class="p">,</span><span class="n">w</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">pos</span><span class="p">):</span> 
            <span class="n">alpha</span> <span class="o">=</span> <span class="n">prev_alphas</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">+</span> <span class="n">p</span>
            <span class="n">alphas</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">alpha</span><span class="p">)</span>
            <span class="n">sub_acc</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">p</span> <span class="o">+</span> <span class="n">alpha</span><span class="p">)</span>
        <span class="n">acc</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">utils</span><span class="o">.</span><span class="n">log_sum</span><span class="p">(</span><span class="n">sub_acc</span><span class="p">)</span> <span class="o">-</span> <span class="n">utils</span><span class="o">.</span><span class="n">log_sum</span><span class="p">(</span><span class="n">alphas</span><span class="p">))</span>
        <span class="n">prev_alphas</span> <span class="o">=</span> <span class="n">alphas</span>
    <span class="k">return</span> <span class="nb">sum</span><span class="p">(</span><span class="n">acc</span><span class="p">)</span></div>


<span class="sd">&quot;&quot;&quot;The function breakdown2score_partial is called at each hypothesis</span>
<span class="sd">expansion. This should only be changed if --combination_scheme is not </span>
<span class="sd">&#39;sum&#39; and --apply_combination_scheme_to_partial_hypos is set to true.</span>
<span class="sd">&quot;&quot;&quot;</span> 
<span class="n">breakdown2score_partial</span> <span class="o">=</span> <span class="n">breakdown2score_sum</span>


<span class="sd">&quot;&quot;&quot;The function breakdown2score_full is called at each creation of a </span>
<span class="sd">full hypothesis, i.e. only once per hypothesis</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="n">breakdown2score_full</span> <span class="o">=</span> <span class="n">breakdown2score_sum</span>


<div class="viewcode-block" id="Decoder"><a class="viewcode-back" href="../../../../cam.sgnmt.decoding.html#cam.sgnmt.decoding.core.Decoder">[docs]</a><span class="k">class</span> <span class="nc">Decoder</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>    
    <span class="sd">&quot;&quot;&quot;A ``Decoder`` instance represents a particular search strategy</span>
<span class="sd">    such as A*, beam search, greedy search etc. Decisions are made </span>
<span class="sd">    based on the outputs of one or many predictors, which are </span>
<span class="sd">    maintained by the ``Decoder`` instance.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">closed_vocab_norm</span> <span class="o">=</span> <span class="n">CLOSED_VOCAB_SCORE_NORM_NONE</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Initializes the decoder instance with no predictors or </span>
<span class="sd">        heuristics.</span>
<span class="sd">        </span>
<span class="sd">        Args:</span>
<span class="sd">            closed_vocab_norm (int): Defines the normalization behavior</span>
<span class="sd">                                     for closed vocabulary predictor</span>
<span class="sd">                                     scores. See the documentation to</span>
<span class="sd">                                     the ``CLOSED_VOCAB_SCORE_NORM_*``</span>
<span class="sd">                                     variables for more information</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">predictors</span> <span class="o">=</span> <span class="p">[]</span> <span class="c1"># Tuples (predictor, weight)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">heuristics</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">heuristic_predictors</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">predictor_names</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">nbest</span> <span class="o">=</span> <span class="mi">1</span> <span class="c1"># length of n-best list</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">combi_predictor_method</span> <span class="o">=</span> <span class="n">Decoder</span><span class="o">.</span><span class="n">combi_arithmetic_unnormalized</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">combine_posteriors</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_combine_posteriors_norm_none</span>
        <span class="k">if</span> <span class="n">closed_vocab_norm</span> <span class="o">==</span> <span class="n">CLOSED_VOCAB_SCORE_NORM_EXACT</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">combine_posteriors</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_combine_posteriors_norm_exact</span>
        <span class="k">elif</span> <span class="n">closed_vocab_norm</span> <span class="o">==</span> <span class="n">CLOSED_VOCAB_SCORE_NORM_REDUCED</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">combine_posteriors</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_combine_posteriors_norm_reduced</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">current_sen_id</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">start_sen_id</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">apply_predictors_count</span> <span class="o">=</span> <span class="mi">0</span>
    
<div class="viewcode-block" id="Decoder.add_predictor"><a class="viewcode-back" href="../../../../cam.sgnmt.decoding.html#cam.sgnmt.decoding.core.Decoder.add_predictor">[docs]</a>    <span class="k">def</span> <span class="nf">add_predictor</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">predictor</span><span class="p">,</span> <span class="n">weight</span><span class="o">=</span><span class="mf">1.0</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Adds a predictor to the decoder. This means that this </span>
<span class="sd">        predictor is going to be used to predict the next target word</span>
<span class="sd">        (see ``predict_next``)</span>
<span class="sd">        </span>
<span class="sd">        Args:</span>
<span class="sd">            name (string): Predictor name like &#39;nmt&#39; or &#39;fst&#39;</span>
<span class="sd">            predictor (Predictor): Predictor instance</span>
<span class="sd">            weight (float): Predictor weight</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">predictors</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">predictor</span><span class="p">,</span> <span class="n">weight</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">predictor_names</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">name</span><span class="p">)</span></div>
    
<div class="viewcode-block" id="Decoder.set_heuristic_predictors"><a class="viewcode-back" href="../../../../cam.sgnmt.decoding.html#cam.sgnmt.decoding.core.Decoder.set_heuristic_predictors">[docs]</a>    <span class="k">def</span> <span class="nf">set_heuristic_predictors</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">heuristic_predictors</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Define the list of predictors used by heuristics. This needs</span>
<span class="sd">        to be called before adding heuristics with ``add_heuristic()``</span>

<span class="sd">        Args:</span>
<span class="sd">            heuristic_predictors (list):  Predictors and their weights </span>
<span class="sd">                                          to be used with heuristics. </span>
<span class="sd">                                          Should be in the same form </span>
<span class="sd">                                          as ``Decoder.predictors``,</span>
<span class="sd">                                          i.e. a list of </span>
<span class="sd">                                          (predictor, weight) tuples</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">heuristic_predictors</span> <span class="o">=</span> <span class="n">heuristic_predictors</span></div>
    
<div class="viewcode-block" id="Decoder.add_heuristic"><a class="viewcode-back" href="../../../../cam.sgnmt.decoding.html#cam.sgnmt.decoding.core.Decoder.add_heuristic">[docs]</a>    <span class="k">def</span> <span class="nf">add_heuristic</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">heuristic</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Add a heuristic to the decoder. For future cost estimates,</span>
<span class="sd">        the sum of the estimates from all heuristics added so far will</span>
<span class="sd">        be used. The predictors used in this heuristic have to be set</span>
<span class="sd">        before via ``set_heuristic_predictors()``</span>
<span class="sd">        </span>
<span class="sd">        Args:</span>
<span class="sd">            heuristic (Heuristic): A heuristic to use for future cost</span>
<span class="sd">                                   estimates</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">heuristic</span><span class="o">.</span><span class="n">set_predictors</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">heuristic_predictors</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">heuristics</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">heuristic</span><span class="p">)</span></div>
    
<div class="viewcode-block" id="Decoder.estimate_future_cost"><a class="viewcode-back" href="../../../../cam.sgnmt.decoding.html#cam.sgnmt.decoding.core.Decoder.estimate_future_cost">[docs]</a>    <span class="k">def</span> <span class="nf">estimate_future_cost</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">hypo</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Uses all heuristics which have been added with </span>
<span class="sd">        ``add_heuristic`` to estimate the future cost for a given</span>
<span class="sd">        partial hypothesis. The estimates are used in heuristic based</span>
<span class="sd">        searches like A*. This function returns the future log *cost* </span>
<span class="sd">        (i.e. the lower the better), assuming that the last word in the</span>
<span class="sd">        partial hypothesis ``hypo`` is consumed next.</span>
<span class="sd">        </span>
<span class="sd">        Args:</span>
<span class="sd">            hypo (PartialHypothesis): Hypothesis for which to estimate</span>
<span class="sd">                                      the future cost given the current</span>
<span class="sd">                                      predictor state</span>
<span class="sd">        </span>
<span class="sd">        Returns</span>
<span class="sd">            float. Future cost</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="nb">sum</span><span class="p">([</span><span class="n">h</span><span class="o">.</span><span class="n">estimate_future_cost</span><span class="p">(</span><span class="n">hypo</span><span class="p">)</span> <span class="k">for</span> <span class="n">h</span> <span class="ow">in</span>  <span class="bp">self</span><span class="o">.</span><span class="n">heuristics</span><span class="p">])</span></div>
    
<div class="viewcode-block" id="Decoder.consume"><a class="viewcode-back" href="../../../../cam.sgnmt.decoding.html#cam.sgnmt.decoding.core.Decoder.consume">[docs]</a>    <span class="k">def</span> <span class="nf">consume</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">word</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Calls ``consume()`` on all predictors. &quot;&quot;&quot;</span>
        <span class="k">for</span> <span class="p">(</span><span class="n">p</span><span class="p">,</span> <span class="n">_</span><span class="p">)</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">predictors</span><span class="p">:</span>
            <span class="n">p</span><span class="o">.</span><span class="n">consume</span><span class="p">(</span><span class="n">word</span><span class="p">)</span> <span class="c1"># May change predictor state</span></div>
    
    <span class="k">def</span> <span class="nf">_get_non_zero_words</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">bounded_predictors</span><span class="p">,</span> <span class="n">posteriors</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Get the set of words from the predictor posteriors which </span>
<span class="sd">        have non-zero probability. This set of words is then passed</span>
<span class="sd">        through to the open vocabulary predictors.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">words</span> <span class="o">=</span> <span class="bp">None</span>
        <span class="k">for</span> <span class="n">idx</span><span class="p">,</span> <span class="n">posterior</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">posteriors</span><span class="p">):</span>
            <span class="p">(</span><span class="n">p</span><span class="p">,</span> <span class="n">_</span><span class="p">)</span> <span class="o">=</span> <span class="n">bounded_predictors</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span>
            <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">get_unk_probability</span><span class="p">(</span><span class="n">posterior</span><span class="p">)</span> <span class="o">==</span> <span class="n">NEG_INF</span><span class="p">:</span> <span class="c1"># Restrict to this</span>
                <span class="k">if</span> <span class="ow">not</span> <span class="n">words</span><span class="p">:</span>
                    <span class="n">words</span> <span class="o">=</span> <span class="nb">set</span><span class="p">(</span><span class="n">utils</span><span class="o">.</span><span class="n">common_viewkeys</span><span class="p">(</span><span class="n">posterior</span><span class="p">))</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">words</span> <span class="o">=</span> <span class="n">words</span> <span class="o">&amp;</span> <span class="nb">set</span><span class="p">(</span><span class="n">utils</span><span class="o">.</span><span class="n">common_viewkeys</span><span class="p">(</span><span class="n">posterior</span><span class="p">))</span>
                <span class="k">if</span> <span class="ow">not</span> <span class="n">words</span><span class="p">:</span> <span class="c1"># Special case empty set: no word is possible</span>
                    <span class="k">return</span> <span class="nb">set</span><span class="p">([</span><span class="n">utils</span><span class="o">.</span><span class="n">EOS_ID</span><span class="p">])</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">words</span><span class="p">:</span> <span class="c1"># If no restricting predictor, use union</span>
            <span class="n">words</span> <span class="o">=</span> <span class="nb">set</span><span class="p">(</span><span class="n">utils</span><span class="o">.</span><span class="n">common_viewkeys</span><span class="p">(</span><span class="n">posteriors</span><span class="p">[</span><span class="mi">0</span><span class="p">]))</span>
            <span class="k">for</span> <span class="n">posterior</span> <span class="ow">in</span> <span class="n">posteriors</span><span class="p">[</span><span class="mi">1</span><span class="p">:]:</span>
                <span class="n">words</span> <span class="o">=</span> <span class="n">words</span> <span class="o">|</span> <span class="nb">set</span><span class="p">(</span><span class="n">utils</span><span class="o">.</span><span class="n">common_viewkeys</span><span class="p">(</span><span class="n">posterior</span><span class="p">))</span>
        <span class="k">return</span> <span class="n">words</span>
    
<div class="viewcode-block" id="Decoder.apply_predictors"><a class="viewcode-back" href="../../../../cam.sgnmt.decoding.html#cam.sgnmt.decoding.core.Decoder.apply_predictors">[docs]</a>    <span class="k">def</span> <span class="nf">apply_predictors</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Get the distribution over the next word by combining the</span>
<span class="sd">        predictor scores.</span>
<span class="sd">        </span>
<span class="sd">        Returns:</span>
<span class="sd">            combined,score_breakdown: Two dicts. ``combined`` maps </span>
<span class="sd">            target word ids to the combined score, ``score_breakdown``</span>
<span class="sd">            contains the scores for each predictor separately </span>
<span class="sd">            represented as tuples (unweighted_score, predictor_weight)</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">apply_predictors_count</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="n">bounded_predictors</span> <span class="o">=</span> <span class="p">[</span><span class="n">el</span> <span class="k">for</span> <span class="n">el</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">predictors</span> 
                        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">el</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">UnboundedVocabularyPredictor</span><span class="p">)]</span>
        <span class="c1"># Get bounded posteriors</span>
        <span class="n">bounded_posteriors</span> <span class="o">=</span> <span class="p">[</span><span class="n">p</span><span class="o">.</span><span class="n">predict_next</span><span class="p">()</span> <span class="k">for</span> <span class="p">(</span><span class="n">p</span><span class="p">,</span> <span class="n">_</span><span class="p">)</span> <span class="ow">in</span> <span class="n">bounded_predictors</span><span class="p">]</span>
        <span class="n">non_zero_words</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_non_zero_words</span><span class="p">(</span><span class="n">bounded_predictors</span><span class="p">,</span>
                                                  <span class="n">bounded_posteriors</span><span class="p">)</span>
        <span class="c1"># Add unbounded predictors and unk probabilities</span>
        <span class="n">posteriors</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">unk_probs</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">bounded_idx</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">for</span> <span class="p">(</span><span class="n">p</span><span class="p">,</span> <span class="n">_</span><span class="p">)</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">predictors</span><span class="p">:</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">p</span><span class="p">,</span> <span class="n">UnboundedVocabularyPredictor</span><span class="p">):</span>
                <span class="n">posterior</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">predict_next</span><span class="p">(</span><span class="n">non_zero_words</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span> <span class="c1"># Take it from the bounded_* variables</span>
                <span class="n">posterior</span> <span class="o">=</span> <span class="n">bounded_posteriors</span><span class="p">[</span><span class="n">bounded_idx</span><span class="p">]</span>
                <span class="n">bounded_idx</span> <span class="o">+=</span> <span class="mi">1</span>
            <span class="n">posteriors</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">posterior</span><span class="p">)</span>
            <span class="n">unk_probs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">get_unk_probability</span><span class="p">(</span><span class="n">posterior</span><span class="p">))</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">combine_posteriors</span><span class="p">(</span><span class="n">non_zero_words</span><span class="p">,</span> <span class="n">posteriors</span><span class="p">,</span> <span class="n">unk_probs</span><span class="p">)</span></div>
    
    <span class="k">def</span> <span class="nf">_combine_posteriors_norm_none</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
                                      <span class="n">non_zero_words</span><span class="p">,</span>
                                      <span class="n">posteriors</span><span class="p">,</span>
                                      <span class="n">unk_probs</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Combine predictor posteriors according the normalization</span>
<span class="sd">        scheme ``CLOSED_VOCAB_SCORE_NORM_NONE``. For more information</span>
<span class="sd">        on closed vocabulary predictor score normalization see the </span>
<span class="sd">        documentation on the ``CLOSED_VOCAB_SCORE_NORM_*`` vars.</span>
<span class="sd">        </span>
<span class="sd">        Args:</span>
<span class="sd">            non_zero_words (set): All words with positive probability</span>
<span class="sd">            posteriors: Predictor posterior distributions calculated</span>
<span class="sd">                        with ``predict_next()``</span>
<span class="sd">            unk_probs: UNK probabilities of the predictors, calculated</span>
<span class="sd">                       with ``get_unk_probability``</span>
<span class="sd">        </span>
<span class="sd">        Returns:</span>
<span class="sd">            combined,score_breakdown: like in ``apply_predictors()``</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">combined</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="n">score_breakdown</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="k">for</span> <span class="n">trgt_word</span> <span class="ow">in</span> <span class="n">non_zero_words</span><span class="p">:</span>
            <span class="n">preds</span> <span class="o">=</span> <span class="p">[(</span><span class="n">utils</span><span class="o">.</span><span class="n">common_get</span><span class="p">(</span><span class="n">posteriors</span><span class="p">[</span><span class="n">idx</span><span class="p">],</span>
                                       <span class="n">trgt_word</span><span class="p">,</span> <span class="n">unk_probs</span><span class="p">[</span><span class="n">idx</span><span class="p">]),</span> <span class="n">w</span><span class="p">)</span>
                        <span class="k">for</span> <span class="n">idx</span><span class="p">,</span> <span class="p">(</span><span class="n">_</span><span class="p">,</span><span class="n">w</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">predictors</span><span class="p">)]</span>
            <span class="n">combined</span><span class="p">[</span><span class="n">trgt_word</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">combi_predictor_method</span><span class="p">(</span><span class="n">preds</span><span class="p">)</span> 
            <span class="n">score_breakdown</span><span class="p">[</span><span class="n">trgt_word</span><span class="p">]</span> <span class="o">=</span> <span class="n">preds</span>
        <span class="k">return</span> <span class="n">combined</span><span class="p">,</span> <span class="n">score_breakdown</span>
    
    <span class="k">def</span> <span class="nf">_combine_posteriors_norm_exact</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
                                       <span class="n">non_zero_words</span><span class="p">,</span>
                                       <span class="n">posteriors</span><span class="p">,</span>
                                       <span class="n">unk_probs</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Combine predictor posteriors according the normalization</span>
<span class="sd">        scheme ``CLOSED_VOCAB_SCORE_NORM_EXACT``. For more information</span>
<span class="sd">        on closed vocabulary predictor score normalization see the </span>
<span class="sd">        documentation on the ``CLOSED_VOCAB_SCORE_NORM_*`` vars.</span>
<span class="sd">        </span>
<span class="sd">        Args:</span>
<span class="sd">            non_zero_words (set): All words with positive probability</span>
<span class="sd">            posteriors: Predictor posterior distributions calculated</span>
<span class="sd">                        with ``predict_next()``</span>
<span class="sd">            unk_probs: UNK probabilities of the predictors, calculated</span>
<span class="sd">                       with ``get_unk_probability``</span>
<span class="sd">        </span>
<span class="sd">        Returns:</span>
<span class="sd">            combined,score_breakdown: like in ``apply_predictors()``</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">n_predictors</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">predictors</span><span class="p">)</span>
        <span class="n">score_breakdown_raw</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="n">unk_counts</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="n">n_predictors</span>
        <span class="k">for</span> <span class="n">trgt_word</span> <span class="ow">in</span> <span class="n">non_zero_words</span><span class="p">:</span>
            <span class="n">preds</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="k">for</span> <span class="n">idx</span><span class="p">,</span> <span class="p">(</span><span class="n">_</span><span class="p">,</span><span class="n">w</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">predictors</span><span class="p">):</span>
                <span class="k">if</span> <span class="n">utils</span><span class="o">.</span><span class="n">common_contains</span><span class="p">(</span><span class="n">posteriors</span><span class="p">[</span><span class="n">idx</span><span class="p">],</span> <span class="n">trgt_word</span><span class="p">):</span>
                    <span class="n">preds</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">posteriors</span><span class="p">[</span><span class="n">idx</span><span class="p">][</span><span class="n">trgt_word</span><span class="p">],</span> <span class="n">w</span><span class="p">))</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">preds</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">unk_probs</span><span class="p">[</span><span class="n">idx</span><span class="p">],</span> <span class="n">w</span><span class="p">))</span>
                    <span class="n">unk_counts</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span> <span class="o">+=</span> <span class="mi">1</span>
            <span class="n">score_breakdown_raw</span><span class="p">[</span><span class="n">trgt_word</span><span class="p">]</span> <span class="o">=</span> <span class="n">preds</span>
        <span class="n">renorm_factors</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.0</span><span class="p">]</span> <span class="o">*</span> <span class="n">n_predictors</span>
        <span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="nb">xrange</span><span class="p">(</span><span class="n">n_predictors</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">unk_counts</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
                <span class="n">renorm_factors</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span>
                            <span class="mf">1.0</span> 
                            <span class="o">+</span> <span class="p">(</span><span class="n">unk_counts</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span> <span class="o">-</span> <span class="mf">1.0</span><span class="p">)</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">unk_probs</span><span class="p">[</span><span class="n">idx</span><span class="p">]))</span>  
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_combine_posteriors_with_renorm</span><span class="p">(</span><span class="n">score_breakdown_raw</span><span class="p">,</span>
                                                    <span class="n">renorm_factors</span><span class="p">)</span>
    
    <span class="k">def</span> <span class="nf">_combine_posteriors_norm_reduced</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
                                         <span class="n">non_zero_words</span><span class="p">,</span>
                                         <span class="n">posteriors</span><span class="p">,</span>
                                         <span class="n">unk_probs</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Combine predictor posteriors according the normalization</span>
<span class="sd">        scheme ``CLOSED_VOCAB_SCORE_NORM_REDUCED``. For more information</span>
<span class="sd">        on closed vocabulary predictor score normalization see the </span>
<span class="sd">        documentation on the ``CLOSED_VOCAB_SCORE_NORM_*`` vars.</span>
<span class="sd">        </span>
<span class="sd">        Args:</span>
<span class="sd">            non_zero_words (set): All words with positive probability</span>
<span class="sd">            posteriors: Predictor posterior distributions calculated</span>
<span class="sd">                        with ``predict_next()``</span>
<span class="sd">            unk_probs: UNK probabilities of the predictors, calculated</span>
<span class="sd">                       with ``get_unk_probability``</span>
<span class="sd">        </span>
<span class="sd">        Returns:</span>
<span class="sd">            combined,score_breakdown: like in ``apply_predictors()``</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">n_predictors</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">predictors</span><span class="p">)</span>
        <span class="n">score_breakdown_raw</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="k">for</span> <span class="n">trgt_word</span> <span class="ow">in</span> <span class="n">non_zero_words</span><span class="p">:</span> 
            <span class="n">score_breakdown_raw</span><span class="p">[</span><span class="n">trgt_word</span><span class="p">]</span> <span class="o">=</span> <span class="p">[(</span><span class="n">utils</span><span class="o">.</span><span class="n">common_get</span><span class="p">(</span>
                                                <span class="n">posteriors</span><span class="p">[</span><span class="n">idx</span><span class="p">],</span>
                                                <span class="n">trgt_word</span><span class="p">,</span> <span class="n">unk_probs</span><span class="p">[</span><span class="n">idx</span><span class="p">]),</span> <span class="n">w</span><span class="p">)</span>
                        <span class="k">for</span> <span class="n">idx</span><span class="p">,</span> <span class="p">(</span><span class="n">_</span><span class="p">,</span><span class="n">w</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">predictors</span><span class="p">)]</span>
        <span class="n">sums</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="nb">xrange</span><span class="p">(</span><span class="n">n_predictors</span><span class="p">):</span>
            <span class="n">sums</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">utils</span><span class="o">.</span><span class="n">log_sum</span><span class="p">([</span><span class="n">preds</span><span class="p">[</span><span class="n">idx</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span> 
                            <span class="k">for</span> <span class="n">preds</span> <span class="ow">in</span> <span class="n">score_breakdown_raw</span><span class="o">.</span><span class="n">itervalues</span><span class="p">()]))</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_combine_posteriors_with_renorm</span><span class="p">(</span><span class="n">score_breakdown_raw</span><span class="p">,</span> <span class="n">sums</span><span class="p">)</span>
    
    <span class="k">def</span> <span class="nf">_combine_posteriors_with_renorm</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
                                        <span class="n">score_breakdown_raw</span><span class="p">,</span>
                                        <span class="n">renorm_factors</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Helper function for ``_combine_posteriors_norm_*`` functions</span>
<span class="sd">        to renormalize score breakdowns by predictor specific factors.</span>
<span class="sd">        </span>
<span class="sd">        Returns:</span>
<span class="sd">            combined,score_breakdown: like in ``apply_predictors()``</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">n_predictors</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">predictors</span><span class="p">)</span>
        <span class="n">combined</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="n">score_breakdown</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="k">for</span> <span class="n">trgt_word</span><span class="p">,</span><span class="n">preds_raw</span> <span class="ow">in</span> <span class="n">score_breakdown_raw</span><span class="o">.</span><span class="n">iteritems</span><span class="p">():</span>
            <span class="n">preds</span> <span class="o">=</span> <span class="p">[(</span><span class="n">preds_raw</span><span class="p">[</span><span class="n">idx</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span> <span class="o">-</span> <span class="n">renorm_factors</span><span class="p">[</span><span class="n">idx</span><span class="p">],</span>
                      <span class="n">preds_raw</span><span class="p">[</span><span class="n">idx</span><span class="p">][</span><span class="mi">1</span><span class="p">])</span> <span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="nb">xrange</span><span class="p">(</span><span class="n">n_predictors</span><span class="p">)]</span>
            <span class="n">combined</span><span class="p">[</span><span class="n">trgt_word</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">combi_predictor_method</span><span class="p">(</span><span class="n">preds</span><span class="p">)</span> 
            <span class="n">score_breakdown</span><span class="p">[</span><span class="n">trgt_word</span><span class="p">]</span> <span class="o">=</span> <span class="n">preds</span>
        <span class="k">return</span> <span class="n">combined</span><span class="p">,</span> <span class="n">score_breakdown</span>
    
<div class="viewcode-block" id="Decoder.set_start_sen_id"><a class="viewcode-back" href="../../../../cam.sgnmt.decoding.html#cam.sgnmt.decoding.core.Decoder.set_start_sen_id">[docs]</a>    <span class="k">def</span> <span class="nf">set_start_sen_id</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">start_sen_id</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Set the internal sentence id counter `self.current_sen_id``</span>
<span class="sd">        to ``start_sen_id`` and resets all predictors.&quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">start_sen_id</span> <span class="o">=</span> <span class="n">start_sen_id</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">reset_predictors</span><span class="p">()</span></div>

<div class="viewcode-block" id="Decoder.reset_predictors"><a class="viewcode-back" href="../../../../cam.sgnmt.decoding.html#cam.sgnmt.decoding.core.Decoder.reset_predictors">[docs]</a>    <span class="k">def</span> <span class="nf">reset_predictors</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Calls ``reset()`` on all predictors and resets the sentence</span>
<span class="sd">        id counter ``self.current_sen_id``. &quot;&quot;&quot;</span>
        <span class="k">for</span> <span class="p">(</span><span class="n">p</span><span class="p">,</span> <span class="n">_</span><span class="p">)</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">predictors</span><span class="p">:</span>
            <span class="n">p</span><span class="o">.</span><span class="n">reset</span><span class="p">()</span>
        <span class="c1"># -1 because its incremented in initialize_predictors</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">current_sen_id</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">start_sen_id</span><span class="o">-</span><span class="mi">1</span></div>
            
<div class="viewcode-block" id="Decoder.initialize_predictors"><a class="viewcode-back" href="../../../../cam.sgnmt.decoding.html#cam.sgnmt.decoding.core.Decoder.initialize_predictors">[docs]</a>    <span class="k">def</span> <span class="nf">initialize_predictors</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">src_sentence</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;First, increases the sentence id counter and calls</span>
<span class="sd">        ``initialize()`` on all predictors. Then, ``initialize()`` is</span>
<span class="sd">        called for all heuristics.</span>
<span class="sd">        </span>
<span class="sd">        Args:</span>
<span class="sd">            src_sentence (list): List of source word ids without &lt;S&gt; or</span>
<span class="sd">                                 &lt;/S&gt; which make up the source sentence</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">current_sen_id</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="k">for</span> <span class="p">(</span><span class="n">p</span><span class="p">,</span> <span class="n">_</span><span class="p">)</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">predictors</span><span class="p">:</span>
            <span class="n">p</span><span class="o">.</span><span class="n">set_current_sen_id</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">current_sen_id</span><span class="p">)</span>
            <span class="n">p</span><span class="o">.</span><span class="n">initialize</span><span class="p">(</span><span class="n">src_sentence</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">h</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">heuristics</span><span class="p">:</span>
            <span class="n">h</span><span class="o">.</span><span class="n">initialize</span><span class="p">(</span><span class="n">src_sentence</span><span class="p">)</span></div>
    
<div class="viewcode-block" id="Decoder.set_predictor_states"><a class="viewcode-back" href="../../../../cam.sgnmt.decoding.html#cam.sgnmt.decoding.core.Decoder.set_predictor_states">[docs]</a>    <span class="k">def</span> <span class="nf">set_predictor_states</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">states</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Calls ``set_state()`` on all predictors. &quot;&quot;&quot;</span>
        <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">for</span> <span class="p">(</span><span class="n">p</span><span class="p">,</span> <span class="n">_</span><span class="p">)</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">predictors</span><span class="p">:</span>
            <span class="n">p</span><span class="o">.</span><span class="n">set_state</span><span class="p">(</span><span class="n">states</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
            <span class="n">i</span> <span class="o">=</span> <span class="n">i</span> <span class="o">+</span> <span class="mi">1</span></div>
    
<div class="viewcode-block" id="Decoder.get_predictor_states"><a class="viewcode-back" href="../../../../cam.sgnmt.decoding.html#cam.sgnmt.decoding.core.Decoder.get_predictor_states">[docs]</a>    <span class="k">def</span> <span class="nf">get_predictor_states</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Calls ``get_state()`` on all predictors. &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="p">[</span><span class="n">p</span><span class="o">.</span><span class="n">get_state</span><span class="p">()</span> <span class="k">for</span> <span class="p">(</span><span class="n">p</span><span class="p">,</span> <span class="n">_</span><span class="p">)</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">predictors</span><span class="p">]</span></div>
    
<div class="viewcode-block" id="Decoder.set_predictor_combi_method"><a class="viewcode-back" href="../../../../cam.sgnmt.decoding.html#cam.sgnmt.decoding.core.Decoder.set_predictor_combi_method">[docs]</a>    <span class="k">def</span> <span class="nf">set_predictor_combi_method</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">method</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Defines how to accumulate scores over the sequence. Should</span>
<span class="sd">        be one of the ``combi_`` methods defined below</span>
<span class="sd">        </span>
<span class="sd">        Args:</span>
<span class="sd">            method (function):  A function which accepts a list of</span>
<span class="sd">                                tuples [(out1, weight1), ...] and</span>
<span class="sd">                                calculates a combined score, e.g.</span>
<span class="sd">                                one of the ``combi_*`` methods</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">predictor_combi_method</span> <span class="o">=</span> <span class="n">method</span></div>
    
    <span class="nd">@staticmethod</span>
<div class="viewcode-block" id="Decoder.combi_arithmetic_unnormalized"><a class="viewcode-back" href="../../../../cam.sgnmt.decoding.html#cam.sgnmt.decoding.core.Decoder.combi_arithmetic_unnormalized">[docs]</a>    <span class="k">def</span> <span class="nf">combi_arithmetic_unnormalized</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Calculates the weighted sum (or geometric mean of log </span>
<span class="sd">        values). Do not use with empty lists.</span>
<span class="sd">        </span>
<span class="sd">        Args:</span>
<span class="sd">            x (list): List of tuples [(out1, weight1), ...]</span>
<span class="sd">        </span>
<span class="sd">        Returns:</span>
<span class="sd">            float. Weighted sum out1*weight1+out2*weight2...</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="p">(</span><span class="n">fAcc</span><span class="p">,</span> <span class="n">_</span><span class="p">)</span> <span class="o">=</span> <span class="nb">reduce</span><span class="p">(</span><span class="k">lambda</span> <span class="p">(</span><span class="n">f1</span><span class="p">,</span><span class="n">w1</span><span class="p">),</span> <span class="p">(</span><span class="n">f2</span><span class="p">,</span><span class="n">w2</span><span class="p">):(</span><span class="n">f1</span><span class="o">*</span><span class="n">w1</span> <span class="o">+</span> <span class="n">f2</span><span class="o">*</span><span class="n">w2</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">),</span>
                           <span class="n">x</span><span class="p">,</span>
                           <span class="p">(</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">))</span>
        <span class="k">return</span> <span class="n">fAcc</span></div>
    
    <span class="nd">@staticmethod</span>
<div class="viewcode-block" id="Decoder.combi_geometric_unnormalized"><a class="viewcode-back" href="../../../../cam.sgnmt.decoding.html#cam.sgnmt.decoding.core.Decoder.combi_geometric_unnormalized">[docs]</a>    <span class="k">def</span> <span class="nf">combi_geometric_unnormalized</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Calculates the weighted geometric mean. Do not use empty </span>
<span class="sd">        lists.</span>
<span class="sd">        </span>
<span class="sd">        Args:</span>
<span class="sd">            x (list): List of tuples [(out1, weight1), ...]</span>
<span class="sd">        </span>
<span class="sd">        Returns:</span>
<span class="sd">            float. Weighted geo. mean: out1^weight1*out2^weight2...</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="p">(</span><span class="n">fAcc</span><span class="p">,</span> <span class="n">_</span><span class="p">)</span> <span class="o">=</span> <span class="nb">reduce</span><span class="p">(</span><span class="k">lambda</span> <span class="p">(</span><span class="n">f1</span><span class="p">,</span> <span class="n">w1</span><span class="p">),</span> <span class="p">(</span><span class="n">f2</span><span class="p">,</span> <span class="n">w2</span><span class="p">):</span> <span class="p">(</span><span class="nb">pow</span><span class="p">(</span><span class="n">f1</span><span class="p">,</span><span class="n">w1</span><span class="p">)</span> <span class="o">*</span> <span class="nb">pow</span><span class="p">(</span><span class="n">f2</span><span class="o">*</span><span class="n">w2</span><span class="p">),</span>
                                                       <span class="mf">1.0</span><span class="p">),</span>
                           <span class="n">x</span><span class="p">,</span>
                           <span class="p">(</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">))</span>
        <span class="k">return</span> <span class="n">fAcc</span></div>

    <span class="nd">@abstractmethod</span>
<div class="viewcode-block" id="Decoder.decode"><a class="viewcode-back" href="../../../../cam.sgnmt.decoding.html#cam.sgnmt.decoding.core.Decoder.decode">[docs]</a>    <span class="k">def</span> <span class="nf">decode</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">src_sentence</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Decodes a single source sentence. This method has to be </span>
<span class="sd">        implemented by subclasses. It contains the core of the </span>
<span class="sd">        implemented search strategy ``src_sentence`` is a list of</span>
<span class="sd">        source word ids representing the source sentence without</span>
<span class="sd">        &lt;S&gt; or &lt;/S&gt; symbols. This method returns a list of hypotheses,</span>
<span class="sd">        order descending by score such that the first entry is the best</span>
<span class="sd">        decoding result. Implementations should delegate the scoring of</span>
<span class="sd">        hypotheses to the predictors via ``apply_predictors()``, and</span>
<span class="sd">        organize predictor states with the methods ``consume()``,</span>
<span class="sd">        ``get_predictor_states()`` and ``set_predictor_states()``. In</span>
<span class="sd">        this way, the decoder is decoupled from the scoring modules.</span>
<span class="sd">        </span>
<span class="sd">        Args:</span>
<span class="sd">            src_sentence (list): List of source word ids without &lt;S&gt; or</span>
<span class="sd">                                 &lt;/S&gt; which make up the source sentence</span>
<span class="sd">        </span>
<span class="sd">        Returns:</span>
<span class="sd">            list. A list of ``Hypothesis`` instances ordered by their</span>
<span class="sd">            score.</span>
<span class="sd">        </span>
<span class="sd">        Raises:</span>
<span class="sd">            ``NotImplementedError``: if the method is not implemented</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span></div></div>
</pre></div>

           </div>
          </div>
          <footer>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2016, Felix Stahlberg, University of Cambridge.

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/snide/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  

    <script type="text/javascript">
        var DOCUMENTATION_OPTIONS = {
            URL_ROOT:'../../../../',
            VERSION:'0.1',
            COLLAPSE_INDEX:false,
            FILE_SUFFIX:'.html',
            HAS_SOURCE:  true
        };
    </script>
      <script type="text/javascript" src="../../../../_static/jquery.js"></script>
      <script type="text/javascript" src="../../../../_static/underscore.js"></script>
      <script type="text/javascript" src="../../../../_static/doctools.js"></script>

  

  
  
    <script type="text/javascript" src="../../../../_static/js/theme.js"></script>
  

  
  
  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.StickyNav.enable();
      });
  </script>
   

</body>
</html>