

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>cam.sgnmt.blocks.pruning &mdash; SGNMT 0.6 documentation</title>
  

  
  

  

  
  
    

  

  
  
    <link rel="stylesheet" href="../../../../_static/css/theme.css" type="text/css" />
  

  
    <link rel="stylesheet" href="../../../../_static/custom.css" type="text/css" />
  

  
    <link rel="top" title="SGNMT 0.6 documentation" href="../../../../index.html"/>
        <link rel="up" title="Module code" href="../../../index.html"/> 

  
  <script src="../../../../_static/js/modernizr.min.js"></script>

</head>

<body class="wy-body-for-nav" role="document">

  <div class="wy-grid-for-nav">

    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search">
          

          
            <a href="../../../../index.html" class="icon icon-home"> SGNMT
          

          
          </a>

          
            
            
              <div class="version">
                0.6
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
                <ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../setup.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../tutorial.html">Tutorial: Basics</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../adding_components.html">Tutorial: Adding new components</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../kyoto_nmt.html">Tutorial:  NMT decoding strategies</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../command_line.html">Command-line reference</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../predictors.html">Predictors</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../decoders.html">Decoders</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../examples.html">Examples</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../faq.html">Common issues</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../publications.html">Publications</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../cam.sgnmt.html">All modules</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" role="navigation" aria-label="top navigation">
        <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
        <a href="../../../../index.html">SGNMT</a>
      </nav>


      
      <div class="wy-nav-content">
        <div class="rst-content">
          





<div role="navigation" aria-label="breadcrumbs navigation">
  <ul class="wy-breadcrumbs">
    <li><a href="../../../../index.html">Docs</a> &raquo;</li>
      
          <li><a href="../../../index.html">Module code</a> &raquo;</li>
      
    <li>cam.sgnmt.blocks.pruning</li>
      <li class="wy-breadcrumbs-aside">
        
          
        
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <h1>Source code for cam.sgnmt.blocks.pruning</h1><div class="highlight"><pre>
<span></span><span class="sd">&quot;&quot;&quot;This module contains code for model pruning during training. This</span>
<span class="sd">implements the data-bound neuron removal algorithm descibed in</span>

<span class="sd">Unfolding and Shrinking Neural Machine Translation Ensembles</span>
<span class="sd">Felix Stahlberg and Bill Byrne</span>
<span class="sd">https://arxiv.org/abs/1704.03279</span>

<span class="sd">Note that to avoid rebuilding the computation graph after each</span>
<span class="sd">prunning operation, we do not remove neurons but set their connections</span>
<span class="sd">to zero. To realize speed ups, neurons with zero weights must be</span>
<span class="sd">removed in a postprocessing step.</span>
<span class="sd">&quot;&quot;&quot;</span>

<span class="kn">import</span> <span class="nn">logging</span>

<span class="kn">from</span> <span class="nn">blocks.algorithms</span> <span class="kn">import</span> <span class="n">GradientDescent</span>
<span class="kn">from</span> <span class="nn">blocks.graph</span> <span class="kn">import</span> <span class="n">ComputationGraph</span>
<span class="kn">from</span> <span class="nn">blocks.bricks.sequence_generators</span> <span class="kn">import</span> <span class="n">SequenceGenerator</span>
<span class="kn">from</span> <span class="nn">blocks.bricks.base</span> <span class="kn">import</span> <span class="n">application</span>
<span class="kn">from</span> <span class="nn">blocks.utils</span> <span class="kn">import</span> <span class="n">dict_union</span><span class="p">,</span> <span class="n">dict_subset</span>
<span class="kn">from</span> <span class="nn">blocks.bricks</span> <span class="kn">import</span> <span class="n">FeedforwardSequence</span><span class="p">,</span> <span class="n">Initializable</span>
<span class="kn">from</span> <span class="nn">blocks.utils</span> <span class="kn">import</span> <span class="n">pack</span>
<span class="kn">from</span> <span class="nn">theano</span> <span class="kn">import</span> <span class="n">tensor</span>
<span class="kn">import</span> <span class="nn">theano</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>

<span class="n">logger</span> <span class="o">=</span> <span class="n">logging</span><span class="o">.</span><span class="n">getLogger</span><span class="p">(</span><span class="n">__name__</span><span class="p">)</span>

<span class="n">INF_DIST</span> <span class="o">=</span> <span class="mf">10000.0</span>

<div class="viewcode-block" id="PrunableLayer"><a class="viewcode-back" href="../../../../cam.sgnmt.blocks.html#cam.sgnmt.blocks.pruning.PrunableLayer">[docs]</a><span class="k">class</span> <span class="nc">PrunableLayer</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;This class represents a layer definition loaded from the file</span>
<span class="sd">    system and keeps track of neurons which have been removed in the</span>
<span class="sd">    layer.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> 
                 <span class="n">name</span><span class="p">,</span> 
                 <span class="n">theano_variable</span><span class="p">,</span> 
                 <span class="n">trg_size</span><span class="p">,</span> 
                 <span class="n">n_steps</span><span class="p">,</span> 
                 <span class="n">maxout</span><span class="o">=</span><span class="bp">False</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Creates a new ``PrunableLayer`` instance.</span>
<span class="sd">        </span>
<span class="sd">        Args:</span>
<span class="sd">            name (string): Name of the layer</span>
<span class="sd">            theano_variable (TheanoVariable): Variable in the </span>
<span class="sd">                                              computation graph which</span>
<span class="sd">                                              stores the neuron</span>
<span class="sd">                                              activities in the layer</span>
<span class="sd">            trg_size (int): Remove neurons in this layer until this</span>
<span class="sd">                            layer size is reached</span>
<span class="sd">            n_steps (int): Number of pruning operations</span>
<span class="sd">            maxout (bool): Whether this layer is a maxout layer.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">name</span> <span class="o">=</span> <span class="n">name</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">theano_variable</span> <span class="o">=</span> <span class="n">theano_variable</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dists</span> <span class="o">=</span> <span class="bp">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">activities</span> <span class="o">=</span> <span class="bp">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">mask</span> <span class="o">=</span> <span class="bp">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_obs</span> <span class="o">=</span> <span class="mf">0.0</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">trg_size</span> <span class="o">=</span> <span class="n">trg_size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_steps</span> <span class="o">=</span> <span class="n">n_steps</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">connections</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">pruned_neurons</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">obs</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">maxout</span> <span class="o">=</span> <span class="n">maxout</span>

<div class="viewcode-block" id="PrunableLayer.reset"><a class="viewcode-back" href="../../../../cam.sgnmt.blocks.html#cam.sgnmt.blocks.pruning.PrunableLayer.reset">[docs]</a>    <span class="k">def</span> <span class="nf">reset</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Resets the activity records. Can be called after a pruning</span>
<span class="sd">        operation to maintain recency.</span>
<span class="sd">        &quot;&quot;&quot;</span> 
        <span class="bp">self</span><span class="o">.</span><span class="n">dists</span> <span class="o">=</span> <span class="bp">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">activities</span> <span class="o">=</span> <span class="bp">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_obs</span> <span class="o">=</span> <span class="mf">0.0</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">obs</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Layer </span><span class="si">%s</span><span class="s2"> reset&quot;</span> <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="n">name</span><span class="p">)</span></div>

<div class="viewcode-block" id="PrunableLayer.initialize_mask"><a class="viewcode-back" href="../../../../cam.sgnmt.blocks.html#cam.sgnmt.blocks.pruning.PrunableLayer.initialize_mask">[docs]</a>    <span class="k">def</span> <span class="nf">initialize_mask</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Initialize the neuron mask to a upper triangular matrix, ie.</span>
<span class="sd">        no neuron has been removed.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">mask</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">triu</span><span class="p">(</span><span class="n">INF_DIST</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">ones_like</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dists</span><span class="p">))</span></div>

<div class="viewcode-block" id="PrunableLayer.derive_step_size"><a class="viewcode-back" href="../../../../cam.sgnmt.blocks.html#cam.sgnmt.blocks.pruning.PrunableLayer.derive_step_size">[docs]</a>    <span class="k">def</span> <span class="nf">derive_step_size</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Calculate the required step size to reach the target size</span>
<span class="sd">        for this layer.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">step_size</span> <span class="o">=</span> <span class="nb">int</span><span class="p">((</span><span class="bp">self</span><span class="o">.</span><span class="n">get_size</span><span class="p">()</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">trg_size</span><span class="p">)</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_steps</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">step_size</span> <span class="o">+=</span> <span class="mi">1</span></div>

<div class="viewcode-block" id="PrunableLayer.get_size"><a class="viewcode-back" href="../../../../cam.sgnmt.blocks.html#cam.sgnmt.blocks.pruning.PrunableLayer.get_size">[docs]</a>    <span class="k">def</span> <span class="nf">get_size</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Get the size of the layer. &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">mask</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span></div>

<div class="viewcode-block" id="PrunableLayer.register_activities"><a class="viewcode-back" href="../../../../cam.sgnmt.blocks.html#cam.sgnmt.blocks.pruning.PrunableLayer.register_activities">[docs]</a>    <span class="k">def</span> <span class="nf">register_activities</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">activity</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Store the layer activities in a training batch and update </span>
<span class="sd">        the distance matrix.</span>
<span class="sd">        </span>
<span class="sd">        Args:</span>
<span class="sd">            activity (array): Neuron activity in the most recent batch</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># TODO: Use Decoder training stream mask!</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">activity</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">activity</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]))</span><span class="o">.</span><span class="n">transpose</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">obs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="c1"># http://stackoverflow.com/questions/15556116/implementing-support-</span>
        <span class="c1"># vector-machine-efficiently-computing-gram-matrix-k</span>
        <span class="n">pt_sq_norms</span> <span class="o">=</span> <span class="p">(</span><span class="n">x</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">dists_sq</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">x</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>
        <span class="n">dists_sq</span> <span class="o">*=</span> <span class="o">-</span><span class="mi">2</span>
        <span class="n">dists_sq</span> <span class="o">+=</span> <span class="n">pt_sq_norms</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="n">dists_sq</span> <span class="o">+=</span> <span class="n">pt_sq_norms</span>
        <span class="n">activities_sq</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">square</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">dists</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">dists</span> <span class="o">=</span> <span class="n">dists_sq</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">activities</span> <span class="o">=</span> <span class="n">activities_sq</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">dists</span> <span class="o">+=</span> <span class="n">dists_sq</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">activities</span> <span class="o">+=</span> <span class="n">activities_sq</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_obs</span> <span class="o">+=</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span></div>

<div class="viewcode-block" id="PrunableLayer.count_unpruned_neurons"><a class="viewcode-back" href="../../../../cam.sgnmt.blocks.html#cam.sgnmt.blocks.pruning.PrunableLayer.count_unpruned_neurons">[docs]</a>    <span class="k">def</span> <span class="nf">count_unpruned_neurons</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Get the number of unpruned neurons in the layer. &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_size</span><span class="p">()</span> <span class="o">-</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">pruned_neurons</span><span class="p">)</span></div>

<div class="viewcode-block" id="PrunableLayer.prune"><a class="viewcode-back" href="../../../../cam.sgnmt.blocks.html#cam.sgnmt.blocks.pruning.PrunableLayer.prune">[docs]</a>    <span class="k">def</span> <span class="nf">prune</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">params_dict</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Perform a single pruning operation. The number of neurons to</span>
<span class="sd">        delete depends on the step size and the difference between the</span>
<span class="sd">        current and the target layer size.</span>
<span class="sd">        </span>
<span class="sd">        Args:</span>
<span class="sd">            params_dict (dict): Dictionary of numpy arrays</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">mask</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">initialize_mask</span><span class="p">()</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">derive_step_size</span><span class="p">()</span>
        <span class="n">n_to_delete</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">count_unpruned_neurons</span><span class="p">()</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">trg_size</span><span class="p">,</span>
                          <span class="bp">self</span><span class="o">.</span><span class="n">step_size</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">n_to_delete</span> <span class="o">&lt;=</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Layer </span><span class="si">%s</span><span class="s2"> already pruned enough&quot;</span> <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="n">name</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">reset</span><span class="p">()</span>
            <span class="k">return</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">activities</span> <span class="o">/=</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_obs</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dists</span> <span class="o">/=</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_obs</span>
        <span class="n">activity_discounts</span> <span class="o">=</span> <span class="n">get_activity_discounts</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span>
        <span class="n">search_mat</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">multiply</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dists</span><span class="p">,</span> <span class="n">activity_discounts</span><span class="p">)</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">mask</span>
        <span class="n">idxs_flat</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argsort</span><span class="p">(</span><span class="n">search_mat</span><span class="p">,</span> <span class="bp">None</span><span class="p">)</span>
        <span class="n">idxs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">unravel_index</span><span class="p">(</span><span class="n">idxs_flat</span><span class="p">,</span> <span class="n">search_mat</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
        <span class="n">min_score</span> <span class="o">=</span> <span class="n">search_mat</span><span class="p">[</span><span class="n">idxs</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">],</span> <span class="n">idxs</span><span class="p">[</span><span class="mi">1</span><span class="p">][</span><span class="mi">0</span><span class="p">]]</span>
        <span class="n">to_delete</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span><span class="n">j</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">idxs</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">idxs</span><span class="p">[</span><span class="mi">1</span><span class="p">]):</span>
            <span class="k">if</span> <span class="n">i</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">pruned_neurons</span> <span class="ow">or</span> <span class="n">j</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">pruned_neurons</span><span class="p">:</span>
                <span class="k">continue</span>
            <span class="n">max_score</span> <span class="o">=</span> <span class="n">search_mat</span><span class="p">[</span><span class="n">i</span><span class="p">,</span><span class="n">j</span><span class="p">]</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">activities</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">activities</span><span class="p">[</span><span class="n">j</span><span class="p">]:</span>
                <span class="n">i</span><span class="p">,</span><span class="n">j</span> <span class="o">=</span> <span class="n">j</span><span class="p">,</span><span class="n">i</span>
            <span class="n">to_delete</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">))</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">pruned_neurons</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">j</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">mask</span><span class="p">[</span><span class="n">j</span><span class="p">,:]</span> <span class="o">=</span> <span class="n">INF_DIST</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">mask</span><span class="p">[:,</span><span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="n">INF_DIST</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">to_delete</span><span class="p">)</span> <span class="o">&gt;=</span> <span class="n">n_to_delete</span><span class="p">:</span>
                <span class="k">break</span>
        <span class="n">compensate_for_pruning</span><span class="p">(</span><span class="n">to_delete</span><span class="p">,</span> <span class="bp">self</span><span class="p">,</span> <span class="n">params_dict</span><span class="p">)</span>
        <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;</span><span class="si">%s</span><span class="s2">: Prune </span><span class="si">%d</span><span class="s2"> neurons obs=</span><span class="si">%d</span><span class="s2"> min=</span><span class="si">%f</span><span class="s2"> max=</span><span class="si">%f</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="p">(</span>
                                                         <span class="bp">self</span><span class="o">.</span><span class="n">name</span><span class="p">,</span>
                                                         <span class="nb">len</span><span class="p">(</span><span class="n">to_delete</span><span class="p">),</span>
                                                         <span class="bp">self</span><span class="o">.</span><span class="n">n_obs</span><span class="p">,</span>
                                                         <span class="n">min_score</span><span class="p">,</span>
                                                         <span class="n">max_score</span><span class="p">))</span></div>

<div class="viewcode-block" id="PrunableLayer.sanity_check"><a class="viewcode-back" href="../../../../cam.sgnmt.blocks.html#cam.sgnmt.blocks.pruning.PrunableLayer.sanity_check">[docs]</a>    <span class="k">def</span> <span class="nf">sanity_check</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">params_dict</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Checks whether the weight matrices are consistent with the</span>
<span class="sd">        list of neurons which have been removed so far. All incoming</span>
<span class="sd">        and outgoing connections of prunned neurons should be zero.</span>
<span class="sd">        </span>
<span class="sd">        Args:</span>
<span class="sd">            params_dict (dict): Dictionary with numpy arrays</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">geps</span> <span class="o">=</span> <span class="mf">0.0</span>
        <span class="k">for</span> <span class="n">conn</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">connections</span><span class="p">:</span>
            <span class="n">mat</span> <span class="o">=</span> <span class="n">params_dict</span><span class="p">[</span><span class="n">conn</span><span class="o">.</span><span class="n">mat_name</span><span class="p">]</span><span class="o">.</span><span class="n">get_value</span><span class="p">()</span>
            <span class="n">mat_idxs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">pruned_neurons</span>
            <span class="k">if</span> <span class="n">conn</span><span class="o">.</span><span class="n">start_idx</span> <span class="o">&gt;</span> <span class="mf">0.0</span><span class="p">:</span>
                <span class="n">offset</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">mat</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="n">conn</span><span class="o">.</span><span class="n">dim</span><span class="p">]</span> <span class="o">*</span> <span class="n">conn</span><span class="o">.</span><span class="n">start_idx</span><span class="p">)</span>
                <span class="n">mat_idxs</span> <span class="o">=</span> <span class="p">[</span><span class="n">idx</span><span class="o">+</span><span class="n">offset</span> <span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="n">mat_idxs</span><span class="p">]</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">mat</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
                <span class="n">eps</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">absolute</span><span class="p">(</span><span class="n">mat</span><span class="p">[</span><span class="n">mat_idxs</span><span class="p">]))</span>
            <span class="k">elif</span> <span class="n">conn</span><span class="o">.</span><span class="n">dim</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                <span class="n">eps</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">absolute</span><span class="p">(</span><span class="n">mat</span><span class="p">[</span><span class="n">mat_idxs</span><span class="p">,:]))</span>
            <span class="k">elif</span> <span class="n">conn</span><span class="o">.</span><span class="n">dim</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
                <span class="n">eps</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">absolute</span><span class="p">(</span><span class="n">mat</span><span class="p">[:,</span><span class="n">mat_idxs</span><span class="p">]))</span>
            <span class="n">geps</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="n">eps</span><span class="p">,</span> <span class="n">geps</span><span class="p">)</span>
        <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Sanity check: max of </span><span class="si">%d</span><span class="s2"> prunned connections: </span><span class="si">%f</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="p">(</span>
                                                    <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">pruned_neurons</span><span class="p">),</span> 
                                                    <span class="n">geps</span><span class="p">))</span></div></div>
            
<span class="k">def</span> <span class="nf">_get_activity_discounts_sum</span><span class="p">(</span><span class="n">layer</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;For a pair of neurons, use the sum of their activities to </span>
<span class="sd">    discount their distance.</span>
<span class="sd">    </span>
<span class="sd">    Args:</span>
<span class="sd">        layer (PrunableLayer): The layer which is to be pruned</span>
<span class="sd">    </span>
<span class="sd">    Returns:</span>
<span class="sd">        array. Discount matrix for the layer.</span>
<span class="sd">    &quot;&quot;&quot;</span> 
    <span class="k">return</span> <span class="n">layer</span><span class="o">.</span><span class="n">activities</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span> <span class="o">+</span> <span class="n">layer</span><span class="o">.</span><span class="n">activities</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">))</span>

<span class="k">def</span> <span class="nf">_get_activity_discounts_min</span><span class="p">(</span><span class="n">layer</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;For a pair of neurons, use the minimum of their activities to </span>
<span class="sd">    discount their distance.</span>
<span class="sd">    </span>
<span class="sd">    Args:</span>
<span class="sd">        layer (PrunableLayer): The layer which is to be pruned</span>
<span class="sd">    </span>
<span class="sd">    Returns:</span>
<span class="sd">        array. Discount matrix for the layer.</span>
<span class="sd">    &quot;&quot;&quot;</span> 
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">minimum</span><span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="n">activities</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)),</span>
                      <span class="n">layer</span><span class="o">.</span><span class="n">activities</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)))</span>

<span class="n">get_activity_discounts</span> <span class="o">=</span> <span class="n">_get_activity_discounts_min</span>
<span class="sd">&quot;&quot;&quot;We decide which neuron to prune based on (a) their similarity, and</span>
<span class="sd">(b) we prefer neurons with small activity. We provide two strategies</span>
<span class="sd">for (b): Using the minimum or the sum of the activities in neuron</span>
<span class="sd">pairs. The original method uses the minimum.  </span>
<span class="sd">    </span>
<span class="sd">Args:</span>
<span class="sd">    layer (PrunableLayer): The layer which is to be pruned</span>
<span class="sd">    </span>
<span class="sd">Returns:</span>
<span class="sd">    array. Discount matrix for the layer.</span>
<span class="sd">&quot;&quot;&quot;</span> 

<span class="k">def</span> <span class="nf">_compensate_for_pruning_sum</span><span class="p">(</span><span class="n">to_delete</span><span class="p">,</span> <span class="n">layer</span><span class="p">,</span> <span class="n">params_dict</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;This is a data-bound version of the approach of Srinivas and</span>
<span class="sd">    Babu (2015) which compensates for a neuron removal by adding</span>
<span class="sd">    the outgoing weights to the weights of a similar neuron. The </span>
<span class="sd">    parameter dictionary ``params_dict`` is updated accordingly.</span>
<span class="sd">    </span>
<span class="sd">    Args:</span>
<span class="sd">        to_delete (list): List of i,j neuron pairs which were selected</span>
<span class="sd">                          for deletion</span>
<span class="sd">        layer (PrunableLayer): The layer which we are currently pruning</span>
<span class="sd">        params_dict (dict): Dictionary of numpy arrays (weight matrices)</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span><span class="n">j</span> <span class="ow">in</span> <span class="n">to_delete</span><span class="p">:</span>
        <span class="c1"># Prune neuron j, add output connections to i</span>
        <span class="k">for</span> <span class="n">conn</span> <span class="ow">in</span> <span class="n">layer</span><span class="o">.</span><span class="n">connections</span><span class="p">:</span>
            <span class="n">mat</span> <span class="o">=</span> <span class="n">params_dict</span><span class="p">[</span><span class="n">conn</span><span class="o">.</span><span class="n">mat_name</span><span class="p">]</span><span class="o">.</span><span class="n">get_value</span><span class="p">()</span>
            <span class="n">mat_i</span> <span class="o">=</span> <span class="n">i</span>
            <span class="n">mat_j</span> <span class="o">=</span> <span class="n">j</span>
            <span class="k">if</span> <span class="n">conn</span><span class="o">.</span><span class="n">start_idx</span> <span class="o">&gt;</span> <span class="mf">0.0</span><span class="p">:</span>
                <span class="n">offset</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">mat</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="n">conn</span><span class="o">.</span><span class="n">dim</span><span class="p">]</span> <span class="o">*</span> <span class="n">conn</span><span class="o">.</span><span class="n">start_idx</span><span class="p">)</span>
                <span class="n">mat_i</span> <span class="o">+=</span> <span class="n">offset</span>
                <span class="n">mat_j</span> <span class="o">+=</span> <span class="n">offset</span>
            <span class="k">if</span> <span class="n">conn</span><span class="o">.</span><span class="n">direction</span> <span class="o">==</span> <span class="s2">&quot;in&quot;</span> <span class="ow">and</span> <span class="n">layer</span><span class="o">.</span><span class="n">maxout</span><span class="p">:</span>
                <span class="n">mat</span> <span class="o">=</span> <span class="n">set_zero_in_mat</span><span class="p">(</span><span class="n">mat</span><span class="p">,</span> <span class="n">conn</span><span class="o">.</span><span class="n">dim</span><span class="p">,</span> <span class="n">mat_j</span><span class="o">*</span><span class="mi">2</span><span class="p">)</span>
                <span class="n">mat</span> <span class="o">=</span> <span class="n">set_zero_in_mat</span><span class="p">(</span><span class="n">mat</span><span class="p">,</span> <span class="n">conn</span><span class="o">.</span><span class="n">dim</span><span class="p">,</span> <span class="n">mat_j</span><span class="o">*</span><span class="mi">2</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">mat</span> <span class="o">=</span> <span class="n">set_zero_in_mat</span><span class="p">(</span><span class="n">mat</span><span class="p">,</span> <span class="n">conn</span><span class="o">.</span><span class="n">dim</span><span class="p">,</span> <span class="n">mat_j</span><span class="p">)</span>
            <span class="n">params_dict</span><span class="p">[</span><span class="n">conn</span><span class="o">.</span><span class="n">mat_name</span><span class="p">]</span><span class="o">.</span><span class="n">set_value</span><span class="p">(</span><span class="n">mat</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">_compensate_for_pruning_interpol</span><span class="p">(</span><span class="n">to_delete</span><span class="p">,</span> <span class="n">layer</span><span class="p">,</span> <span class="n">params_dict</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;This is the data-bound removal algorithm from Stahlberg and</span>
<span class="sd">    Byrne (2017) based on linear interpolations. The parameter</span>
<span class="sd">    dictionary ``params_dict`` is updated accordingly.</span>
<span class="sd">    </span>
<span class="sd">    Args:</span>
<span class="sd">        to_delete (list): List of i,j neuron pairs which were selected</span>
<span class="sd">                          for deletion</span>
<span class="sd">        layer (PrunableLayer): The layer which we are currently pruning</span>
<span class="sd">        params_dict (dict): Dictionary of numpy arrays (weight matrices)</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">reduced_obs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">hstack</span><span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="n">obs</span><span class="p">)[:,</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span>
                                                    <span class="n">layer</span><span class="o">.</span><span class="n">n_obs</span><span class="p">,</span> 
                                                    <span class="n">size</span><span class="o">=</span><span class="mi">50000</span><span class="p">)]</span><span class="o">.</span><span class="n">transpose</span><span class="p">()</span>
    <span class="n">delete_idxs</span> <span class="o">=</span> <span class="p">[</span><span class="n">j</span> <span class="k">for</span> <span class="n">i</span><span class="p">,</span><span class="n">j</span> <span class="ow">in</span> <span class="n">to_delete</span><span class="p">]</span>
    <span class="n">survive_mask</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="n">layer</span><span class="o">.</span><span class="n">get_size</span><span class="p">(),),</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">bool</span><span class="p">)</span>
    <span class="n">survive_mask</span><span class="p">[</span><span class="n">layer</span><span class="o">.</span><span class="n">pruned_neurons</span><span class="p">]</span> <span class="o">=</span> <span class="bp">False</span>
    <span class="n">survive_idxs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">survive_mask</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">A</span> <span class="o">=</span> <span class="n">reduced_obs</span><span class="p">[:,</span><span class="n">survive_idxs</span><span class="p">]</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">reduced_obs</span><span class="p">[:,</span><span class="n">delete_idxs</span><span class="p">]</span>
    <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Least square A=</span><span class="si">%s</span><span class="s2"> y=</span><span class="si">%s</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">A</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">y</span><span class="o">.</span><span class="n">shape</span><span class="p">))</span>
    <span class="n">weights</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">lstsq</span><span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="n">y</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
    <span class="k">for</span> <span class="n">conn</span> <span class="ow">in</span> <span class="n">layer</span><span class="o">.</span><span class="n">connections</span><span class="p">:</span>
        <span class="n">mat</span> <span class="o">=</span> <span class="n">params_dict</span><span class="p">[</span><span class="n">conn</span><span class="o">.</span><span class="n">mat_name</span><span class="p">]</span><span class="o">.</span><span class="n">get_value</span><span class="p">()</span>
        <span class="n">work</span> <span class="o">=</span> <span class="n">mat</span>
        <span class="k">if</span> <span class="n">conn</span><span class="o">.</span><span class="n">dim</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">work</span> <span class="o">=</span> <span class="n">work</span><span class="o">.</span><span class="n">transpose</span><span class="p">()</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">layer</span><span class="o">.</span><span class="n">maxout</span><span class="p">:</span>
            <span class="n">offset</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">work</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="n">conn</span><span class="o">.</span><span class="n">start_idx</span><span class="p">)</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">work</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">==</span> <span class="mi">2</span><span class="p">:</span>
                <span class="n">work</span> <span class="o">=</span> <span class="n">work</span><span class="p">[</span><span class="n">offset</span><span class="p">:</span><span class="n">offset</span><span class="o">+</span><span class="n">layer</span><span class="o">.</span><span class="n">get_size</span><span class="p">(),</span> <span class="p">:]</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">work</span> <span class="o">=</span> <span class="n">work</span><span class="p">[</span><span class="n">offset</span><span class="p">:</span><span class="n">offset</span><span class="o">+</span><span class="n">layer</span><span class="o">.</span><span class="n">get_size</span><span class="p">()]</span>
        <span class="k">if</span> <span class="n">conn</span><span class="o">.</span><span class="n">direction</span> <span class="o">==</span> <span class="s2">&quot;out&quot;</span><span class="p">:</span> 
            <span class="n">work</span><span class="p">[</span><span class="n">survive_idxs</span><span class="p">,:]</span> <span class="o">+=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">weights</span><span class="p">,</span> <span class="n">work</span><span class="p">[</span><span class="n">delete_idxs</span><span class="p">])</span>
        <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="n">delete_idxs</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">conn</span><span class="o">.</span><span class="n">direction</span> <span class="o">==</span> <span class="s2">&quot;in&quot;</span> <span class="ow">and</span> <span class="n">layer</span><span class="o">.</span><span class="n">maxout</span><span class="p">:</span>
                <span class="n">work</span> <span class="o">=</span> <span class="n">set_zero_in_mat</span><span class="p">(</span><span class="n">work</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="n">j</span><span class="o">*</span><span class="mi">2</span><span class="p">)</span>
                <span class="n">work</span> <span class="o">=</span> <span class="n">set_zero_in_mat</span><span class="p">(</span><span class="n">work</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="n">j</span><span class="o">*</span><span class="mi">2</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">work</span> <span class="o">=</span> <span class="n">set_zero_in_mat</span><span class="p">(</span><span class="n">work</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="n">j</span><span class="p">)</span>
        <span class="n">params_dict</span><span class="p">[</span><span class="n">conn</span><span class="o">.</span><span class="n">mat_name</span><span class="p">]</span><span class="o">.</span><span class="n">set_value</span><span class="p">(</span><span class="n">mat</span><span class="p">)</span>


<span class="n">compensate_for_pruning</span> <span class="o">=</span> <span class="n">_compensate_for_pruning_interpol</span>
<span class="sd">&quot;&quot;&quot;This the the strategy used to compensate for the removal of a </span>
<span class="sd">neuron. It can be set to ``_compensate_for_pruning_interpol`` or</span>
<span class="sd">``_compensate_for_pruning_sum``. The first one is based on linear</span>
<span class="sd">combinations of the remaining neurons and should be preferred for</span>
<span class="sd">NMT networks as shown in https://arxiv.org/abs/1704.03279. The</span>
<span class="sd">parameter dictionary ``params_dict`` is updated accordingly.</span>
<span class="sd">    </span>
<span class="sd">Args:</span>
<span class="sd">    to_delete (list): List of i,j neuron pairs which were selected</span>
<span class="sd">                        for deletion</span>
<span class="sd">    layer (PrunableLayer): The layer which we are currently pruning</span>
<span class="sd">    params_dict (dict): Dictionary of numpy arrays (weight matrices)</span>
<span class="sd">&quot;&quot;&quot;</span>

<div class="viewcode-block" id="add_in_mat"><a class="viewcode-back" href="../../../../cam.sgnmt.blocks.html#cam.sgnmt.blocks.pruning.add_in_mat">[docs]</a><span class="k">def</span> <span class="nf">add_in_mat</span><span class="p">(</span><span class="n">mat</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">f_idx</span><span class="p">,</span> <span class="n">t_idx</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Helper method to add a row or column to another one in a matrix.</span>
<span class="sd">    </span>
<span class="sd">    Args:</span>
<span class="sd">        mat (array): two dimensional numpy array.</span>
<span class="sd">        dim (int): 0 for rows, 1 for columns</span>
<span class="sd">        f_idx (int): Index of the first row or column</span>
<span class="sd">        t_idx (int): Index of the second row or column</span>
<span class="sd">    </span>
<span class="sd">    Returns:</span>
<span class="sd">        array. Matrix in which the first row or column is added to the</span>
<span class="sd">        second one.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">mat</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
        <span class="n">mat</span><span class="p">[</span><span class="n">t_idx</span><span class="p">]</span> <span class="o">+=</span> <span class="n">mat</span><span class="p">[</span><span class="n">f_idx</span><span class="p">]</span>
    <span class="k">elif</span> <span class="n">dim</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">mat</span><span class="p">[</span><span class="n">t_idx</span><span class="p">,:]</span> <span class="o">+=</span> <span class="n">mat</span><span class="p">[</span><span class="n">f_idx</span><span class="p">,:]</span>
    <span class="k">elif</span> <span class="n">dim</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
        <span class="n">mat</span><span class="p">[:,</span><span class="n">t_idx</span><span class="p">]</span> <span class="o">+=</span> <span class="n">mat</span><span class="p">[:,</span><span class="n">f_idx</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">mat</span></div>


<div class="viewcode-block" id="set_zero_in_mat"><a class="viewcode-back" href="../../../../cam.sgnmt.blocks.html#cam.sgnmt.blocks.pruning.set_zero_in_mat">[docs]</a><span class="k">def</span> <span class="nf">set_zero_in_mat</span><span class="p">(</span><span class="n">mat</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">idx</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Helper method to set a row or column to zero.</span>
<span class="sd">    </span>
<span class="sd">    Args:</span>
<span class="sd">        mat (array): two dimensional numpy array.</span>
<span class="sd">        dim (int): 0 for rows, 1 for columns</span>
<span class="sd">        idx (int): Index of the row or column</span>
<span class="sd">    </span>
<span class="sd">    Returns:</span>
<span class="sd">        array. Matrix in which the ``idx``-the row or column is</span>
<span class="sd">        set to zero.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">mat</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
        <span class="n">mat</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span> <span class="o">=</span> <span class="mf">0.0</span>
    <span class="k">elif</span> <span class="n">dim</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">mat</span><span class="p">[</span><span class="n">idx</span><span class="p">,:]</span> <span class="o">=</span> <span class="mf">0.0</span>
    <span class="k">elif</span> <span class="n">dim</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
        <span class="n">mat</span><span class="p">[:,</span><span class="n">idx</span><span class="p">]</span> <span class="o">=</span> <span class="mf">0.0</span>
    <span class="k">return</span> <span class="n">mat</span></div>


<div class="viewcode-block" id="Connection"><a class="viewcode-back" href="../../../../cam.sgnmt.blocks.html#cam.sgnmt.blocks.pruning.Connection">[docs]</a><span class="k">class</span> <span class="nc">Connection</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;A connection between layer which is represented by a weight </span>
<span class="sd">    matrix.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">direction</span><span class="p">,</span> <span class="n">mat_name</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">start_idx</span> <span class="o">=</span> <span class="mf">0.0</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Creates a new connection.</span>
<span class="sd">        </span>
<span class="sd">        Args:</span>
<span class="sd">            direction (string): &#39;in&#39; if incoming, &#39;out&#39; if outgoing</span>
<span class="sd">            mat_name (string): Name of the corresponding weight matrix</span>
<span class="sd">            dim (int): Dimension along which this layer is adjacent</span>
<span class="sd">            start_idx (float): Blocks uses single weight matrices for</span>
<span class="sd">                               both forget and reset gates. Set this to</span>
<span class="sd">                               0.5 if the layer is just connected to </span>
<span class="sd">                               the lower half of the matrix.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">mat_name</span> <span class="o">=</span> <span class="n">mat_name</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">direction</span> <span class="o">=</span> <span class="n">direction</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dim</span> <span class="o">=</span> <span class="n">dim</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">start_idx</span> <span class="o">=</span> <span class="n">start_idx</span></div>


<div class="viewcode-block" id="PrunableInitializableFeedforwardSequence"><a class="viewcode-back" href="../../../../cam.sgnmt.blocks.html#cam.sgnmt.blocks.pruning.PrunableInitializableFeedforwardSequence">[docs]</a><span class="k">class</span> <span class="nc">PrunableInitializableFeedforwardSequence</span><span class="p">(</span><span class="n">FeedforwardSequence</span><span class="p">,</span> 
                                               <span class="n">Initializable</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Version of ``InitializableFeedforwardSequence`` which allows</span>
<span class="sd">    keeping track of internal neuron activities.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">application_methods</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">pruning_variables_initialized</span> <span class="o">=</span> <span class="bp">False</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">layer_activities</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">PrunableInitializableFeedforwardSequence</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="n">__init__</span><span class="p">(</span>
                                       <span class="n">application_methods</span><span class="p">,</span> 
                                       <span class="n">name</span><span class="o">=</span><span class="s1">&#39;initializablefeedforwardsequence&#39;</span><span class="p">,</span>
                                       <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

    <span class="nd">@application</span>
    <span class="k">def</span> <span class="nf">apply</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">):</span>
        <span class="n">child_input</span> <span class="o">=</span> <span class="n">args</span>
        <span class="k">for</span> <span class="n">application_method</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">application_methods</span><span class="p">:</span>
            <span class="n">output</span> <span class="o">=</span> <span class="n">application_method</span><span class="p">(</span><span class="o">*</span><span class="n">pack</span><span class="p">(</span><span class="n">child_input</span><span class="p">))</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">pruning_variables_initialized</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">layer_activities</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
            <span class="n">child_input</span> <span class="o">=</span> <span class="n">output</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">pruning_variables_initialized</span> <span class="o">=</span> <span class="bp">True</span>
        <span class="k">return</span> <span class="n">output</span></div>


<div class="viewcode-block" id="PrunableSequenceGenerator"><a class="viewcode-back" href="../../../../cam.sgnmt.blocks.html#cam.sgnmt.blocks.pruning.PrunableSequenceGenerator">[docs]</a><span class="k">class</span> <span class="nc">PrunableSequenceGenerator</span><span class="p">(</span><span class="n">SequenceGenerator</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;A sequence generator which keeps prunable layers as class </span>
<span class="sd">    variables s.t. they can be accessed later.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">readout</span><span class="p">,</span> <span class="n">transition</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">pruning_variables_initialized</span> <span class="o">=</span> <span class="bp">False</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">PrunableSequenceGenerator</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="n">__init__</span><span class="p">(</span>
                                                    <span class="n">readout</span><span class="p">,</span> 
                                                    <span class="n">transition</span><span class="p">,</span> 
                                                    <span class="n">name</span><span class="o">=</span><span class="s1">&#39;sequencegenerator&#39;</span><span class="p">,</span> 
                                                    <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

    <span class="nd">@application</span>
    <span class="k">def</span> <span class="nf">cost_matrix</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">application_call</span><span class="p">,</span> <span class="n">outputs</span><span class="p">,</span> <span class="n">mask</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Adapted from ``BaseSequenceGenerator.cost_matrix``</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># We assume the data has axes (time, batch, features, ...)</span>
        <span class="n">batch_size</span> <span class="o">=</span> <span class="n">outputs</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>

        <span class="c1"># Prepare input for the iterative part</span>
        <span class="n">states</span> <span class="o">=</span> <span class="n">dict_subset</span><span class="p">(</span><span class="n">kwargs</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_state_names</span><span class="p">,</span> <span class="n">must_have</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
        <span class="c1"># masks in context are optional (e.g. `attended_mask`)</span>
        <span class="n">contexts</span> <span class="o">=</span> <span class="n">dict_subset</span><span class="p">(</span><span class="n">kwargs</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_context_names</span><span class="p">,</span> <span class="n">must_have</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
        <span class="n">feedback</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">readout</span><span class="o">.</span><span class="n">feedback</span><span class="p">(</span><span class="n">outputs</span><span class="p">)</span>
        <span class="n">inputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fork</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">feedback</span><span class="p">,</span> <span class="n">as_dict</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>

        <span class="c1"># Run the recurrent network</span>
        <span class="n">results</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">transition</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span>
            <span class="n">mask</span><span class="o">=</span><span class="n">mask</span><span class="p">,</span> <span class="n">return_initial_states</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">as_dict</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span>
            <span class="o">**</span><span class="n">dict_union</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">states</span><span class="p">,</span> <span class="n">contexts</span><span class="p">))</span>

        <span class="c1"># Separate the deliverables. The last states are discarded: they</span>
        <span class="c1"># are not used to predict any output symbol. The initial glimpses</span>
        <span class="c1"># are discarded because they are not used for prediction.</span>
        <span class="c1"># Remember, glimpses are computed _before_ output stage, states are</span>
        <span class="c1"># computed after.</span>
        <span class="n">states</span> <span class="o">=</span> <span class="p">{</span><span class="n">name</span><span class="p">:</span> <span class="n">results</span><span class="p">[</span><span class="n">name</span><span class="p">][:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="k">for</span> <span class="n">name</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_state_names</span><span class="p">}</span>
        <span class="n">glimpses</span> <span class="o">=</span> <span class="p">{</span><span class="n">name</span><span class="p">:</span> <span class="n">results</span><span class="p">[</span><span class="n">name</span><span class="p">][</span><span class="mi">1</span><span class="p">:]</span> <span class="k">for</span> <span class="n">name</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_glimpse_names</span><span class="p">}</span>

        <span class="c1"># Compute the cost</span>
        <span class="n">feedback</span> <span class="o">=</span> <span class="n">tensor</span><span class="o">.</span><span class="n">roll</span><span class="p">(</span><span class="n">feedback</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
        <span class="n">feedback</span> <span class="o">=</span> <span class="n">tensor</span><span class="o">.</span><span class="n">set_subtensor</span><span class="p">(</span>
            <span class="n">feedback</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">readout</span><span class="o">.</span><span class="n">feedback</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">readout</span><span class="o">.</span><span class="n">initial_outputs</span><span class="p">(</span><span class="n">batch_size</span><span class="p">)))</span>
        <span class="n">readouts</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">readout</span><span class="o">.</span><span class="n">readout</span><span class="p">(</span>
            <span class="n">feedback</span><span class="o">=</span><span class="n">feedback</span><span class="p">,</span> <span class="o">**</span><span class="n">dict_union</span><span class="p">(</span><span class="n">states</span><span class="p">,</span> <span class="n">glimpses</span><span class="p">,</span> <span class="n">contexts</span><span class="p">))</span>
        <span class="n">costs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">readout</span><span class="o">.</span><span class="n">cost</span><span class="p">(</span><span class="n">readouts</span><span class="p">,</span> <span class="n">outputs</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">mask</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span><span class="p">:</span>
            <span class="n">costs</span> <span class="o">*=</span> <span class="n">mask</span>

        <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">variable</span> <span class="ow">in</span> <span class="nb">list</span><span class="p">(</span><span class="n">glimpses</span><span class="o">.</span><span class="n">items</span><span class="p">())</span> <span class="o">+</span> <span class="nb">list</span><span class="p">(</span><span class="n">states</span><span class="o">.</span><span class="n">items</span><span class="p">()):</span>
            <span class="n">application_call</span><span class="o">.</span><span class="n">add_auxiliary_variable</span><span class="p">(</span>
                <span class="n">variable</span><span class="o">.</span><span class="n">copy</span><span class="p">(),</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>

        <span class="c1"># This variables can be used to initialize the initial states of the</span>
        <span class="c1"># next batch using the last states of the current batch.</span>
        <span class="k">for</span> <span class="n">name</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_state_names</span><span class="p">:</span>
            <span class="n">application_call</span><span class="o">.</span><span class="n">add_auxiliary_variable</span><span class="p">(</span>
                <span class="n">results</span><span class="p">[</span><span class="n">name</span><span class="p">][</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">copy</span><span class="p">(),</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="o">+</span><span class="s2">&quot;_final_value&quot;</span><span class="p">)</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">pruning_variables_initialized</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">results</span> <span class="o">=</span> <span class="n">results</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">pruning_variables_initialized</span> <span class="o">=</span> <span class="bp">True</span>
        <span class="k">return</span> <span class="n">costs</span></div>


<div class="viewcode-block" id="PruningGradientDescent"><a class="viewcode-back" href="../../../../cam.sgnmt.blocks.html#cam.sgnmt.blocks.pruning.PruningGradientDescent">[docs]</a><span class="k">class</span> <span class="nc">PruningGradientDescent</span><span class="p">(</span><span class="n">GradientDescent</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;This is a drop-in replacement for Blocks GradientDescent </span>
<span class="sd">    optimizer. We intersperse the normal SGD updates with pruning</span>
<span class="sd">    operations and record the neuron activities after each training</span>
<span class="sd">    batch.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> 
                 <span class="n">prune_layer_configs</span><span class="p">,</span> 
                 <span class="n">prune_layout_path</span><span class="p">,</span> 
                 <span class="n">prune_every</span><span class="p">,</span> 
                 <span class="n">prune_reset_every</span><span class="p">,</span> 
                 <span class="n">prune_n_steps</span><span class="p">,</span> 
                 <span class="n">nmt_model</span><span class="p">,</span> 
                 <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Constructor for the pruning SGD optimizer.</span>
<span class="sd">        </span>
<span class="sd">        Args:</span>
<span class="sd">            prune_layer_configs (dict): Layer configurations.</span>
<span class="sd">            prune_layout_path (string): Path to the network layout</span>
<span class="sd">                                        file.</span>
<span class="sd">            prune_every (int): Prune every n training iterations</span>
<span class="sd">            prune_reset_every (int): Reset neuron activity records</span>
<span class="sd">                                     every n training iterations.</span>
<span class="sd">            prune_n_steps (int): Number of pruning operations</span>
<span class="sd">            nmt_model (NMTModel): The initialized NMT model.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">prune_every</span> <span class="o">=</span> <span class="n">prune_every</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">prune_reset_every</span> <span class="o">=</span> <span class="n">prune_reset_every</span> <span class="k">if</span> <span class="n">prune_reset_every</span> <span class="o">&gt;</span> <span class="mi">0</span> \
                                                   <span class="k">else</span> <span class="n">prune_every</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_batches</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">nmt_model</span> <span class="o">=</span> <span class="n">nmt_model</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">prune_n_steps</span> <span class="o">=</span> <span class="n">prune_n_steps</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">initialize_layers</span><span class="p">(</span><span class="n">prune_layer_configs</span><span class="p">,</span> <span class="n">prune_layout_path</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">params_dict</span> <span class="o">=</span> <span class="n">nmt_model</span><span class="o">.</span><span class="n">training_model</span><span class="o">.</span><span class="n">get_parameter_dict</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">next_layer_to_prune</span> <span class="o">=</span> <span class="o">-</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">prunable_layers</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">next_layer_to_reset</span> <span class="o">=</span> <span class="o">-</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">prunable_layers</span><span class="p">)</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">PruningGradientDescent</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="n">__init__</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

<div class="viewcode-block" id="PruningGradientDescent.initialize_layers"><a class="viewcode-back" href="../../../../cam.sgnmt.blocks.html#cam.sgnmt.blocks.pruning.PruningGradientDescent.initialize_layers">[docs]</a>    <span class="k">def</span> <span class="nf">initialize_layers</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">layer_configs</span><span class="p">,</span> <span class="n">layout_path</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Initialize all layers which should be pruned in the course </span>
<span class="sd">        of this training.</span>
<span class="sd">        </span>
<span class="sd">        Args:</span>
<span class="sd">            layer_configs (dict): Layer configurations.</span>
<span class="sd">            layout_path (string): Path to the network layout file.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">conns</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">layout_path</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">line</span> <span class="ow">in</span> <span class="n">f</span><span class="p">:</span>
                <span class="k">if</span> <span class="ow">not</span> <span class="n">line</span><span class="o">.</span><span class="n">strip</span><span class="p">():</span>
                    <span class="k">continue</span>
                <span class="n">parts</span> <span class="o">=</span> <span class="n">line</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span><span class="o">.</span><span class="n">split</span><span class="p">()</span>
                <span class="k">if</span> <span class="ow">not</span> <span class="nb">len</span><span class="p">(</span><span class="n">parts</span><span class="p">)</span> <span class="ow">in</span> <span class="p">[</span><span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">]:</span>
                    <span class="n">logging</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span><span class="s2">&quot;Syntax error in prune layout file&quot;</span><span class="p">)</span>
                    <span class="k">continue</span>
                <span class="n">conn</span> <span class="o">=</span> <span class="n">Connection</span><span class="p">(</span><span class="n">parts</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> 
                                  <span class="n">parts</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span> 
                                  <span class="nb">int</span><span class="p">(</span><span class="n">parts</span><span class="p">[</span><span class="mi">3</span><span class="p">]),</span> 
                                  <span class="nb">float</span><span class="p">(</span><span class="n">parts</span><span class="p">[</span><span class="mi">4</span><span class="p">])</span> <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">parts</span><span class="p">)</span> <span class="o">==</span> <span class="mi">5</span> <span class="k">else</span> <span class="mf">0.0</span><span class="p">)</span>
                <span class="k">if</span> <span class="n">parts</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="ow">in</span> <span class="n">conns</span><span class="p">:</span>
                    <span class="n">conns</span><span class="p">[</span><span class="n">parts</span><span class="p">[</span><span class="mi">0</span><span class="p">]]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">conn</span><span class="p">)</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">conns</span><span class="p">[</span><span class="n">parts</span><span class="p">[</span><span class="mi">0</span><span class="p">]]</span> <span class="o">=</span> <span class="p">[</span><span class="n">conn</span><span class="p">]</span>
        <span class="n">seq_gen</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">nmt_model</span><span class="o">.</span><span class="n">decoder</span><span class="o">.</span><span class="n">sequence_generator</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">prunable_layers</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">conf</span> <span class="ow">in</span> <span class="n">layer_configs</span><span class="p">:</span>
            <span class="n">n</span><span class="p">,</span><span class="n">s</span> <span class="o">=</span> <span class="n">conf</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot;:&quot;</span><span class="p">)</span>
            <span class="n">maxout</span> <span class="o">=</span> <span class="bp">False</span>
            <span class="k">if</span> <span class="n">n</span> <span class="o">==</span> <span class="s1">&#39;encfwdgru&#39;</span><span class="p">:</span>
                <span class="n">theano_var</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">nmt_model</span><span class="o">.</span><span class="n">encoder</span><span class="o">.</span><span class="n">bidir</span><span class="o">.</span><span class="n">forward</span>
            <span class="k">elif</span> <span class="n">n</span> <span class="o">==</span> <span class="s1">&#39;encbwdgru&#39;</span><span class="p">:</span>
                <span class="n">theano_var</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">nmt_model</span><span class="o">.</span><span class="n">encoder</span><span class="o">.</span><span class="n">bidir</span><span class="o">.</span><span class="n">backward</span>
            <span class="k">elif</span> <span class="n">n</span> <span class="o">==</span> <span class="s1">&#39;decgru&#39;</span><span class="p">:</span>
                <span class="n">theano_var</span> <span class="o">=</span> <span class="n">seq_gen</span><span class="o">.</span><span class="n">results</span><span class="p">[</span><span class="s1">&#39;states&#39;</span><span class="p">]</span>
            <span class="k">elif</span> <span class="n">n</span> <span class="o">==</span> <span class="s1">&#39;decmaxout&#39;</span><span class="p">:</span>
                <span class="n">theano_var</span> <span class="o">=</span> <span class="n">seq_gen</span><span class="o">.</span><span class="n">readout</span><span class="o">.</span><span class="n">post_merge</span><span class="o">.</span><span class="n">layer_activities</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
                <span class="n">maxout</span> <span class="o">=</span> <span class="bp">True</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">logging</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span><span class="s2">&quot;Unknown prunable layer name </span><span class="si">%s</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="n">n</span><span class="p">)</span>
                <span class="k">continue</span>
            <span class="n">l</span> <span class="o">=</span> <span class="n">PrunableLayer</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> 
                              <span class="n">theano_var</span><span class="p">,</span> 
                              <span class="nb">int</span><span class="p">(</span><span class="n">s</span><span class="p">),</span> 
                              <span class="bp">self</span><span class="o">.</span><span class="n">prune_n_steps</span><span class="p">,</span>
                              <span class="n">maxout</span><span class="o">=</span><span class="n">maxout</span><span class="p">)</span>
            <span class="n">l</span><span class="o">.</span><span class="n">connections</span> <span class="o">=</span> <span class="n">conns</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="p">[])</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">prunable_layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">l</span><span class="p">)</span></div>
    
<div class="viewcode-block" id="PruningGradientDescent.initialize"><a class="viewcode-back" href="../../../../cam.sgnmt.blocks.html#cam.sgnmt.blocks.pruning.PruningGradientDescent.initialize">[docs]</a>    <span class="k">def</span> <span class="nf">initialize</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Initialize the training algorithm.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Initializing the training algorithm&quot;</span><span class="p">)</span>
        <span class="n">update_values</span> <span class="o">=</span> <span class="p">[</span><span class="n">new_value</span> <span class="k">for</span> <span class="n">_</span><span class="p">,</span> <span class="n">new_value</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">updates</span><span class="p">]</span>
        <span class="n">activity_variables</span> <span class="o">=</span> <span class="p">[</span><span class="n">l</span><span class="o">.</span><span class="n">theano_variable</span> <span class="k">for</span> <span class="n">l</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">prunable_layers</span><span class="p">]</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="s2">&quot;Inferring graph inputs...&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">inputs</span> <span class="o">=</span> <span class="n">ComputationGraph</span><span class="p">(</span><span class="n">update_values</span><span class="p">)</span><span class="o">.</span><span class="n">inputs</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="s2">&quot;Compiling training function...&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_function</span> <span class="o">=</span> <span class="n">theano</span><span class="o">.</span><span class="n">function</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">inputs</span><span class="p">,</span> 
                                         <span class="n">activity_variables</span><span class="p">,</span> 
                                         <span class="n">updates</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">updates</span><span class="p">,</span> 
                                         <span class="o">**</span><span class="bp">self</span><span class="o">.</span><span class="n">theano_func_kwargs</span><span class="p">)</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;The training algorithm is initialized&quot;</span><span class="p">)</span></div>

<div class="viewcode-block" id="PruningGradientDescent.process_batch"><a class="viewcode-back" href="../../../../cam.sgnmt.blocks.html#cam.sgnmt.blocks.pruning.PruningGradientDescent.process_batch">[docs]</a>    <span class="k">def</span> <span class="nf">process_batch</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Overrides ``GradientDescent.process_batch`` and adds </span>
<span class="sd">        recording neuron activities and pruning neurons to the</span>
<span class="sd">        pipeline.</span>
<span class="sd">        </span>
<span class="sd">        Args:</span>
<span class="sd">            batch (array): Current training batch</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_batches</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_validate_source_names</span><span class="p">(</span><span class="n">batch</span><span class="p">)</span>
        <span class="n">ordered_batch</span> <span class="o">=</span> <span class="p">[</span><span class="n">batch</span><span class="p">[</span><span class="n">v</span><span class="o">.</span><span class="n">name</span><span class="p">]</span> <span class="k">for</span> <span class="n">v</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">inputs</span><span class="p">]</span>
        <span class="n">activities</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_function</span><span class="p">(</span><span class="o">*</span><span class="n">ordered_batch</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">activity</span><span class="p">,</span> <span class="n">layer</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">activities</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">prunable_layers</span><span class="p">):</span>
            <span class="n">layer</span><span class="o">.</span><span class="n">register_activities</span><span class="p">(</span><span class="n">activity</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_batches</span> <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="n">prune_every</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">next_layer_to_prune</span> <span class="o">+=</span> <span class="mi">1</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">next_layer_to_prune</span> <span class="o">&gt;=</span> <span class="mi">0</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">next_layer_to_prune</span> <span class="o">%=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">prunable_layers</span><span class="p">)</span>
                <span class="n">layer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">prunable_layers</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">next_layer_to_prune</span><span class="p">]</span>
                <span class="n">layer</span><span class="o">.</span><span class="n">prune</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">params_dict</span><span class="p">)</span>
                <span class="n">layer</span><span class="o">.</span><span class="n">sanity_check</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">params_dict</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_batches</span> <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="n">prune_reset_every</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">next_layer_to_reset</span> <span class="o">+=</span> <span class="mi">1</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">next_layer_to_reset</span> <span class="o">&gt;=</span> <span class="mi">0</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">next_layer_to_reset</span> <span class="o">%=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">prunable_layers</span><span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">prunable_layers</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">next_layer_to_reset</span><span class="p">]</span><span class="o">.</span><span class="n">reset</span><span class="p">()</span></div></div>

</pre></div>

           </div>
          </div>
          <footer>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2019, University of Cambridge.

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/snide/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  

    <script type="text/javascript">
        var DOCUMENTATION_OPTIONS = {
            URL_ROOT:'../../../../',
            VERSION:'0.6',
            COLLAPSE_INDEX:false,
            FILE_SUFFIX:'.html',
            HAS_SOURCE:  true
        };
    </script>
      <script type="text/javascript" src="../../../../_static/jquery.js"></script>
      <script type="text/javascript" src="../../../../_static/underscore.js"></script>
      <script type="text/javascript" src="../../../../_static/doctools.js"></script>

  

  
  
    <script type="text/javascript" src="../../../../_static/js/theme.js"></script>
  

  
  
  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.StickyNav.enable();
      });
  </script>
   

</body>
</html>