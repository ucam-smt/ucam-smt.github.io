

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Predictors &mdash; SGNMT 1.0 documentation</title>
  

  
  

  

  
  
    

  

  
  
    <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  

  
    <link rel="stylesheet" href="_static/custom.css" type="text/css" />
  

  
    <link rel="top" title="SGNMT 1.0 documentation" href="index.html"/>
        <link rel="next" title="Decoders" href="decoders.html"/>
        <link rel="prev" title="Command-line reference" href="command_line.html"/> 

  
  <script src="_static/js/modernizr.min.js"></script>

</head>

<body class="wy-body-for-nav" role="document">

  <div class="wy-grid-for-nav">

    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search">
          

          
            <a href="index.html" class="icon icon-home"> SGNMT
          

          
          </a>

          
            
            
              <div class="version">
                1.0
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
                <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="setup.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="tutorial.html">Tutorial: Basics (T2T)</a></li>
<li class="toctree-l1"><a class="reference internal" href="tutorial_pytorch.html">Tutorial: fairseq (PyTorch)</a></li>
<li class="toctree-l1"><a class="reference internal" href="adding_components.html">Tutorial: Adding new components</a></li>
<li class="toctree-l1"><a class="reference internal" href="bea19_gec.html">Tutorial:  Grammatical Error Correction (BEA19 Submission)</a></li>
<li class="toctree-l1"><a class="reference internal" href="tutorial_blocks.html">Tutorial: Blocks/Thano (outdated)</a></li>
<li class="toctree-l1"><a class="reference internal" href="command_line.html">Command-line reference</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Predictors</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#main-predictors">Main predictors</a></li>
<li class="toctree-l2"><a class="reference internal" href="#experimental-predictors">Experimental predictors</a></li>
<li class="toctree-l2"><a class="reference internal" href="#predictor-modules">Predictor modules</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#module-contents">Module contents</a></li>
<li class="toctree-l3"><a class="reference internal" href="#cam-sgnmt-predictors-automata-module">cam.sgnmt.predictors.automata module</a></li>
<li class="toctree-l3"><a class="reference internal" href="#cam-sgnmt-predictors-bow-module">cam.sgnmt.predictors.bow module</a></li>
<li class="toctree-l3"><a class="reference internal" href="#cam-sgnmt-predictors-core-module">cam.sgnmt.predictors.core module</a></li>
<li class="toctree-l3"><a class="reference internal" href="#cam-sgnmt-predictors-ffnnlm-module">cam.sgnmt.predictors.ffnnlm module</a></li>
<li class="toctree-l3"><a class="reference internal" href="#cam-sgnmt-predictors-forced-module">cam.sgnmt.predictors.forced module</a></li>
<li class="toctree-l3"><a class="reference internal" href="#cam-sgnmt-predictors-grammar-module">cam.sgnmt.predictors.grammar module</a></li>
<li class="toctree-l3"><a class="reference internal" href="#cam-sgnmt-predictors-length-module">cam.sgnmt.predictors.length module</a></li>
<li class="toctree-l3"><a class="reference internal" href="#cam-sgnmt-predictors-misc-module">cam.sgnmt.predictors.misc module</a></li>
<li class="toctree-l3"><a class="reference internal" href="#cam-sgnmt-predictors-ngram-module">cam.sgnmt.predictors.ngram module</a></li>
<li class="toctree-l3"><a class="reference internal" href="#cam-sgnmt-predictors-parse-module">cam.sgnmt.predictors.parse module</a></li>
<li class="toctree-l3"><a class="reference internal" href="#cam-sgnmt-predictors-pytorch-fairseq-module">cam.sgnmt.predictors.pytorch_fairseq module</a></li>
<li class="toctree-l3"><a class="reference internal" href="#cam-sgnmt-predictors-structure-module">cam.sgnmt.predictors.structure module</a></li>
<li class="toctree-l3"><a class="reference internal" href="#cam-sgnmt-predictors-tf-nizza-module">cam.sgnmt.predictors.tf_nizza module</a></li>
<li class="toctree-l3"><a class="reference internal" href="#cam-sgnmt-predictors-tf-t2t-module">cam.sgnmt.predictors.tf_t2t module</a></li>
<li class="toctree-l3"><a class="reference internal" href="#cam-sgnmt-predictors-tokenization-module">cam.sgnmt.predictors.tokenization module</a></li>
<li class="toctree-l3"><a class="reference internal" href="#cam-sgnmt-predictors-vocabulary-module">cam.sgnmt.predictors.vocabulary module</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="decoders.html">Decoders</a></li>
<li class="toctree-l1"><a class="reference internal" href="examples.html">Examples</a></li>
<li class="toctree-l1"><a class="reference internal" href="faq.html">Common issues</a></li>
<li class="toctree-l1"><a class="reference internal" href="publications.html">Publications</a></li>
<li class="toctree-l1"><a class="reference internal" href="cam.sgnmt.html">All modules</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" role="navigation" aria-label="top navigation">
        <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
        <a href="index.html">SGNMT</a>
      </nav>


      
      <div class="wy-nav-content">
        <div class="rst-content">
          

 



<div role="navigation" aria-label="breadcrumbs navigation">
  <ul class="wy-breadcrumbs">
    <li><a href="index.html">Docs</a> &raquo;</li>
      
    <li>Predictors</li>
      <li class="wy-breadcrumbs-aside">
        
          
            <a href="_sources/predictors.txt" rel="nofollow"> View page source</a>
          
        
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="predictors">
<h1>Predictors<a class="headerlink" href="#predictors" title="Permalink to this headline">¶</a></h1>
<p>Predictors are scoring modules which define a distribution over target words given the history and some side information like the source sentence.
If vocabulary sizes differ among predictors, we fill in gaps with predictor UNK scores.</p>
<p>Note that you can use multiple instances of the same predictor. For example, &#8216;t2t,t2t,t2t&#8217; can be used for ensembling three T2T models.
You can often override parts of the predictor configurations for subsequent predictors by adding the predictor number (e.g. see <code class="docutils literal"><span class="pre">--t2t_checkpoint_dir2</span></code> or <code class="docutils literal"><span class="pre">--fst_path2</span></code>)</p>
<div class="section" id="main-predictors">
<h2>Main predictors<a class="headerlink" href="#main-predictors" title="Permalink to this headline">¶</a></h2>
<p>The following main predictors are available. The installation of additional (optional) software required by some of the predictors is described on the <a class="reference internal" href="setup.html#setup-label"><span class="std std-ref">Installation</span></a> page.</p>
<p>For a more detailed description of the predictors, search for the name of the predictor in the <a class="reference internal" href="#predictor-modules-label"><span class="std std-ref">Predictor modules</span></a> section.</p>
<ul>
<li><p class="first"><strong>t2t</strong>: Predictor for tensor2tensor models. Requires Tensor2Tensor.</p>
<p>Options: <code class="docutils literal"><span class="pre">t2t_usr_dir</span></code>, <code class="docutils literal"><span class="pre">t2t_model</span></code>, <code class="docutils literal"><span class="pre">t2t_problem</span></code>, <code class="docutils literal"><span class="pre">t2t_hparams_set</span></code>, <code class="docutils literal"><span class="pre">t2t_checkpoint_dir</span></code>, <code class="docutils literal"><span class="pre">pred_src_vocab_size</span></code>, <code class="docutils literal"><span class="pre">pred_trg_vocab_size</span></code>, <code class="docutils literal"><span class="pre">n_cpu_threads</span></code></p>
</li>
<li><p class="first"><strong>fairseq</strong>: Predictor for fairseq models. Requires fairseq.</p>
<p>Options: <code class="docutils literal"><span class="pre">fairseq_path</span></code>, <code class="docutils literal"><span class="pre">fairseq_user_dir</span></code>, <code class="docutils literal"><span class="pre">fairseq_lang_pair</span></code>, <code class="docutils literal"><span class="pre">n_cpu_threads</span></code></p>
</li>
<li><p class="first"><strong>kenlm</strong>: Count-based n-gram language model in ARPA format. Requires KenLM.</p>
<p>Options: <code class="docutils literal"><span class="pre">lm_path</span></code></p>
</li>
<li><p class="first"><strong>forced</strong>: Forced decoding with one reference</p>
<p>Options: <code class="docutils literal"><span class="pre">trg_test</span></code></p>
</li>
<li><p class="first"><strong>forcedlst</strong>: Forced decoding with a Moses n-best list (n-best list rescoring)</p>
<p>Options: <code class="docutils literal"><span class="pre">trg_test</span></code>, <code class="docutils literal"><span class="pre">forcedlst_match_unk</span></code>, <code class="docutils literal"><span class="pre">forcedlst_sparse_feat</span></code>, <code class="docutils literal"><span class="pre">use_nbest_weights</span></code></p>
</li>
<li><p class="first"><strong>osm</strong>: Constraints output to valid OSM sequences</p>
<p>Options: <code class="docutils literal"><span class="pre">osm_type</span></code></p>
</li>
<li><p class="first"><strong>bow</strong>: Forced decoding with one bag-of-words ref.</p>
<p>Options: <code class="docutils literal"><span class="pre">trg_test</span></code>, <code class="docutils literal"><span class="pre">heuristic_scores_file</span></code>, <code class="docutils literal"><span class="pre">bow_heuristic_strategies</span></code>, <code class="docutils literal"><span class="pre">bow_accept_subsets</span></code>, <code class="docutils literal"><span class="pre">bow_accept_duplicates</span></code>, <code class="docutils literal"><span class="pre">pred_trg_vocab_size</span></code></p>
</li>
<li><p class="first"><strong>fst</strong>: Deterministic translation lattices</p>
<p>Options: <code class="docutils literal"><span class="pre">fst_path</span></code>, <code class="docutils literal"><span class="pre">use_fst_weights</span></code>, <code class="docutils literal"><span class="pre">normalize_fst_weights</span></code>, <code class="docutils literal"><span class="pre">fst_to_log</span></code>, <code class="docutils literal"><span class="pre">fst_skip_bos_weight</span></code></p>
</li>
<li><p class="first"><strong>nfst</strong>: Non-deterministic translation lattices</p>
<p>Options: <code class="docutils literal"><span class="pre">fst_path</span></code>, <code class="docutils literal"><span class="pre">use_fst_weights</span></code>, <code class="docutils literal"><span class="pre">normalize_fst_weights</span></code>, <code class="docutils literal"><span class="pre">fst_to_log</span></code>, <code class="docutils literal"><span class="pre">fst_skip_bos_weight</span></code></p>
</li>
<li><p class="first"><strong>wc</strong>: Number of words feature.</p>
<p>Options: <code class="docutils literal"><span class="pre">wc_word</span></code>, <code class="docutils literal"><span class="pre">negative_wc</span></code>, <code class="docutils literal"><span class="pre">wc_nonterminal_penalty</span></code>, <code class="docutils literal"><span class="pre">syntax_nonterminal_ids</span></code>, <code class="docutils literal"><span class="pre">syntax_min_terminal_id</span></code>, <code class="docutils literal"><span class="pre">syntax_max_terminal_id</span></code>, <code class="docutils literal"><span class="pre">pred_trg_vocab_size</span></code></p>
</li>
<li><p class="first"><strong>ngramc</strong>: For using MBR n-gram posteriors.</p>
<p>Options: <code class="docutils literal"><span class="pre">ngramc_path</span></code>, <code class="docutils literal"><span class="pre">ngramc_order</span></code></p>
</li>
</ul>
<p>All predictors can be combined with one or more wrapper predictors by adding the wrapper name separated by a _ symbol. Following main wrappers are available:</p>
<ul>
<li><p class="first"><strong>idxmap</strong>: Add this wrapper to predictors which use an alternative word map.</p>
<p>Options: <code class="docutils literal"><span class="pre">src_idxmap</span></code>, <code class="docutils literal"><span class="pre">trg_idxmap</span></code></p>
</li>
<li><p class="first"><strong>altsrc</strong>: This wrapper loads source sentences from an alternative source.</p>
<p>Options: <code class="docutils literal"><span class="pre">altsrc_test</span></code></p>
</li>
<li><p class="first"><strong>fsttok</strong>: Uses an FST to transduce SGNMT tokens to predictor tokens.</p>
<p>Options: <code class="docutils literal"><span class="pre">fsttok_path</span></code>, <code class="docutils literal"><span class="pre">fsttok_max_pending_score</span></code>, <code class="docutils literal"><span class="pre">fst_unk_id</span></code></p>
</li>
</ul>
</div>
<div class="section" id="experimental-predictors">
<h2>Experimental predictors<a class="headerlink" href="#experimental-predictors" title="Permalink to this headline">¶</a></h2>
<p>Experimental predictors are less frequently used but working predictor implementations for special cases.</p>
<ul>
<li><p class="first"><strong>editt2t</strong>: Predictor for searching over t2t models via edit operations. Requires Tensor2Tensor.</p>
<p>Options: <code class="docutils literal"><span class="pre">t2t_usr_dir</span></code>, <code class="docutils literal"><span class="pre">t2t_model</span></code>, <code class="docutils literal"><span class="pre">t2t_problem</span></code>, <code class="docutils literal"><span class="pre">t2t_hparams_set</span></code>, <code class="docutils literal"><span class="pre">t2t_checkpoint_dir</span></code>, <code class="docutils literal"><span class="pre">pred_src_vocab_size</span></code>, <code class="docutils literal"><span class="pre">pred_trg_vocab_size</span></code>, <code class="docutils literal"><span class="pre">trg_test</span></code>, <code class="docutils literal"><span class="pre">beam</span></code></p>
</li>
<li><p class="first"><strong>fertt2t</strong>: Predictor for tensor2tensor models predicting source token fertilities. Requires Tensor2Tensor.</p>
<p>Options: <code class="docutils literal"><span class="pre">t2t_usr_dir</span></code>, <code class="docutils literal"><span class="pre">t2t_model</span></code>, <code class="docutils literal"><span class="pre">t2t_problem</span></code>, <code class="docutils literal"><span class="pre">t2t_hparams_set</span></code>, <code class="docutils literal"><span class="pre">t2t_checkpoint_dir</span></code>, <code class="docutils literal"><span class="pre">pred_src_vocab_size</span></code>, <code class="docutils literal"><span class="pre">pred_trg_vocab_size</span></code></p>
</li>
<li><p class="first"><strong>segt2t</strong>: Predictor for tensor2tensor models with <code class="docutils literal"><span class="pre">_seg</span></code> and <code class="docutils literal"><span class="pre">_pos</span></code> features. Requires Tensor2Tensor.</p>
<p>Options: <code class="docutils literal"><span class="pre">t2t_usr_dir</span></code>, <code class="docutils literal"><span class="pre">t2t_model</span></code>, <code class="docutils literal"><span class="pre">t2t_problem</span></code>, <code class="docutils literal"><span class="pre">t2t_hparams_set</span></code>, <code class="docutils literal"><span class="pre">t2t_checkpoint_dir</span></code>, <code class="docutils literal"><span class="pre">pred_src_vocab_size</span></code>, <code class="docutils literal"><span class="pre">pred_trg_vocab_size</span></code></p>
</li>
<li><p class="first"><strong>nizza</strong>: Nizza alignment models. Requires Nizza.</p>
<p>Options: <code class="docutils literal"><span class="pre">nizza_model</span></code>, <code class="docutils literal"><span class="pre">nizza_hparams_set</span></code>, <code class="docutils literal"><span class="pre">nizza_checkpoint_dir</span></code>, <code class="docutils literal"><span class="pre">pred_src_vocab_size</span></code>, <code class="docutils literal"><span class="pre">pred_trg_vocab_size</span></code></p>
</li>
<li><p class="first"><strong>lexnizza</strong>: Uses Nizza lexical scores to check coverage. Requires Nizza.</p>
<p>Options: <code class="docutils literal"><span class="pre">nizza_model</span></code>, <code class="docutils literal"><span class="pre">nizza_hparams_set</span></code>, <code class="docutils literal"><span class="pre">nizza_checkpoint_dir</span></code>, <code class="docutils literal"><span class="pre">pred_src_vocab_size</span></code>, <code class="docutils literal"><span class="pre">pred_trg_vocab_size</span></code>, <code class="docutils literal"><span class="pre">lexnizza_alpha</span></code>, <code class="docutils literal"><span class="pre">lexnizza_beta</span></code>, <code class="docutils literal"><span class="pre">lexnizza_shortlist_strategies</span></code>, <code class="docutils literal"><span class="pre">lexnizza_max_shortlist_length</span></code></p>
</li>
<li><p class="first"><strong>bracket</strong>: Enforces well-formed bracket expressions</p>
<p>Options: <code class="docutils literal"><span class="pre">syntax_pop_id</span></code> , <code class="docutils literal"><span class="pre">syntax_max_terminal_id</span></code>, <code class="docutils literal"><span class="pre">syntax_max_depth</span></code>, <code class="docutils literal"><span class="pre">extlength_path</span></code></p>
</li>
<li><p class="first"><strong>forcedosm</strong>: Forced alignment with an OSM model</p>
<p>Options: <code class="docutils literal"><span class="pre">trg_test</span></code></p>
</li>
<li><p class="first"><strong>rtn</strong>: Recurrent transition networks as created by HiFST with late expansion.</p>
<p>Options: <code class="docutils literal"><span class="pre">rtn_path</span></code>, <code class="docutils literal"><span class="pre">use_rtn_weights</span></code>, <code class="docutils literal"><span class="pre">minimize_rtns</span></code>, <code class="docutils literal"><span class="pre">remove_epsilon_in_rtns</span></code>, <code class="docutils literal"><span class="pre">normalize_rtn_weights</span></code></p>
</li>
<li><p class="first"><strong>lrhiero</strong>: Direct Hiero (left-to-right Hiero). This is an EXPERIMENTAL implementation of LRHiero.</p>
<p>Options: <code class="docutils literal"><span class="pre">rules_path</span></code>, <code class="docutils literal"><span class="pre">grammar_feature_weights</span></code>, <code class="docutils literal"><span class="pre">use_grammar_weights</span></code></p>
</li>
<li><p class="first"><strong>unkc</strong>: Poisson model for number of UNKs.</p>
<p>Options: <code class="docutils literal"><span class="pre">unk_count_lambdas</span></code>, <code class="docutils literal"><span class="pre">pred_trg_vocab_size</span></code></p>
</li>
<li><p class="first"><strong>length</strong>: Target sentence length model.</p>
<p>Options: <code class="docutils literal"><span class="pre">src_test_raw</span></code>, <code class="docutils literal"><span class="pre">length_model_weights</span></code>, <code class="docutils literal"><span class="pre">use_length_point_probs</span></code></p>
</li>
<li><p class="first"><strong>extlength</strong>: External target sentence lengths.</p>
<p>Options: <code class="docutils literal"><span class="pre">extlength_path</span></code></p>
</li>
</ul>
<p>Following experimental predictor wrappers are available:</p>
<ul>
<li><p class="first"><strong>glue</strong>: Masks sentence-level predictors when SGNMT runs on the document level.</p>
<p>Options:</p>
</li>
<li><p class="first"><strong>parse</strong>: Internal beam search over a representation which contains some pre-defined non-terminal ids, which should not appear in the output.</p>
<p>Options: <code class="docutils literal"><span class="pre">parse_tok_grammar</span></code>, <code class="docutils literal"><span class="pre">parse_bpe_path</span></code>, <code class="docutils literal"><span class="pre">syntax_path</span></code>, <code class="docutils literal"><span class="pre">syntax_bpe_path</span></code>, <code class="docutils literal"><span class="pre">syntax_word_out</span></code>, <code class="docutils literal"><span class="pre">normalize_fst_weights</span></code>, <code class="docutils literal"><span class="pre">syntax_norm_alpha</span></code>, <code class="docutils literal"><span class="pre">syntax_internal_beam</span></code>, <code class="docutils literal"><span class="pre">syntax_max_internal_len</span></code>, <code class="docutils literal"><span class="pre">syntax_allow_early_eos</span></code>, <code class="docutils literal"><span class="pre">syntax_consume_ooc</span></code>, <code class="docutils literal"><span class="pre">syntax_terminal_restrict</span></code>, <code class="docutils literal"><span class="pre">syntax_internal_only</span></code>, <code class="docutils literal"><span class="pre">syntax_eow_ids</span></code>, <code class="docutils literal"><span class="pre">syntax_terminal_ids</span></code></p>
</li>
<li><p class="first"><strong>rank</strong>: Does not use the scores of the wrapped predictor directly but the rank in the scores table.</p>
<p>Options:</p>
</li>
<li><p class="first"><strong>ngramize</strong>: Extracts n-gram posteriors from a predictor without feedback loop.</p>
<p>Options: <code class="docutils literal"><span class="pre">min_ngram_order</span></code>, <code class="docutils literal"><span class="pre">max_ngram_order</span></code>, <code class="docutils literal"><span class="pre">max_len_factor</span></code></p>
</li>
<li><p class="first"><strong>skipvocab</strong>: Uses internal beam search to skip a subset of the predictor vocabulary.</p>
<p>Options: <code class="docutils literal"><span class="pre">beam</span></code>, <code class="docutils literal"><span class="pre">skipvocab_max_id</span></code>, <code class="docutils literal"><span class="pre">skipvocab_stop_size</span></code></p>
</li>
<li><p class="first"><strong>maskvocab</strong>: Hides a subset of the SGNMT vocabulary from the wrapped predictor.</p>
<p>Options: <code class="docutils literal"><span class="pre">maskvocab_words</span></code></p>
</li>
<li><p class="first"><strong>unkvocab</strong>: This wrapper explicitly excludes matching word indices higher than <code class="docutils literal"><span class="pre">pred_trg_vocab_size</span></code> with UNK scores.</p>
<p>Options: <code class="docutils literal"><span class="pre">pred_trg_vocab_size</span></code></p>
</li>
<li><p class="first"><strong>word2char</strong>: Wraps word-level predictors when SGNMT is running on character level.</p>
<p>Options: <code class="docutils literal"><span class="pre">word2char_map</span></code></p>
</li>
</ul>
</div>
<div class="section" id="predictor-modules">
<span id="predictor-modules-label"></span><h2>Predictor modules<a class="headerlink" href="#predictor-modules" title="Permalink to this headline">¶</a></h2>
<div class="section" id="module-contents">
<h3>Module contents<a class="headerlink" href="#module-contents" title="Permalink to this headline">¶</a></h3>
<p>Predictors are the scoring modules used in SGNMT. They can be used
together to form a combined search space and scores. Note that the
configuration of predictors is not decoupled with the central
configuration (yet). Therefore, new predictors need to be referenced to
in <code class="docutils literal"><span class="pre">blocks.decode</span></code>, and their configuration parameters need to be
added to <code class="docutils literal"><span class="pre">blocks.ui</span></code>.</p>
</div>
<div class="section" id="cam-sgnmt-predictors-automata-module">
<h3>cam.sgnmt.predictors.automata module<a class="headerlink" href="#cam-sgnmt-predictors-automata-module" title="Permalink to this headline">¶</a></h3>
<p>This module encapsulates the predictor interface to OpenFST. This
module depends on OpenFST. To enable Python support in OpenFST, use a
recent version (&gt;=1.5.4) and compile with <code class="docutils literal"><span class="pre">--enable_python</span></code>.
Further information can be found here:</p>
<p><a class="reference external" href="http://www.openfst.org/twiki/bin/view/FST/PythonExtension">http://www.openfst.org/twiki/bin/view/FST/PythonExtension</a></p>
<p>This file includes the fst, nfst, and rtn predictors.</p>
<p>Note: If we use arc weights in FSTs, we multiply them by -1 as
everything in SGNMT is logprob, not -logprob as in FSTs log
or tropical semirings. You can disable this behavior with &#8211;fst_to_log</p>
<p>Note2: The FSTs and RTNs are assumed to have both &lt;S&gt; and &lt;/S&gt;. This
has compatibility reasons, as lattices generated by HiFST have these
symbols.</p>
<dl class="data">
<dt>
<code class="descclassname">cam.sgnmt.predictors.automata.</code><code class="descname">EPS_ID</code><em class="property"> = 0</em></dt>
<dd><p>OpenFST&#8217;s reserved ID for epsilon arcs.</p>
</dd></dl>

<dl class="class">
<dt>
<em class="property">class </em><code class="descclassname">cam.sgnmt.predictors.automata.</code><code class="descname">FstPredictor</code><span class="sig-paren">(</span><em>fst_path</em>, <em>use_weights</em>, <em>normalize_scores</em>, <em>skip_bos_weight=True</em>, <em>to_log=True</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/automata.html#FstPredictor"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Bases: <a class="reference internal" href="cam.sgnmt.predictors.html#cam.sgnmt.predictors.core.Predictor" title="cam.sgnmt.predictors.core.Predictor"><code class="xref py py-class docutils literal"><span class="pre">cam.sgnmt.predictors.core.Predictor</span></code></a></p>
<p>This predictor can read determinized translation lattices. The
predictor state consists of the current node. This is unique as the
lattices are determinized.</p>
<p>Creates a new fst predictor.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>fst_path</strong> (<em>string</em>) &#8211; Path to the FST file</li>
<li><strong>use_weights</strong> (<em>bool</em>) &#8211; If false, replace all arc weights with
0 (=log 1).</li>
<li><strong>normalize_scores</strong> (<em>bool</em>) &#8211; If true, we normalize the weights
on all outgoing arcs such that
they sum up to 1</li>
<li><strong>skip_bos_weight</strong> (<em>bool</em>) &#8211; Add the score at the &lt;S&gt; arc to the
&lt;/S&gt; arc if this is false. This results
in scores consistent with
OpenFST&#8217;s replace operation,
as &lt;S&gt; scores are normally
ignored by SGNMT.</li>
<li><strong>to_log</strong> (<em>bool</em>) &#8211; SGNMT uses normal log probs (scores) while
arc weights in FSTs normally have cost (i.e.
neg. log values) semantics. Therefore, if
true, we multiply arc weights by -1.</li>
</ul>
</td>
</tr>
</tbody>
</table>
<dl class="method">
<dt>
<code class="descname">consume</code><span class="sig-paren">(</span><em>word</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/automata.html#FstPredictor.consume"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Updates the current node by following the arc labelled with
<code class="docutils literal"><span class="pre">word</span></code>. If there is no such arc, we set <code class="docutils literal"><span class="pre">cur_node</span></code> to -1,
indicating that the predictor is in an invalid state. In this
case, all subsequent <code class="docutils literal"><span class="pre">predict_next</span></code> calls will return the
empty set.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>word</strong> (<em>int</em>) &#8211; Word on an outgoing arc from the current node</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body">float. Weight on the traversed arc</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">estimate_future_cost</code><span class="sig-paren">(</span><em>hypo</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/automata.html#FstPredictor.estimate_future_cost"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>The FST predictor comes with its own heuristic function. We
use the shortest path in the fst as future cost estimator.</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">get_state</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/automata.html#FstPredictor.get_state"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Returns the current node.</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">get_unk_probability</code><span class="sig-paren">(</span><em>posterior</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/automata.html#FstPredictor.get_unk_probability"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Returns negative infinity if UNK is not in the lattice.
Otherwise, return UNK score.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body">float. Negative infinity</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">initialize</code><span class="sig-paren">(</span><em>src_sentence</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/automata.html#FstPredictor.initialize"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Loads the FST from the file system and consumes the start
of sentence symbol.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>src_sentence</strong> (<em>list</em>) &#8211; Not used</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">initialize_heuristic</code><span class="sig-paren">(</span><em>src_sentence</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/automata.html#FstPredictor.initialize_heuristic"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Creates a matrix of shortest distances between nodes.</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">is_equal</code><span class="sig-paren">(</span><em>state1</em>, <em>state2</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/automata.html#FstPredictor.is_equal"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Returns true if the current node is the same</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">predict_next</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/automata.html#FstPredictor.predict_next"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Uses the outgoing arcs from the current node to build up the
scores for the next word.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body">dict. Set of words on outgoing arcs from the current node
together with their scores, or an empty set if we currently
have no active node or fst.</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">set_state</code><span class="sig-paren">(</span><em>state</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/automata.html#FstPredictor.set_state"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Sets the current node.</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt>
<em class="property">class </em><code class="descclassname">cam.sgnmt.predictors.automata.</code><code class="descname">NondeterministicFstPredictor</code><span class="sig-paren">(</span><em>fst_path</em>, <em>use_weights</em>, <em>normalize_scores</em>, <em>skip_bos_weight=True</em>, <em>to_log=True</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/automata.html#NondeterministicFstPredictor"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Bases: <a class="reference internal" href="cam.sgnmt.predictors.html#cam.sgnmt.predictors.core.Predictor" title="cam.sgnmt.predictors.core.Predictor"><code class="xref py py-class docutils literal"><span class="pre">cam.sgnmt.predictors.core.Predictor</span></code></a></p>
<p>This predictor can handle non-deterministic translation
lattices. In contrast to the fst predictor for deterministic
lattices, we store a set of nodes which are all reachable from
the start node through the current history.</p>
<p>Creates a new nfst predictor.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>fst_path</strong> (<em>string</em>) &#8211; Path to the FST file</li>
<li><strong>use_weights</strong> (<em>bool</em>) &#8211; If false, replace all arc weights with
0 (=log 1).</li>
<li><strong>normalize_scores</strong> (<em>bool</em>) &#8211; If true, we normalize the weights
on all outgoing arcs such that
they sum up to 1</li>
<li><strong>skip_bos_weight</strong> (<em>bool</em>) &#8211; If true, set weights on &lt;S&gt; arcs
to 0 (= log1)</li>
<li><strong>to_log</strong> (<em>bool</em>) &#8211; SGNMT uses normal log probs (scores) while
arc weights in FSTs normally have cost (i.e.
neg. log values) semantics. Therefore, if
true, we multiply arc weights by -1.</li>
</ul>
</td>
</tr>
</tbody>
</table>
<dl class="method">
<dt>
<code class="descname">consume</code><span class="sig-paren">(</span><em>word</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/automata.html#NondeterministicFstPredictor.consume"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Updates the current nodes by searching for all nodes which
are reachable from the current nodes by a path consisting of
any number of epsilons and exactly one <code class="docutils literal"><span class="pre">word</span></code> label. If there
is no such arc, we set the predictor in an invalid state. In
this case, all subsequent <code class="docutils literal"><span class="pre">predict_next</span></code> calls will return
the empty set.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>word</strong> (<em>int</em>) &#8211; Word on an outgoing arc from the current node</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">estimate_future_cost</code><span class="sig-paren">(</span><em>hypo</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/automata.html#NondeterministicFstPredictor.estimate_future_cost"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>The FST predictor comes with its own heuristic function. We
use the shortest path in the fst as future cost estimator.</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">get_state</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/automata.html#NondeterministicFstPredictor.get_state"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Returns the set of current nodes</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">get_unk_probability</code><span class="sig-paren">(</span><em>posterior</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/automata.html#NondeterministicFstPredictor.get_unk_probability"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Always returns negative infinity: Words outside the
translation lattice are not possible according to this
predictor.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body">float. Negative infinity</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">initialize</code><span class="sig-paren">(</span><em>src_sentence</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/automata.html#NondeterministicFstPredictor.initialize"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Loads the FST from the file system and consumes the start
of sentence symbol.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>src_sentence</strong> (<em>list</em>) &#8211; Not used</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">initialize_heuristic</code><span class="sig-paren">(</span><em>src_sentence</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/automata.html#NondeterministicFstPredictor.initialize_heuristic"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Creates a matrix of shortest distances between all nodes</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">is_equal</code><span class="sig-paren">(</span><em>state1</em>, <em>state2</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/automata.html#NondeterministicFstPredictor.is_equal"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Returns true if the current nodes are the same</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">predict_next</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/automata.html#NondeterministicFstPredictor.predict_next"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Uses the outgoing arcs from all current node to build up the
scores for the next word. This method does not follow epsilon
arcs: <code class="docutils literal"><span class="pre">consume</span></code> updates <code class="docutils literal"><span class="pre">cur_nodes</span></code> such that all reachable
arcs with word ids are connected directly with a node in
<code class="docutils literal"><span class="pre">cur_nodes</span></code>. If there are multiple arcs with the same word,
we use the log sum of the arc weights as score.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body">dict. Set of words on outgoing arcs from the current node
together with their scores, or an empty set if we currently
have no active nodes or fst.</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">set_state</code><span class="sig-paren">(</span><em>state</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/automata.html#NondeterministicFstPredictor.set_state"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Sets the set of current nodes</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt>
<em class="property">class </em><code class="descclassname">cam.sgnmt.predictors.automata.</code><code class="descname">RtnPredictor</code><span class="sig-paren">(</span><em>rtn_path</em>, <em>use_weights</em>, <em>normalize_scores</em>, <em>to_log=True</em>, <em>minimize_rtns=False</em>, <em>rmeps=True</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/automata.html#RtnPredictor"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Bases: <a class="reference internal" href="cam.sgnmt.predictors.html#cam.sgnmt.predictors.core.Predictor" title="cam.sgnmt.predictors.core.Predictor"><code class="xref py py-class docutils literal"><span class="pre">cam.sgnmt.predictors.core.Predictor</span></code></a></p>
<p>Predictor for RTNs (recurrent transition networks). This
predictor assumes a directory structure as produced by HiFST. You
can use this predictor for non-deterministic lattices too. This
implementation supports late expansion: RTNs are only expanded as
far as necessary to retrieve all currently reachable states.</p>
<p><code class="docutils literal"><span class="pre">cur_nodes</span></code> contains the accumulated weights from the last
consumed word (if ambiguous, the largest)</p>
<p>This implementation does not maintain a list of active nodes like
the other automata predictors. Instead, we store the current
history and search for the active nodes at each expansion. This is
more expensive, but fstreplace might change state IDs so a list of
active nodes might get corrupted.</p>
<p>Note that this predictor does not support FSTs in gzip format.</p>
<p>Creates a new RTN predictor.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>rtn_path</strong> (<em>string</em>) &#8211; Path to the RTN directory</li>
<li><strong>use_weights</strong> (<em>bool</em>) &#8211; If false, replace all arc weights with
0 (=log 1).</li>
<li><strong>normalize_scores</strong> (<em>bool</em>) &#8211; If true, we normalize the weights
on all outgoing arcs such that
they sum up to 1</li>
<li><strong>to_log</strong> (<em>bool</em>) &#8211; SGNMT uses normal log probs (scores) while
arc weights in FSTs normally have cost (i.e.
neg. log values) semantics. Therefore, if
true, we multiply arc weights by -1.</li>
<li><strong>minimize_rtns</strong> (<em>bool</em>) &#8211; Minimize the FST after each replace
operation</li>
<li><strong>rmeps</strong> (<em>bool</em>) &#8211; Remove epsilons in the FST after each replace
operation</li>
</ul>
</td>
</tr>
</tbody>
</table>
<dl class="method">
<dt>
<code class="descname">add_to_label_fst_map_recursive</code><span class="sig-paren">(</span><em>label_fst_map</em>, <em>visited_nodes</em>, <em>root_node</em>, <em>acc_weight</em>, <em>history</em>, <em>func</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/automata.html#RtnPredictor.add_to_label_fst_map_recursive"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Adds arcs to <code class="docutils literal"><span class="pre">label_fst_map</span></code> if they are labeled with an
NT symbol and reachable from <code class="docutils literal"><span class="pre">root_node</span></code> via <code class="docutils literal"><span class="pre">history</span></code>.</p>
<p>Note: visited_nodes is maintained for each history separately</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">consume</code><span class="sig-paren">(</span><em>word</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/automata.html#RtnPredictor.consume"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Adds <code class="docutils literal"><span class="pre">word</span></code> to the current history.</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">expand_rtn</code><span class="sig-paren">(</span><em>func</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/automata.html#RtnPredictor.expand_rtn"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>This method expands the RTN as far as necessary. This means
that the RTN is expanded s.t. we can build the posterior for
<code class="docutils literal"><span class="pre">cur_history</span></code>. In practice, this means that we follow all
epsilon edges and replaces all NT edges until all paths with
the prefix <code class="docutils literal"><span class="pre">cur_history</span></code> in the RTN have at least one more
terminal token. Then, we apply <code class="docutils literal"><span class="pre">func</span></code> to all reachable nodes.</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">get_state</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/automata.html#RtnPredictor.get_state"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Returns the current history.</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">get_sub_fst</code><span class="sig-paren">(</span><em>fst_id</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/automata.html#RtnPredictor.get_sub_fst"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Load sub fst from the file system or the cache</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">get_unk_probability</code><span class="sig-paren">(</span><em>posterior</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/automata.html#RtnPredictor.get_unk_probability"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Always returns negative infinity: Words outside the
RTN are not possible according to this predictor.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body">float. Negative infinity</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">initialize</code><span class="sig-paren">(</span><em>src_sentence</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/automata.html#RtnPredictor.initialize"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Loads the root RTN and consumes the start of sentence
symbol.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>src_sentence</strong> (<em>list</em>) &#8211; Not used</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">is_nt_label</code><span class="sig-paren">(</span><em>label</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/automata.html#RtnPredictor.is_nt_label"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Returns true if <code class="docutils literal"><span class="pre">label</span></code> is a non-terminal.</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">predict_next</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/automata.html#RtnPredictor.predict_next"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Expands RTN as far as possible and uses the outgoing edges
from nodes reachable by the current history to build up
the posterior for the next word. If there are no such nodes
or arcs, or no root FST is loaded, return the empty set.</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">set_state</code><span class="sig-paren">(</span><em>state</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/automata.html#RtnPredictor.set_state"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Sets the current history.</p>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="cam-sgnmt-predictors-bow-module">
<h3>cam.sgnmt.predictors.bow module<a class="headerlink" href="#cam-sgnmt-predictors-bow-module" title="Permalink to this headline">¶</a></h3>
<p>This module contains predictors for bag of words experiments. This
is the standard bow predictor and the bowsearch predictor which first
does an unrestricted search to construct a skeleton and then restricts
the order of words by that skeleton (in addition to the bag
restriction).</p>
<dl class="class">
<dt>
<em class="property">class </em><code class="descclassname">cam.sgnmt.predictors.bow.</code><code class="descname">BagOfWordsPredictor</code><span class="sig-paren">(</span><em>trg_test_file</em>, <em>accept_subsets=False</em>, <em>accept_duplicates=False</em>, <em>heuristic_scores_file=''</em>, <em>collect_stats_strategy='best'</em>, <em>heuristic_add_consumed=False</em>, <em>heuristic_add_remaining=True</em>, <em>diversity_heuristic_factor=-1.0</em>, <em>equivalence_vocab=-1</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/bow.html#BagOfWordsPredictor"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Bases: <a class="reference internal" href="cam.sgnmt.predictors.html#cam.sgnmt.predictors.core.Predictor" title="cam.sgnmt.predictors.core.Predictor"><code class="xref py py-class docutils literal"><span class="pre">cam.sgnmt.predictors.core.Predictor</span></code></a></p>
<p>This predictor is similar to the forced predictor, but it does
not enforce the word order in the reference. Therefore, it assigns
1 to all hypotheses which have the words in the reference in any
order, and -inf to all other hypos.</p>
<p>Creates a new bag-of-words predictor.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>trg_test_file</strong> (<em>string</em>) &#8211; Path to the plain text file with
the target sentences. Must have the
same number of lines as the number
of source sentences to decode. The
word order in the target sentences
is not relevant for this predictor.</li>
<li><strong>accept_subsets</strong> (<em>bool</em>) &#8211; If true, this predictor permits
EOS even if the bag is not fully
consumed yet</li>
<li><strong>accept_duplicates</strong> (<em>bool</em>) &#8211; If true, counts are not updated
when a word is consumed. This
means that we allow a word in a
bag to appear multiple times</li>
<li><strong>heuristic_scores_file</strong> (<em>string</em>) &#8211; Path to the unigram scores
which are used if this
predictor estimates future
costs</li>
<li><strong>collect_stats_strategy</strong> (<em>string</em>) &#8211; best, full, or all. Defines
how unigram estimates are
collected for heuristic</li>
<li><strong>heuristic_add_consumed</strong> (<em>bool</em>) &#8211; Set to true to add the
difference between actual
partial score and unigram
estimates of consumed words
to the predictor heuristic</li>
<li><strong>heuristic_add_remaining</strong> (<em>bool</em>) &#8211; Set to true to add the sum
of unigram scores of words
remaining in the bag to the
predictor heuristic</li>
<li><strong>diversity_heuristic_factor</strong> (<em>float</em>) &#8211; Factor for diversity
heuristic which
penalizes hypotheses
with the same bag as
full hypos</li>
<li><strong>equivalence_vocab</strong> (<em>int</em>) &#8211; If positive, predictor states are
considered equal if the the
remaining words within that vocab
and OOVs regarding this vocab are
the same. Only relevant when using
hypothesis recombination</li>
</ul>
</td>
</tr>
</tbody>
</table>
<dl class="method">
<dt>
<code class="descname">consume</code><span class="sig-paren">(</span><em>word</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/bow.html#BagOfWordsPredictor.consume"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Updates the bag by deleting the consumed word.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>word</strong> (<em>int</em>) &#8211; Next word to consume</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">estimate_future_cost</code><span class="sig-paren">(</span><em>hypo</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/bow.html#BagOfWordsPredictor.estimate_future_cost"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>The bow predictor comes with its own heuristic function. We
use the sum of scores of the remaining words as future cost
estimator.</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">get_state</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/bow.html#BagOfWordsPredictor.get_state"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>State of this predictor is the current bag</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">get_unk_probability</code><span class="sig-paren">(</span><em>posterior</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/bow.html#BagOfWordsPredictor.get_unk_probability"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Returns negative infinity unconditionally: Words which are
not in the target sentence have assigned probability 0 by
this predictor.</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">initialize</code><span class="sig-paren">(</span><em>src_sentence</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/bow.html#BagOfWordsPredictor.initialize"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Creates a new bag for the current target sentence..</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>src_sentence</strong> (<em>list</em>) &#8211; Not used</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">initialize_heuristic</code><span class="sig-paren">(</span><em>src_sentence</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/bow.html#BagOfWordsPredictor.initialize_heuristic"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Calls <code class="docutils literal"><span class="pre">reset</span></code> of the used unigram table with estimates
<code class="docutils literal"><span class="pre">self.estimates</span></code> to clear all statistics from the previous
sentence</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>src_sentence</strong> (<em>list</em>) &#8211; Not used</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">is_equal</code><span class="sig-paren">(</span><em>state1</em>, <em>state2</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/bow.html#BagOfWordsPredictor.is_equal"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Returns true if the bag is the same</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">notify</code><span class="sig-paren">(</span><em>message</em>, <em>message_type=1</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/bow.html#BagOfWordsPredictor.notify"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>This gets called if this predictor observes the decoder. It
updates unigram heuristic estimates via passing through this
message to the unigram table <code class="docutils literal"><span class="pre">self.estimates</span></code>.</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">predict_next</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/bow.html#BagOfWordsPredictor.predict_next"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>If the bag is empty, the only allowed symbol is EOS.
Otherwise, return the list of keys in the bag.</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">set_state</code><span class="sig-paren">(</span><em>state</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/bow.html#BagOfWordsPredictor.set_state"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>State of this predictor is the current bag</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt>
<em class="property">class </em><code class="descclassname">cam.sgnmt.predictors.bow.</code><code class="descname">BagOfWordsSearchPredictor</code><span class="sig-paren">(</span><em>main_decoder</em>, <em>hypo_recombination</em>, <em>trg_test_file</em>, <em>accept_subsets=False</em>, <em>accept_duplicates=False</em>, <em>heuristic_scores_file=''</em>, <em>collect_stats_strategy='best'</em>, <em>heuristic_add_consumed=False</em>, <em>heuristic_add_remaining=True</em>, <em>diversity_heuristic_factor=-1.0</em>, <em>equivalence_vocab=-1</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/bow.html#BagOfWordsSearchPredictor"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Bases: <a class="reference internal" href="cam.sgnmt.predictors.html#cam.sgnmt.predictors.bow.BagOfWordsPredictor" title="cam.sgnmt.predictors.bow.BagOfWordsPredictor"><code class="xref py py-class docutils literal"><span class="pre">cam.sgnmt.predictors.bow.BagOfWordsPredictor</span></code></a></p>
<p>Combines the bag-of-words predictor with a proxy decoding pass
which creates a skeleton translation.</p>
<p>Creates a new bag-of-words predictor with pre search</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>main_decoder</strong> (<a class="reference internal" href="cam.sgnmt.html#cam.sgnmt.io.Decoder" title="cam.sgnmt.io.Decoder"><em>Decoder</em></a>) &#8211; Reference to the main decoder
instance, used to fetch the predictors</li>
<li><strong>hypo_recombination</strong> (<em>bool</em>) &#8211; Activates hypo recombination for the
pre decoder</li>
<li><strong>trg_test_file</strong> (<em>string</em>) &#8211; Path to the plain text file with
the target sentences. Must have the
same number of lines as the number
of source sentences to decode. The
word order in the target sentences
is not relevant for this predictor.</li>
<li><strong>accept_subsets</strong> (<em>bool</em>) &#8211; If true, this predictor permits
EOS even if the bag is not fully
consumed yet</li>
<li><strong>accept_duplicates</strong> (<em>bool</em>) &#8211; If true, counts are not updated
when a word is consumed. This
means that we allow a word in a
bag to appear multiple times</li>
<li><strong>heuristic_scores_file</strong> (<em>string</em>) &#8211; Path to the unigram scores
which are used if this
predictor estimates future
costs</li>
<li><strong>collect_stats_strategy</strong> (<em>string</em>) &#8211; best, full, or all. Defines
how unigram estimates are
collected for heuristic</li>
<li><strong>heuristic_add_consumed</strong> (<em>bool</em>) &#8211; Set to true to add the
difference between actual
partial score and unigram
estimates of consumed words
to the predictor heuristic</li>
<li><strong>heuristic_add_remaining</strong> (<em>bool</em>) &#8211; Set to true to add the sum
of unigram scores of words
remaining in the bag to the
predictor heuristic</li>
<li><strong>equivalence_vocab</strong> (<em>int</em>) &#8211; If positive, predictor states are
considered equal if the the
remaining words within that vocab
and OOVs regarding this vocab are
the same. Only relevant when using
hypothesis recombination</li>
</ul>
</td>
</tr>
</tbody>
</table>
<dl class="method">
<dt>
<code class="descname">consume</code><span class="sig-paren">(</span><em>word</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/bow.html#BagOfWordsSearchPredictor.consume"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Calls super class <code class="docutils literal"><span class="pre">consume</span></code>. If not in <code class="docutils literal"><span class="pre">pre_mode</span></code>,
update skeleton info.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>word</strong> (<em>int</em>) &#8211; Next word to consume</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">get_state</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/bow.html#BagOfWordsSearchPredictor.get_state"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>If in pre_mode, state of this predictor is the current bag
Otherwise, its the bag plus skeleton state</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">initialize</code><span class="sig-paren">(</span><em>src_sentence</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/bow.html#BagOfWordsSearchPredictor.initialize"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>If in <code class="docutils literal"><span class="pre">pre_mode</span></code>, pass through to super class. Otherwise,
initialize skeleton.</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">is_equal</code><span class="sig-paren">(</span><em>state1</em>, <em>state2</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/bow.html#BagOfWordsSearchPredictor.is_equal"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Returns true if the bag and the skeleton states are the same</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">predict_next</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/bow.html#BagOfWordsSearchPredictor.predict_next"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>If in <code class="docutils literal"><span class="pre">pre_mode</span></code>, pass through to super class. Otherwise,
scan skeleton</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">set_state</code><span class="sig-paren">(</span><em>state</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/bow.html#BagOfWordsSearchPredictor.set_state"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>If in pre_mode, state of this predictor is the current bag
Otherwise, its the bag plus skeleton state</p>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="cam-sgnmt-predictors-core-module">
<h3>cam.sgnmt.predictors.core module<a class="headerlink" href="#cam-sgnmt-predictors-core-module" title="Permalink to this headline">¶</a></h3>
<p>This module contains the two basic predictor interfaces
for bounded and unbounded vocabulary predictors.</p>
<dl class="class">
<dt>
<em class="property">class </em><code class="descclassname">cam.sgnmt.predictors.core.</code><code class="descname">Predictor</code><a class="reference internal" href="_modules/cam/sgnmt/predictors/core.html#Predictor"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Bases: <a class="reference internal" href="cam.sgnmt.html#cam.sgnmt.utils.Observer" title="cam.sgnmt.utils.Observer"><code class="xref py py-class docutils literal"><span class="pre">cam.sgnmt.utils.Observer</span></code></a></p>
<p>A predictor produces the predictive probability distribution of
the next word given the state of the predictor. The state may
change during <code class="docutils literal"><span class="pre">predict_next()</span></code> and <code class="docutils literal"><span class="pre">consume()</span></code>. The functions
<code class="docutils literal"><span class="pre">get_state()</span></code> and <code class="docutils literal"><span class="pre">set_state()</span></code> can be used for non-greedy
decoding. Note: The state describes the predictor with the current
history. It does not encapsulate the current source sentence, i.e.
you cannot recover a predictor state if <code class="docutils literal"><span class="pre">initialize()</span></code> was called
in between. <code class="docutils literal"><span class="pre">predict_next()</span></code> and <code class="docutils literal"><span class="pre">consume()</span></code> must be called
alternately. This holds even when using <code class="docutils literal"><span class="pre">get_state()</span></code> and
<code class="docutils literal"><span class="pre">set_state()</span></code>: Loading/saving states is transparent to the
predictor instance.</p>
<p>Initializes <code class="docutils literal"><span class="pre">current_sen_id</span></code> with 0.</p>
<dl class="method">
<dt>
<code class="descname">consume</code><span class="sig-paren">(</span><em>word</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/core.html#Predictor.consume"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Expand the current history by <code class="docutils literal"><span class="pre">word</span></code> and update the
internal predictor state accordingly. Two calls of <code class="docutils literal"><span class="pre">consume()</span></code>
must be separated by a <code class="docutils literal"><span class="pre">predict_next()</span></code> call.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>word</strong> (<em>int</em>) &#8211; Word to add to the current history</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">estimate_future_cost</code><span class="sig-paren">(</span><em>hypo</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/core.html#Predictor.estimate_future_cost"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Predictors can implement their own look-ahead cost functions.
They are used in A* if the &#8211;heuristics parameter is set to
predictor. This function should return the future log <em>cost</em>
(i.e. the lower the better) given the current predictor state,
assuming that the last word in the partial hypothesis &#8216;hypo&#8217; is
consumed next. This function must not change the internal
predictor state.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>hypo</strong> (<a class="reference internal" href="cam.sgnmt.decoding.html#cam.sgnmt.decoding.core.PartialHypothesis" title="cam.sgnmt.decoding.core.PartialHypothesis"><em>PartialHypothesis</em></a>) &#8211; Hypothesis for which to estimate
the future cost given the current
predictor state</td>
</tr>
</tbody>
</table>
<dl class="docutils">
<dt>Returns</dt>
<dd>float. Future cost</dd>
</dl>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">finalize_posterior</code><span class="sig-paren">(</span><em>scores</em>, <em>use_weights</em>, <em>normalize_scores</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/core.html#Predictor.finalize_posterior"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>This method can be used to enforce the parameters use_weights
normalize_scores in predictors with dict posteriors.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>scores</strong> (<em>dict</em>) &#8211; unnormalized log valued scores</li>
<li><strong>use_weights</strong> (<em>bool</em>) &#8211; Set to false to replace all values in
<code class="docutils literal"><span class="pre">scores</span></code> with 0 (= log 1)</li>
<li><strong>normalize_scores</strong> &#8211; Set to true to make the exp of elements
in <code class="docutils literal"><span class="pre">scores</span></code> sum up to 1</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">get_state</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/core.html#Predictor.get_state"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Get the current predictor state. The state can be any object
or tuple of objects which makes it possible to return to the
predictor state with the current history.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body">object. Predictor state</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">get_unk_probability</code><span class="sig-paren">(</span><em>posterior</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/core.html#Predictor.get_unk_probability"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>This function defines the probability of all words which are
not in <code class="docutils literal"><span class="pre">posterior</span></code>. This is usually used to combine open and
closed vocabulary predictors. The argument <code class="docutils literal"><span class="pre">posterior</span></code> should
have been produced with <code class="docutils literal"><span class="pre">predict_next()</span></code></p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>posterior</strong> (<em>list,array,dict</em>) &#8211; Return value of the last call
of <code class="docutils literal"><span class="pre">predict_next</span></code></td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body">Score to use for words outside <code class="docutils literal"><span class="pre">posterior</span></code></td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body">float</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">initialize</code><span class="sig-paren">(</span><em>src_sentence</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/core.html#Predictor.initialize"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Initialize the predictor with the given source sentence.
This resets the internal predictor state and loads everything
which is constant throughout the processing of a single source
sentence. For example, the NMT decoder runs the encoder network
and stores the source annotations.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>src_sentence</strong> (<em>list</em>) &#8211; List of word IDs which form the source
sentence without &lt;S&gt; or &lt;/S&gt;</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">initialize_heuristic</code><span class="sig-paren">(</span><em>src_sentence</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/core.html#Predictor.initialize_heuristic"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>This is called after <code class="docutils literal"><span class="pre">initialize()</span></code> if the predictor is
registered as heuristic predictor (i.e.
<code class="docutils literal"><span class="pre">estimate_future_cost()</span></code> will be called in the future).
Predictors can implement this function for initialization of
their own heuristic mechanisms.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>src_sentence</strong> (<em>list</em>) &#8211; List of word IDs which form the source
sentence without &lt;S&gt; or &lt;/S&gt;</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">is_equal</code><span class="sig-paren">(</span><em>state1</em>, <em>state2</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/core.html#Predictor.is_equal"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Returns true if two predictor states are equal, i.e. both
states will always result in the same scores. This is used for
hypothesis recombination</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>state1</strong> (<em>object</em>) &#8211; First predictor state</li>
<li><strong>state2</strong> (<em>object</em>) &#8211; Second predictor state</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first last">bool. True if both states are equal, false if not</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">notify</code><span class="sig-paren">(</span><em>message</em>, <em>message_type=1</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/core.html#Predictor.notify"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>We implement the <code class="docutils literal"><span class="pre">notify</span></code> method from the <code class="docutils literal"><span class="pre">Observer</span></code>
super class with an empty method here s.t. predictors do not
need to implement it.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>message</strong> (<em>object</em>) &#8211; The posterior sent by the decoder</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">predict_next</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/core.html#Predictor.predict_next"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Returns the predictive distribution over the target
vocabulary for the next word given the predictor state. Note
that the prediction itself can change the state of the
predictor. For example, the neural predictor updates the
decoder network state and its attention to predict the next
word. Two calls of <code class="docutils literal"><span class="pre">predict_next()</span></code> must be separated by a
<code class="docutils literal"><span class="pre">consume()</span></code> call.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body">dictionary,array,list. Word log probabilities for the next
target token. All ids which are not set are assumed to have
probability <code class="docutils literal"><span class="pre">get_unk_probability()</span></code></td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">set_current_sen_id</code><span class="sig-paren">(</span><em>cur_sen_id</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/core.html#Predictor.set_current_sen_id"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>This function is called between <code class="docutils literal"><span class="pre">initialize()</span></code> calls to
increment the sentence id counter. It can also be used to skip
sentences for the &#8211;range argument.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>cur_sen_id</strong> (<em>int</em>) &#8211; Sentence id for the next call of
<code class="docutils literal"><span class="pre">initialize()</span></code></td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">set_state</code><span class="sig-paren">(</span><em>state</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/core.html#Predictor.set_state"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Loads a predictor state from an object created with
<code class="docutils literal"><span class="pre">get_state()</span></code>. Note that this does not copy the argument but
just references the given state. If <code class="docutils literal"><span class="pre">state</span></code> is going to be
used in the future to return to that point again, you should
copy the state with <code class="docutils literal"><span class="pre">copy.deepcopy()</span></code> before.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>state</strong> (<em>object</em>) &#8211; Predictor state as returned by
<code class="docutils literal"><span class="pre">get_state()</span></code></td>
</tr>
</tbody>
</table>
</dd></dl>

</dd></dl>

<dl class="class">
<dt>
<em class="property">class </em><code class="descclassname">cam.sgnmt.predictors.core.</code><code class="descname">UnboundedVocabularyPredictor</code><a class="reference internal" href="_modules/cam/sgnmt/predictors/core.html#UnboundedVocabularyPredictor"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Bases: <a class="reference internal" href="cam.sgnmt.predictors.html#cam.sgnmt.predictors.core.Predictor" title="cam.sgnmt.predictors.core.Predictor"><code class="xref py py-class docutils literal"><span class="pre">cam.sgnmt.predictors.core.Predictor</span></code></a></p>
<p>Predictors under this class implement models with very large
target vocabularies, for which it is too inefficient to list the
entire posterior. Instead, they are evaluated only for a given list
of target words. This list is usually created by taking all non-zero
probability words from the bounded vocabulary predictors. An
example of a unbounded vocabulary predictor is the ngram predictor:
Instead of listing the entire ngram vocabulary, we run srilm only
on the words which are possible according other predictor (e.g. fst
or nmt). This is realized by introducing the <code class="docutils literal"><span class="pre">trgt_words</span></code>
argument to <code class="docutils literal"><span class="pre">predict_next</span></code>.</p>
<p>Initializes <code class="docutils literal"><span class="pre">current_sen_id</span></code> with 0.</p>
<dl class="method">
<dt>
<code class="descname">predict_next</code><span class="sig-paren">(</span><em>trgt_words</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/core.html#UnboundedVocabularyPredictor.predict_next"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Like in <code class="docutils literal"><span class="pre">Predictor</span></code>, returns the predictive distribution
over target words given the predictor state. Note
that the prediction itself can change the state of the
predictor. For example, the neural predictor updates the
decoder network state and its attention to predict the next
word. Two calls of <code class="docutils literal"><span class="pre">predict_next()</span></code> must be separated by a
<code class="docutils literal"><span class="pre">consume()</span></code> call.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>trgt_words</strong> (<em>list</em>) &#8211; List of target word ids.</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body">dictionary,array,list. Word log probabilities for the next
target token. All ids which are not set are assumed to have
probability <code class="docutils literal"><span class="pre">get_unk_probability()</span></code>. The returned set should
not contain any ids which are not in <code class="docutils literal"><span class="pre">trgt_words</span></code>, but it
does not have to score all of them</td>
</tr>
</tbody>
</table>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="cam-sgnmt-predictors-ffnnlm-module">
<h3>cam.sgnmt.predictors.ffnnlm module<a class="headerlink" href="#cam-sgnmt-predictors-ffnnlm-module" title="Permalink to this headline">¶</a></h3>
</div>
<div class="section" id="cam-sgnmt-predictors-forced-module">
<h3>cam.sgnmt.predictors.forced module<a class="headerlink" href="#cam-sgnmt-predictors-forced-module" title="Permalink to this headline">¶</a></h3>
<p>This module contains predictors for forced decoding. This can be
done either with one reference (forced <code class="docutils literal"><span class="pre">ForcedPredictor</span></code>), or with
multiple references in form of a n-best list (forcedlst
<code class="docutils literal"><span class="pre">ForcedLstPredictor</span></code>).</p>
<dl class="class">
<dt>
<em class="property">class </em><code class="descclassname">cam.sgnmt.predictors.forced.</code><code class="descname">ForcedLstPredictor</code><span class="sig-paren">(</span><em>trg_test_file</em>, <em>use_scores=True</em>, <em>match_unk=False</em>, <em>feat_name=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/forced.html#ForcedLstPredictor"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Bases: <a class="reference internal" href="cam.sgnmt.predictors.html#cam.sgnmt.predictors.core.Predictor" title="cam.sgnmt.predictors.core.Predictor"><code class="xref py py-class docutils literal"><span class="pre">cam.sgnmt.predictors.core.Predictor</span></code></a></p>
<p>This predictor can be used for direct n-best list rescoring. In
contrast to the <code class="docutils literal"><span class="pre">ForcedPredictor</span></code>, it reads an n-best list in
Moses format and uses its scores as predictive probabilities of the
&lt;/S&gt; symbol. Everywhere else it gives the predictive probability 1
if the history corresponds to at least one n-best list entry, 0
otherwise. From the n-best list we use
First column: Sentence id
Second column: Hypothesis in integer format
Last column: score</p>
<p>Note: Behavior is undefined if you have duplicates in the n-best
list</p>
<p>TODO: Would be much more efficient to use Tries for
cur_trgt_sentences instead of a flat list.</p>
<p>Creates a new n-best rescoring predictor instance.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>trg_test_file</strong> (<em>string</em>) &#8211; Path to the n-best list</li>
<li><strong>use_scores</strong> (<em>bool</em>) &#8211; Whether to use the scores from the
n-best list. If false, use uniform
scores of 0 (=log 1).</li>
<li><strong>match_unk</strong> (<em>bool</em>) &#8211; If true, allow any word where the n-best
list contains UNK.</li>
<li><strong>feat_name</strong> (<em>string</em>) &#8211; Instead of the combined score in the
last column of the Moses n-best list,
we can use one of the sparse features.
Set this to the name of the feature
(denoted as &lt;name&gt;= in the n-best list)
if you wish to do that.</li>
</ul>
</td>
</tr>
</tbody>
</table>
<dl class="method">
<dt>
<code class="descname">consume</code><span class="sig-paren">(</span><em>word</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/forced.html#ForcedLstPredictor.consume"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Extends the current history by <code class="docutils literal"><span class="pre">word</span></code>.</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">get_state</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/forced.html#ForcedLstPredictor.get_state"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Returns the current history.</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">get_unk_probability</code><span class="sig-paren">(</span><em>posterior</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/forced.html#ForcedLstPredictor.get_unk_probability"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Return negative infinity unconditionally - words outside the
n-best list are not possible according to this predictor.</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">initialize</code><span class="sig-paren">(</span><em>src_sentence</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/forced.html#ForcedLstPredictor.initialize"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Resets the history and loads the n-best list entries for the
next source sentence</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>src_sentence</strong> (<em>list</em>) &#8211; Not used</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">is_equal</code><span class="sig-paren">(</span><em>state1</em>, <em>state2</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/forced.html#ForcedLstPredictor.is_equal"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Returns true if the history is the same</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">predict_next</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/forced.html#ForcedLstPredictor.predict_next"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Outputs 0.0 (i.e. prob=1) for all words for which there is
an entry <code class="docutils literal"><span class="pre">in</span> <span class="pre">cur_trg_sentences</span></code>, and the score in
<code class="docutils literal"><span class="pre">cur_trg_sentences</span></code> if the current history is by itself equal
to an entry in <code class="docutils literal"><span class="pre">cur_trg_sentences</span></code>.</p>
<p>TODO: The implementation here is fairly inefficient as it scans
through all target sentences linearly. Would be better to
organize the target sentences in a Trie</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">set_state</code><span class="sig-paren">(</span><em>state</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/forced.html#ForcedLstPredictor.set_state"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Sets the current history.</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt>
<em class="property">class </em><code class="descclassname">cam.sgnmt.predictors.forced.</code><code class="descname">ForcedPredictor</code><span class="sig-paren">(</span><em>trg_test_file</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/forced.html#ForcedPredictor"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Bases: <a class="reference internal" href="cam.sgnmt.predictors.html#cam.sgnmt.predictors.core.Predictor" title="cam.sgnmt.predictors.core.Predictor"><code class="xref py py-class docutils literal"><span class="pre">cam.sgnmt.predictors.core.Predictor</span></code></a></p>
<p>This predictor realizes forced decoding. It stores one target
sentence for each source sentence and outputs predictive probability
1 along this path, and 0 otherwise.</p>
<p>Creates a new forced decoding predictor.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>trg_test_file</strong> (<em>string</em>) &#8211; Path to the plain text file with
the target sentences. Must have the
same number of lines as the number
of source sentences to decode</td>
</tr>
</tbody>
</table>
<dl class="method">
<dt>
<code class="descname">consume</code><span class="sig-paren">(</span><em>word</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/forced.html#ForcedPredictor.consume"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>If <code class="docutils literal"><span class="pre">word</span></code> matches the target sentence, we increase the
current history by one. Otherwise, we set this predictor in
an invalid state, in which it always predicts &lt;/S&gt;</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>word</strong> (<em>int</em>) &#8211; Next word to consume</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">get_state</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/forced.html#ForcedPredictor.get_state"><span class="viewcode-link">[source]</span></a></dt>
<dd><p><code class="docutils literal"><span class="pre">cur_trg_sentence</span></code> can be changed so its part of the
predictor state</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">get_unk_probability</code><span class="sig-paren">(</span><em>posterior</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/forced.html#ForcedPredictor.get_unk_probability"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Returns negative infinity unconditionally: Words which are
not in the target sentence have assigned probability 0 by
this predictor.</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">initialize</code><span class="sig-paren">(</span><em>src_sentence</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/forced.html#ForcedPredictor.initialize"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Fetches the corresponding target sentence and resets the
current history.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>src_sentence</strong> (<em>list</em>) &#8211; Not used</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">is_equal</code><span class="sig-paren">(</span><em>state1</em>, <em>state2</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/forced.html#ForcedPredictor.is_equal"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Returns true if the state is the same</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">predict_next</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/forced.html#ForcedPredictor.predict_next"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Returns a dictionary with one entry and value 0 (=log 1). The
key is either the next word in the target sentence or (if the
target sentence has no more words) the end-of-sentence symbol.</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">set_state</code><span class="sig-paren">(</span><em>state</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/forced.html#ForcedPredictor.set_state"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Set the predictor state.</p>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="cam-sgnmt-predictors-grammar-module">
<h3>cam.sgnmt.predictors.grammar module<a class="headerlink" href="#cam-sgnmt-predictors-grammar-module" title="Permalink to this headline">¶</a></h3>
<p>This module contains everything related to the hiero predictor. This
predictor allows applying rules from a syntactical SMT system directly
in SGNMT. The main interface is <code class="docutils literal"><span class="pre">RuleXtractPredictor</span></code> which can be
used like other predictors during decoding.
The Hiero predictor follows are the LRHiero implementation from</p>
<p><a class="reference external" href="https://github.com/sfu-natlang/lrhiero">https://github.com/sfu-natlang/lrhiero</a></p>
<blockquote>
<div>Efficient Left-to-Right Hierarchical Phrase-based Translation with
Improved Reordering.
Maryam Siahbani, Baskaran Sankaran and Anoop Sarkar.
EMNLP 2013. Oct 18-21, 2013. Seattle, USA.</div></blockquote>
<p>However, note that we modified the code to
a) deal with an arbitrary number of non-terminals
b) work with ruleXtract
c) allow spurious ambiguity</p>
<p>ATTENTION: This implementation is experimental!!</p>
<dl class="class">
<dt>
<em class="property">class </em><code class="descclassname">cam.sgnmt.predictors.grammar.</code><code class="descname">Cell</code><span class="sig-paren">(</span><em>init_hypo=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/grammar.html#Cell"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Comparable to a CYK cell: A set of hypotheses. If duplicates are
added, we do hypo combination by combining the costs and retraining
only one of them. Internally, the hypotheses are stored in a list
sorted by the sum of the translation prefix</p>
<p>Creates a new <code class="docutils literal"><span class="pre">Cell</span></code> with only one hypothesis.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>init_hypo</strong> (<a class="reference internal" href="cam.sgnmt.predictors.html#cam.sgnmt.predictors.grammar.LRHieroHypothesis" title="cam.sgnmt.predictors.grammar.LRHieroHypothesis"><em>LRHieroHypothesis</em></a>) &#8211; Initial hypothesis</td>
</tr>
</tbody>
</table>
<dl class="method">
<dt>
<code class="descname">add</code><span class="sig-paren">(</span><em>hypo</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/grammar.html#Cell.add"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Add a new hypothesis to the cell. If an equivalent
hypothesis already exists, combine both hypotheses.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>hypo</strong> (<a class="reference internal" href="cam.sgnmt.predictors.html#cam.sgnmt.predictors.grammar.LRHieroHypothesis" title="cam.sgnmt.predictors.grammar.LRHieroHypothesis"><em>LRHieroHypothesis</em></a>) &#8211; Hypothesis to add under the key
<code class="docutils literal"><span class="pre">hypo.key</span></code></td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">filter</code><span class="sig-paren">(</span><em>pos</em>, <em>symb</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/grammar.html#Cell.filter"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Remove all hypotheses which do not have <code class="docutils literal"><span class="pre">symb</span></code> at <code class="docutils literal"><span class="pre">pos</span></code>
in their <code class="docutils literal"><span class="pre">trgt_prefix</span></code>. Breaks if <code class="docutils literal"><span class="pre">pos</span></code> is out of range for
some <code class="docutils literal"><span class="pre">trgt_prefix</span></code></p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">findIdx</code><span class="sig-paren">(</span><em>key</em>, <em>a</em>, <em>b</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/grammar.html#Cell.findIdx"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Find index of first element with given key. If there is no
such key, return last element with largest key smaller than key
This is a recursive function which only searches in the
interval [a,b]</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">pop</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/grammar.html#Cell.pop"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Removes a hypothesis from the cell.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body">LRHieroHypothesis. The removed hypothesis</td>
</tr>
</tbody>
</table>
</dd></dl>

</dd></dl>

<dl class="class">
<dt>
<em class="property">class </em><code class="descclassname">cam.sgnmt.predictors.grammar.</code><code class="descname">LRHieroHypothesis</code><span class="sig-paren">(</span><em>trgt_prefix</em>, <em>spans</em>, <em>cost</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/grammar.html#LRHieroHypothesis"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Represents a LRHiero hypothesis, which is defined by the
accumulated cost, the target prefix, and open source spans.</p>
<p>Creates a new LRHiero hypothesis</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>trgt_prefix</strong> (<em>list</em>) &#8211; Target side translation prefix, i.e.
the partial target sentence which is
translated so far</li>
<li><strong>spans</strong> (<em>list</em>) &#8211; List of spans which are not covered yet, in
left-to-right order on target side</li>
<li><strong>cost</strong> (<em>float</em>) &#8211; Cost of this partial hypothesis</li>
</ul>
</td>
</tr>
</tbody>
</table>
<dl class="method">
<dt>
<code class="descname">is_final</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/grammar.html#LRHieroHypothesis.is_final"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Returns true if this hypothesis has no open spans</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt>
<em class="property">class </em><code class="descclassname">cam.sgnmt.predictors.grammar.</code><code class="descname">Node</code><a class="reference internal" href="_modules/cam/sgnmt/predictors/grammar.html#Node"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Represents a node in the Trie.</p>
</dd></dl>

<dl class="class">
<dt>
<em class="property">class </em><code class="descclassname">cam.sgnmt.predictors.grammar.</code><code class="descname">Rule</code><span class="sig-paren">(</span><em>rhs_src</em>, <em>rhs_trgt</em>, <em>trgt_src_map</em>, <em>cost</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/grammar.html#Rule"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>A rule consists of <code class="docutils literal"><span class="pre">rhs_src</span></code> and <code class="docutils literal"><span class="pre">rhs_trgt</span></code>, both are
sequences of integers. NTs are indicated with negative sign. The
<code class="docutils literal"><span class="pre">trgt_src_map</span></code> defines which NT on the target side belongs to
which NT on the source side.</p>
<p>Creates a new rule.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>rhs_src</strong> (<em>list</em>) &#8211; Source on the right hand side of the rule</li>
<li><strong>rhs_trgt</strong> (<em>list</em>) &#8211; Target on the right hand side of the rule</li>
<li><strong>trgt_src_map</strong> (<em>dict</em>) &#8211; Defines which NT on the target side
belongs to which NT on the source side</li>
</ul>
</td>
</tr>
</tbody>
</table>
<dl class="attribute">
<dt>
<code class="descname">last_id</code><em class="property"> = 0</em></dt>
<dd></dd></dl>

</dd></dl>

<dl class="class">
<dt>
<em class="property">class </em><code class="descclassname">cam.sgnmt.predictors.grammar.</code><code class="descname">RuleSet</code><a class="reference internal" href="_modules/cam/sgnmt/predictors/grammar.html#RuleSet"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>This class stores the set of rules and provides efficient retrieval and
matching functionality</p>
<p>Initializes the set by setting up the trie data structure
for storing the rules.</p>
<dl class="attribute">
<dt>
<code class="descname">INF</code><em class="property"> = 10000</em></dt>
<dd></dd></dl>

<dl class="method">
<dt>
<code class="descname">create_rule</code><span class="sig-paren">(</span><em>rhs_src</em>, <em>rhs_trgt</em>, <em>weight</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/grammar.html#RuleSet.create_rule"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Creates a rule object (factory method)</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>rhs_src</strong> (<em>list</em>) &#8211; String sequence describing the source of
the right-hand-side of the rule</li>
<li><strong>rhs_trgt</strong> (<em>list</em>) &#8211; String sequence describing the target of
the right-hand-side of the rule</li>
<li><strong>weight</strong> (<em>float</em>) &#8211; Rule weight</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first last"><code class="docutils literal"><span class="pre">Rule</span></code> or <code class="docutils literal"><span class="pre">None</span></code> if something went wrong</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">expand_hypo</code><span class="sig-paren">(</span><em>hypo</em>, <em>src_seq</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/grammar.html#RuleSet.expand_hypo"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Similar to <code class="docutils literal"><span class="pre">getSpanRules()</span></code> and <code class="docutils literal"><span class="pre">GrowHypothesis()</span></code> in
Alg. 1 in (Siahbani, 2013) combined. Gets all rules which match
the given span.</p>
<ul class="simple">
<li>If the p parameter of the span is a single non-terminal, we
return hypotheses resulting from productions of this non-
terminal. Note that rules might be applicable in many different
ways: X-&gt; A the B can be applied to foo the bar the baz in two
ways. In this case, we add the translation prefix, but leave the
borders of the span untouched, and change the <code class="docutils literal"><span class="pre">p</span></code> value to
<code class="docutils literal"><span class="pre">thr</span> <span class="pre">rhs</span></code> of the production (i.e. &#8220;A the B&#8221;). If p consists
of multiple characters, the spans store the minimum and maximum
<em>length</em>, not the begin and end since the exact begin and end
positions are variable.</li>
<li>If the p parameter of the span has length &gt; 1, we return a
set of hypotheses in which the first subspan has a single NT
as p parameter.</li>
</ul>
<p>Through this contract we can e.g. handle spurious ambiguity, if
two NT are on the source side. However, resolving this
ambiguity is implemented in a lazy fashion: we delay fixing the
span boundaries until we need to expand the hypothesis once
more, and then we fix only the first boundaries for the first
span.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>hypo</strong> (<a class="reference internal" href="cam.sgnmt.predictors.html#cam.sgnmt.predictors.grammar.LRHieroHypothesis" title="cam.sgnmt.predictors.grammar.LRHieroHypothesis"><em>LRHieroHypothesis</em></a>) &#8211; Hypothesis to expand</li>
<li><strong>src_seq</strong> (<em>list</em>) &#8211; Source sequence to match</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">parse</code><span class="sig-paren">(</span><em>line</em>, <em>feature_weights=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/grammar.html#RuleSet.parse"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Parse a line in a rule file from ruleXtract and add the rule
to the set.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>line</strong> (<em>string</em>) &#8211; </li>
<li><strong>feature_weights</strong> (<em>list</em>) &#8211; score or <code class="docutils literal"><span class="pre">None</span></code> to use uniform
weights</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">update_span_len_range</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/grammar.html#RuleSet.update_span_len_range"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>This method updates the <code class="docutils literal"><span class="pre">span_len_range</span></code> variable by
finding boundaries for the spans each non terminal can cover.
This is done iteratively: First, guess the range for each NT to
(0, inf). Then, iterate through all rules for a specific NT and
adjust the boundaries given the ranges for all other NTs. Do
this until ranges do not change anymore. This is an expensive
operation should be done after adding all rules. Note also that
the tries store a reference to <code class="docutils literal"><span class="pre">self.span_len_range</span></code>, i.e.
the variable is propagated to all tries automatically.</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt>
<em class="property">class </em><code class="descclassname">cam.sgnmt.predictors.grammar.</code><code class="descname">RuleXtractPredictor</code><span class="sig-paren">(</span><em>ruleXtract_path</em>, <em>use_weights</em>, <em>feature_weights=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/grammar.html#RuleXtractPredictor"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Bases: <a class="reference internal" href="cam.sgnmt.predictors.html#cam.sgnmt.predictors.core.Predictor" title="cam.sgnmt.predictors.core.Predictor"><code class="xref py py-class docutils literal"><span class="pre">cam.sgnmt.predictors.core.Predictor</span></code></a></p>
<p>Predictor based on ruleXtract rules. Bins are organized
according the number of target words. We assume that no rule
produces the empty word on the source side (but possibly on the
target side). Hypotheses are produced iteratively s.t. the
following invariant holds: The bins contain a set of (partial)
hypotheses from which we can derive all full hypotheses which are
consistent with the current target prefix (i.e. the prefix of the
target sentence which has already been translated). This set is
updated when calling either consume_word or predict_next: consume_
word deletes all hypotheses which become inconsistent with the new
word. <code class="docutils literal"><span class="pre">predict_next</span></code> requires all hypotheses to have a target_
prefix length of at least one plus the number of consumed words.
Therefore, <code class="docutils literal"><span class="pre">predict_next</span></code> expands hypotheses as long as they are
shorter. This fits nicely with grouping hypotheses in bins of same
target prefix length: we expand until all low rank bins are empty.
We predict the next target word by using the cost of the best
hypothesis with the word at the right position.</p>
<p>Note that this predictor is similar to the decoding algorithm in</p>
<blockquote>
<div>Efficient Left-to-Right Hierarchical Phrase-based Translation with
Improved Reordering.
Maryam Siahbani, Baskaran Sankaran and Anoop Sarkar.
EMNLP 2013. Oct 18-21, 2013. Seattle, USA.</div></blockquote>
<p>without cube pruning, but it is extended to an arbitrary number of
non-terminals as produced with ruleXtract.</p>
<p>Creates a new hiero predictor.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>ruleXtract_path</strong> (<em>string</em>) &#8211; Path to the rules file</li>
<li><strong>use_weights</strong> (<em>bool</em>) &#8211; If false, set all hypothesis scores
uniformly to 0 (= log 1). If true,
use the rule weights to compute
hypothesis scores</li>
<li><strong>feature_weights</strong> (<em>list</em>) &#8211; Rule feature weights to compute
the rule scores. If this is none
we use uniform weights</li>
</ul>
</td>
</tr>
</tbody>
</table>
<dl class="method">
<dt>
<code class="descname">build_posterior</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/grammar.html#RuleXtractPredictor.build_posterior"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>We need to scan all hypotheses in <code class="docutils literal"><span class="pre">self.stacks</span></code> and add up
scores grouped by the symbol at the n_consumed+1-th position.
Then, we add end-of-sentence probability by checking
<code class="docutils literal"><span class="pre">self.finals[n_consumed]</span></code></p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">consume</code><span class="sig-paren">(</span><em>word</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/grammar.html#RuleXtractPredictor.consume"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Remove all hypotheses with translation prefixes which do not
match <code class="docutils literal"><span class="pre">word</span></code></p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">get_state</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/grammar.html#RuleXtractPredictor.get_state"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Predictor state consists of the stacks, the completed
hypotheses, and the number of consumed words.</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">get_unk_probability</code><span class="sig-paren">(</span><em>posterior</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/grammar.html#RuleXtractPredictor.get_unk_probability"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Returns negative infinity if the posterior is not empty as
words outside the grammar are not possible according this
predictor. If <code class="docutils literal"><span class="pre">posterior</span></code> is empty, return 0 (= log 1)</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">initialize</code><span class="sig-paren">(</span><em>src_sentence</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/grammar.html#RuleXtractPredictor.initialize"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Delete all bins and add the initial cell to the first bin</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">predict_next</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/grammar.html#RuleXtractPredictor.predict_next"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>For predicting the distribution of the next target tokens,
we need to empty the stack with the current history length
by expanding all hypotheses on it. Then, all hypotheses are
in larger bins, i.e. have a longer target prefix than the
current history. Thus, we can look up the possible next words
by iterating through all active hypotheses.</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">set_state</code><span class="sig-paren">(</span><em>state</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/grammar.html#RuleXtractPredictor.set_state"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Set the predictor state.</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt>
<em class="property">class </em><code class="descclassname">cam.sgnmt.predictors.grammar.</code><code class="descname">Span</code><span class="sig-paren">(</span><em>p</em>, <em>borders</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/grammar.html#Span"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Span is defined by the start and end position and the
corresponding sequence of terminal and non-terminal symbols p.
Normally, p is just a single NT symbol. However, if there is
ambiguity with how to apply a rule to a span (e.g.
rule X -&gt; X the X to span foo the bar the baz) we allow to resolve
them later on demand. In this case, p = X the X</p>
<p>Fully initializes a new <code class="docutils literal"><span class="pre">Span</span></code> instance.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>p</strong> (<em>list</em>) &#8211; See class docstring for <code class="docutils literal"><span class="pre">Span</span></code></li>
<li><strong>borders</strong> (<em>tuple</em>) &#8211; (begin, end) with begin inclusive and end
exclusive</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="class">
<dt>
<em class="property">class </em><code class="descclassname">cam.sgnmt.predictors.grammar.</code><code class="descname">Trie</code><span class="sig-paren">(</span><em>span_len_range</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/grammar.html#Trie"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>This trie implementation allows matching NT symbols with arbitrary
symbol sequences with certain lengths when searching.
Note: This trie does not implement edge collapsing - each edge is
labeled with exactly one word</p>
<p>Creates an empty trie data structure.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>span_len_range</strong> (<em>tuple</em>) &#8211; minimum and maximum span lengths
for non-terminal symbols</td>
</tr>
</tbody>
</table>
<dl class="method">
<dt>
<code class="descname">add</code><span class="sig-paren">(</span><em>seq</em>, <em>element</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/grammar.html#Trie.add"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Add an element to the trie data structure. The key sequence
<code class="docutils literal"><span class="pre">seq</span></code> can contain non-terminals with negative IDs. If a
element with the same key already exists in the data structure,
we do not delete it but store both items.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>seq</strong> (<em>list</em>) &#8211; Sequence of terminals and non-terminals used as
key in the trie</li>
<li><strong>element</strong> (<em>object</em>) &#8211; Object to associate with <code class="docutils literal"><span class="pre">seq</span></code></li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">get_all_elements</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/grammar.html#Trie.get_all_elements"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Retrieve all elements stored in the trie</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">get_elements</code><span class="sig-paren">(</span><em>src_seq</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/grammar.html#Trie.get_elements"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Get all elements (e.g. rules) which match the given sequence
of source tokens.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>seq</strong> (<em>list</em>) &#8211; Sequence of terminals and non-terminals used as
key in the trie</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><code class="docutils literal"><span class="pre">(rules,</span> <span class="pre">nt_span_lens)</span></code>. The first dictionary
contains all applying rules. <code class="docutils literal"><span class="pre">nt_span_lens</span></code> lists the
number of symbols each of the NTs on the source side
covers. Make sure that <code class="docutils literal"><span class="pre">self.span_len_range</span></code> is updated</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body">two dicts</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">replace</code><span class="sig-paren">(</span><em>seq</em>, <em>element</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/grammar.html#Trie.replace"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Replaces all elements stored at a <code class="docutils literal"><span class="pre">seq</span></code> with a new single
element <code class="docutils literal"><span class="pre">element</span></code>. This is equivalent to first removing all
items with key <code class="docutils literal"><span class="pre">seq</span></code>, and then add the new element with
<code class="docutils literal"><span class="pre">add(seq,</span> <span class="pre">element)</span></code></p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>seq</strong> (<em>list</em>) &#8211; Sequence of terminals and non-terminals used as
key in the trie</li>
<li><strong>element</strong> (<em>object</em>) &#8211; Object to associate with <code class="docutils literal"><span class="pre">seq</span></code></li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="cam-sgnmt-predictors-length-module">
<h3>cam.sgnmt.predictors.length module<a class="headerlink" href="#cam-sgnmt-predictors-length-module" title="Permalink to this headline">¶</a></h3>
<p>This module contains predictors that deal wit the length of the
target sentence. The <code class="docutils literal"><span class="pre">NBLengthPredictor</span></code> assumes a negative binomial
distribution on the target sentence lengths, where the parameters r and
p are linear combinations of features extracted from the source
sentence. The <code class="docutils literal"><span class="pre">WordCountPredictor</span></code> adds the number of words as cost,
which can be used to prevent hypotheses from getting to short when
using a language model.</p>
<dl class="class">
<dt>
<em class="property">class </em><code class="descclassname">cam.sgnmt.predictors.length.</code><code class="descname">ExternalLengthPredictor</code><span class="sig-paren">(</span><em>path</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/length.html#ExternalLengthPredictor"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Bases: <a class="reference internal" href="cam.sgnmt.predictors.html#cam.sgnmt.predictors.core.Predictor" title="cam.sgnmt.predictors.core.Predictor"><code class="xref py py-class docutils literal"><span class="pre">cam.sgnmt.predictors.core.Predictor</span></code></a></p>
<p>This predictor loads the distribution over target sentence
lengths from an external file. The file contains blank separated
length:score pairs in each line which define the length
distribution. The predictor adds the specified scores directly
to the EOS score.</p>
<p>Creates a external length distribution predictor.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>path</strong> (<em>string</em>) &#8211; Path to the file with target sentence length
distributions.</td>
</tr>
</tbody>
</table>
<dl class="method">
<dt>
<code class="descname">consume</code><span class="sig-paren">(</span><em>word</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/length.html#ExternalLengthPredictor.consume"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Increases word counter by one.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>word</strong> (<em>int</em>) &#8211; Not used</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">get_state</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/length.html#ExternalLengthPredictor.get_state"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Returns the number of consumed words</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">get_unk_probability</code><span class="sig-paren">(</span><em>posterior</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/length.html#ExternalLengthPredictor.get_unk_probability"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Returns 0=log 1 if the partial hypothesis does not exceed
max length. Otherwise, predict next returns an empty set,
and we set everything else to -inf.</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">initialize</code><span class="sig-paren">(</span><em>src_sentence</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/length.html#ExternalLengthPredictor.initialize"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Fetches the corresponding target sentence length
distribution and resets the word counter.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>src_sentence</strong> (<em>list</em>) &#8211; Not used</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">is_equal</code><span class="sig-paren">(</span><em>state1</em>, <em>state2</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/length.html#ExternalLengthPredictor.is_equal"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Returns true if the number of consumed words is the same</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">predict_next</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/length.html#ExternalLengthPredictor.predict_next"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Returns a dictionary with one entry and value 0 (=log 1). The
key is either the next word in the target sentence or (if the
target sentence has no more words) the end-of-sentence symbol.</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">set_state</code><span class="sig-paren">(</span><em>state</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/length.html#ExternalLengthPredictor.set_state"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Set the number of consumed words</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt>
<em class="property">class </em><code class="descclassname">cam.sgnmt.predictors.length.</code><code class="descname">NBLengthPredictor</code><span class="sig-paren">(</span><em>text_file</em>, <em>model_weights</em>, <em>use_point_probs</em>, <em>offset=0</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/length.html#NBLengthPredictor"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Bases: <a class="reference internal" href="cam.sgnmt.predictors.html#cam.sgnmt.predictors.core.Predictor" title="cam.sgnmt.predictors.core.Predictor"><code class="xref py py-class docutils literal"><span class="pre">cam.sgnmt.predictors.core.Predictor</span></code></a></p>
<p>This predictor assumes that target sentence lengths are
distributed according a negative binomial distribution with
parameters r,p. r is linear in features, p is the logistic of a
linear function over the features. Weights can be trained using
the Matlab script <code class="docutils literal"><span class="pre">estimate_length_model.m</span></code></p>
<p>Let w be the model_weights. All features are extracted from the
src sentence:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="n">r</span> <span class="o">=</span> <span class="n">w0</span> <span class="o">*</span> <span class="c1">#char</span>
<span class="o">+</span> <span class="n">w1</span> <span class="o">*</span> <span class="c1">#words</span>
<span class="o">+</span> <span class="n">w2</span> <span class="o">*</span> <span class="c1">#punctuation</span>
<span class="o">+</span> <span class="n">w3</span> <span class="o">*</span> <span class="c1">#char/#words</span>
<span class="o">+</span> <span class="n">w4</span> <span class="o">*</span> <span class="c1">#punct/#words</span>
<span class="o">+</span> <span class="n">w10</span>

<span class="n">p</span> <span class="o">=</span> <span class="n">logistic</span><span class="p">(</span><span class="n">w5</span> <span class="o">*</span> <span class="c1">#char</span>
<span class="o">+</span> <span class="n">w6</span> <span class="o">*</span> <span class="c1">#words</span>
<span class="o">+</span> <span class="n">w7</span> <span class="o">*</span> <span class="c1">#punctuation</span>
<span class="o">+</span> <span class="n">w8</span> <span class="o">*</span> <span class="c1">#char/#words</span>
<span class="o">+</span> <span class="n">w9</span> <span class="o">*</span> <span class="c1">#punct/#words</span>
<span class="o">+</span> <span class="n">w11</span><span class="p">)</span>

<span class="n">target_length</span> <span class="o">~</span> <span class="n">NB</span><span class="p">(</span><span class="n">r</span><span class="p">,</span><span class="n">p</span><span class="p">)</span>
</pre></div>
</div>
<p>The biases w10 and w11 are optional.</p>
<p>The predictor predicts EOS with NB(#consumed_words,r,p)</p>
<p>Creates a new target sentence length model predictor.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>text_file</strong> (<em>string</em>) &#8211; Path to the text file with the
unindexed source sentences, i.e. not
using word ids</li>
<li><strong>model_weights</strong> (<em>list</em>) &#8211; Weights w0 to w11 of the length
model. See class docstring for more
information</li>
<li><strong>use_point_probs</strong> (<em>bool</em>) &#8211; Use point estimates for EOS token,
0.0 otherwise</li>
<li><strong>offset</strong> (<em>int</em>) &#8211; Subtract this from hypothesis length before
applying the NB model</li>
</ul>
</td>
</tr>
</tbody>
</table>
<dl class="method">
<dt>
<code class="descname">consume</code><span class="sig-paren">(</span><em>word</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/length.html#NBLengthPredictor.consume"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Increases the current history length</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>word</strong> (<em>int</em>) &#8211; Not used</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">get_state</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/length.html#NBLengthPredictor.get_state"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>State consists of the number of consumed words, and the
accumulator for previous EOS probability estimates if we
don&#8217;t use point estimates.</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">get_unk_probability</code><span class="sig-paren">(</span><em>posterior</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/length.html#NBLengthPredictor.get_unk_probability"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>If we use point estimates, return 0 (=1). Otherwise, return
the 1-p(EOS), with p(EOS) fetched from <code class="docutils literal"><span class="pre">posterior</span></code></p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">initialize</code><span class="sig-paren">(</span><em>src_sentence</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/length.html#NBLengthPredictor.initialize"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Extract features for the source sentence. Note that this
method does not use <code class="docutils literal"><span class="pre">src_sentence</span></code> as we need the string
representation of the source sentence to extract features.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>src_sentence</strong> (<em>list</em>) &#8211; Not used</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">is_equal</code><span class="sig-paren">(</span><em>state1</em>, <em>state2</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/length.html#NBLengthPredictor.is_equal"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Returns true if the number of consumed words is the same</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">predict_next</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/length.html#NBLengthPredictor.predict_next"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Returns a dictionary with single entry for EOS.</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">set_state</code><span class="sig-paren">(</span><em>state</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/length.html#NBLengthPredictor.set_state"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Set the predictor state</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt>
<em class="property">class </em><code class="descclassname">cam.sgnmt.predictors.length.</code><code class="descname">NgramCountPredictor</code><span class="sig-paren">(</span><em>path</em>, <em>order=0</em>, <em>discount_factor=-1.0</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/length.html#NgramCountPredictor"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Bases: <a class="reference internal" href="cam.sgnmt.predictors.html#cam.sgnmt.predictors.core.Predictor" title="cam.sgnmt.predictors.core.Predictor"><code class="xref py py-class docutils literal"><span class="pre">cam.sgnmt.predictors.core.Predictor</span></code></a></p>
<p>This predictor counts the number of n-grams in hypotheses. n-gram
posteriors are loaded from a file. The predictor score is the sum of
all n-gram posteriors in a hypothesis.</p>
<p>Creates a new ngram count predictor instance.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>path</strong> (<em>string</em>) &#8211; Path to the n-gram posteriors. File format:
&lt;ngram&gt; : &lt;score&gt; (one ngram per line). Use
placeholder %d for sentence id.</li>
<li><strong>order</strong> (<em>int</em>) &#8211; If positive, count n-grams of the specified
order. Otherwise, count all n-grams</li>
<li><strong>discount_factor</strong> (<em>float</em>) &#8211; If non-negative, discount n-gram
posteriors by this factor each time
they are consumed</li>
</ul>
</td>
</tr>
</tbody>
</table>
<dl class="method">
<dt>
<code class="descname">consume</code><span class="sig-paren">(</span><em>word</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/length.html#NgramCountPredictor.consume"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Adds <code class="docutils literal"><span class="pre">word</span></code> to the current history. Shorten if the extended
history exceeds <code class="docutils literal"><span class="pre">max_history_len</span></code>.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>word</strong> (<em>int</em>) &#8211; Word to add to the history.</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">get_state</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/length.html#NgramCountPredictor.get_state"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Current history is the predictor state</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">get_unk_probability</code><span class="sig-paren">(</span><em>posterior</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/length.html#NgramCountPredictor.get_unk_probability"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Always return 0.0</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">initialize</code><span class="sig-paren">(</span><em>src_sentence</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/length.html#NgramCountPredictor.initialize"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Loads n-gram posteriors and resets history.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>src_sentence</strong> (<em>list</em>) &#8211; not used</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">is_equal</code><span class="sig-paren">(</span><em>state1</em>, <em>state2</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/length.html#NgramCountPredictor.is_equal"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Hypothesis recombination is
not supported if discounting is enabled.</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">predict_next</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/length.html#NgramCountPredictor.predict_next"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Composes the posterior vector by collecting all ngrams which
are consistent with the current history.</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">set_state</code><span class="sig-paren">(</span><em>state</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/length.html#NgramCountPredictor.set_state"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Current history is the predictor state</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt>
<em class="property">class </em><code class="descclassname">cam.sgnmt.predictors.length.</code><code class="descname">NgramizePredictor</code><span class="sig-paren">(</span><em>min_order</em>, <em>max_order</em>, <em>max_len_factor</em>, <em>slave_predictor</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/length.html#NgramizePredictor"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Bases: <a class="reference internal" href="cam.sgnmt.predictors.html#cam.sgnmt.predictors.core.Predictor" title="cam.sgnmt.predictors.core.Predictor"><code class="xref py py-class docutils literal"><span class="pre">cam.sgnmt.predictors.core.Predictor</span></code></a></p>
<p>This wrapper extracts n-gram posteriors from a predictor which
does not depend on the particular argument of <cite>consume()</cite>. In that
case, we can build a lookup mechanism for all possible n-grams in
a single forward pass through the predictor search space: We record
all posteriors (predict_next() return values) of the slave
predictor during a greedy pass in <cite>initialize()</cite>. The wrapper
predictor state is the current n-gram history. We use the
(semiring) sum over all possible positions of the current n-gram
history in the recorded slave predictor posteriors to form the
n-gram scores returned by this predictor.</p>
<p>Note that this wrapper does not work correctly if the slave
predictor feeds back the selected token in the history, ie. depends
on the particular token which is provided via <cite>consume()</cite>.</p>
<p>TODO: Make this wrapper work with slaves which return dicts.</p>
<p>Creates a new ngramize wrapper predictor.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>min_order</strong> (<em>int</em>) &#8211; Minimum n-gram order</li>
<li><strong>max_order</strong> (<em>int</em>) &#8211; Maximum n-gram order</li>
<li><strong>max_len_factor</strong> (<em>int</em>) &#8211; Stop the forward pass through the
slave predictor after src_length
times this factor</li>
<li><strong>slave_predictor</strong> (<a class="reference internal" href="cam.sgnmt.predictors.html#cam.sgnmt.predictors.core.Predictor" title="cam.sgnmt.predictors.core.Predictor"><em>Predictor</em></a>) &#8211; Instance of the predictor which
uses the source sentences in
<code class="docutils literal"><span class="pre">src_test</span></code></li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Raises:</th><td class="field-body"><p class="first last">AttributeError if order is not positive.</p>
</td>
</tr>
</tbody>
</table>
<dl class="method">
<dt>
<code class="descname">consume</code><span class="sig-paren">(</span><em>word</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/length.html#NgramizePredictor.consume"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Pass through to slave predictor</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">get_state</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/length.html#NgramizePredictor.get_state"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>State is the current n-gram history.</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">get_unk_probability</code><span class="sig-paren">(</span><em>posterior</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/length.html#NgramizePredictor.get_unk_probability"><span class="viewcode-link">[source]</span></a></dt>
<dd></dd></dl>

<dl class="method">
<dt>
<code class="descname">initialize</code><span class="sig-paren">(</span><em>src_sentence</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/length.html#NgramizePredictor.initialize"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Runs greedy decoding on the slave predictor to populate
self.scores and self.unk_scores, resets the history.</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">initialize_heuristic</code><span class="sig-paren">(</span><em>src_sentence</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/length.html#NgramizePredictor.initialize_heuristic"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Pass through to slave predictor</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">is_equal</code><span class="sig-paren">(</span><em>state1</em>, <em>state2</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/length.html#NgramizePredictor.is_equal"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Pass through to slave predictor</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">predict_next</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/length.html#NgramizePredictor.predict_next"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Looks up ngram scores via self.scores.</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">set_current_sen_id</code><span class="sig-paren">(</span><em>cur_sen_id</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/length.html#NgramizePredictor.set_current_sen_id"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>We need to override this method to propagate current_
sentence_id to the slave predictor</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">set_state</code><span class="sig-paren">(</span><em>state</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/length.html#NgramizePredictor.set_state"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>State is the current n-gram history.</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt>
<em class="property">class </em><code class="descclassname">cam.sgnmt.predictors.length.</code><code class="descname">UnkCountPredictor</code><span class="sig-paren">(</span><em>src_vocab_size</em>, <em>lambdas</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/length.html#UnkCountPredictor"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Bases: <a class="reference internal" href="cam.sgnmt.predictors.html#cam.sgnmt.predictors.core.Predictor" title="cam.sgnmt.predictors.core.Predictor"><code class="xref py py-class docutils literal"><span class="pre">cam.sgnmt.predictors.core.Predictor</span></code></a></p>
<p>This predictor regulates the number of UNKs in the output. We
assume that the number of UNKs in the target sentence is Poisson
distributed. This predictor is configured with n lambdas for
0,1,...,&gt;=n-1 UNKs in the source sentence.</p>
<p>Initializes the UNK count predictor.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>src_vocab_size</strong> (<em>int</em>) &#8211; Size of source language vocabulary.
Indices greater than this are
considered as UNK.</li>
<li><strong>lambdas</strong> (<em>list</em>) &#8211; List of floats. The first entry is the
lambda parameter given that the number of
unks in the source sentence is 0 etc. The
last float is lambda given that the source
sentence has more than n-1 unks.</li>
</ul>
</td>
</tr>
</tbody>
</table>
<dl class="method">
<dt>
<code class="descname">consume</code><span class="sig-paren">(</span><em>word</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/length.html#UnkCountPredictor.consume"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Increases unk counter by one if <code class="docutils literal"><span class="pre">word</span></code> is unk.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>word</strong> (<em>int</em>) &#8211; Increase counter if <code class="docutils literal"><span class="pre">word</span></code> is UNK</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">get_state</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/length.html#UnkCountPredictor.get_state"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Returns the number of consumed words</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">get_unk_probability</code><span class="sig-paren">(</span><em>posterior</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/length.html#UnkCountPredictor.get_unk_probability"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Always returns 0 (= log 1) except for the first time</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">initialize</code><span class="sig-paren">(</span><em>src_sentence</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/length.html#UnkCountPredictor.initialize"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Count UNKs in <code class="docutils literal"><span class="pre">src_sentence</span></code> and reset counters.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>src_sentence</strong> (<em>list</em>) &#8211; Count UNKs in this list</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">is_equal</code><span class="sig-paren">(</span><em>state1</em>, <em>state2</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/length.html#UnkCountPredictor.is_equal"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Returns true if the state is the same</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">predict_next</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/length.html#UnkCountPredictor.predict_next"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Set score for EOS to the number of consumed words</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">set_state</code><span class="sig-paren">(</span><em>state</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/length.html#UnkCountPredictor.set_state"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Set the number of consumed words</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt>
<em class="property">class </em><code class="descclassname">cam.sgnmt.predictors.length.</code><code class="descname">WeightNonTerminalPredictor</code><span class="sig-paren">(</span><em>slave_predictor</em>, <em>penalty_factor=1.0</em>, <em>nonterminal_ids=None</em>, <em>min_terminal_id=0</em>, <em>max_terminal_id=30003</em>, <em>vocab_size=30003</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/length.html#WeightNonTerminalPredictor"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Bases: <a class="reference internal" href="cam.sgnmt.predictors.html#cam.sgnmt.predictors.core.Predictor" title="cam.sgnmt.predictors.core.Predictor"><code class="xref py py-class docutils literal"><span class="pre">cam.sgnmt.predictors.core.Predictor</span></code></a></p>
<p>This wrapper multiplies the weight of given tokens (those outside
the min/max terminal range) by a factor.</p>
<p>Creates a new id-weighting wrapper for a predictor</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>slave_predictor</strong> &#8211; predictor to apply penalty to.</li>
<li><strong>penalty_factor</strong> (<em>float</em>) &#8211; factor by which to multiply tokens in range</li>
<li><strong>min_terminal_id</strong> &#8211; lower bound of tokens <em>not</em> to penalize,</li>
</ul>
</td>
</tr>
</tbody>
</table>
<dl class="docutils">
<dt>if nonterminal_penalty selected</dt>
<dd>max_terminal_id: upper bound of tokens <em>not</em> to penalize,</dd>
<dt>if nonterminal_penalty selected</dt>
<dd>vocab_size: upper bound of tokens, used to find nonterminal range</dd>
</dl>
<dl class="method">
<dt>
<code class="descname">consume</code><span class="sig-paren">(</span><em>word</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/length.html#WeightNonTerminalPredictor.consume"><span class="viewcode-link">[source]</span></a></dt>
<dd></dd></dl>

<dl class="method">
<dt>
<code class="descname">get_state</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/length.html#WeightNonTerminalPredictor.get_state"><span class="viewcode-link">[source]</span></a></dt>
<dd></dd></dl>

<dl class="method">
<dt>
<code class="descname">get_unk_probability</code><span class="sig-paren">(</span><em>posterior</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/length.html#WeightNonTerminalPredictor.get_unk_probability"><span class="viewcode-link">[source]</span></a></dt>
<dd></dd></dl>

<dl class="method">
<dt>
<code class="descname">initialize</code><span class="sig-paren">(</span><em>src_sentence</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/length.html#WeightNonTerminalPredictor.initialize"><span class="viewcode-link">[source]</span></a></dt>
<dd></dd></dl>

<dl class="method">
<dt>
<code class="descname">is_equal</code><span class="sig-paren">(</span><em>state1</em>, <em>state2</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/length.html#WeightNonTerminalPredictor.is_equal"><span class="viewcode-link">[source]</span></a></dt>
<dd></dd></dl>

<dl class="method">
<dt>
<code class="descname">predict_next</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/length.html#WeightNonTerminalPredictor.predict_next"><span class="viewcode-link">[source]</span></a></dt>
<dd></dd></dl>

<dl class="method">
<dt>
<code class="descname">set_state</code><span class="sig-paren">(</span><em>state</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/length.html#WeightNonTerminalPredictor.set_state"><span class="viewcode-link">[source]</span></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="class">
<dt>
<em class="property">class </em><code class="descclassname">cam.sgnmt.predictors.length.</code><code class="descname">WordCountPredictor</code><span class="sig-paren">(</span><em>word=-1</em>, <em>nonterminal_penalty=False</em>, <em>nonterminal_ids=None</em>, <em>min_terminal_id=0</em>, <em>max_terminal_id=30003</em>, <em>negative_wc=True</em>, <em>vocab_size=30003</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/length.html#WordCountPredictor"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Bases: <a class="reference internal" href="cam.sgnmt.predictors.html#cam.sgnmt.predictors.core.Predictor" title="cam.sgnmt.predictors.core.Predictor"><code class="xref py py-class docutils literal"><span class="pre">cam.sgnmt.predictors.core.Predictor</span></code></a></p>
<p>This predictor adds the (negative) number of words as feature.
This means that this predictor encourages shorter hypotheses when
used with a positive weight.</p>
<p>Creates a new word count predictor instance.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>word</strong> (<em>int</em>) &#8211; If this is non-negative we count only the
number of the specified word. If its
negative, count all words</li>
<li><strong>nonterminal_penalty</strong> (<em>bool</em>) &#8211; If true, apply penalty only to
tokens in a range  (the range <em>outside</em>
min/max terminal id)</li>
<li><strong>nonterminal_ids</strong> &#8211; file containing ids of nonterminal tokens</li>
<li><strong>min_terminal_id</strong> &#8211; lower bound of tokens <em>not</em> to penalize,
if nonterminal_penalty selected</li>
<li><strong>max_terminal_id</strong> &#8211; upper bound of tokens <em>not</em> to penalize,
if nonterminal_penalty selected</li>
<li><strong>negative_wc</strong> &#8211; If true, the score of this predictor is the
negative word count.</li>
<li><strong>vocab_size</strong> &#8211; upper bound of tokens, used to find nonterminal range</li>
</ul>
</td>
</tr>
</tbody>
</table>
<dl class="method">
<dt>
<code class="descname">consume</code><span class="sig-paren">(</span><em>word</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/length.html#WordCountPredictor.consume"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Empty</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">get_state</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/length.html#WordCountPredictor.get_state"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Returns true</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">get_unk_probability</code><span class="sig-paren">(</span><em>posterior</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/length.html#WordCountPredictor.get_unk_probability"><span class="viewcode-link">[source]</span></a></dt>
<dd></dd></dl>

<dl class="method">
<dt>
<code class="descname">initialize</code><span class="sig-paren">(</span><em>src_sentence</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/length.html#WordCountPredictor.initialize"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Empty</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">is_equal</code><span class="sig-paren">(</span><em>state1</em>, <em>state2</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/length.html#WordCountPredictor.is_equal"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Returns true</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">predict_next</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/length.html#WordCountPredictor.predict_next"><span class="viewcode-link">[source]</span></a></dt>
<dd></dd></dl>

<dl class="method">
<dt>
<code class="descname">set_state</code><span class="sig-paren">(</span><em>state</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/length.html#WordCountPredictor.set_state"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Empty</p>
</dd></dl>

</dd></dl>

<dl class="function">
<dt>
<code class="descclassname">cam.sgnmt.predictors.length.</code><code class="descname">load_external_ids</code><span class="sig-paren">(</span><em>path</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/length.html#load_external_ids"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>load file of ids to list</p>
</dd></dl>

<dl class="function">
<dt>
<code class="descclassname">cam.sgnmt.predictors.length.</code><code class="descname">load_external_lengths</code><span class="sig-paren">(</span><em>path</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/length.html#load_external_lengths"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Loads a length distribution from a plain text file. The file
must contain blank separated &lt;length&gt;:&lt;score&gt; pairs in each line.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>path</strong> (<em>string</em>) &#8211; Path to the length file.</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body">list of dicts mapping a length to its scores, one dict for each
sentence.</td>
</tr>
</tbody>
</table>
</dd></dl>

</div>
<div class="section" id="cam-sgnmt-predictors-misc-module">
<h3>cam.sgnmt.predictors.misc module<a class="headerlink" href="#cam-sgnmt-predictors-misc-module" title="Permalink to this headline">¶</a></h3>
<p>This module provides helper predictors and predictor wrappers which
are not directly used for scoring. An example is the altsrc predictor
wrapper which loads source sentences from a different file.</p>
<dl class="class">
<dt>
<em class="property">class </em><code class="descclassname">cam.sgnmt.predictors.misc.</code><code class="descname">AltsrcPredictor</code><span class="sig-paren">(</span><em>src_test</em>, <em>slave_predictor</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/misc.html#AltsrcPredictor"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Bases: <a class="reference internal" href="cam.sgnmt.predictors.html#cam.sgnmt.predictors.core.Predictor" title="cam.sgnmt.predictors.core.Predictor"><code class="xref py py-class docutils literal"><span class="pre">cam.sgnmt.predictors.core.Predictor</span></code></a></p>
<p>This wrapper loads the source sentences from an alternative
source file. The <code class="docutils literal"><span class="pre">src_sentence</span></code> arguments of <code class="docutils literal"><span class="pre">initialize</span></code> and
<code class="docutils literal"><span class="pre">initialize_heuristic</span></code> are overridden with sentences loaded from
the file specified via the argument <code class="docutils literal"><span class="pre">--altsrc_test</span></code>. All other
methods are pass through calls to the slave predictor.</p>
<p>Creates a new altsrc wrapper predictor.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>src_test</strong> (<em>string</em>) &#8211; Path to the text file with source
sentences</li>
<li><strong>slave_predictor</strong> (<a class="reference internal" href="cam.sgnmt.predictors.html#cam.sgnmt.predictors.core.Predictor" title="cam.sgnmt.predictors.core.Predictor"><em>Predictor</em></a>) &#8211; Instance of the predictor which
uses the source sentences in
<code class="docutils literal"><span class="pre">src_test</span></code></li>
</ul>
</td>
</tr>
</tbody>
</table>
<dl class="method">
<dt>
<code class="descname">consume</code><span class="sig-paren">(</span><em>word</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/misc.html#AltsrcPredictor.consume"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Pass through to slave predictor</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">estimate_future_cost</code><span class="sig-paren">(</span><em>hypo</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/misc.html#AltsrcPredictor.estimate_future_cost"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Pass through to slave predictor</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">get_state</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/misc.html#AltsrcPredictor.get_state"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Pass through to slave predictor</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">get_unk_probability</code><span class="sig-paren">(</span><em>posterior</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/misc.html#AltsrcPredictor.get_unk_probability"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Pass through to slave predictor</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">initialize</code><span class="sig-paren">(</span><em>src_sentence</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/misc.html#AltsrcPredictor.initialize"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Pass through to slave predictor but replace
<code class="docutils literal"><span class="pre">src_sentence</span></code> with a sentence from <code class="docutils literal"><span class="pre">self.altsens</span></code></p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">initialize_heuristic</code><span class="sig-paren">(</span><em>src_sentence</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/misc.html#AltsrcPredictor.initialize_heuristic"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Pass through to slave predictor but replace
<code class="docutils literal"><span class="pre">src_sentence</span></code> with a sentence from <code class="docutils literal"><span class="pre">self.altsens</span></code></p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">is_equal</code><span class="sig-paren">(</span><em>state1</em>, <em>state2</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/misc.html#AltsrcPredictor.is_equal"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Pass through to slave predictor</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">predict_next</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/misc.html#AltsrcPredictor.predict_next"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Pass through to slave predictor</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">set_current_sen_id</code><span class="sig-paren">(</span><em>cur_sen_id</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/misc.html#AltsrcPredictor.set_current_sen_id"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>We need to override this method to propagate current_
sentence_id to the slave predictor</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">set_state</code><span class="sig-paren">(</span><em>state</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/misc.html#AltsrcPredictor.set_state"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Pass through to slave predictor</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt>
<em class="property">class </em><code class="descclassname">cam.sgnmt.predictors.misc.</code><code class="descname">GluePredictor</code><span class="sig-paren">(</span><em>max_len_factor</em>, <em>slave_predictor</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/misc.html#GluePredictor"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Bases: <a class="reference internal" href="cam.sgnmt.predictors.html#cam.sgnmt.predictors.core.Predictor" title="cam.sgnmt.predictors.core.Predictor"><code class="xref py py-class docutils literal"><span class="pre">cam.sgnmt.predictors.core.Predictor</span></code></a></p>
<p>This wrapper masks sentence-level predictors when SGNMT runs on
the document level. The SGNMT hypotheses consist of multiple
sentences, glued together with &lt;s&gt;, but the wrapped predictor is
trained on the sentence level. This predictor splits input
sequences at &lt;s&gt; and feed them to the predictor one by one. The
wrapped predictor is initialized with a new source sentence when
the sentence boundary symbol &lt;s&gt; is emitted. Note that using the
predictor heuristic of the wrapped predictor estimates the future
cost for the current sentence, not for the entire document.</p>
<p>Creates a new glue wrapper predictor.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>max_len_factor</strong> (<em>int</em>) &#8211; Target sentences cannot be longer
than this times source sentence length</li>
<li><strong>slave_predictor</strong> (<a class="reference internal" href="cam.sgnmt.predictors.html#cam.sgnmt.predictors.core.Predictor" title="cam.sgnmt.predictors.core.Predictor"><em>Predictor</em></a>) &#8211; Instance of the sentence-level
predictor.</li>
</ul>
</td>
</tr>
</tbody>
</table>
<dl class="method">
<dt>
<code class="descname">consume</code><span class="sig-paren">(</span><em>word</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/misc.html#GluePredictor.consume"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>If <code class="docutils literal"><span class="pre">word</span></code> is &lt;s&gt;, initialize the slave predictor with the
next source sentence. Otherwise, pass through <code class="docutils literal"><span class="pre">word</span></code> to the
<code class="docutils literal"><span class="pre">consume()</span></code> method of the slave.</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">estimate_future_cost</code><span class="sig-paren">(</span><em>hypo</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/misc.html#GluePredictor.estimate_future_cost"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Pass through to slave predictor</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">get_state</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/misc.html#GluePredictor.get_state"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>State is the slave state plus the source sentence index.</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">get_unk_probability</code><span class="sig-paren">(</span><em>posterior</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/misc.html#GluePredictor.get_unk_probability"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Pass through to slave predictor</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">initialize</code><span class="sig-paren">(</span><em>src_sentence</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/misc.html#GluePredictor.initialize"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Splits <code class="docutils literal"><span class="pre">src_sentence</span></code> at <code class="docutils literal"><span class="pre">utils.GO_ID</span></code>, stores all
segments for later use, and calls <code class="docutils literal"><span class="pre">initialize()</span></code> of the
slave predictor with the first segment.</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">initialize_heuristic</code><span class="sig-paren">(</span><em>src_sentence</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/misc.html#GluePredictor.initialize_heuristic"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Pass through to slave predictor.</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">is_equal</code><span class="sig-paren">(</span><em>state1</em>, <em>state2</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/misc.html#GluePredictor.is_equal"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Pass through to slave predictor</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">is_last_sentence</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/misc.html#GluePredictor.is_last_sentence"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Returns True if the current sentence is the last sentence
in this document - i.e. we have already consumed n-1 &lt;s&gt;
symbols since the last call of <code class="docutils literal"><span class="pre">initialize()</span></code>.</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">predict_next</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/misc.html#GluePredictor.predict_next"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Calls predict_next() of the wrapped predictor. Replaces BOS
scores with EOS score if we still have source sentences left.</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">set_current_sen_id</code><span class="sig-paren">(</span><em>cur_sen_id</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/misc.html#GluePredictor.set_current_sen_id"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>We need to override this method to propagate current_
sentence_id to the slave predictor</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">set_state</code><span class="sig-paren">(</span><em>state</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/misc.html#GluePredictor.set_state"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>State is the slave state plus the source sentence index.</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt>
<em class="property">class </em><code class="descclassname">cam.sgnmt.predictors.misc.</code><code class="descname">RankPredictor</code><span class="sig-paren">(</span><em>slave_predictor</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/misc.html#RankPredictor"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Bases: <a class="reference internal" href="cam.sgnmt.predictors.html#cam.sgnmt.predictors.core.Predictor" title="cam.sgnmt.predictors.core.Predictor"><code class="xref py py-class docutils literal"><span class="pre">cam.sgnmt.predictors.core.Predictor</span></code></a></p>
<p>This wrapper converts predictor scores to (negative) ranks, i.e.
the best word gets a score of -1, the second best of -2 and so on.</p>
<p>Note: Using this predictor with UNK matching or predictor heuristics
is not recommended.</p>
<p>Creates a new rank wrapper predictor.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>slave_predictor</strong> (<a class="reference internal" href="cam.sgnmt.predictors.html#cam.sgnmt.predictors.core.Predictor" title="cam.sgnmt.predictors.core.Predictor"><em>Predictor</em></a>) &#8211; Use score of this predictor to
compute ranks.</td>
</tr>
</tbody>
</table>
<dl class="method">
<dt>
<code class="descname">consume</code><span class="sig-paren">(</span><em>word</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/misc.html#RankPredictor.consume"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Pass through to slave predictor</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">estimate_future_cost</code><span class="sig-paren">(</span><em>hypo</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/misc.html#RankPredictor.estimate_future_cost"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Pass through to slave predictor</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">get_state</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/misc.html#RankPredictor.get_state"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Pass through to slave predictor</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">get_unk_probability</code><span class="sig-paren">(</span><em>posterior</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/misc.html#RankPredictor.get_unk_probability"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Pass through to slave predictor</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">initialize</code><span class="sig-paren">(</span><em>src_sentence</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/misc.html#RankPredictor.initialize"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Pass through to slave predictor.</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">initialize_heuristic</code><span class="sig-paren">(</span><em>src_sentence</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/misc.html#RankPredictor.initialize_heuristic"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Pass through to slave predictor.</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">is_equal</code><span class="sig-paren">(</span><em>state1</em>, <em>state2</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/misc.html#RankPredictor.is_equal"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Pass through to slave predictor</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">predict_next</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/misc.html#RankPredictor.predict_next"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Pass through to slave predictor</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">score2rank</code><span class="sig-paren">(</span><em>scores</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/misc.html#RankPredictor.score2rank"><span class="viewcode-link">[source]</span></a></dt>
<dd></dd></dl>

<dl class="method">
<dt>
<code class="descname">set_current_sen_id</code><span class="sig-paren">(</span><em>cur_sen_id</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/misc.html#RankPredictor.set_current_sen_id"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>We need to override this method to propagate current_
sentence_id to the slave predictor</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">set_state</code><span class="sig-paren">(</span><em>state</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/misc.html#RankPredictor.set_state"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Pass through to slave predictor</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt>
<em class="property">class </em><code class="descclassname">cam.sgnmt.predictors.misc.</code><code class="descname">UnboundedAltsrcPredictor</code><span class="sig-paren">(</span><em>src_test</em>, <em>slave_predictor</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/misc.html#UnboundedAltsrcPredictor"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Bases: <a class="reference internal" href="cam.sgnmt.predictors.html#cam.sgnmt.predictors.misc.AltsrcPredictor" title="cam.sgnmt.predictors.misc.AltsrcPredictor"><code class="xref py py-class docutils literal"><span class="pre">cam.sgnmt.predictors.misc.AltsrcPredictor</span></code></a>, <a class="reference internal" href="cam.sgnmt.predictors.html#cam.sgnmt.predictors.core.UnboundedVocabularyPredictor" title="cam.sgnmt.predictors.core.UnboundedVocabularyPredictor"><code class="xref py py-class docutils literal"><span class="pre">cam.sgnmt.predictors.core.UnboundedVocabularyPredictor</span></code></a></p>
<p>This class is a version of <code class="docutils literal"><span class="pre">AltsrcPredictor</span></code> for unbounded
vocabulary predictors. This needs an adjusted <code class="docutils literal"><span class="pre">predict_next</span></code>
method to pass through the set of target words to score correctly.</p>
<p>Pass through to <code class="docutils literal"><span class="pre">AltsrcPredictor.__init__</span></code></p>
<dl class="method">
<dt>
<code class="descname">predict_next</code><span class="sig-paren">(</span><em>trgt_words</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/misc.html#UnboundedAltsrcPredictor.predict_next"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Pass through to slave predictor</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt>
<em class="property">class </em><code class="descclassname">cam.sgnmt.predictors.misc.</code><code class="descname">UnboundedGluePredictor</code><span class="sig-paren">(</span><em>max_len_factor</em>, <em>slave_predictor</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/misc.html#UnboundedGluePredictor"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Bases: <a class="reference internal" href="cam.sgnmt.predictors.html#cam.sgnmt.predictors.misc.GluePredictor" title="cam.sgnmt.predictors.misc.GluePredictor"><code class="xref py py-class docutils literal"><span class="pre">cam.sgnmt.predictors.misc.GluePredictor</span></code></a>, <a class="reference internal" href="cam.sgnmt.predictors.html#cam.sgnmt.predictors.core.UnboundedVocabularyPredictor" title="cam.sgnmt.predictors.core.UnboundedVocabularyPredictor"><code class="xref py py-class docutils literal"><span class="pre">cam.sgnmt.predictors.core.UnboundedVocabularyPredictor</span></code></a></p>
<p>This class is a version of <code class="docutils literal"><span class="pre">GluePredictor</span></code> for unbounded
vocabulary predictors.</p>
<p>Creates a new glue wrapper predictor.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>max_len_factor</strong> (<em>int</em>) &#8211; Target sentences cannot be longer
than this times source sentence length</li>
<li><strong>slave_predictor</strong> (<a class="reference internal" href="cam.sgnmt.predictors.html#cam.sgnmt.predictors.core.Predictor" title="cam.sgnmt.predictors.core.Predictor"><em>Predictor</em></a>) &#8211; Instance of the sentence-level
predictor.</li>
</ul>
</td>
</tr>
</tbody>
</table>
<dl class="method">
<dt>
<code class="descname">predict_next</code><span class="sig-paren">(</span><em>trgt_words</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/misc.html#UnboundedGluePredictor.predict_next"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Pass through to slave predictor</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt>
<em class="property">class </em><code class="descclassname">cam.sgnmt.predictors.misc.</code><code class="descname">UnboundedRankPredictor</code><span class="sig-paren">(</span><em>slave_predictor</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/misc.html#UnboundedRankPredictor"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Bases: <a class="reference internal" href="cam.sgnmt.predictors.html#cam.sgnmt.predictors.misc.RankPredictor" title="cam.sgnmt.predictors.misc.RankPredictor"><code class="xref py py-class docutils literal"><span class="pre">cam.sgnmt.predictors.misc.RankPredictor</span></code></a>, <a class="reference internal" href="cam.sgnmt.predictors.html#cam.sgnmt.predictors.core.UnboundedVocabularyPredictor" title="cam.sgnmt.predictors.core.UnboundedVocabularyPredictor"><code class="xref py py-class docutils literal"><span class="pre">cam.sgnmt.predictors.core.UnboundedVocabularyPredictor</span></code></a></p>
<p>This class is a version of <code class="docutils literal"><span class="pre">RankPredictor</span></code> for unbounded
vocabulary predictors. This needs an adjusted <code class="docutils literal"><span class="pre">predict_next</span></code>
method to pass through the set of target words to score correctly.</p>
<p>Creates a new rank wrapper predictor.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>slave_predictor</strong> (<a class="reference internal" href="cam.sgnmt.predictors.html#cam.sgnmt.predictors.core.Predictor" title="cam.sgnmt.predictors.core.Predictor"><em>Predictor</em></a>) &#8211; Use score of this predictor to
compute ranks.</td>
</tr>
</tbody>
</table>
<dl class="method">
<dt>
<code class="descname">predict_next</code><span class="sig-paren">(</span><em>trgt_words</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/misc.html#UnboundedRankPredictor.predict_next"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Return ranks instead of slave scores</p>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="cam-sgnmt-predictors-ngram-module">
<h3>cam.sgnmt.predictors.ngram module<a class="headerlink" href="#cam-sgnmt-predictors-ngram-module" title="Permalink to this headline">¶</a></h3>
<p>This module contains predictors for n-gram (Kneser-Ney) language
modeling. This is a <code class="docutils literal"><span class="pre">UnboundedVocabularyPredictor</span></code> as the vocabulary
size ngram models normally do not permit complete enumeration of the
posterior.</p>
<dl class="class">
<dt>
<em class="property">class </em><code class="descclassname">cam.sgnmt.predictors.ngram.</code><code class="descname">KenLMPredictor</code><span class="sig-paren">(</span><em>path</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/ngram.html#KenLMPredictor"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Bases: <a class="reference internal" href="cam.sgnmt.predictors.html#cam.sgnmt.predictors.core.UnboundedVocabularyPredictor" title="cam.sgnmt.predictors.core.UnboundedVocabularyPredictor"><code class="xref py py-class docutils literal"><span class="pre">cam.sgnmt.predictors.core.UnboundedVocabularyPredictor</span></code></a></p>
<p>KenLM predictor based on
<a class="reference external" href="https://github.com/kpu/kenlm">https://github.com/kpu/kenlm</a></p>
<p>The predictor state is described by the n-gram history.</p>
<p>Creates a new n-gram language model predictor.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>path</strong> (<em>string</em>) &#8211; Path to the ARPA language model file</td>
</tr>
<tr class="field-even field"><th class="field-name">Raises:</th><td class="field-body">NameError. If KenLM is not installed</td>
</tr>
</tbody>
</table>
<dl class="method">
<dt>
<code class="descname">consume</code><span class="sig-paren">(</span><em>word</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/ngram.html#KenLMPredictor.consume"><span class="viewcode-link">[source]</span></a></dt>
<dd></dd></dl>

<dl class="method">
<dt>
<code class="descname">get_state</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/ngram.html#KenLMPredictor.get_state"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Returns the current n-gram history</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">get_unk_probability</code><span class="sig-paren">(</span><em>posterior</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/ngram.html#KenLMPredictor.get_unk_probability"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Use the probability for &#8216;&lt;unk&gt;&#8217; in the language model</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">initialize</code><span class="sig-paren">(</span><em>src_sentence</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/ngram.html#KenLMPredictor.initialize"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Initializes the KenLM state.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>src_sentence</strong> (<em>list</em>) &#8211; Not used</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">is_equal</code><span class="sig-paren">(</span><em>state1</em>, <em>state2</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/ngram.html#KenLMPredictor.is_equal"><span class="viewcode-link">[source]</span></a></dt>
<dd></dd></dl>

<dl class="method">
<dt>
<code class="descname">predict_next</code><span class="sig-paren">(</span><em>words</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/ngram.html#KenLMPredictor.predict_next"><span class="viewcode-link">[source]</span></a></dt>
<dd></dd></dl>

<dl class="method">
<dt>
<code class="descname">set_state</code><span class="sig-paren">(</span><em>state</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/ngram.html#KenLMPredictor.set_state"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Sets the current n-gram history and LM state</p>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="cam-sgnmt-predictors-parse-module">
<h3>cam.sgnmt.predictors.parse module<a class="headerlink" href="#cam-sgnmt-predictors-parse-module" title="Permalink to this headline">¶</a></h3>
<dl class="class">
<dt>
<em class="property">class </em><code class="descclassname">cam.sgnmt.predictors.parse.</code><code class="descname">BpeParsePredictor</code><span class="sig-paren">(</span><em>grammar_path</em>, <em>bpe_rule_path</em>, <em>slave_predictor</em>, <em>word_out=True</em>, <em>normalize_scores=True</em>, <em>norm_alpha=1.0</em>, <em>beam_size=1</em>, <em>max_internal_len=35</em>, <em>allow_early_eos=False</em>, <em>consume_out_of_class=False</em>, <em>eow_ids=None</em>, <em>terminal_restrict=True</em>, <em>terminal_ids=None</em>, <em>internal_only_restrict=False</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/parse.html#BpeParsePredictor"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Bases: <a class="reference internal" href="cam.sgnmt.predictors.html#cam.sgnmt.predictors.parse.TokParsePredictor" title="cam.sgnmt.predictors.parse.TokParsePredictor"><code class="xref py py-class docutils literal"><span class="pre">cam.sgnmt.predictors.parse.TokParsePredictor</span></code></a></p>
<p>Predict over a BPE-based grammar with two possible grammar constraints:
one between non-terminals and bpe start-of-word tokens, one over
bpe tokens in a word</p>
<dl class="docutils">
<dt>Creates a new parse predictor wrapper which can be constrained to 2</dt>
<dd>grammars: one over non-terminals / terminals, one internally to
constrain BPE units within a single word</dd>
</dl>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>grammar_path</strong> (<em>string</em>) &#8211; Path to the grammar file</li>
<li><strong>bpe_rule_path</strong> (<em>string</em>) &#8211; Path to file defining rules between BPEs</li>
<li><strong>slave_predictor</strong> &#8211; predictor to wrap</li>
<li><strong>word_out</strong> (<em>bool</em>) &#8211; since this wrapper can be used for grammar
constraint, this bool determines whether we
also do internal beam search over non-terminals</li>
<li><strong>normalize_scores</strong> (<em>bool</em>) &#8211; true if normalizing scores, e.g. if some
are removed from the posterior</li>
<li><strong>norm_alpha</strong> (<em>float</em>) &#8211; may be used for path weight normalization</li>
<li><strong>beam_size</strong> (<em>int</em>) &#8211; beam size for internal beam search</li>
<li><strong>max_internal_len</strong> (<em>int</em>) &#8211; max number of consecutive nonterminals
before path is ignored by internal search</li>
<li><strong>allow_early_eos</strong> (<em>bool</em>) &#8211; true if permitting EOS consumed even if
it is not permitted by the grammar
at that point</li>
<li><strong>consume_out_of_class</strong> (<em>bool</em>) &#8211; true if permitting any tokens to be
consumed even if not allowed by the
grammar at that point</li>
<li><strong>eow_ids</strong> (<em>string</em>) &#8211; path to file containing ids of BPEs that mark
the end of a word</li>
<li><strong>terminal_restrict</strong> (<em>bool</em>) &#8211; true if applying grammar constraint over
nonterminals and terminals</li>
<li><strong>terminal_ids</strong> (<em>string</em>) &#8211; path to file containing all terminal ids</li>
<li><strong>internal_only_restrict</strong> (<em>bool</em>) &#8211; true if applying grammar constraint
over BPE units inside words</li>
</ul>
</td>
</tr>
</tbody>
</table>
<dl class="method">
<dt>
<code class="descname">get_all_terminals</code><span class="sig-paren">(</span><em>terminal_ids</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/parse.html#BpeParsePredictor.get_all_terminals"><span class="viewcode-link">[source]</span></a></dt>
<dd></dd></dl>

<dl class="method">
<dt>
<code class="descname">get_bpe_can_follow</code><span class="sig-paren">(</span><em>rule_path</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/parse.html#BpeParsePredictor.get_bpe_can_follow"><span class="viewcode-link">[source]</span></a></dt>
<dd></dd></dl>

<dl class="method">
<dt>
<code class="descname">get_eow_ids</code><span class="sig-paren">(</span><em>eow_ids</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/parse.html#BpeParsePredictor.get_eow_ids"><span class="viewcode-link">[source]</span></a></dt>
<dd></dd></dl>

<dl class="method">
<dt>
<code class="descname">is_nt</code><span class="sig-paren">(</span><em>word</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/parse.html#BpeParsePredictor.is_nt"><span class="viewcode-link">[source]</span></a></dt>
<dd></dd></dl>

<dl class="method">
<dt>
<code class="descname">predict_next</code><span class="sig-paren">(</span><em>predicting_next_word=False</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/parse.html#BpeParsePredictor.predict_next"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>predict next tokens as permitted by
the current stack and the BPE grammar</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">update_stacks</code><span class="sig-paren">(</span><em>word</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/parse.html#BpeParsePredictor.update_stacks"><span class="viewcode-link">[source]</span></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="class">
<dt>
<em class="property">class </em><code class="descclassname">cam.sgnmt.predictors.parse.</code><code class="descname">InternalHypo</code><span class="sig-paren">(</span><em>score</em>, <em>token_score</em>, <em>predictor_state</em>, <em>word_to_consume</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/parse.html#InternalHypo"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal"><span class="pre">object</span></code></p>
<p>Helper class for internal parse predictor beam search over nonterminals</p>
<dl class="method">
<dt>
<code class="descname">extend</code><span class="sig-paren">(</span><em>score</em>, <em>predictor_state</em>, <em>word_to_consume</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/parse.html#InternalHypo.extend"><span class="viewcode-link">[source]</span></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="class">
<dt>
<em class="property">class </em><code class="descclassname">cam.sgnmt.predictors.parse.</code><code class="descname">ParsePredictor</code><span class="sig-paren">(</span><em>slave_predictor</em>, <em>normalize_scores=True</em>, <em>beam_size=4</em>, <em>max_internal_len=35</em>, <em>nonterminal_ids=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/parse.html#ParsePredictor"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Bases: <a class="reference internal" href="cam.sgnmt.predictors.html#cam.sgnmt.predictors.core.Predictor" title="cam.sgnmt.predictors.core.Predictor"><code class="xref py py-class docutils literal"><span class="pre">cam.sgnmt.predictors.core.Predictor</span></code></a></p>
<p>Predictor wrapper allowing internal beam search over a representation
which contains some pre-defined &#8216;non-terminal&#8217; ids, which should not appear
in the output.</p>
<p>Create a new parse wrapper for a predictor</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>slave_predictor</strong> &#8211; predictor to wrap with parse wrapper</li>
<li><strong>normalize_scores</strong> (<em>bool</em>) &#8211; whether to normalize posterior scores,
e.g. after some tokens have been removed</li>
<li><strong>beam_size</strong> (<em>int</em>) &#8211; beam size for internal beam search over non-terminals</li>
<li><strong>max_internal_len</strong> (<em>int</em>) &#8211; number of consecutive non-terminal tokens
allowed in internal search before path is ignored</li>
<li><strong>nonterminal_ids</strong> &#8211; file containing non-terminal ids, one per line</li>
</ul>
</td>
</tr>
</tbody>
</table>
<dl class="method">
<dt>
<code class="descname">are_best_terminal</code><span class="sig-paren">(</span><em>posterior</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/parse.html#ParsePredictor.are_best_terminal"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Return true if most probable tokens in posterior are all terminals
(including EOS)</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">consume</code><span class="sig-paren">(</span><em>word</em>, <em>internal=False</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/parse.html#ParsePredictor.consume"><span class="viewcode-link">[source]</span></a></dt>
<dd></dd></dl>

<dl class="method">
<dt>
<code class="descname">find_word_beam</code><span class="sig-paren">(</span><em>posterior</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/parse.html#ParsePredictor.find_word_beam"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Internal beam search over posterior until a beam of terminals
is found</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">get_state</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/parse.html#ParsePredictor.get_state"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Returns the current state.</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">get_unk_probability</code><span class="sig-paren">(</span><em>posterior</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/parse.html#ParsePredictor.get_unk_probability"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Return unk probability as determined by slave predictor
:returns: float, unk prob</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">initialize</code><span class="sig-paren">(</span><em>src_sentence</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/parse.html#ParsePredictor.initialize"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Initializes slave predictor with source sentence</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>src_sentence</strong> (<em>list</em>) &#8211; </td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">initialize_heuristic</code><span class="sig-paren">(</span><em>src_sentence</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/parse.html#ParsePredictor.initialize_heuristic"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Creates a matrix of shortest distances between nodes.</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">initialize_internal_hypos</code><span class="sig-paren">(</span><em>posterior</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/parse.html#ParsePredictor.initialize_internal_hypos"><span class="viewcode-link">[source]</span></a></dt>
<dd></dd></dl>

<dl class="method">
<dt>
<code class="descname">is_equal</code><span class="sig-paren">(</span><em>state1</em>, <em>state2</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/parse.html#ParsePredictor.is_equal"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Returns true if the current node is the same</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">maybe_add_new_top_tokens</code><span class="sig-paren">(</span><em>top_terminals</em>, <em>hypo</em>, <em>next_hypos</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/parse.html#ParsePredictor.maybe_add_new_top_tokens"><span class="viewcode-link">[source]</span></a></dt>
<dd></dd></dl>

<dl class="method">
<dt>
<code class="descname">predict_next</code><span class="sig-paren">(</span><em>predicting_internally=False</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/parse.html#ParsePredictor.predict_next"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Predict next tokens.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>predicting_internally</strong> &#8211; will be true if called from internal
beam search, prevents infinite loop</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">set_state</code><span class="sig-paren">(</span><em>state</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/parse.html#ParsePredictor.set_state"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Sets the current state.</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt>
<em class="property">class </em><code class="descclassname">cam.sgnmt.predictors.parse.</code><code class="descname">TokParsePredictor</code><span class="sig-paren">(</span><em>grammar_path</em>, <em>slave_predictor</em>, <em>word_out=True</em>, <em>normalize_scores=True</em>, <em>norm_alpha=1.0</em>, <em>beam_size=1</em>, <em>max_internal_len=35</em>, <em>allow_early_eos=False</em>, <em>consume_out_of_class=False</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/parse.html#TokParsePredictor"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Bases: <a class="reference internal" href="cam.sgnmt.predictors.html#cam.sgnmt.predictors.parse.ParsePredictor" title="cam.sgnmt.predictors.parse.ParsePredictor"><code class="xref py py-class docutils literal"><span class="pre">cam.sgnmt.predictors.parse.ParsePredictor</span></code></a></p>
<p>Unlike ParsePredictor, the grammar predicts tokens according to a grammar.
Use BPEParsePredictor if including rules to connect BPE units inside words.</p>
<p>Creates a new parse predictor wrapper.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>grammar_path</strong> (<em>string</em>) &#8211; Path to the grammar file</li>
<li><strong>slave_predictor</strong> &#8211; predictor to wrap</li>
<li><strong>word_out</strong> (<em>bool</em>) &#8211; since this wrapper can be used for grammar
constraint, this bool determines whether we
also do internal beam search over non-terminals</li>
<li><strong>normalize_scores</strong> (<em>bool</em>) &#8211; true if normalizing scores, e.g. if some
are removed from the posterior</li>
<li><strong>norm_alpha</strong> (<em>float</em>) &#8211; may be used for path weight normalization</li>
<li><strong>beam_size</strong> (<em>int</em>) &#8211; beam size for internal beam search</li>
<li><strong>max_internal_len</strong> (<em>int</em>) &#8211; max number of consecutive nonterminals
before path is ignored by internal search</li>
<li><strong>allow_early_eos</strong> (<em>bool</em>) &#8211; true if permitting EOS consumed even if
it is not permitted by the grammar
at that point</li>
<li><strong>consume_out_of_class</strong> (<em>bool</em>) &#8211; true if permitting any tokens to be
consumed even if not allowed by the
grammar at that point</li>
</ul>
</td>
</tr>
</tbody>
</table>
<dl class="method">
<dt>
<code class="descname">consume</code><span class="sig-paren">(</span><em>word</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/parse.html#TokParsePredictor.consume"><span class="viewcode-link">[source]</span></a></dt>
<dd><table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>word</strong> (<em>int</em>) &#8211; word token being consumed</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">find_word</code><span class="sig-paren">(</span><em>posterior</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/parse.html#TokParsePredictor.find_word"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Check whether rhs of best option in posterior is a terminal
if it is, return the posterior for decoding
if not, take the best result and follow that path until a word is found
this follows a greedy 1best or a beam path through non-terminals</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">find_word_beam</code><span class="sig-paren">(</span><em>posterior</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/parse.html#TokParsePredictor.find_word_beam"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Do an internal beam search over non-terminal functions to find
the next best n terminal tokens, as ranked by normalized path score</p>
<dl class="docutils">
<dt>Returns: posterior containing up to n terminal tokens</dt>
<dd>and their normalized path score</dd>
</dl>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">find_word_greedy</code><span class="sig-paren">(</span><em>posterior</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/parse.html#TokParsePredictor.find_word_greedy"><span class="viewcode-link">[source]</span></a></dt>
<dd></dd></dl>

<dl class="method">
<dt>
<code class="descname">get_current_allowed</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/parse.html#TokParsePredictor.get_current_allowed"><span class="viewcode-link">[source]</span></a></dt>
<dd></dd></dl>

<dl class="method">
<dt>
<code class="descname">get_state</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/parse.html#TokParsePredictor.get_state"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Returns the current state, including slave predictor state</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">initialize</code><span class="sig-paren">(</span><em>src_sentence</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/parse.html#TokParsePredictor.initialize"><span class="viewcode-link">[source]</span></a></dt>
<dd></dd></dl>

<dl class="method">
<dt>
<code class="descname">norm_hypo_score</code><span class="sig-paren">(</span><em>hypo</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/parse.html#TokParsePredictor.norm_hypo_score"><span class="viewcode-link">[source]</span></a></dt>
<dd></dd></dl>

<dl class="method">
<dt>
<code class="descname">norm_score</code><span class="sig-paren">(</span><em>score</em>, <em>beam_len</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/parse.html#TokParsePredictor.norm_score"><span class="viewcode-link">[source]</span></a></dt>
<dd></dd></dl>

<dl class="method">
<dt>
<code class="descname">predict_next</code><span class="sig-paren">(</span><em>predicting_next_word=False</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/parse.html#TokParsePredictor.predict_next"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>predict next tokens as permitted by
the current stack and the grammar</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">prepare_grammar</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/parse.html#TokParsePredictor.prepare_grammar"><span class="viewcode-link">[source]</span></a></dt>
<dd></dd></dl>

<dl class="method">
<dt>
<code class="descname">replace_lhs</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/parse.html#TokParsePredictor.replace_lhs"><span class="viewcode-link">[source]</span></a></dt>
<dd></dd></dl>

<dl class="method">
<dt>
<code class="descname">set_state</code><span class="sig-paren">(</span><em>state</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/parse.html#TokParsePredictor.set_state"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Sets the current state</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">update_stacks</code><span class="sig-paren">(</span><em>word</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/parse.html#TokParsePredictor.update_stacks"><span class="viewcode-link">[source]</span></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="function">
<dt>
<code class="descclassname">cam.sgnmt.predictors.parse.</code><code class="descname">load_external_ids</code><span class="sig-paren">(</span><em>path</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/parse.html#load_external_ids"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>load file of ids to list</p>
</dd></dl>

</div>
<div class="section" id="cam-sgnmt-predictors-pytorch-fairseq-module">
<h3>cam.sgnmt.predictors.pytorch_fairseq module<a class="headerlink" href="#cam-sgnmt-predictors-pytorch-fairseq-module" title="Permalink to this headline">¶</a></h3>
<p>This is the interface to the fairseq library.</p>
<p><a class="reference external" href="https://github.com/pytorch/fairseq">https://github.com/pytorch/fairseq</a></p>
<p>The fairseq predictor can read any model trained with fairseq.</p>
<dl class="data">
<dt>
<code class="descclassname">cam.sgnmt.predictors.pytorch_fairseq.</code><code class="descname">FAIRSEQ_INITIALIZED</code><em class="property"> = False</em></dt>
<dd><p>Set to true by _initialize_fairseq() after first constructor call.</p>
</dd></dl>

<dl class="class">
<dt>
<em class="property">class </em><code class="descclassname">cam.sgnmt.predictors.pytorch_fairseq.</code><code class="descname">FairseqPredictor</code><span class="sig-paren">(</span><em>model_path</em>, <em>user_dir</em>, <em>lang_pair</em>, <em>n_cpu_threads=-1</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/pytorch_fairseq.html#FairseqPredictor"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Bases: <a class="reference internal" href="cam.sgnmt.predictors.html#cam.sgnmt.predictors.core.Predictor" title="cam.sgnmt.predictors.core.Predictor"><code class="xref py py-class docutils literal"><span class="pre">cam.sgnmt.predictors.core.Predictor</span></code></a></p>
<p>Predictor for using fairseq models.</p>
<p>Initializes a fairseq predictor.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>model_path</strong> (<em>string</em>) &#8211; Path to the fairseq model (<a href="#id1"><span class="problematic" id="id2">*</span></a>.pt). Like
&#8211;path in fairseq-interactive.</li>
<li><strong>lang_pair</strong> (<em>string</em>) &#8211; Language pair string (e.g. &#8216;en-fr&#8217;).</li>
<li><strong>user_dir</strong> (<em>string</em>) &#8211; Path to fairseq user directory.</li>
<li><strong>n_cpu_threads</strong> (<em>int</em>) &#8211; Number of CPU threads. If negative,
use GPU.</li>
</ul>
</td>
</tr>
</tbody>
</table>
<dl class="method">
<dt>
<code class="descname">consume</code><span class="sig-paren">(</span><em>word</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/pytorch_fairseq.html#FairseqPredictor.consume"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Append <code class="docutils literal"><span class="pre">word</span></code> to the current history.</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">get_state</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/pytorch_fairseq.html#FairseqPredictor.get_state"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>The predictor state is the complete history.</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">get_unk_probability</code><span class="sig-paren">(</span><em>posterior</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/pytorch_fairseq.html#FairseqPredictor.get_unk_probability"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Fetch posterior[utils.UNK_ID]</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">initialize</code><span class="sig-paren">(</span><em>src_sentence</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/pytorch_fairseq.html#FairseqPredictor.initialize"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Initialize source tensors, reset consumed.</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">is_equal</code><span class="sig-paren">(</span><em>state1</em>, <em>state2</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/pytorch_fairseq.html#FairseqPredictor.is_equal"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Returns true if the history is the same</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">predict_next</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/pytorch_fairseq.html#FairseqPredictor.predict_next"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Call the fairseq model.</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">set_state</code><span class="sig-paren">(</span><em>state</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/pytorch_fairseq.html#FairseqPredictor.set_state"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>The predictor state is the complete history.</p>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="cam-sgnmt-predictors-structure-module">
<h3>cam.sgnmt.predictors.structure module<a class="headerlink" href="#cam-sgnmt-predictors-structure-module" title="Permalink to this headline">¶</a></h3>
<p>This module implements constraints which assure that highly structured
output is well-formatted. For example, the bracket predictor checks for
balanced bracket expressions, and the OSM predictor prevents any sequence
of operations which cannot be compiled to a string.</p>
<dl class="class">
<dt>
<em class="property">class </em><code class="descclassname">cam.sgnmt.predictors.structure.</code><code class="descname">BracketPredictor</code><span class="sig-paren">(</span><em>max_terminal_id</em>, <em>closing_bracket_id</em>, <em>max_depth=-1</em>, <em>extlength_path=''</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/structure.html#BracketPredictor"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Bases: <a class="reference internal" href="cam.sgnmt.predictors.html#cam.sgnmt.predictors.core.UnboundedVocabularyPredictor" title="cam.sgnmt.predictors.core.UnboundedVocabularyPredictor"><code class="xref py py-class docutils literal"><span class="pre">cam.sgnmt.predictors.core.UnboundedVocabularyPredictor</span></code></a></p>
<p>This predictor constrains the output to well-formed bracket
expressions. It also allows to specify the number of terminals with
an external length distribution file.</p>
<p>Creates a new bracket predictor.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>max_terminal_id</strong> (<em>int</em>) &#8211; All IDs greater than this are
brackets</li>
<li><strong>closing_bracket_id</strong> (<em>string</em>) &#8211; All brackets except these ones are
opening. Comma-separated list of integers.</li>
<li><strong>max_depth</strong> (<em>int</em>) &#8211; If positive, restrict the maximum depth</li>
<li><strong>extlength_path</strong> (<em>string</em>) &#8211; If this is set, restrict the
number of terminals to the distribution specified in
the referenced file. Terminals can be implicit: We
count a single terminal between each adjacent opening
and closing bracket.</li>
</ul>
</td>
</tr>
</tbody>
</table>
<dl class="method">
<dt>
<code class="descname">consume</code><span class="sig-paren">(</span><em>word</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/structure.html#BracketPredictor.consume"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Updates current depth and the number of consumed terminals.</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">get_state</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/structure.html#BracketPredictor.get_state"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Returns the current depth and number of consumed terminals</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">get_unk_probability</code><span class="sig-paren">(</span><em>posterior</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/structure.html#BracketPredictor.get_unk_probability"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Always returns 0.0</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">initialize</code><span class="sig-paren">(</span><em>src_sentence</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/structure.html#BracketPredictor.initialize"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Sets the current depth to 0.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>src_sentence</strong> (<em>list</em>) &#8211; Not used</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">is_equal</code><span class="sig-paren">(</span><em>state1</em>, <em>state2</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/structure.html#BracketPredictor.is_equal"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Trivial implementation</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">predict_next</code><span class="sig-paren">(</span><em>words</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/structure.html#BracketPredictor.predict_next"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>If the maximum depth is reached, exclude all opening
brackets. If history is not balanced, exclude EOS. If the
current depth is zero, exclude closing brackets.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>words</strong> (<em>list</em>) &#8211; Set of words to score</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body">dict.</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">set_state</code><span class="sig-paren">(</span><em>state</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/structure.html#BracketPredictor.set_state"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Sets the current depth and number of consumed terminals</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt>
<em class="property">class </em><code class="descclassname">cam.sgnmt.predictors.structure.</code><code class="descname">ForcedOSMPredictor</code><span class="sig-paren">(</span><em>trg_test_file</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/structure.html#ForcedOSMPredictor"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Bases: <a class="reference internal" href="cam.sgnmt.predictors.html#cam.sgnmt.predictors.core.Predictor" title="cam.sgnmt.predictors.core.Predictor"><code class="xref py py-class docutils literal"><span class="pre">cam.sgnmt.predictors.core.Predictor</span></code></a></p>
<p>This predictor allows forced decoding with an OSM output, which
essentially means running the OSM in alignment mode. This predictor
assumes well-formed operation sequences. Please combine this
predictor with the osm constraint predictor to satisfy this
requirement. The state of this predictor is the compiled version of
the current history. It allows terminal symbols which are
consistent with the reference. The end-of-sentence symbol is
supressed until all words in the reference have been consumed.</p>
<p>Creates a new forcedosm predictor.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>trg_test_file</strong> (<em>string</em>) &#8211; Path to the plain text file with
the target sentences. Must have the
same number of lines as the number
of source sentences to decode</td>
</tr>
</tbody>
</table>
<dl class="method">
<dt>
<code class="descname">consume</code><span class="sig-paren">(</span><em>word</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/structure.html#ForcedOSMPredictor.consume"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Updates the compiled string and the head position.</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">get_state</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/structure.html#ForcedOSMPredictor.get_state"><span class="viewcode-link">[source]</span></a></dt>
<dd></dd></dl>

<dl class="method">
<dt>
<code class="descname">get_unk_probability</code><span class="sig-paren">(</span><em>posterior</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/structure.html#ForcedOSMPredictor.get_unk_probability"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Always returns -inf.</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">initialize</code><span class="sig-paren">(</span><em>src_sentence</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/structure.html#ForcedOSMPredictor.initialize"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Resets compiled and head.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>src_sentence</strong> (<em>list</em>) &#8211; Not used</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">is_equal</code><span class="sig-paren">(</span><em>state1</em>, <em>state2</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/structure.html#ForcedOSMPredictor.is_equal"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Trivial implementation</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">predict_next</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/structure.html#ForcedOSMPredictor.predict_next"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Apply word reference constraints.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body">dict.</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">set_state</code><span class="sig-paren">(</span><em>state</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/structure.html#ForcedOSMPredictor.set_state"><span class="viewcode-link">[source]</span></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="class">
<dt>
<em class="property">class </em><code class="descclassname">cam.sgnmt.predictors.structure.</code><code class="descname">OSMPredictor</code><span class="sig-paren">(</span><em>osm_type='osm'</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/structure.html#OSMPredictor"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Bases: <a class="reference internal" href="cam.sgnmt.predictors.html#cam.sgnmt.predictors.core.Predictor" title="cam.sgnmt.predictors.core.Predictor"><code class="xref py py-class docutils literal"><span class="pre">cam.sgnmt.predictors.core.Predictor</span></code></a></p>
<p>This predictor applies the following constraints to an OSM output:</p>
<ul class="simple">
<li>The number of EOP (end-of-phrase) tokens must not exceed the number
of source tokens.</li>
<li>JUMP_FWD and JUMP_BWD tokens are constraint to avoid jumping out of
bounds.</li>
</ul>
<p>Creates a new osm predictor.</p>
<dl class="method">
<dt>
<code class="descname">consume</code><span class="sig-paren">(</span><em>word</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/structure.html#OSMPredictor.consume"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Updates the number of holes, EOPs, and the head position.</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">get_state</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/structure.html#OSMPredictor.get_state"><span class="viewcode-link">[source]</span></a></dt>
<dd></dd></dl>

<dl class="method">
<dt>
<code class="descname">get_unk_probability</code><span class="sig-paren">(</span><em>posterior</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/structure.html#OSMPredictor.get_unk_probability"><span class="viewcode-link">[source]</span></a></dt>
<dd></dd></dl>

<dl class="method">
<dt>
<code class="descname">initialize</code><span class="sig-paren">(</span><em>src_sentence</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/structure.html#OSMPredictor.initialize"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Sets the number of source tokens.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>src_sentence</strong> (<em>list</em>) &#8211; Not used</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">is_equal</code><span class="sig-paren">(</span><em>state1</em>, <em>state2</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/structure.html#OSMPredictor.is_equal"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Trivial implementation</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">predict_next</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/structure.html#OSMPredictor.predict_next"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Apply OSM constraints.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body">dict.</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">set_state</code><span class="sig-paren">(</span><em>state</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/structure.html#OSMPredictor.set_state"><span class="viewcode-link">[source]</span></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="function">
<dt>
<code class="descclassname">cam.sgnmt.predictors.structure.</code><code class="descname">load_external_lengths</code><span class="sig-paren">(</span><em>path</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/structure.html#load_external_lengths"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Loads a length distribution from a plain text file. The file
must contain blank separated &lt;length&gt;:&lt;score&gt; pairs in each line.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>path</strong> (<em>string</em>) &#8211; Path to the length file.</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body">list of dicts mapping a length to its scores, one dict for each
sentence.</td>
</tr>
</tbody>
</table>
</dd></dl>

</div>
<div class="section" id="cam-sgnmt-predictors-tf-nizza-module">
<h3>cam.sgnmt.predictors.tf_nizza module<a class="headerlink" href="#cam-sgnmt-predictors-tf-nizza-module" title="Permalink to this headline">¶</a></h3>
<p>This module integrates Nizza alignment models.</p>
<p><a class="reference external" href="https://github.com/fstahlberg/nizza">https://github.com/fstahlberg/nizza</a></p>
<dl class="class">
<dt>
<em class="property">class </em><code class="descclassname">cam.sgnmt.predictors.tf_nizza.</code><code class="descname">BaseNizzaPredictor</code><span class="sig-paren">(</span><em>src_vocab_size</em>, <em>trg_vocab_size</em>, <em>model_name</em>, <em>hparams_set_name</em>, <em>checkpoint_dir</em>, <em>single_cpu_thread</em>, <em>nizza_unk_id=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/tf_nizza.html#BaseNizzaPredictor"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Bases: <a class="reference internal" href="cam.sgnmt.predictors.html#cam.sgnmt.predictors.core.Predictor" title="cam.sgnmt.predictors.core.Predictor"><code class="xref py py-class docutils literal"><span class="pre">cam.sgnmt.predictors.core.Predictor</span></code></a></p>
<p>Common functionality for Nizza based predictors. This includes
loading checkpoints, creating sessions, and creating computation
graphs.</p>
<p>Initializes a nizza predictor.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>src_vocab_size</strong> (<em>int</em>) &#8211; Source vocabulary size (called inputs_vocab_size
in nizza)</li>
<li><strong>trg_vocab_size</strong> (<em>int</em>) &#8211; Target vocabulary size (called targets_vocab_size
in nizza)</li>
<li><strong>model_name</strong> (<em>string</em>) &#8211; Name of the nizza model</li>
<li><strong>hparams_set_name</strong> (<em>string</em>) &#8211; Name of the nizza hyper-parameter set</li>
<li><strong>checkpoint_dir</strong> (<em>string</em>) &#8211; Path to the Nizza checkpoint directory. The
predictor will load the top most checkpoint in
the <cite>checkpoints</cite> file.</li>
<li><strong>single_cpu_thread</strong> (<em>bool</em>) &#8211; If true, prevent tensorflow from
doing multithreading.</li>
<li><strong>nizza_unk_id</strong> (<em>int</em>) &#8211; If set, use this as UNK id. Otherwise, the
nizza is assumed to have no UNKs</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Raises:</th><td class="field-body"><p class="first last">IOError if checkpoint file not found.</p>
</td>
</tr>
</tbody>
</table>
<dl class="method">
<dt>
<code class="descname">create_session</code><span class="sig-paren">(</span><em>checkpoint_dir</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/tf_nizza.html#BaseNizzaPredictor.create_session"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Creates a MonitoredSession for this predictor.</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">get_unk_probability</code><span class="sig-paren">(</span><em>posterior</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/tf_nizza.html#BaseNizzaPredictor.get_unk_probability"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Fetch posterior[t2t_unk_id] or return NEG_INF if None.</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt>
<em class="property">class </em><code class="descclassname">cam.sgnmt.predictors.tf_nizza.</code><code class="descname">LexNizzaPredictor</code><span class="sig-paren">(</span><em>src_vocab_size</em>, <em>trg_vocab_size</em>, <em>model_name</em>, <em>hparams_set_name</em>, <em>checkpoint_dir</em>, <em>single_cpu_thread</em>, <em>alpha</em>, <em>beta</em>, <em>shortlist_strategies</em>, <em>trg2src_model_name=''</em>, <em>trg2src_hparams_set_name=''</em>, <em>trg2src_checkpoint_dir=''</em>, <em>max_shortlist_length=0</em>, <em>min_id=0</em>, <em>nizza_unk_id=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/tf_nizza.html#LexNizzaPredictor"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Bases: <a class="reference internal" href="cam.sgnmt.predictors.html#cam.sgnmt.predictors.tf_nizza.BaseNizzaPredictor" title="cam.sgnmt.predictors.tf_nizza.BaseNizzaPredictor"><code class="xref py py-class docutils literal"><span class="pre">cam.sgnmt.predictors.tf_nizza.BaseNizzaPredictor</span></code></a></p>
<p>This predictor is only compatible to Model1-like Nizza models
which return lexical translation probabilities in precompute(). The
predictor keeps a list of the same length as the source sentence
and initializes it with zeros. At each timestep it updates this list
by the lexical scores Model1 assigned to the last consumed token.
The predictor score aims to bring up all entries in the list, and
thus serves as a coverage mechanism over the source sentence.</p>
<p>Initializes a nizza predictor.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>src_vocab_size</strong> (<em>int</em>) &#8211; Source vocabulary size (called inputs_vocab_size
in nizza)</li>
<li><strong>trg_vocab_size</strong> (<em>int</em>) &#8211; Target vocabulary size (called targets_vocab_size
in nizza)</li>
<li><strong>model_name</strong> (<em>string</em>) &#8211; Name of the nizza model</li>
<li><strong>hparams_set_name</strong> (<em>string</em>) &#8211; Name of the nizza hyper-parameter set</li>
<li><strong>checkpoint_dir</strong> (<em>string</em>) &#8211; Path to the Nizza checkpoint directory. The
predictor will load the top most checkpoint in
the <cite>checkpoints</cite> file.</li>
<li><strong>single_cpu_thread</strong> (<em>bool</em>) &#8211; If true, prevent tensorflow from
doing multithreading.</li>
<li><strong>alpha</strong> (<em>float</em>) &#8211; Score for each matching word</li>
<li><strong>beta</strong> (<em>float</em>) &#8211; Penalty for each uncovered word at the end</li>
<li><strong>shortlist_strategies</strong> (<em>string</em>) &#8211; Comma-separated list of shortlist
strategies.</li>
<li><strong>trg2src_model_name</strong> (<em>string</em>) &#8211; Name of the target2source nizza model</li>
<li><strong>trg2src_hparams_set_name</strong> (<em>string</em>) &#8211; Name of the nizza hyper-parameter set
for the target2source model</li>
<li><strong>trg2src_checkpoint_dir</strong> (<em>string</em>) &#8211; Path to the Nizza checkpoint directory
for the target2source model. The
predictor will load the top most checkpoint in
the <cite>checkpoints</cite> file.</li>
<li><strong>max_shortlist_length</strong> (<em>int</em>) &#8211; If a shortlist exceeds this limit,
initialize the initial coverage with 1 at this position. If
zero, do not apply any limit</li>
<li><strong>min_id</strong> (<em>int</em>) &#8211; Do not use IDs below this threshold (filters out most
frequent words).</li>
<li><strong>nizza_unk_id</strong> (<em>int</em>) &#8211; If set, use this as UNK id. Otherwise, the
nizza is assumed to have no UNKs</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Raises:</th><td class="field-body"><p class="first last">IOError if checkpoint file not found.</p>
</td>
</tr>
</tbody>
</table>
<dl class="method">
<dt>
<code class="descname">consume</code><span class="sig-paren">(</span><em>word</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/tf_nizza.html#LexNizzaPredictor.consume"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Update coverage.</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">estimate_future_cost</code><span class="sig-paren">(</span><em>hypo</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/tf_nizza.html#LexNizzaPredictor.estimate_future_cost"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>We use the number of uncovered words times beta as heuristic
estimate.</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">get_state</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/tf_nizza.html#LexNizzaPredictor.get_state"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>The predictor state is the coverage vector.</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">get_unk_probability</code><span class="sig-paren">(</span><em>posterior</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/tf_nizza.html#LexNizzaPredictor.get_unk_probability"><span class="viewcode-link">[source]</span></a></dt>
<dd></dd></dl>

<dl class="method">
<dt>
<code class="descname">initialize</code><span class="sig-paren">(</span><em>src_sentence</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/tf_nizza.html#LexNizzaPredictor.initialize"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Set src_sentence, reset consumed.</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">predict_next</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/tf_nizza.html#LexNizzaPredictor.predict_next"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Predict record scores.</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">set_state</code><span class="sig-paren">(</span><em>state</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/tf_nizza.html#LexNizzaPredictor.set_state"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>The predictor state is the coverage vector.</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt>
<em class="property">class </em><code class="descclassname">cam.sgnmt.predictors.tf_nizza.</code><code class="descname">NizzaPredictor</code><span class="sig-paren">(</span><em>src_vocab_size</em>, <em>trg_vocab_size</em>, <em>model_name</em>, <em>hparams_set_name</em>, <em>checkpoint_dir</em>, <em>single_cpu_thread</em>, <em>nizza_unk_id=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/tf_nizza.html#NizzaPredictor"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Bases: <a class="reference internal" href="cam.sgnmt.predictors.html#cam.sgnmt.predictors.tf_nizza.BaseNizzaPredictor" title="cam.sgnmt.predictors.tf_nizza.BaseNizzaPredictor"><code class="xref py py-class docutils literal"><span class="pre">cam.sgnmt.predictors.tf_nizza.BaseNizzaPredictor</span></code></a></p>
<p>This predictor uses Nizza alignment models to derive a posterior over
the target vocabulary for the next position. It mainly relies on the
predict_next_word() implementation of Nizza models.</p>
<p>Initializes a nizza predictor.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>src_vocab_size</strong> (<em>int</em>) &#8211; Source vocabulary size (called inputs_vocab_size
in nizza)</li>
<li><strong>trg_vocab_size</strong> (<em>int</em>) &#8211; Target vocabulary size (called targets_vocab_size
in nizza)</li>
<li><strong>model_name</strong> (<em>string</em>) &#8211; Name of the nizza model</li>
<li><strong>hparams_set_name</strong> (<em>string</em>) &#8211; Name of the nizza hyper-parameter set</li>
<li><strong>checkpoint_dir</strong> (<em>string</em>) &#8211; Path to the Nizza checkpoint directory. The
predictor will load the top most checkpoint in
the <cite>checkpoints</cite> file.</li>
<li><strong>single_cpu_thread</strong> (<em>bool</em>) &#8211; If true, prevent tensorflow from
doing multithreading.</li>
<li><strong>nizza_unk_id</strong> (<em>int</em>) &#8211; If set, use this as UNK id. Otherwise, the
nizza is assumed to have no UNKs</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Raises:</th><td class="field-body"><p class="first last">IOError if checkpoint file not found.</p>
</td>
</tr>
</tbody>
</table>
<dl class="method">
<dt>
<code class="descname">consume</code><span class="sig-paren">(</span><em>word</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/tf_nizza.html#NizzaPredictor.consume"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Append <code class="docutils literal"><span class="pre">word</span></code> to the current history.</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">get_state</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/tf_nizza.html#NizzaPredictor.get_state"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>The predictor state is the complete history.</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">initialize</code><span class="sig-paren">(</span><em>src_sentence</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/tf_nizza.html#NizzaPredictor.initialize"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Set src_sentence, reset consumed.</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">is_equal</code><span class="sig-paren">(</span><em>state1</em>, <em>state2</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/tf_nizza.html#NizzaPredictor.is_equal"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Returns true if the history is the same</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">predict_next</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/tf_nizza.html#NizzaPredictor.predict_next"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Call the T2T model in self.mon_sess.</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">set_state</code><span class="sig-paren">(</span><em>state</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/tf_nizza.html#NizzaPredictor.set_state"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>The predictor state is the complete history.</p>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="cam-sgnmt-predictors-tf-t2t-module">
<h3>cam.sgnmt.predictors.tf_t2t module<a class="headerlink" href="#cam-sgnmt-predictors-tf-t2t-module" title="Permalink to this headline">¶</a></h3>
<p>This is the interface to the tensor2tensor library.</p>
<p><a class="reference external" href="https://github.com/tensorflow/tensor2tensor">https://github.com/tensorflow/tensor2tensor</a></p>
<p>The t2t predictor can read any model trained with tensor2tensor which
includes the transformer model, convolutional models, and RNN-based
sequence models.</p>
<dl class="class">
<dt>
<em class="property">class </em><code class="descclassname">cam.sgnmt.predictors.tf_t2t.</code><code class="descname">EditT2TPredictor</code><span class="sig-paren">(</span><em>src_vocab_size</em>, <em>trg_vocab_size</em>, <em>model_name</em>, <em>problem_name</em>, <em>hparams_set_name</em>, <em>trg_test_file</em>, <em>beam_size</em>, <em>t2t_usr_dir</em>, <em>checkpoint_dir</em>, <em>t2t_unk_id=None</em>, <em>n_cpu_threads=-1</em>, <em>max_terminal_id=-1</em>, <em>pop_id=-1</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/tf_t2t.html#EditT2TPredictor"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal"><span class="pre">cam.sgnmt.predictors.tf_t2t._BaseTensor2TensorPredictor</span></code></p>
<p>This predictor can be used for T2T models conditioning on the
full target sentence. The predictor state is a full target sentence.
The state can be changed by insertions, substitutions, and deletions
of single tokens, whereas each operation is encoded as SGNMT token
in the following way:</p>
<blockquote>
<div>1xxxyyyyy: Insert the token yyyyy at position xxx.
2xxxyyyyy: Replace the xxx-th word with the token yyyyy.
3xxx00000: Delete the xxx-th token.</div></blockquote>
<p>Creates a new edit T2T predictor. This constructor is
similar to the constructor of T2TPredictor but creates a
different computation graph which retrieves scores at each
target position, not only the last one.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>src_vocab_size</strong> (<em>int</em>) &#8211; Source vocabulary size.</li>
<li><strong>trg_vocab_size</strong> (<em>int</em>) &#8211; Target vocabulary size.</li>
<li><strong>model_name</strong> (<em>string</em>) &#8211; T2T model name.</li>
<li><strong>problem_name</strong> (<em>string</em>) &#8211; T2T problem name.</li>
<li><strong>hparams_set_name</strong> (<em>string</em>) &#8211; T2T hparams set name.</li>
<li><strong>trg_test_file</strong> (<em>string</em>) &#8211; Path to a plain text file with
initial target sentences. Can be empty.</li>
<li><strong>beam_size</strong> (<em>int</em>) &#8211; Determines how many substitutions and
insertions are considered at each position.</li>
<li><strong>t2t_usr_dir</strong> (<em>string</em>) &#8211; See &#8211;t2t_usr_dir in tensor2tensor.</li>
<li><strong>checkpoint_dir</strong> (<em>string</em>) &#8211; Path to the T2T checkpoint
directory. The predictor will load
the top most checkpoint in the
<cite>checkpoints</cite> file.</li>
<li><strong>t2t_unk_id</strong> (<em>int</em>) &#8211; If set, use this ID to get UNK scores. If
None, UNK is always scored with -inf.</li>
<li><strong>n_cpu_threads</strong> (<em>int</em>) &#8211; Number of TensorFlow CPU threads.</li>
<li><strong>max_terminal_id</strong> (<em>int</em>) &#8211; If positive, maximum terminal ID. Needs to
be set for syntax-based T2T models.</li>
<li><strong>pop_id</strong> (<em>int</em>) &#8211; If positive, ID of the POP or closing bracket symbol.
Needs to be set for syntax-based T2T models.</li>
</ul>
</td>
</tr>
</tbody>
</table>
<dl class="attribute">
<dt>
<code class="descname">DEL_OFFSET</code><em class="property"> = 300000000</em></dt>
<dd></dd></dl>

<dl class="attribute">
<dt>
<code class="descname">INS_OFFSET</code><em class="property"> = 100000000</em></dt>
<dd></dd></dl>

<dl class="attribute">
<dt>
<code class="descname">MAX_SEQ_LEN</code><em class="property"> = 999</em></dt>
<dd></dd></dl>

<dl class="attribute">
<dt>
<code class="descname">POS_FACTOR</code><em class="property"> = 100000</em></dt>
<dd></dd></dl>

<dl class="attribute">
<dt>
<code class="descname">SUB_OFFSET</code><em class="property"> = 200000000</em></dt>
<dd></dd></dl>

<dl class="method">
<dt>
<code class="descname">consume</code><span class="sig-paren">(</span><em>word</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/tf_t2t.html#EditT2TPredictor.consume"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Append <code class="docutils literal"><span class="pre">word</span></code> to the current history.</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">get_state</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/tf_t2t.html#EditT2TPredictor.get_state"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>The predictor state is the complete target sentence.</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">initialize</code><span class="sig-paren">(</span><em>src_sentence</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/tf_t2t.html#EditT2TPredictor.initialize"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Set src_sentence, reset consumed.</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">is_equal</code><span class="sig-paren">(</span><em>state1</em>, <em>state2</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/tf_t2t.html#EditT2TPredictor.is_equal"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Returns true if the target sentence is the same</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">predict_next</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/tf_t2t.html#EditT2TPredictor.predict_next"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Call the T2T model in self.mon_sess.</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">set_state</code><span class="sig-paren">(</span><em>state</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/tf_t2t.html#EditT2TPredictor.set_state"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>The predictor state is the complete target sentence.</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt>
<em class="property">class </em><code class="descclassname">cam.sgnmt.predictors.tf_t2t.</code><code class="descname">FertilityT2TPredictor</code><span class="sig-paren">(</span><em>src_vocab_size</em>, <em>trg_vocab_size</em>, <em>model_name</em>, <em>problem_name</em>, <em>hparams_set_name</em>, <em>t2t_usr_dir</em>, <em>checkpoint_dir</em>, <em>t2t_unk_id=None</em>, <em>n_cpu_threads=-1</em>, <em>max_terminal_id=-1</em>, <em>pop_id=-1</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/tf_t2t.html#FertilityT2TPredictor"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Bases: <a class="reference internal" href="cam.sgnmt.predictors.html#cam.sgnmt.predictors.tf_t2t.T2TPredictor" title="cam.sgnmt.predictors.tf_t2t.T2TPredictor"><code class="xref py py-class docutils literal"><span class="pre">cam.sgnmt.predictors.tf_t2t.T2TPredictor</span></code></a></p>
<p>Use this predictor to integrate fertility models trained with
T2T. Fertility models output the fertility for each source word
instead of target words. We define the fertility of the i-th
source word in a hypothesis as the number of tokens between the
(i-1)-th and the i-th POP token.</p>
<p>TODO: This is not SOLID (violates substitution principle)</p>
<p>Creates a new T2T predictor. The constructor prepares the
TensorFlow session for predict_next() calls. This includes:
- Load hyper parameters from the given set (hparams)
- Update registry, load T2T model
- Create TF placeholders for source sequence and target prefix
- Create computation graph for computing log probs.
- Create a MonitoredSession object, which also handles</p>
<blockquote>
<div>restoring checkpoints.</div></blockquote>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>src_vocab_size</strong> (<em>int</em>) &#8211; Source vocabulary size.</li>
<li><strong>trg_vocab_size</strong> (<em>int</em>) &#8211; Target vocabulary size.</li>
<li><strong>model_name</strong> (<em>string</em>) &#8211; T2T model name.</li>
<li><strong>problem_name</strong> (<em>string</em>) &#8211; T2T problem name.</li>
<li><strong>hparams_set_name</strong> (<em>string</em>) &#8211; T2T hparams set name.</li>
<li><strong>t2t_usr_dir</strong> (<em>string</em>) &#8211; See &#8211;t2t_usr_dir in tensor2tensor.</li>
<li><strong>checkpoint_dir</strong> (<em>string</em>) &#8211; Path to the T2T checkpoint
directory. The predictor will load
the top most checkpoint in the
<cite>checkpoints</cite> file.</li>
<li><strong>t2t_unk_id</strong> (<em>int</em>) &#8211; If set, use this ID to get UNK scores. If
None, UNK is always scored with -inf.</li>
<li><strong>n_cpu_threads</strong> (<em>int</em>) &#8211; Number of TensorFlow CPU threads.</li>
<li><strong>max_terminal_id</strong> (<em>int</em>) &#8211; If positive, maximum terminal ID. Needs to
be set for syntax-based T2T models.</li>
<li><strong>pop_id</strong> (<em>int</em>) &#8211; If positive, ID of the POP or closing bracket symbol.
Needs to be set for syntax-based T2T models.</li>
</ul>
</td>
</tr>
</tbody>
</table>
<dl class="method">
<dt>
<code class="descname">consume</code><span class="sig-paren">(</span><em>word</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/tf_t2t.html#FertilityT2TPredictor.consume"><span class="viewcode-link">[source]</span></a></dt>
<dd></dd></dl>

<dl class="method">
<dt>
<code class="descname">get_state</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/tf_t2t.html#FertilityT2TPredictor.get_state"><span class="viewcode-link">[source]</span></a></dt>
<dd></dd></dl>

<dl class="method">
<dt>
<code class="descname">get_unk_probability</code><span class="sig-paren">(</span><em>posterior</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/tf_t2t.html#FertilityT2TPredictor.get_unk_probability"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Returns self.other_scores[n_aligned_words].</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">initialize</code><span class="sig-paren">(</span><em>src_sentence</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/tf_t2t.html#FertilityT2TPredictor.initialize"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Set src_sentence, compute fertilities for first src word.</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">is_equal</code><span class="sig-paren">(</span><em>state1</em>, <em>state2</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/tf_t2t.html#FertilityT2TPredictor.is_equal"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Returns true if the history is the same</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">predict_next</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/tf_t2t.html#FertilityT2TPredictor.predict_next"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Returns self.pop_scores[n_aligned_words] for POP and EOS.</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">set_state</code><span class="sig-paren">(</span><em>state</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/tf_t2t.html#FertilityT2TPredictor.set_state"><span class="viewcode-link">[source]</span></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="data">
<dt>
<code class="descclassname">cam.sgnmt.predictors.tf_t2t.</code><code class="descname">POP</code><em class="property"> = '##POP##'</em></dt>
<dd><p>Textual representation of the POP symbol.</p>
</dd></dl>

<dl class="class">
<dt>
<em class="property">class </em><code class="descclassname">cam.sgnmt.predictors.tf_t2t.</code><code class="descname">SegT2TPredictor</code><span class="sig-paren">(</span><em>src_vocab_size</em>, <em>trg_vocab_size</em>, <em>model_name</em>, <em>problem_name</em>, <em>hparams_set_name</em>, <em>t2t_usr_dir</em>, <em>checkpoint_dir</em>, <em>t2t_unk_id=None</em>, <em>n_cpu_threads=-1</em>, <em>max_terminal_id=-1</em>, <em>pop_id=-1</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/tf_t2t.html#SegT2TPredictor"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal"><span class="pre">cam.sgnmt.predictors.tf_t2t._BaseTensor2TensorPredictor</span></code></p>
<p>This predictor is designed for document-level T2T models. It
differs from the normal t2t predictor in the following ways:</p>
<ul class="simple">
<li>In addition to <cite>input</cite> and <cite>targets</cite>, it generates the features
<cite>inputs_seg</cite>. <cite>targets_seg</cite>, <cite>inputs_pos</cite>, <cite>targets_pos</cite> which
are used in glue models and the contextual Transformer.</li>
<li>The history is pruned when it exceeds a maximum number of &lt;s&gt;
symbols. This can be used to reduce complexity for document-level
models on very long documents. When the maximum number is reached,
we start removing sentences from <code class="docutils literal"><span class="pre">self.consumed</span></code>, starting with
the sentence which is <cite>begin_margin</cite> away from the document start
and <cite>end_margin</cite> sentences away from the current sentence.</li>
</ul>
<p>Creates a new document-level T2T predictor. See
T2TPredictor.__init__().</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>src_vocab_size</strong> (<em>int</em>) &#8211; Source vocabulary size.</li>
<li><strong>trg_vocab_size</strong> (<em>int</em>) &#8211; Target vocabulary size.</li>
<li><strong>model_name</strong> (<em>string</em>) &#8211; T2T model name.</li>
<li><strong>problem_name</strong> (<em>string</em>) &#8211; T2T problem name.</li>
<li><strong>hparams_set_name</strong> (<em>string</em>) &#8211; T2T hparams set name.</li>
<li><strong>t2t_usr_dir</strong> (<em>string</em>) &#8211; See &#8211;t2t_usr_dir in tensor2tensor.</li>
<li><strong>checkpoint_dir</strong> (<em>string</em>) &#8211; Path to the T2T checkpoint
directory. The predictor will load
the top most checkpoint in the
<cite>checkpoints</cite> file.</li>
<li><strong>t2t_unk_id</strong> (<em>int</em>) &#8211; If set, use this ID to get UNK scores. If
None, UNK is always scored with -inf.</li>
<li><strong>n_cpu_threads</strong> (<em>int</em>) &#8211; Number of TensorFlow CPU threads.</li>
<li><strong>max_terminal_id</strong> (<em>int</em>) &#8211; If positive, maximum terminal ID. Needs to
be set for syntax-based T2T models.</li>
<li><strong>pop_id</strong> (<em>int</em>) &#8211; If positive, ID of the POP or closing bracket symbol.
Needs to be set for syntax-based T2T models.</li>
</ul>
</td>
</tr>
</tbody>
</table>
<dl class="method">
<dt>
<code class="descname">consume</code><span class="sig-paren">(</span><em>word</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/tf_t2t.html#SegT2TPredictor.consume"><span class="viewcode-link">[source]</span></a></dt>
<dd></dd></dl>

<dl class="method">
<dt>
<code class="descname">get_state</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/tf_t2t.html#SegT2TPredictor.get_state"><span class="viewcode-link">[source]</span></a></dt>
<dd></dd></dl>

<dl class="method">
<dt>
<code class="descname">get_unk_probability</code><span class="sig-paren">(</span><em>posterior</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/tf_t2t.html#SegT2TPredictor.get_unk_probability"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Fetch posterior[t2t_unk_id]</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">initialize</code><span class="sig-paren">(</span><em>src_sentence</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/tf_t2t.html#SegT2TPredictor.initialize"><span class="viewcode-link">[source]</span></a></dt>
<dd></dd></dl>

<dl class="method">
<dt>
<code class="descname">is_equal</code><span class="sig-paren">(</span><em>state1</em>, <em>state2</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/tf_t2t.html#SegT2TPredictor.is_equal"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Returns true if the (pruned) history is the same</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">predict_next</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/tf_t2t.html#SegT2TPredictor.predict_next"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Call the T2T model in self.mon_sess.</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">set_state</code><span class="sig-paren">(</span><em>state</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/tf_t2t.html#SegT2TPredictor.set_state"><span class="viewcode-link">[source]</span></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="class">
<dt>
<em class="property">class </em><code class="descclassname">cam.sgnmt.predictors.tf_t2t.</code><code class="descname">T2TPredictor</code><span class="sig-paren">(</span><em>src_vocab_size</em>, <em>trg_vocab_size</em>, <em>model_name</em>, <em>problem_name</em>, <em>hparams_set_name</em>, <em>t2t_usr_dir</em>, <em>checkpoint_dir</em>, <em>t2t_unk_id=None</em>, <em>n_cpu_threads=-1</em>, <em>max_terminal_id=-1</em>, <em>pop_id=-1</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/tf_t2t.html#T2TPredictor"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal"><span class="pre">cam.sgnmt.predictors.tf_t2t._BaseTensor2TensorPredictor</span></code></p>
<p>This predictor implements scoring with Tensor2Tensor models. We
follow the decoder implementation in T2T and do not reuse network
states in decoding. We rather compute the full forward pass along
the current history. Therefore, the decoder state is simply the
the full history of consumed words.</p>
<p>Creates a new T2T predictor. The constructor prepares the
TensorFlow session for predict_next() calls. This includes:
- Load hyper parameters from the given set (hparams)
- Update registry, load T2T model
- Create TF placeholders for source sequence and target prefix
- Create computation graph for computing log probs.
- Create a MonitoredSession object, which also handles</p>
<blockquote>
<div>restoring checkpoints.</div></blockquote>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>src_vocab_size</strong> (<em>int</em>) &#8211; Source vocabulary size.</li>
<li><strong>trg_vocab_size</strong> (<em>int</em>) &#8211; Target vocabulary size.</li>
<li><strong>model_name</strong> (<em>string</em>) &#8211; T2T model name.</li>
<li><strong>problem_name</strong> (<em>string</em>) &#8211; T2T problem name.</li>
<li><strong>hparams_set_name</strong> (<em>string</em>) &#8211; T2T hparams set name.</li>
<li><strong>t2t_usr_dir</strong> (<em>string</em>) &#8211; See &#8211;t2t_usr_dir in tensor2tensor.</li>
<li><strong>checkpoint_dir</strong> (<em>string</em>) &#8211; Path to the T2T checkpoint
directory. The predictor will load
the top most checkpoint in the
<cite>checkpoints</cite> file.</li>
<li><strong>t2t_unk_id</strong> (<em>int</em>) &#8211; If set, use this ID to get UNK scores. If
None, UNK is always scored with -inf.</li>
<li><strong>n_cpu_threads</strong> (<em>int</em>) &#8211; Number of TensorFlow CPU threads.</li>
<li><strong>max_terminal_id</strong> (<em>int</em>) &#8211; If positive, maximum terminal ID. Needs to
be set for syntax-based T2T models.</li>
<li><strong>pop_id</strong> (<em>int</em>) &#8211; If positive, ID of the POP or closing bracket symbol.
Needs to be set for syntax-based T2T models.</li>
</ul>
</td>
</tr>
</tbody>
</table>
<dl class="method">
<dt>
<code class="descname">consume</code><span class="sig-paren">(</span><em>word</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/tf_t2t.html#T2TPredictor.consume"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Append <code class="docutils literal"><span class="pre">word</span></code> to the current history.</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">get_state</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/tf_t2t.html#T2TPredictor.get_state"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>The predictor state is the complete history.</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">initialize</code><span class="sig-paren">(</span><em>src_sentence</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/tf_t2t.html#T2TPredictor.initialize"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Set src_sentence, reset consumed.</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">is_equal</code><span class="sig-paren">(</span><em>state1</em>, <em>state2</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/tf_t2t.html#T2TPredictor.is_equal"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Returns true if the history is the same</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">predict_next</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/tf_t2t.html#T2TPredictor.predict_next"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Call the T2T model in self.mon_sess.</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">set_state</code><span class="sig-paren">(</span><em>state</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/tf_t2t.html#T2TPredictor.set_state"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>The predictor state is the complete history.</p>
</dd></dl>

</dd></dl>

<dl class="data">
<dt>
<code class="descclassname">cam.sgnmt.predictors.tf_t2t.</code><code class="descname">T2T_INITIALIZED</code><em class="property"> = False</em></dt>
<dd><p>Set to true by _initialize_t2t() after first constructor call.</p>
</dd></dl>

<dl class="function">
<dt>
<code class="descclassname">cam.sgnmt.predictors.tf_t2t.</code><code class="descname">expand_input_dims_for_t2t</code><span class="sig-paren">(</span><em>t</em>, <em>batched=False</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/tf_t2t.html#expand_input_dims_for_t2t"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Expands a plain input tensor for using it in a T2T graph.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>t</strong> &#8211; Tensor</li>
<li><strong>batched</strong> &#8211; Whether to expand on the left side</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first last">Tensor <cite>t</cite> expanded by 1 dimension on the left and two dimensions
on the right.</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt>
<code class="descclassname">cam.sgnmt.predictors.tf_t2t.</code><code class="descname">gather_2d</code><span class="sig-paren">(</span><em>params</em>, <em>indices</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/tf_t2t.html#gather_2d"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>This is a batched version of tf.gather(), ie. it applies tf.gather() to
each batch separately.</p>
<p class="rubric">Example</p>
<dl class="docutils">
<dt>params = [[10, 11, 12, 13, 14],</dt>
<dd>[20, 21, 22, 23, 24]]</dd>
<dt>indices = [[0, 0, 1, 1, 1, 2],</dt>
<dd>[1, 3, 0, 0, 2, 2]]</dd>
<dt>result = [[10, 10, 11, 11, 11, 12],</dt>
<dd>[21, 23, 20, 20, 22, 22]]</dd>
</dl>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>params</strong> &#8211; A [batch_size, n, ...] tensor with data</li>
<li><strong>indices</strong> &#8211; A [batch_size, num_indices] int32 tensor with indices into params.
Entries must be smaller than n</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first last">The result of tf.gather() on each entry of the batch.</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt>
<code class="descclassname">cam.sgnmt.predictors.tf_t2t.</code><code class="descname">log_prob_from_logits</code><span class="sig-paren">(</span><em>logits</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/tf_t2t.html#log_prob_from_logits"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Softmax function.</p>
</dd></dl>

</div>
<div class="section" id="cam-sgnmt-predictors-tokenization-module">
<h3>cam.sgnmt.predictors.tokenization module<a class="headerlink" href="#cam-sgnmt-predictors-tokenization-module" title="Permalink to this headline">¶</a></h3>
<p>This module contains wrapper predictors which support decoding with
diverse tokenization. The <code class="docutils literal"><span class="pre">Word2charPredictor</span></code> can be used if the
decoder operates on fine-grained tokens such as characters, but the
tokenization of a predictor is coarse-grained (e.g. words or subwords).</p>
<p>The <code class="docutils literal"><span class="pre">word2char</span></code> predictor maintains an explicit list of word boundary
characters and applies consume and predict_next whenever a word boundary
character is consumed.</p>
<p>The <code class="docutils literal"><span class="pre">fsttok</span></code> predictor also masks coarse grained predictors when SGNMT
uses fine-grained tokens such as characters. This wrapper loads an FST
which transduces character to predictor-unit sequences.</p>
<dl class="class">
<dt>
<em class="property">class </em><code class="descclassname">cam.sgnmt.predictors.tokenization.</code><code class="descname">CombinedState</code><span class="sig-paren">(</span><em>fst_node</em>, <em>pred_state</em>, <em>posterior</em>, <em>unconsumed=[]</em>, <em>pending_score=0.0</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/tokenization.html#CombinedState"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal"><span class="pre">object</span></code></p>
<p>Combines an FST state with predictor state. Use by the fsttok
predictor.</p>
<dl class="method">
<dt>
<code class="descname">consume_all</code><span class="sig-paren">(</span><em>predictor</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/tokenization.html#CombinedState.consume_all"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Consume all unconsumed tokens and update pred_state,
pending_score, and posterior accordingly.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>predictor</strong> (<a class="reference internal" href="cam.sgnmt.predictors.html#cam.sgnmt.predictors.core.Predictor" title="cam.sgnmt.predictors.core.Predictor"><em>Predictor</em></a>) &#8211; Predictor instance</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">consume_single</code><span class="sig-paren">(</span><em>predictor</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/tokenization.html#CombinedState.consume_single"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Consume a single token in <code class="docutils literal"><span class="pre">self.unconsumed</span></code>.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>predictor</strong> (<a class="reference internal" href="cam.sgnmt.predictors.html#cam.sgnmt.predictors.core.Predictor" title="cam.sgnmt.predictors.core.Predictor"><em>Predictor</em></a>) &#8211; Predictor instance</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">score</code><span class="sig-paren">(</span><em>token</em>, <em>predictor</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/tokenization.html#CombinedState.score"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Returns a score which can be added if <code class="docutils literal"><span class="pre">token</span></code> is consumed
next. This is not necessarily the full score but an upper bound
on it: Continuations will have a score lower or equal than
this. We only use the current posterior vector and do not
consume tokens with the wrapped predictor.</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">traverse_fst</code><span class="sig-paren">(</span><em>trans_fst</em>, <em>char</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/tokenization.html#CombinedState.traverse_fst"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Returns a list of <code class="docutils literal"><span class="pre">CombinedState``s</span> <span class="pre">with</span> <span class="pre">the</span> <span class="pre">same</span> <span class="pre">predictor</span>
<span class="pre">state</span> <span class="pre">and</span> <span class="pre">posterior,</span> <span class="pre">but</span> <span class="pre">an</span> <span class="pre">``fst_node</span></code> which is reachable
via the input label <code class="docutils literal"><span class="pre">char</span></code>. If the output tabe contains
symbols, add them to <code class="docutils literal"><span class="pre">unconsumed</span></code>.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>trans_fst</strong> (<em>Fst</em>) &#8211; FST to traverse</li>
<li><strong>char</strong> (<em>int</em>) &#8211; Index of character</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first last">list. List of combined states reachable via <code class="docutils literal"><span class="pre">char</span></code></p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">update_posterior</code><span class="sig-paren">(</span><em>predictor</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/tokenization.html#CombinedState.update_posterior"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>If <code class="docutils literal"><span class="pre">self.posterior</span></code> is None, call <code class="docutils literal"><span class="pre">predict_next</span></code> to
be able to score the next tokens.</p>
</dd></dl>

</dd></dl>

<dl class="data">
<dt>
<code class="descclassname">cam.sgnmt.predictors.tokenization.</code><code class="descname">EPS_ID</code><em class="property"> = 0</em></dt>
<dd><p>OpenFST&#8217;s reserved ID for epsilon arcs.</p>
</dd></dl>

<dl class="class">
<dt>
<em class="property">class </em><code class="descclassname">cam.sgnmt.predictors.tokenization.</code><code class="descname">FSTTokPredictor</code><span class="sig-paren">(</span><em>path</em>, <em>fst_unk_id</em>, <em>max_pending_score</em>, <em>slave_predictor</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/tokenization.html#FSTTokPredictor"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Bases: <a class="reference internal" href="cam.sgnmt.predictors.html#cam.sgnmt.predictors.core.Predictor" title="cam.sgnmt.predictors.core.Predictor"><code class="xref py py-class docutils literal"><span class="pre">cam.sgnmt.predictors.core.Predictor</span></code></a></p>
<p>This wrapper can be used if the SGNMT decoder operates on the
character level, but a predictor uses a more coarse grained
tokenization. The mapping is defined by an FST which transduces
character to predictor unit sequences. This wrapper maintains a
list of <code class="docutils literal"><span class="pre">CombinedState</span></code> objects which are tuples of an FST node
and a predictor state for which holds:</p>
<ul class="simple">
<li>The input labels on the path to the node are consistent with the
consumed characters</li>
<li>The output labels on the path to the node are consistent with the
predictor states</li>
</ul>
<p>Constructor for the fsttok wrapper</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>path</strong> (<em>string</em>) &#8211; Path to an FST which transduces characters
to predictor tokens</li>
<li><strong>fst_unk_id</strong> (<em>int</em>) &#8211; ID used to represent UNK in the FSTs
(usually 999999998)</li>
<li><strong>max_pending_score</strong> (<em>float</em>) &#8211; Maximum pending score in a
<code class="docutils literal"><span class="pre">CombinedState</span></code> instance.</li>
<li><strong>slave_predictor</strong> (<a class="reference internal" href="cam.sgnmt.predictors.html#cam.sgnmt.predictors.core.Predictor" title="cam.sgnmt.predictors.core.Predictor"><em>Predictor</em></a>) &#8211; Wrapped predictor</li>
</ul>
</td>
</tr>
</tbody>
</table>
<dl class="method">
<dt>
<code class="descname">consume</code><span class="sig-paren">(</span><em>word</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/tokenization.html#FSTTokPredictor.consume"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Update <code class="docutils literal"><span class="pre">self.states</span></code> to be consistent with <code class="docutils literal"><span class="pre">word</span></code> and
consumes all the predictor tokens.</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">estimate_future_cost</code><span class="sig-paren">(</span><em>hypo</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/tokenization.html#FSTTokPredictor.estimate_future_cost"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Not implemented yet</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">get_state</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/tokenization.html#FSTTokPredictor.get_state"><span class="viewcode-link">[source]</span></a></dt>
<dd></dd></dl>

<dl class="method">
<dt>
<code class="descname">get_unk_probability</code><span class="sig-paren">(</span><em>posterior</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/tokenization.html#FSTTokPredictor.get_unk_probability"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Always returns negative infinity. Handling UNKs needs to be
realized by the FST.</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">initialize</code><span class="sig-paren">(</span><em>src_sentence</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/tokenization.html#FSTTokPredictor.initialize"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Pass through to slave predictor. The source sentence is not
modified. <code class="docutils literal"><span class="pre">states</span></code> is updated to the initial FST node and
predictor posterior and state.</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">initialize_heuristic</code><span class="sig-paren">(</span><em>src_sentence</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/tokenization.html#FSTTokPredictor.initialize_heuristic"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Pass through to slave predictor. The source sentence is not
modified</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">is_equal</code><span class="sig-paren">(</span><em>state1</em>, <em>state2</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/tokenization.html#FSTTokPredictor.is_equal"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Not implemented yet</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">predict_next</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/tokenization.html#FSTTokPredictor.predict_next"><span class="viewcode-link">[source]</span></a></dt>
<dd></dd></dl>

<dl class="method">
<dt>
<code class="descname">set_current_sen_id</code><span class="sig-paren">(</span><em>cur_sen_id</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/tokenization.html#FSTTokPredictor.set_current_sen_id"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>We need to override this method to propagate current_
sentence_id to the slave predictor</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">set_state</code><span class="sig-paren">(</span><em>state</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/tokenization.html#FSTTokPredictor.set_state"><span class="viewcode-link">[source]</span></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="class">
<dt>
<em class="property">class </em><code class="descclassname">cam.sgnmt.predictors.tokenization.</code><code class="descname">Word2charPredictor</code><span class="sig-paren">(</span><em>map_path</em>, <em>slave_predictor</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/tokenization.html#Word2charPredictor"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Bases: <a class="reference internal" href="cam.sgnmt.predictors.html#cam.sgnmt.predictors.core.UnboundedVocabularyPredictor" title="cam.sgnmt.predictors.core.UnboundedVocabularyPredictor"><code class="xref py py-class docutils literal"><span class="pre">cam.sgnmt.predictors.core.UnboundedVocabularyPredictor</span></code></a></p>
<p>This predictor wraps word level predictors when SGNMT is running
on the character level. The mapping between word ID and character
ID sequence is loaded from the file system. All characters which
do not appear in that mapping are treated as word boundary
makers. The wrapper blocks consume and predict_next calls until a
word boundary marker is consumed, and updates the slave predictor
according the word between the last two word boundaries. The
mapping is done only on the target side, and the source sentences
are passed through as they are. To use alternative tokenization on
the source side, see the altsrc predictor wrapper. The word2char
wrapper is always an <code class="docutils literal"><span class="pre">UnboundedVocabularyPredictor</span></code>.</p>
<p>Creates a new word2char wrapper predictor. The map_path
file has to be plain text files, each line containing the
mapping from a word index to the character index sequence
(format: word char1 char2... charn).</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>map_path</strong> (<em>string</em>) &#8211; Path to the mapping file</li>
<li><strong>slave_predictor</strong> (<a class="reference internal" href="cam.sgnmt.predictors.html#cam.sgnmt.predictors.core.Predictor" title="cam.sgnmt.predictors.core.Predictor"><em>Predictor</em></a>) &#8211; Instance of the predictor with
a different wmap than SGNMT</li>
</ul>
</td>
</tr>
</tbody>
</table>
<dl class="method">
<dt>
<code class="descname">consume</code><span class="sig-paren">(</span><em>word</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/tokenization.html#Word2charPredictor.consume"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>If <code class="docutils literal"><span class="pre">word</span></code> is a word boundary marker, truncate <code class="docutils literal"><span class="pre">word_stub</span></code>
and let the slave predictor consume word_stub. Otherwise,
extend <code class="docutils literal"><span class="pre">word_stub</span></code> by the character.</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">estimate_future_cost</code><span class="sig-paren">(</span><em>hypo</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/tokenization.html#Word2charPredictor.estimate_future_cost"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Not supported</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">get_state</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/tokenization.html#Word2charPredictor.get_state"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Pass through to slave predictor</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">get_unk_probability</code><span class="sig-paren">(</span><em>posterior</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/tokenization.html#Word2charPredictor.get_unk_probability"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>This is about the unkown character, not word. Since the word
level slave predictor has no notion of the unknown character,
we return NEG_INF unconditionally.</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">initialize</code><span class="sig-paren">(</span><em>src_sentence</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/tokenization.html#Word2charPredictor.initialize"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Pass through to slave predictor. The source sentence is not
modified</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">initialize_heuristic</code><span class="sig-paren">(</span><em>src_sentence</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/tokenization.html#Word2charPredictor.initialize_heuristic"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Pass through to slave predictor. The source sentence is not
modified</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">is_equal</code><span class="sig-paren">(</span><em>state1</em>, <em>state2</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/tokenization.html#Word2charPredictor.is_equal"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Pass through to slave predictor</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">predict_next</code><span class="sig-paren">(</span><em>trgt_words</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/tokenization.html#Word2charPredictor.predict_next"><span class="viewcode-link">[source]</span></a></dt>
<dd></dd></dl>

<dl class="method">
<dt>
<code class="descname">set_current_sen_id</code><span class="sig-paren">(</span><em>cur_sen_id</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/tokenization.html#Word2charPredictor.set_current_sen_id"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>We need to override this method to propagate current_
sentence_id to the slave predictor</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">set_state</code><span class="sig-paren">(</span><em>state</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/tokenization.html#Word2charPredictor.set_state"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Pass through to slave predictor</p>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="cam-sgnmt-predictors-vocabulary-module">
<h3>cam.sgnmt.predictors.vocabulary module<a class="headerlink" href="#cam-sgnmt-predictors-vocabulary-module" title="Permalink to this headline">¶</a></h3>
<p>Predictor wrappers in this module work with the vocabulary of the
wrapped predictor. An example is the idxmap wrapper which makes it
possible to use an alternative word map.</p>
<dl class="class">
<dt>
<em class="property">class </em><code class="descclassname">cam.sgnmt.predictors.vocabulary.</code><code class="descname">IdxmapPredictor</code><span class="sig-paren">(</span><em>src_idxmap_path</em>, <em>trgt_idxmap_path</em>, <em>slave_predictor</em>, <em>slave_weight</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/vocabulary.html#IdxmapPredictor"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Bases: <a class="reference internal" href="cam.sgnmt.predictors.html#cam.sgnmt.predictors.core.Predictor" title="cam.sgnmt.predictors.core.Predictor"><code class="xref py py-class docutils literal"><span class="pre">cam.sgnmt.predictors.core.Predictor</span></code></a></p>
<p>This wrapper predictor can be applied to slave predictors which
use different wmaps than SGNMT. It translates between SGNMT word
indices and predictors indices each time the predictor is called.
This mapping is transparent to both the decoder and the wrapped
slave predictor.</p>
<p>Creates a new idxmap wrapper predictor. The index maps have
to be plain text files, each line containing the mapping from
a SGNMT word index to the slave predictor word index.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>src_idxmap_path</strong> (<em>string</em>) &#8211; Path to the source index map</li>
<li><strong>trgt_idxmap_path</strong> (<em>string</em>) &#8211; Path to the target index map</li>
<li><strong>slave_predictor</strong> (<a class="reference internal" href="cam.sgnmt.predictors.html#cam.sgnmt.predictors.core.Predictor" title="cam.sgnmt.predictors.core.Predictor"><em>Predictor</em></a>) &#8211; Instance of the predictor with
a different wmap than SGNMT</li>
<li><strong>slave_weight</strong> (<em>float</em>) &#8211; Slave predictor weight</li>
</ul>
</td>
</tr>
</tbody>
</table>
<dl class="method">
<dt>
<code class="descname">consume</code><span class="sig-paren">(</span><em>word</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/vocabulary.html#IdxmapPredictor.consume"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Pass through to slave predictor</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">estimate_future_cost</code><span class="sig-paren">(</span><em>hypo</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/vocabulary.html#IdxmapPredictor.estimate_future_cost"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Pass through to slave predictor</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">get_state</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/vocabulary.html#IdxmapPredictor.get_state"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Pass through to slave predictor</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">get_unk_probability</code><span class="sig-paren">(</span><em>posterior</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/vocabulary.html#IdxmapPredictor.get_unk_probability"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>ATTENTION: We should translate the posterior array
back to slave predictor indices. However, the unk_id is
translated to the identical index, and others normally do not
matter when computing the UNK probability. Therefore, we
refrain from a complete conversion and pass through
<code class="docutils literal"><span class="pre">posterior</span></code> without changing its word indices.</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">initialize</code><span class="sig-paren">(</span><em>src_sentence</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/vocabulary.html#IdxmapPredictor.initialize"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Pass through to slave predictor</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">initialize_heuristic</code><span class="sig-paren">(</span><em>src_sentence</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/vocabulary.html#IdxmapPredictor.initialize_heuristic"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Pass through to slave predictor</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">is_equal</code><span class="sig-paren">(</span><em>state1</em>, <em>state2</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/vocabulary.html#IdxmapPredictor.is_equal"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Pass through to slave predictor</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">load_map</code><span class="sig-paren">(</span><em>path</em>, <em>name</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/vocabulary.html#IdxmapPredictor.load_map"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Load a index map file. Mappings should be bijections, but
there is no sanity check in place to verify this.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>path</strong> (<em>string</em>) &#8211; Path to the mapping file</li>
<li><strong>name</strong> (<em>string</em>) &#8211; &#8216;source&#8217; or &#8216;target&#8217; for error messages</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first last">dict. Mapping from SGNMT index to slave predictor index</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">predict_next</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/vocabulary.html#IdxmapPredictor.predict_next"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Pass through to slave predictor</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">set_current_sen_id</code><span class="sig-paren">(</span><em>cur_sen_id</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/vocabulary.html#IdxmapPredictor.set_current_sen_id"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>We need to override this method to propagate current_
sentence_id to the slave predictor</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">set_state</code><span class="sig-paren">(</span><em>state</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/vocabulary.html#IdxmapPredictor.set_state"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Pass through to slave predictor</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt>
<em class="property">class </em><code class="descclassname">cam.sgnmt.predictors.vocabulary.</code><code class="descname">MaskvocabPredictor</code><span class="sig-paren">(</span><em>words</em>, <em>slave_predictor</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/vocabulary.html#MaskvocabPredictor"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Bases: <a class="reference internal" href="cam.sgnmt.predictors.html#cam.sgnmt.predictors.core.Predictor" title="cam.sgnmt.predictors.core.Predictor"><code class="xref py py-class docutils literal"><span class="pre">cam.sgnmt.predictors.core.Predictor</span></code></a></p>
<p>This wrapper predictor hides certain words in the SGNMT
vocabulary from the predictor. Those words are scored by the
masked predictor with zero. The wrapper passes through consume()
only for other words.</p>
<p>Creates a new idxmap wrapper predictor. The index maps have
to be plain text files, each line containing the mapping from
a SGNMT word index to the slave predictor word index.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>words</strong> (<em>set</em>) &#8211; List of masked words</li>
<li><strong>slave_predictor</strong> (<a class="reference internal" href="cam.sgnmt.predictors.html#cam.sgnmt.predictors.core.Predictor" title="cam.sgnmt.predictors.core.Predictor"><em>Predictor</em></a>) &#8211; Instance of the predictor with
a different wmap than SGNMT</li>
</ul>
</td>
</tr>
</tbody>
</table>
<dl class="method">
<dt>
<code class="descname">consume</code><span class="sig-paren">(</span><em>word</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/vocabulary.html#MaskvocabPredictor.consume"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Pass through to slave predictor</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">estimate_future_cost</code><span class="sig-paren">(</span><em>hypo</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/vocabulary.html#MaskvocabPredictor.estimate_future_cost"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Pass through to slave predictor</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">get_state</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/vocabulary.html#MaskvocabPredictor.get_state"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Pass through to slave predictor</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">get_unk_probability</code><span class="sig-paren">(</span><em>posterior</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/vocabulary.html#MaskvocabPredictor.get_unk_probability"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Pass through to slave predictor</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">initialize</code><span class="sig-paren">(</span><em>src_sentence</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/vocabulary.html#MaskvocabPredictor.initialize"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Pass through to slave predictor</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">initialize_heuristic</code><span class="sig-paren">(</span><em>src_sentence</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/vocabulary.html#MaskvocabPredictor.initialize_heuristic"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Pass through to slave predictor</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">is_equal</code><span class="sig-paren">(</span><em>state1</em>, <em>state2</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/vocabulary.html#MaskvocabPredictor.is_equal"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Pass through to slave predictor</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">predict_next</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/vocabulary.html#MaskvocabPredictor.predict_next"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Pass through to slave predictor, set masked to 0.0</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">set_current_sen_id</code><span class="sig-paren">(</span><em>cur_sen_id</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/vocabulary.html#MaskvocabPredictor.set_current_sen_id"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>We need to override this method to propagate current_
sentence_id to the slave predictor</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">set_state</code><span class="sig-paren">(</span><em>state</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/vocabulary.html#MaskvocabPredictor.set_state"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Pass through to slave predictor</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt>
<em class="property">class </em><code class="descclassname">cam.sgnmt.predictors.vocabulary.</code><code class="descname">SkipvocabInternalHypothesis</code><span class="sig-paren">(</span><em>score</em>, <em>predictor_state</em>, <em>word_to_consume</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/vocabulary.html#SkipvocabInternalHypothesis"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal"><span class="pre">object</span></code></p>
<p>Helper class for internal beam search in skipvocab.</p>
</dd></dl>

<dl class="class">
<dt>
<em class="property">class </em><code class="descclassname">cam.sgnmt.predictors.vocabulary.</code><code class="descname">SkipvocabPredictor</code><span class="sig-paren">(</span><em>max_id</em>, <em>stop_size</em>, <em>beam</em>, <em>slave_predictor</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/vocabulary.html#SkipvocabPredictor"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Bases: <a class="reference internal" href="cam.sgnmt.predictors.html#cam.sgnmt.predictors.core.Predictor" title="cam.sgnmt.predictors.core.Predictor"><code class="xref py py-class docutils literal"><span class="pre">cam.sgnmt.predictors.core.Predictor</span></code></a></p>
<p>This predictor wrapper masks predictors with a larger vocabulary
than the SGNMT vocabulary. The SGNMT OOV words are not scored with
UNK scores from the other predictors like usual, but are hidden by
this wrapper. Therefore, this wrapper does not produce any word
from the larger vocabulary, but searches internally until enough
in-vocabulary word scores are collected from the wrapped predictor.</p>
<p>Creates a new skipvocab wrapper predictor.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>max_id</strong> (<em>int</em>) &#8211; All words greater than this are skipped</li>
<li><strong>stop_size</strong> (<em>int</em>) &#8211; Stop internal beam search when the best
stop_size words are in-vocabulary</li>
<li><strong>beam</strong> (<em>int</em>) &#8211; Beam size of internal beam search</li>
<li><strong>slave_predictor</strong> (<a class="reference internal" href="cam.sgnmt.predictors.html#cam.sgnmt.predictors.core.Predictor" title="cam.sgnmt.predictors.core.Predictor"><em>Predictor</em></a>) &#8211; Wrapped predictor.</li>
</ul>
</td>
</tr>
</tbody>
</table>
<dl class="method">
<dt>
<code class="descname">consume</code><span class="sig-paren">(</span><em>word</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/vocabulary.html#SkipvocabPredictor.consume"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Pass through to slave predictor</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">estimate_future_cost</code><span class="sig-paren">(</span><em>hypo</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/vocabulary.html#SkipvocabPredictor.estimate_future_cost"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Pass through to slave predictor</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">get_state</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/vocabulary.html#SkipvocabPredictor.get_state"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Pass through to slave predictor</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">get_unk_probability</code><span class="sig-paren">(</span><em>posterior</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/vocabulary.html#SkipvocabPredictor.get_unk_probability"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Pass through to slave predictor</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">initialize</code><span class="sig-paren">(</span><em>src_sentence</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/vocabulary.html#SkipvocabPredictor.initialize"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Pass through to slave predictor</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">initialize_heuristic</code><span class="sig-paren">(</span><em>src_sentence</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/vocabulary.html#SkipvocabPredictor.initialize_heuristic"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Pass through to slave predictor</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">is_equal</code><span class="sig-paren">(</span><em>state1</em>, <em>state2</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/vocabulary.html#SkipvocabPredictor.is_equal"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Pass through to slave predictor</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">predict_next</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/vocabulary.html#SkipvocabPredictor.predict_next"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>This method first performs beam search internally to update
the slave predictor state to a point where the best stop_size
entries in the predict_next() return value are in-vocabulary
(bounded by max_id). Then, it returns the slave posterior in
that state.</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">set_current_sen_id</code><span class="sig-paren">(</span><em>cur_sen_id</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/vocabulary.html#SkipvocabPredictor.set_current_sen_id"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>We need to override this method to propagate current_
sentence_id to the slave predictor</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">set_state</code><span class="sig-paren">(</span><em>state</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/vocabulary.html#SkipvocabPredictor.set_state"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Pass through to slave predictor</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt>
<em class="property">class </em><code class="descclassname">cam.sgnmt.predictors.vocabulary.</code><code class="descname">UnboundedIdxmapPredictor</code><span class="sig-paren">(</span><em>src_idxmap_path</em>, <em>trgt_idxmap_path</em>, <em>slave_predictor</em>, <em>slave_weight</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/vocabulary.html#UnboundedIdxmapPredictor"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Bases: <a class="reference internal" href="cam.sgnmt.predictors.html#cam.sgnmt.predictors.vocabulary.IdxmapPredictor" title="cam.sgnmt.predictors.vocabulary.IdxmapPredictor"><code class="xref py py-class docutils literal"><span class="pre">cam.sgnmt.predictors.vocabulary.IdxmapPredictor</span></code></a>, <a class="reference internal" href="cam.sgnmt.predictors.html#cam.sgnmt.predictors.core.UnboundedVocabularyPredictor" title="cam.sgnmt.predictors.core.UnboundedVocabularyPredictor"><code class="xref py py-class docutils literal"><span class="pre">cam.sgnmt.predictors.core.UnboundedVocabularyPredictor</span></code></a></p>
<p>This class is a version of <code class="docutils literal"><span class="pre">IdxmapPredictor</span></code> for unbounded
vocabulary predictors. This needs an adjusted <code class="docutils literal"><span class="pre">predict_next</span></code>
method to pass through the set of target words to score correctly.</p>
<p>Pass through to <code class="docutils literal"><span class="pre">IdxmapPredictor.__init__</span></code></p>
<dl class="method">
<dt>
<code class="descname">predict_next</code><span class="sig-paren">(</span><em>trgt_words</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/vocabulary.html#UnboundedIdxmapPredictor.predict_next"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Pass through to slave predictor</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt>
<em class="property">class </em><code class="descclassname">cam.sgnmt.predictors.vocabulary.</code><code class="descname">UnboundedMaskvocabPredictor</code><span class="sig-paren">(</span><em>words</em>, <em>slave_predictor</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/vocabulary.html#UnboundedMaskvocabPredictor"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Bases: <a class="reference internal" href="cam.sgnmt.predictors.html#cam.sgnmt.predictors.vocabulary.MaskvocabPredictor" title="cam.sgnmt.predictors.vocabulary.MaskvocabPredictor"><code class="xref py py-class docutils literal"><span class="pre">cam.sgnmt.predictors.vocabulary.MaskvocabPredictor</span></code></a>, <a class="reference internal" href="cam.sgnmt.predictors.html#cam.sgnmt.predictors.core.UnboundedVocabularyPredictor" title="cam.sgnmt.predictors.core.UnboundedVocabularyPredictor"><code class="xref py py-class docutils literal"><span class="pre">cam.sgnmt.predictors.core.UnboundedVocabularyPredictor</span></code></a></p>
<p>This class is a version of <code class="docutils literal"><span class="pre">MaskvocabPredictor</span></code> for unbounded
vocabulary predictors. This needs an adjusted <code class="docutils literal"><span class="pre">predict_next</span></code>
method to pass through the set of target words to score correctly.</p>
<p>Creates a new idxmap wrapper predictor. The index maps have
to be plain text files, each line containing the mapping from
a SGNMT word index to the slave predictor word index.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>words</strong> (<em>set</em>) &#8211; List of masked words</li>
<li><strong>slave_predictor</strong> (<a class="reference internal" href="cam.sgnmt.predictors.html#cam.sgnmt.predictors.core.Predictor" title="cam.sgnmt.predictors.core.Predictor"><em>Predictor</em></a>) &#8211; Instance of the predictor with
a different wmap than SGNMT</li>
</ul>
</td>
</tr>
</tbody>
</table>
<dl class="method">
<dt>
<code class="descname">predict_next</code><span class="sig-paren">(</span><em>trgt_words</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/vocabulary.html#UnboundedMaskvocabPredictor.predict_next"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Pass through to slave predictor, set masked to 0.0</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt>
<em class="property">class </em><code class="descclassname">cam.sgnmt.predictors.vocabulary.</code><code class="descname">UnkvocabPredictor</code><span class="sig-paren">(</span><em>trg_vocab_size</em>, <em>slave_predictor</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/vocabulary.html#UnkvocabPredictor"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Bases: <a class="reference internal" href="cam.sgnmt.predictors.html#cam.sgnmt.predictors.core.Predictor" title="cam.sgnmt.predictors.core.Predictor"><code class="xref py py-class docutils literal"><span class="pre">cam.sgnmt.predictors.core.Predictor</span></code></a></p>
<p>If the predictor wrapped by the unkvocab wrapper produces an UNK
with predict next, this wrapper adds explicit NEG_INF scores to all
in-vocabulary words not in its posterior. This can control which
words are matched by the UNK scores of other predictors.</p>
<p>Creates a new unkvocab wrapper predictor.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>trg_vocab_size</strong> (<em>int</em>) &#8211; Size of the target vocabulary</td>
</tr>
</tbody>
</table>
<dl class="method">
<dt>
<code class="descname">consume</code><span class="sig-paren">(</span><em>word</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/vocabulary.html#UnkvocabPredictor.consume"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Pass through to slave predictor</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">estimate_future_cost</code><span class="sig-paren">(</span><em>hypo</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/vocabulary.html#UnkvocabPredictor.estimate_future_cost"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Pass through to slave predictor</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">get_state</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/vocabulary.html#UnkvocabPredictor.get_state"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Pass through to slave predictor</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">get_unk_probability</code><span class="sig-paren">(</span><em>posterior</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/vocabulary.html#UnkvocabPredictor.get_unk_probability"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Pass through to slave predictor</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">initialize</code><span class="sig-paren">(</span><em>src_sentence</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/vocabulary.html#UnkvocabPredictor.initialize"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Pass through to slave predictor</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">initialize_heuristic</code><span class="sig-paren">(</span><em>src_sentence</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/vocabulary.html#UnkvocabPredictor.initialize_heuristic"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Pass through to slave predictor</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">is_equal</code><span class="sig-paren">(</span><em>state1</em>, <em>state2</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/vocabulary.html#UnkvocabPredictor.is_equal"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Pass through to slave predictor</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">predict_next</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/vocabulary.html#UnkvocabPredictor.predict_next"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Pass through to slave predictor. If the posterior from the
slave predictor contains util.UNK_ID, add NEG_INF for all
word ids lower than trg_vocab_size that are not already
defined</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">set_current_sen_id</code><span class="sig-paren">(</span><em>cur_sen_id</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/vocabulary.html#UnkvocabPredictor.set_current_sen_id"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>We need to override this method to propagate current_
sentence_id to the slave predictor</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">set_state</code><span class="sig-paren">(</span><em>state</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/vocabulary.html#UnkvocabPredictor.set_state"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Pass through to slave predictor</p>
</dd></dl>

</dd></dl>

</div>
</div>
</div>


           </div>
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="decoders.html" class="btn btn-neutral float-right" title="Decoders" accesskey="n">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="command_line.html" class="btn btn-neutral" title="Command-line reference" accesskey="p"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2019, University of Cambridge.

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/snide/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  

    <script type="text/javascript">
        var DOCUMENTATION_OPTIONS = {
            URL_ROOT:'./',
            VERSION:'1.0',
            COLLAPSE_INDEX:false,
            FILE_SUFFIX:'.html',
            HAS_SOURCE:  true
        };
    </script>
      <script type="text/javascript" src="_static/jquery.js"></script>
      <script type="text/javascript" src="_static/underscore.js"></script>
      <script type="text/javascript" src="_static/doctools.js"></script>

  

  
  
    <script type="text/javascript" src="_static/js/theme.js"></script>
  

  
  
  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.StickyNav.enable();
      });
  </script>
   

</body>
</html>