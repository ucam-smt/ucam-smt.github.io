

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Predictors &mdash; SGNMT 0.1 documentation</title>
  

  
  

  

  
  
    

  

  
  
    <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  

  
    <link rel="stylesheet" href="_static/custom.css" type="text/css" />
  

  
    <link rel="top" title="SGNMT 0.1 documentation" href="index.html"/>
        <link rel="next" title="Decoders" href="decoders.html"/>
        <link rel="prev" title="Command-line reference" href="command_line.html"/> 

  
  <script src="_static/js/modernizr.min.js"></script>

</head>

<body class="wy-body-for-nav" role="document">

  <div class="wy-grid-for-nav">

    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search">
          

          
            <a href="index.html" class="icon icon-home"> SGNMT
          

          
          </a>

          
            
            
              <div class="version">
                0.1
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
                <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="setup.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="tutorial.html">Tutorial</a></li>
<li class="toctree-l1"><a class="reference internal" href="command_line.html">Command-line reference</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Predictors</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#available-predictors">Available predictors</a></li>
<li class="toctree-l2"><a class="reference internal" href="#predictor-modules">Predictor modules</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#cam-sgnmt-predictors-automata-module">cam.sgnmt.predictors.automata module</a></li>
<li class="toctree-l3"><a class="reference internal" href="#cam-sgnmt-predictors-blocks-neural-module">cam.sgnmt.predictors.blocks_neural module</a></li>
<li class="toctree-l3"><a class="reference internal" href="#cam-sgnmt-predictors-forced-module">cam.sgnmt.predictors.forced module</a></li>
<li class="toctree-l3"><a class="reference internal" href="#cam-sgnmt-predictors-grammar-module">cam.sgnmt.predictors.grammar module</a></li>
<li class="toctree-l3"><a class="reference internal" href="#cam-sgnmt-predictors-length-module">cam.sgnmt.predictors.length module</a></li>
<li class="toctree-l3"><a class="reference internal" href="#cam-sgnmt-predictors-misc-module">cam.sgnmt.predictors.misc module</a></li>
<li class="toctree-l3"><a class="reference internal" href="#cam-sgnmt-predictors-ngram-module">cam.sgnmt.predictors.ngram module</a></li>
<li class="toctree-l3"><a class="reference internal" href="#cam-sgnmt-predictors-nnlm-module">cam.sgnmt.predictors.nnlm module</a></li>
<li class="toctree-l3"><a class="reference internal" href="#module-contents">Module contents</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="decoders.html">Decoders</a></li>
<li class="toctree-l1"><a class="reference internal" href="faq.html">Frequently Asked Questions</a></li>
<li class="toctree-l1"><a class="reference internal" href="publications.html">Publications</a></li>
<li class="toctree-l1"><a class="reference internal" href="cam.sgnmt.html">All modules</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" role="navigation" aria-label="top navigation">
        <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
        <a href="index.html">SGNMT</a>
      </nav>


      
      <div class="wy-nav-content">
        <div class="rst-content">
          

 



<div role="navigation" aria-label="breadcrumbs navigation">
  <ul class="wy-breadcrumbs">
    <li><a href="index.html">Docs</a> &raquo;</li>
      
    <li>Predictors</li>
      <li class="wy-breadcrumbs-aside">
        
          
            <a href="_sources/predictors.txt" rel="nofollow"> View page source</a>
          
        
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="predictors">
<h1>Predictors<a class="headerlink" href="#predictors" title="Permalink to this headline">¶</a></h1>
<p>Predictors are scoring modules which define a distribution over target words given the history and some side information like the source sentence.
If vocabulary sizes differ among predictors, we fill in gaps with predictor UNK scores.</p>
<p>Predictors are specified using the <code class="docutils literal"><span class="pre">--predictors</span></code> and <code class="docutils literal"><span class="pre">--predictor_weights</span></code> arguments, e.g.:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span>$ python decode.py --predictors nmt,fst,nplm --predictor_weights 0.7,0.1,0.2 ...
</pre></div>
</div>
<p>See the <a class="reference internal" href="tutorial.html#tutorial-label"><span class="std std-ref">Tutorial</span></a> page for examples how to use predictors for decoding.</p>
<div class="section" id="available-predictors">
<h2>Available predictors<a class="headerlink" href="#available-predictors" title="Permalink to this headline">¶</a></h2>
<p>The following predictors are available:</p>
<ul>
<li><p class="first"><strong>nmt</strong>: neural machine translation predictor.</p>
<p>Options: see the NMT model configurations plus <code class="docutils literal"><span class="pre">proto</span></code>, <code class="docutils literal"><span class="pre">nmt_model_selector</span></code>, <code class="docutils literal"><span class="pre">cache_nmt_posteriors</span></code>.</p>
</li>
<li><p class="first"><strong>srilm</strong>: n-gram language model.</p>
<p>Options: <code class="docutils literal"><span class="pre">srilm_path</span></code>, <code class="docutils literal"><span class="pre">srilm_order</span></code></p>
</li>
<li><p class="first"><strong>nplm</strong>: neural n-gram language model (NPLM).</p>
<p>Options: <code class="docutils literal"><span class="pre">nplm_path</span></code>, <code class="docutils literal"><span class="pre">normalize_nplm_probs</span></code></p>
</li>
<li><p class="first"><strong>forced</strong>: Forced decoding with one reference</p>
<p>Options: <code class="docutils literal"><span class="pre">trg_test</span></code></p>
</li>
<li><p class="first"><strong>forcedlst</strong>: Forced decoding with a Moses n-best list (n-best list rescoring)</p>
<p>Options: <code class="docutils literal"><span class="pre">trg_test</span></code>, <code class="docutils literal"><span class="pre">forcedlst_sparse_feat</span></code>, <code class="docutils literal"><span class="pre">use_nbest_weights</span></code></p>
</li>
<li><p class="first"><strong>fst</strong>: Deterministic translation lattices</p>
<p>Options: <code class="docutils literal"><span class="pre">fst_path</span></code>, <code class="docutils literal"><span class="pre">use_fst_weights</span></code>, <code class="docutils literal"><span class="pre">normalize_fst_weights</span></code>, <code class="docutils literal"><span class="pre">fst_to_log</span></code>, <code class="docutils literal"><span class="pre">add_fst_bos_to_eos_weight</span></code></p>
</li>
<li><p class="first"><strong>nfst</strong>: Non-deterministic translation lattices</p>
<p>Options: <code class="docutils literal"><span class="pre">fst_path</span></code>, <code class="docutils literal"><span class="pre">use_fst_weights</span></code>, <code class="docutils literal"><span class="pre">normalize_fst_weights</span></code>, <code class="docutils literal"><span class="pre">fst_to_log</span></code>, <code class="docutils literal"><span class="pre">add_fst_bos_to_eos_weight</span></code></p>
</li>
<li><p class="first"><strong>rtn</strong>: Recurrent transition networks as created by HiFST with late expansion.</p>
<p>Options: <code class="docutils literal"><span class="pre">rtn_path</span></code>, <code class="docutils literal"><span class="pre">use_rtn_weights</span></code>, <code class="docutils literal"><span class="pre">minimize_rtns</span></code>, <code class="docutils literal"><span class="pre">remove_epsilon_in_rtns</span></code>, <code class="docutils literal"><span class="pre">normalize_rtn_weights</span></code></p>
</li>
<li><p class="first"><strong>lrhiero</strong>: Direct Hiero (left-to-right Hiero). This is a EXPERIMENTAL implementation of LRHiero.</p>
<p>Options: <code class="docutils literal"><span class="pre">rules_path</span></code>, <code class="docutils literal"><span class="pre">grammar_feature_weights</span></code>, <code class="docutils literal"><span class="pre">use_grammar_weights</span></code></p>
</li>
<li><p class="first"><strong>wc</strong>: Number of words feature.</p>
<p>Options: no options.</p>
</li>
<li><p class="first"><strong>length</strong>: Target sentence length model Options:</p>
<p><code class="docutils literal"><span class="pre">src_test_raw</span></code>, <code class="docutils literal"><span class="pre">length_model_weights</span></code>, <code class="docutils literal"><span class="pre">use_length_point_probs</span></code></p>
</li>
</ul>
<p>All predictors can be combined with one or more wrapper predictors by adding the wrapper name separated by a _ symbol. Following wrappers are available:</p>
<ul class="simple">
<li><em>idxmap</em>: Add this wrapper to predictors which use an alternative word map.
Options: <code class="docutils literal"><span class="pre">src_idxmap</span></code>, <code class="docutils literal"><span class="pre">trg_idxmap</span></code></li>
</ul>
<p>Note that you can use multiple instances of the same predictor. For example, &#8216;nmt,nmt,nmt&#8217; can be used for ensembling three NMT systems.
You can often override parts of the predictor configurations for subsequent predictors by adding the predictor number (e.g. see <code class="docutils literal"><span class="pre">--nmt_config2</span></code> or <code class="docutils literal"><span class="pre">--fst_path2</span></code>)</p>
<p>Detailed descriptions are available below in the modules.</p>
</div>
<div class="section" id="predictor-modules">
<h2>Predictor modules<a class="headerlink" href="#predictor-modules" title="Permalink to this headline">¶</a></h2>
<div class="section" id="cam-sgnmt-predictors-automata-module">
<h3>cam.sgnmt.predictors.automata module<a class="headerlink" href="#cam-sgnmt-predictors-automata-module" title="Permalink to this headline">¶</a></h3>
<p>This module encapsulates the predictor interface to OpenFST. This
module depends on OpenFST. To enable Python support in OpenFST, use a
recent version (&gt;=1.5.2) and compile with <code class="docutils literal"><span class="pre">--enable_python</span></code>.
Further information can be found here:</p>
<p><a class="reference external" href="http://www.openfst.org/twiki/bin/view/FST/PythonExtension">http://www.openfst.org/twiki/bin/view/FST/PythonExtension</a></p>
<p>This file includes the fst, nfst, and rtn predictors.</p>
<p>Note: If we ise arc weights in FSTs, we multiply them by -1 as
everything in SGNMT is logprob, not -logprob as in FSTs log
or tropical semirings. You can disable this behavior with &#8211;fst_to_log</p>
<p>Note2: The FSTs and RTNs are assumed to have both &lt;S&gt; and &lt;/S&gt;. This
has compatibility reasons, as lattices generated by HiFST have these
symbols.</p>
<dl class="data">
<dt>
<code class="descclassname">cam.sgnmt.predictors.automata.</code><code class="descname">EPS_ID</code><em class="property"> = 0</em></dt>
<dd><p>OpenFST&#8217;s reserved ID for epsilon arcs.</p>
</dd></dl>

<dl class="class">
<dt>
<em class="property">class </em><code class="descclassname">cam.sgnmt.predictors.automata.</code><code class="descname">FstPredictor</code><span class="sig-paren">(</span><em>fst_path</em>, <em>use_weights</em>, <em>normalize_scores</em>, <em>add_bos_to_eos_score=False</em>, <em>to_log=True</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/automata.html#FstPredictor"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Bases: <a class="reference internal" href="cam.sgnmt.decoding.html#cam.sgnmt.decoding.core.Predictor" title="cam.sgnmt.decoding.core.Predictor"><code class="xref py py-class docutils literal"><span class="pre">cam.sgnmt.decoding.core.Predictor</span></code></a></p>
<p>This predictor can read determinized translation lattices. The
predictor state consists of the current node. This is unique as the
lattices are determinized.</p>
<dl class="method">
<dt>
<code class="descname">consume</code><span class="sig-paren">(</span><em>word</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/automata.html#FstPredictor.consume"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Updates the current node by following the arc labelled with
<code class="docutils literal"><span class="pre">word</span></code>. If there is no such arc, we set <code class="docutils literal"><span class="pre">cur_node</span></code> to -1,
indicating that the predictor is in an invalid state. In this
case, all subsequent <code class="docutils literal"><span class="pre">predict_next</span></code> calls will return the
empty set.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>word</strong> (<em>int</em>) &#8211; Word on an outgoing arc from the current node</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body">float. Weight on the traversed arc</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">estimate_future_cost</code><span class="sig-paren">(</span><em>hypo</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/automata.html#FstPredictor.estimate_future_cost"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>The FST predictor comes with its own heuristic function. We
use the shortest path in the fst as future cost estimator.</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">get_state</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/automata.html#FstPredictor.get_state"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Returns the current node.</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">get_unk_probability</code><span class="sig-paren">(</span><em>posterior</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/automata.html#FstPredictor.get_unk_probability"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Always returns negative infinity: Words outside the
translation lattice are not possible according to this
predictor.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body">float. Negative infinity</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">initialize</code><span class="sig-paren">(</span><em>src_sentence</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/automata.html#FstPredictor.initialize"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Loads the FST from the file system and consumes the start
of sentence symbol.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>src_sentence</strong> (<em>list</em>) &#8211; Not used</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">initialize_heuristic</code><span class="sig-paren">(</span><em>src_sentence</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/automata.html#FstPredictor.initialize_heuristic"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Creates a matrix of shortest distances between nodes.</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">predict_next</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/automata.html#FstPredictor.predict_next"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Uses the outgoing arcs from the current node to build up the
scores for the next word.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body">dict. Set of words on outgoing arcs from the current node
together with their scores, or an empty set if we currently
have no active node or fst.</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">reset</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/automata.html#FstPredictor.reset"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Resets the loaded FST object and current node.</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">set_state</code><span class="sig-paren">(</span><em>state</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/automata.html#FstPredictor.set_state"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Sets the current node.</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt>
<em class="property">class </em><code class="descclassname">cam.sgnmt.predictors.automata.</code><code class="descname">NondeterministicFstPredictor</code><span class="sig-paren">(</span><em>fst_path</em>, <em>use_weights</em>, <em>normalize_scores</em>, <em>to_log=True</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/automata.html#NondeterministicFstPredictor"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Bases: <a class="reference internal" href="cam.sgnmt.decoding.html#cam.sgnmt.decoding.core.Predictor" title="cam.sgnmt.decoding.core.Predictor"><code class="xref py py-class docutils literal"><span class="pre">cam.sgnmt.decoding.core.Predictor</span></code></a></p>
<p>This predictor can handle non-deterministic translation
lattices. In contrast to the fst predictor for deterministic
lattices, we store a set of nodes which are all reachable from
the start node through the current history.</p>
<dl class="method">
<dt>
<code class="descname">consume</code><span class="sig-paren">(</span><em>word</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/automata.html#NondeterministicFstPredictor.consume"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Updates the current nodes by searching for all nodes which
are reachable from the current nodes by a path consisting of
any number of epsilons and exactly one <code class="docutils literal"><span class="pre">word</span></code> label. If there
is no such arc, we set the predictor in an invalid state. In
this case, all subsequent <code class="docutils literal"><span class="pre">predict_next</span></code> calls will return
the empty set.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>word</strong> (<em>int</em>) &#8211; Word on an outgoing arc from the current node</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">estimate_future_cost</code><span class="sig-paren">(</span><em>hypo</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/automata.html#NondeterministicFstPredictor.estimate_future_cost"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>The FST predictor comes with its own heuristic function. We
use the shortest path in the fst as future cost estimator.</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">get_state</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/automata.html#NondeterministicFstPredictor.get_state"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Returns the set of current nodes</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">get_unk_probability</code><span class="sig-paren">(</span><em>posterior</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/automata.html#NondeterministicFstPredictor.get_unk_probability"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Always returns negative infinity: Words outside the
translation lattice are not possible according to this
predictor.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body">float. Negative infinity</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">initialize</code><span class="sig-paren">(</span><em>src_sentence</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/automata.html#NondeterministicFstPredictor.initialize"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Loads the FST from the file system and consumes the start
of sentence symbol.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>src_sentence</strong> (<em>list</em>) &#8211; Not used</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">initialize_heuristic</code><span class="sig-paren">(</span><em>src_sentence</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/automata.html#NondeterministicFstPredictor.initialize_heuristic"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Creates a matrix of shortest distances between all nodes</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">predict_next</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/automata.html#NondeterministicFstPredictor.predict_next"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Uses the outgoing arcs from all current node to build up the
scores for the next word. This method does not follow epsilon
arcs: <code class="docutils literal"><span class="pre">consume</span></code> updates <code class="docutils literal"><span class="pre">cur_nodes</span></code> such that all reachable
arcs with word ids are connected directly with a node in
<code class="docutils literal"><span class="pre">cur_nodes</span></code>. If there are multiple arcs with the same word,
we use the log sum of the arc weights as score.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body">dict. Set of words on outgoing arcs from the current node
together with their scores, or an empty set if we currently
have no active nodes or fst.</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">reset</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/automata.html#NondeterministicFstPredictor.reset"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Resets the FST and empties the set of current nodes</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">set_state</code><span class="sig-paren">(</span><em>state</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/automata.html#NondeterministicFstPredictor.set_state"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Sets the set of current nodes</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt>
<em class="property">class </em><code class="descclassname">cam.sgnmt.predictors.automata.</code><code class="descname">RtnPredictor</code><span class="sig-paren">(</span><em>rtn_path</em>, <em>use_weights</em>, <em>normalize_scores</em>, <em>to_log=True</em>, <em>minimize_rtns=False</em>, <em>rmeps=True</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/automata.html#RtnPredictor"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Bases: <a class="reference internal" href="cam.sgnmt.decoding.html#cam.sgnmt.decoding.core.Predictor" title="cam.sgnmt.decoding.core.Predictor"><code class="xref py py-class docutils literal"><span class="pre">cam.sgnmt.decoding.core.Predictor</span></code></a></p>
<p>Predictor for RTNs (recurrent transition networks). This
predictor assumes a directory structure as produced by HiFST. You
can use this predictor for non-deterministic lattices too. This
implementation supports late expansion: RTNs are only expanded as
far as necessary to retrieve all currently reachable states.</p>
<p><code class="docutils literal"><span class="pre">cur_nodes</span></code> contains the accumulated weights from the last
consumed word (if ambiguous, the largest)</p>
<p>This implementation does not maintain a list of active nodes like
the other automata predictors. Instead, we store the current
history and search for the active nodes at each expansion. This is
more expensive, but fstreplace might change state IDs so a list of
active nodes might get corrupted.</p>
<p>Note that this predictor does not support FSTs in gzip format.</p>
<dl class="method">
<dt>
<code class="descname">add_to_label_fst_map_recursive</code><span class="sig-paren">(</span><em>label_fst_map</em>, <em>visited_nodes</em>, <em>root_node</em>, <em>acc_weight</em>, <em>history</em>, <em>func</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/automata.html#RtnPredictor.add_to_label_fst_map_recursive"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Adds arcs to <code class="docutils literal"><span class="pre">label_fst_map</span></code> if they are labeled with an
NT symbol and reachable from <code class="docutils literal"><span class="pre">root_node</span></code> via <code class="docutils literal"><span class="pre">history</span></code>.</p>
<p>Note: visited_nodes is maintained for each history separately</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">consume</code><span class="sig-paren">(</span><em>word</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/automata.html#RtnPredictor.consume"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Adds <code class="docutils literal"><span class="pre">word</span></code> to the current history.</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">expand_rtn</code><span class="sig-paren">(</span><em>func</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/automata.html#RtnPredictor.expand_rtn"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>This method expands the RTN as far as necessary. This means
that the RTN is expanded s.t. we can build the posterior for
<code class="docutils literal"><span class="pre">cur_history</span></code>. In practice, this means that we follow all
epsilon edges and replaces all NT edges until all paths with
the prefix <code class="docutils literal"><span class="pre">cur_history</span></code> in the RTN have at least one more
terminal token. Then, we apply <code class="docutils literal"><span class="pre">func</span></code> to all reachable nodes.</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">get_state</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/automata.html#RtnPredictor.get_state"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Returns the current history.</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">get_sub_fst</code><span class="sig-paren">(</span><em>fst_id</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/automata.html#RtnPredictor.get_sub_fst"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Load sub fst from the file system or the cache</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">get_unk_probability</code><span class="sig-paren">(</span><em>posterior</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/automata.html#RtnPredictor.get_unk_probability"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Always returns negative infinity: Words outside the
RTN are not possible according to this predictor.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body">float. Negative infinity</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">initialize</code><span class="sig-paren">(</span><em>src_sentence</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/automata.html#RtnPredictor.initialize"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Loads the root RTN and consumes the start of sentence
symbol.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>src_sentence</strong> (<em>list</em>) &#8211; Not used</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">is_nt_label</code><span class="sig-paren">(</span><em>label</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/automata.html#RtnPredictor.is_nt_label"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Returns true if <code class="docutils literal"><span class="pre">label</span></code> is a non-terminal.</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">predict_next</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/automata.html#RtnPredictor.predict_next"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Expands RTN as far as possible and uses the outgoing edges
from nodes reachable by the current history to build up
the posterior for the next word. If there are no such nodes
or arcs, or no root FST is loaded, return the empty set.</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">reset</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/automata.html#RtnPredictor.reset"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Unloads the current RTN</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">set_state</code><span class="sig-paren">(</span><em>state</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/automata.html#RtnPredictor.set_state"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Sets the current history.</p>
</dd></dl>

</dd></dl>

<dl class="data">
<dt>
<code class="descclassname">cam.sgnmt.predictors.automata.</code><code class="descname">TMP_FILENAME</code><em class="property"> = '/tmp/sgnmt.30155.fst'</em></dt>
<dd><p>Temporary file name to use if a FST file is zipped.</p>
</dd></dl>

<dl class="function">
<dt>
<code class="descclassname">cam.sgnmt.predictors.automata.</code><code class="descname">load_fst</code><span class="sig-paren">(</span><em>path</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/automata.html#load_fst"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Loads a FST from the file system using PyFSTs <code class="docutils literal"><span class="pre">read()</span></code> method.
GZipped format is also supported. The arc type must be standard
or log, otherwise PyFST cannot load them.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>path</strong> (<em>string</em>) &#8211; Path to the FST file to load</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body">fst. PyFST FST object or <code class="docutils literal"><span class="pre">None</span></code> if FST could not be read</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt>
<code class="descclassname">cam.sgnmt.predictors.automata.</code><code class="descname">w2f</code><span class="sig-paren">(</span><em>fstweight</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/automata.html#w2f"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Converts an arc weight to float</p>
</dd></dl>

</div>
<div class="section" id="cam-sgnmt-predictors-blocks-neural-module">
<h3>cam.sgnmt.predictors.blocks_neural module<a class="headerlink" href="#cam-sgnmt-predictors-blocks-neural-module" title="Permalink to this headline">¶</a></h3>
<p>This is the only module outside the <code class="docutils literal"><span class="pre">blocks</span></code> package with
dependency on the Blocks framework. It contains the neural machine
translation predictor nmt. Code is partially taken from the neural
machine translation example in blocks.</p>
<p><a class="reference external" href="https://github.com/mila-udem/blocks-examples/tree/master/machine_translation">https://github.com/mila-udem/blocks-examples/tree/master/machine_translation</a></p>
<p>Note that using this predictor slows down decoding compared to the
original NMT decoding because search cannot be parallelized. However,
it is much more flexible as it can be combined with other predictors.</p>
<dl class="class">
<dt>
<em class="property">class </em><code class="descclassname">cam.sgnmt.predictors.blocks_neural.</code><code class="descname">LoadNMT</code><span class="sig-paren">(</span><em>nmt_model_path</em>, <em>saveto</em>, <em>model</em>, <em>**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/blocks_neural.html#LoadNMT"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Bases: <a class="reference internal" href="cam.sgnmt.blocks.machine_translation.html#cam.sgnmt.blocks.machine_translation.checkpoint.SaveLoadUtils" title="cam.sgnmt.blocks.machine_translation.checkpoint.SaveLoadUtils"><code class="xref py py-class docutils literal"><span class="pre">cam.sgnmt.blocks.machine_translation.checkpoint.SaveLoadUtils</span></code></a></p>
<p>Loads parameters log and iterations state. This class is adapted
from the <code class="docutils literal"><span class="pre">LoadNMT</span></code> class in the blocks example and contains
some copied code. Note that we do not use BLOCKS_DELIMITER.
Instead, we always use &#8216;-&#8216; to keep back compatibility with older
models.</p>
<dl class="method">
<dt>
<code class="descname">load_parameters</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/blocks_neural.html#LoadNMT.load_parameters"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Currently not used, kept for consistency with blocks
reference implementation.</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">load_weights</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/blocks_neural.html#LoadNMT.load_weights"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Load the model parameters from the model file. Compare with
<code class="docutils literal"><span class="pre">blocks.machine_translation.LoadNMT</span></code>.</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt>
<em class="property">class </em><code class="descclassname">cam.sgnmt.predictors.blocks_neural.</code><code class="descname">MyopticSearch</code><span class="sig-paren">(</span><em>samples</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/blocks_neural.html#MyopticSearch"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal"><span class="pre">blocks.search.BeamSearch</span></code></p>
<p>This class hacks into blocks beam search to leverage off the
initialization routines. Note that this has nothing to do with
SGNMTs high level decoding in <code class="docutils literal"><span class="pre">cam.sgnmt.decoding</span></code>. We basically
replace the <code class="docutils literal"><span class="pre">search()</span></code> with single_step_``decoding()`` which
generates the posteriors for the next word. Thus, it fits in the
predictor framework. We try to use <code class="docutils literal"><span class="pre">BeamSearch</span></code> functionality
wherever possible.</p>
</dd></dl>

<dl class="data">
<dt>
<code class="descclassname">cam.sgnmt.predictors.blocks_neural.</code><code class="descname">NEG_INF</code><em class="property"> = -inf</em></dt>
<dd><p>Name of the default model file (not checkpoints)</p>
</dd></dl>

<dl class="class">
<dt>
<em class="property">class </em><code class="descclassname">cam.sgnmt.predictors.blocks_neural.</code><code class="descname">NMTPredictor</code><span class="sig-paren">(</span><em>nmt_model_path</em>, <em>enable_cache</em>, <em>config</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/blocks_neural.html#NMTPredictor"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Bases: <a class="reference internal" href="cam.sgnmt.decoding.html#cam.sgnmt.decoding.core.Predictor" title="cam.sgnmt.decoding.core.Predictor"><code class="xref py py-class docutils literal"><span class="pre">cam.sgnmt.decoding.core.Predictor</span></code></a></p>
<p>This is the neural machine translation predictor. The predicted
posteriors are equal to the distribution generated by the decoder
network in NMT. This predictor heavily relies on the NMT example in
blocks.</p>
<dl class="method">
<dt>
<code class="descname">consume</code><span class="sig-paren">(</span><em>word</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/blocks_neural.html#NMTPredictor.consume"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Feeds back <code class="docutils literal"><span class="pre">word</span></code> to the decoder network. This includes
embedding of <code class="docutils literal"><span class="pre">word</span></code>, running the attention network and update
the recurrent decoder layer.</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">get_state</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/blocks_neural.html#NMTPredictor.get_state"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>The NMT predictor state consists of the decoder network
state, and (for caching) the current history of consumed words</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">get_unk_probability</code><span class="sig-paren">(</span><em>posterior</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/blocks_neural.html#NMTPredictor.get_unk_probability"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Returns the UNK probability defined by NMT.</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">initialize</code><span class="sig-paren">(</span><em>src_sentence</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/blocks_neural.html#NMTPredictor.initialize"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Runs the encoder network to create the source annotations
for the source sentence. If the cache is enabled, empty the
cache.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>src_sentence</strong> (<em>list</em>) &#8211; List of word ids without &lt;S&gt; and &lt;/S&gt;
which represent the source sentence.</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">is_history_cachable</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/blocks_neural.html#NMTPredictor.is_history_cachable"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Returns true if cache is enabled and history contains UNK</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">predict_next</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/blocks_neural.html#NMTPredictor.predict_next"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Uses cache or runs the decoder network to get the
distribution over the next target words.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body">np array. Full distribution over the entire NMT vocabulary
for the next target token.</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">reset</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/blocks_neural.html#NMTPredictor.reset"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Deletes the source side annotations and decoder state.</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">set_state</code><span class="sig-paren">(</span><em>state</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/blocks_neural.html#NMTPredictor.set_state"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Set the NMT predictor state.</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">set_up_predictor</code><span class="sig-paren">(</span><em>nmt_model_path</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/blocks_neural.html#NMTPredictor.set_up_predictor"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Initializes the predictor with the given NMT model. Code
following <code class="docutils literal"><span class="pre">blocks.machine_translation.main</span></code>.</p>
</dd></dl>

</dd></dl>

<dl class="data">
<dt>
<code class="descclassname">cam.sgnmt.predictors.blocks_neural.</code><code class="descname">PARAMS_FILE_NAME</code><em class="property"> = 'params.npz'</em></dt>
<dd><p>Pattern for checkpoints created in training for model selection</p>
</dd></dl>

<dl class="function">
<dt>
<code class="descclassname">cam.sgnmt.predictors.blocks_neural.</code><code class="descname">get_nmt_model_path_best_bleu</code><span class="sig-paren">(</span><em>nmt_config</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/blocks_neural.html#get_nmt_model_path_best_bleu"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Returns the path to the checkpoint with the best BLEU score. If
no checkpoint can be found, back up to params.npz.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>nmt_config</strong> (<em>dict</em>) &#8211; NMT configuration. We will use the field
<code class="docutils literal"><span class="pre">saveto</span></code> to get the training directory</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body">string. Path to the checkpoint file with best BLEU score</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt>
<code class="descclassname">cam.sgnmt.predictors.blocks_neural.</code><code class="descname">get_nmt_model_path_most_recent</code><span class="sig-paren">(</span><em>nmt_config</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/blocks_neural.html#get_nmt_model_path_most_recent"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Returns the path to the most recent checkpoint. If
no checkpoint can be found, back up to params.npz.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>nmt_config</strong> (<em>dict</em>) &#8211; NMT configuration. We will use the field
<code class="docutils literal"><span class="pre">saveto</span></code> to get the training directory</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body">string. Path to the most recent checkpoint file</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt>
<code class="descclassname">cam.sgnmt.predictors.blocks_neural.</code><code class="descname">get_nmt_model_path_params</code><span class="sig-paren">(</span><em>nmt_config</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/blocks_neural.html#get_nmt_model_path_params"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Returns the path to the params.npz. This file usually contains
the latest model parameters.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>nmt_config</strong> (<em>dict</em>) &#8211; NMT configuration. We will use the field
<code class="docutils literal"><span class="pre">saveto</span></code> to get the training directory</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body">string. Path to the params.npz</td>
</tr>
</tbody>
</table>
</dd></dl>

</div>
<div class="section" id="cam-sgnmt-predictors-forced-module">
<h3>cam.sgnmt.predictors.forced module<a class="headerlink" href="#cam-sgnmt-predictors-forced-module" title="Permalink to this headline">¶</a></h3>
<p>This module contains predictors for forced decoding. This can be
done either with one reference (forced <code class="docutils literal"><span class="pre">ForcedPredictor</span></code>), or with
multiple references in form of a n-best list (forcedlst
<code class="docutils literal"><span class="pre">ForcedLstPredictor</span></code>).</p>
<dl class="class">
<dt>
<em class="property">class </em><code class="descclassname">cam.sgnmt.predictors.forced.</code><code class="descname">ForcedLstPredictor</code><span class="sig-paren">(</span><em>trg_test_file</em>, <em>use_scores=True</em>, <em>feat_name=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/forced.html#ForcedLstPredictor"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Bases: <a class="reference internal" href="cam.sgnmt.decoding.html#cam.sgnmt.decoding.core.Predictor" title="cam.sgnmt.decoding.core.Predictor"><code class="xref py py-class docutils literal"><span class="pre">cam.sgnmt.decoding.core.Predictor</span></code></a></p>
<p>This predictor can be used for direct n-best list rescoring. In
contrast to the <code class="docutils literal"><span class="pre">ForcedPredictor</span></code>, it reads an n-best list in
Moses format and uses its scores as predictive probabilities of the
&lt;/S&gt; symbol. Everywhere else it gives the predictive probability 1
if the history corresponds to at least one n-best list entry, 0
otherwise. From the n-best list we use
First column: Sentence id
Second column: Hypothesis in integer format
Last column: score</p>
<p>Note: Behavior is undefined if you have duplicates in the n-best
list</p>
<p>TODO: Would be much more efficient to use Tries for
cur_trgt_sentences instead of a flat list.</p>
<dl class="method">
<dt>
<code class="descname">consume</code><span class="sig-paren">(</span><em>word</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/forced.html#ForcedLstPredictor.consume"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Extends the current history by <code class="docutils literal"><span class="pre">word</span></code>.</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">get_state</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/forced.html#ForcedLstPredictor.get_state"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Returns the current history.</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">get_unk_probability</code><span class="sig-paren">(</span><em>posterior</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/forced.html#ForcedLstPredictor.get_unk_probability"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Return negative infinity unconditionally - words outside the
n-best list are not possible according to this predictor.</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">initialize</code><span class="sig-paren">(</span><em>src_sentence</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/forced.html#ForcedLstPredictor.initialize"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Resets the history and loads the n-best list entries for the
next source sentence</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>src_sentence</strong> (<em>list</em>) &#8211; Not used</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">predict_next</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/forced.html#ForcedLstPredictor.predict_next"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Outputs 0.0 (i.e. prob=1) for all words for which there is
an entry <code class="docutils literal"><span class="pre">in</span> <span class="pre">cur_trg_sentences</span></code>, and the score in
<code class="docutils literal"><span class="pre">cur_trg_sentences</span></code> if the current history is by itself equal
to an entry in <code class="docutils literal"><span class="pre">cur_trg_sentences</span></code>.</p>
<p>TODO: The implementation here is fairly inefficient as it scans
through all target sentences linearly. Would be better to
organize the target sentences in a Trie</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">reset</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/forced.html#ForcedLstPredictor.reset"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Empty method.</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">set_state</code><span class="sig-paren">(</span><em>state</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/forced.html#ForcedLstPredictor.set_state"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Sets the current history.</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt>
<em class="property">class </em><code class="descclassname">cam.sgnmt.predictors.forced.</code><code class="descname">ForcedPredictor</code><span class="sig-paren">(</span><em>trg_test_file</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/forced.html#ForcedPredictor"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Bases: <a class="reference internal" href="cam.sgnmt.decoding.html#cam.sgnmt.decoding.core.Predictor" title="cam.sgnmt.decoding.core.Predictor"><code class="xref py py-class docutils literal"><span class="pre">cam.sgnmt.decoding.core.Predictor</span></code></a></p>
<p>This predictor realizes forced decoding. It stores one target
sentence for each source sentence and outputs predictive probability
1 along this path, and 0 otherwise.</p>
<dl class="method">
<dt>
<code class="descname">consume</code><span class="sig-paren">(</span><em>word</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/forced.html#ForcedPredictor.consume"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>If <code class="docutils literal"><span class="pre">word</span></code> matches the target sentence, we increase the
current history by one. Otherwise, we set this predictor in
an invalid state, in which it always predicts &lt;/S&gt;</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>word</strong> (<em>int</em>) &#8211; Next word to consume</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">get_state</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/forced.html#ForcedPredictor.get_state"><span class="viewcode-link">[source]</span></a></dt>
<dd><p><code class="docutils literal"><span class="pre">cur_trg_sentence</span></code> can be changed so its part of the
predictor state</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">get_unk_probability</code><span class="sig-paren">(</span><em>posterior</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/forced.html#ForcedPredictor.get_unk_probability"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Returns negative infinity unconditionally: Words which are
not in the target sentence have assigned probability 0 by
this predictor.</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">initialize</code><span class="sig-paren">(</span><em>src_sentence</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/forced.html#ForcedPredictor.initialize"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Fetches the corresponding target sentence and resets the
current history.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>src_sentence</strong> (<em>list</em>) &#8211; Not used</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">predict_next</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/forced.html#ForcedPredictor.predict_next"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Returns a dictionary with one entry and value 0 (=log 1). The
key is either the next word in the target sentence or (if the
target sentence has no more words) the end-of-sentence symbol.</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">reset</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/forced.html#ForcedPredictor.reset"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Empty method.</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">set_state</code><span class="sig-paren">(</span><em>state</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/forced.html#ForcedPredictor.set_state"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Set the predictor state.</p>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="cam-sgnmt-predictors-grammar-module">
<h3>cam.sgnmt.predictors.grammar module<a class="headerlink" href="#cam-sgnmt-predictors-grammar-module" title="Permalink to this headline">¶</a></h3>
<p>This module contains everything related to the hiero predictor. This
predictor allows applying rules from a syntactical SMT system directly
in SGNMT. The main interface is <code class="docutils literal"><span class="pre">RuleXtractPredictor</span></code> which can be
used like other predictors during decoding.
The Hiero predictor follows are the LRHiero implementation from</p>
<p><a class="reference external" href="https://github.com/sfu-natlang/lrhiero">https://github.com/sfu-natlang/lrhiero</a></p>
<blockquote>
<div>Efficient Left-to-Right Hierarchical Phrase-based Translation with
Improved Reordering.
Maryam Siahbani, Baskaran Sankaran and Anoop Sarkar.
EMNLP 2013. Oct 18-21, 2013. Seattle, USA.</div></blockquote>
<p>However, note that we modified the code to
a) deal with an arbitrary number of non-terminals
b) work with ruleXtract
c) allow spurious ambiguity</p>
<p>ATTENTION: This implementation is experimental!!</p>
<dl class="class">
<dt>
<em class="property">class </em><code class="descclassname">cam.sgnmt.predictors.grammar.</code><code class="descname">Cell</code><span class="sig-paren">(</span><em>init_hypo=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/grammar.html#Cell"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Comparable to a CYK cell: A set of hypotheses. If duplicates are
added, we do hypo combination by combining the costs and retraining
only one of them. Internally, the hypotheses are stored in a list
sorted by the sum of the translation prefix</p>
<dl class="method">
<dt>
<code class="descname">add</code><span class="sig-paren">(</span><em>hypo</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/grammar.html#Cell.add"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Add a new hypothesis to the cell. If an equivalent
hypothesis already exists, combine both hypotheses.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>hypo</strong> (<a class="reference internal" href="cam.sgnmt.predictors.html#cam.sgnmt.predictors.grammar.LRHieroHypothesis" title="cam.sgnmt.predictors.grammar.LRHieroHypothesis"><em>LRHieroHypothesis</em></a>) &#8211; Hypothesis to add under the key
<code class="docutils literal"><span class="pre">hypo.key</span></code></td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">filter</code><span class="sig-paren">(</span><em>pos</em>, <em>symb</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/grammar.html#Cell.filter"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Remove all hypotheses which do not have <code class="docutils literal"><span class="pre">symb</span></code> at <code class="docutils literal"><span class="pre">pos</span></code>
in their <code class="docutils literal"><span class="pre">trgt_prefix</span></code>. Breaks if <code class="docutils literal"><span class="pre">pos</span></code> is out of range for
some <code class="docutils literal"><span class="pre">trgt_prefix</span></code></p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">findIdx</code><span class="sig-paren">(</span><em>key</em>, <em>a</em>, <em>b</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/grammar.html#Cell.findIdx"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Find index of first element with given key. If there is no
such key, return last element with largest key smaller than key
This is a recursive function which only searches in the
interval [a,b]</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">pop</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/grammar.html#Cell.pop"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Removes a hypothesis from the cell.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body">LRHieroHypothesis. The removed hypothesis</td>
</tr>
</tbody>
</table>
</dd></dl>

</dd></dl>

<dl class="class">
<dt>
<em class="property">class </em><code class="descclassname">cam.sgnmt.predictors.grammar.</code><code class="descname">LRHieroHypothesis</code><span class="sig-paren">(</span><em>trgt_prefix</em>, <em>spans</em>, <em>cost</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/grammar.html#LRHieroHypothesis"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Represents a LRHiero hypothesis, which is defined by the
accumulated cost, the target prefix, and open source spans.</p>
<dl class="method">
<dt>
<code class="descname">is_final</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/grammar.html#LRHieroHypothesis.is_final"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Returns true if this hypothesis has no open spans</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt>
<em class="property">class </em><code class="descclassname">cam.sgnmt.predictors.grammar.</code><code class="descname">Node</code><a class="reference internal" href="_modules/cam/sgnmt/predictors/grammar.html#Node"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Represents a node in the Trie.</p>
</dd></dl>

<dl class="class">
<dt>
<em class="property">class </em><code class="descclassname">cam.sgnmt.predictors.grammar.</code><code class="descname">Rule</code><span class="sig-paren">(</span><em>rhs_src</em>, <em>rhs_trgt</em>, <em>trgt_src_map</em>, <em>cost</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/grammar.html#Rule"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>A rule consists of <code class="docutils literal"><span class="pre">rhs_src</span></code> and <code class="docutils literal"><span class="pre">rhs_trgt</span></code>, both are
sequences of integers. NTs are indicated with negative sign. The
<code class="docutils literal"><span class="pre">trgt_src_map</span></code> defines which NT on the target side belongs to
which NT on the source side.</p>
<dl class="attribute">
<dt>
<code class="descname">last_id</code><em class="property"> = 0</em></dt>
<dd></dd></dl>

</dd></dl>

<dl class="class">
<dt>
<em class="property">class </em><code class="descclassname">cam.sgnmt.predictors.grammar.</code><code class="descname">RuleSet</code><a class="reference internal" href="_modules/cam/sgnmt/predictors/grammar.html#RuleSet"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>This class stores the set of rules and provides efficient retrieval and
matching functionality</p>
<dl class="attribute">
<dt>
<code class="descname">INF</code><em class="property"> = 10000</em></dt>
<dd></dd></dl>

<dl class="method">
<dt>
<code class="descname">create_rule</code><span class="sig-paren">(</span><em>rhs_src</em>, <em>rhs_trgt</em>, <em>weight</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/grammar.html#RuleSet.create_rule"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Creates a rule object (factory method)</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>rhs_src</strong> (<em>list</em>) &#8211; String sequence describing the source of
the right-hand-side of the rule</li>
<li><strong>rhs_trgt</strong> (<em>list</em>) &#8211; String sequence describing the target of
the right-hand-side of the rule</li>
<li><strong>weight</strong> (<em>float</em>) &#8211; Rule weight</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first last"><code class="docutils literal"><span class="pre">Rule</span></code> or <code class="docutils literal"><span class="pre">None</span></code> if something went wrong</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">expand_hypo</code><span class="sig-paren">(</span><em>hypo</em>, <em>src_seq</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/grammar.html#RuleSet.expand_hypo"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Similar to <code class="docutils literal"><span class="pre">getSpanRules()</span></code> and <code class="docutils literal"><span class="pre">GrowHypothesis()</span></code> in
Alg. 1 in (Siahbani, 2013) combined. Gets all rules which match
the given span.</p>
<ul class="simple">
<li>If the p parameter of the span is a single non-terminal, we
return hypotheses resulting from productions of this non-
terminal. Note that rules might be applicable in many different
ways: X-&gt; A the B can be applied to foo the bar the baz in two
ways. In this case, we add the translation prefix, but leave the
borders of the span untouched, and change the <code class="docutils literal"><span class="pre">p</span></code> value to
<code class="docutils literal"><span class="pre">thr</span> <span class="pre">rhs</span></code> of the production (i.e. &#8220;A the B&#8221;). If p consists
of multiple characters, the spans store the minimum and maximum
<em>length</em>, not the begin and end since the exact begin and end
positions are variable.</li>
<li>If the p parameter of the span has length &gt; 1, we return a
set of hypotheses in which the first subspan has a single NT
as p parameter.</li>
</ul>
<p>Through this contract we can e.g. handle spurious ambiguity, if
two NT are on the source side. However, resolving this
ambiguity is implemented in a lazy fashion: we delay fixing the
span boundaries until we need to expand the hypothesis once
more, and then we fix only the first boundaries for the first
span.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>hypo</strong> (<a class="reference internal" href="cam.sgnmt.predictors.html#cam.sgnmt.predictors.grammar.LRHieroHypothesis" title="cam.sgnmt.predictors.grammar.LRHieroHypothesis"><em>LRHieroHypothesis</em></a>) &#8211; Hypothesis to expand</li>
<li><strong>src_seq</strong> (<em>list</em>) &#8211; Source sequence to match</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">parse</code><span class="sig-paren">(</span><em>line</em>, <em>feature_weights=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/grammar.html#RuleSet.parse"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Parse a line in a rule file from ruleXtract and add the rule
to the set.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>line</strong> (<em>string</em>) &#8211; </li>
<li><strong>feature_weights</strong> (<em>list</em>) &#8211; score or <code class="docutils literal"><span class="pre">None</span></code> to use uniform
weights</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">update_span_len_range</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/grammar.html#RuleSet.update_span_len_range"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>This method updates the <code class="docutils literal"><span class="pre">span_len_range</span></code> variable by
finding boundaries for the spans each non terminal can cover.
This is done iteratively: First, guess the range for each NT to
(0, inf). Then, iterate through all rules for a specific NT and
adjust the boundaries given the ranges for all other NTs. Do
this until ranges do not change anymore. This is an expensive
operation should be done after adding all rules. Note also that
the tries store a reference to <code class="docutils literal"><span class="pre">self.span_len_range</span></code>, i.e.
the variable is propagated to all tries automatically.</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt>
<em class="property">class </em><code class="descclassname">cam.sgnmt.predictors.grammar.</code><code class="descname">RuleXtractPredictor</code><span class="sig-paren">(</span><em>ruleXtract_path</em>, <em>use_weights</em>, <em>feature_weights=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/grammar.html#RuleXtractPredictor"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Bases: <a class="reference internal" href="cam.sgnmt.decoding.html#cam.sgnmt.decoding.core.Predictor" title="cam.sgnmt.decoding.core.Predictor"><code class="xref py py-class docutils literal"><span class="pre">cam.sgnmt.decoding.core.Predictor</span></code></a></p>
<p>Predictor based on ruleXtract rules. Bins are organized
according the number of target words. We assume that no rule
produces the empty word on the source side (but possibly on the
target side). Hypotheses are produced iteratively s.t. the
following invariant holds: The bins contain a set of (partial)
hypotheses from which we can derive all full hypotheses which are
consistent with the current target prefix (i.e. the prefix of the
target sentence which has already been translated). This set is
updated when calling either consume_word or predict_next: consume_
word deletes all hypotheses which become inconsistent with the new
word. <code class="docutils literal"><span class="pre">predict_next</span></code> requires all hypotheses to have a target_
prefix length of at least one plus the number of consumed words.
Therefore, <code class="docutils literal"><span class="pre">predict_next</span></code> expands hypotheses as long as they are
shorter. This fits nicely with grouping hypotheses in bins of same
target prefix length: we expand until all low rank bins are empty.
We predict the next target word by using the cost of the best
hypothesis with the word at the right position.</p>
<p>Note that this predictor is similar to the decoding algorithm in</p>
<blockquote>
<div>Efficient Left-to-Right Hierarchical Phrase-based Translation with
Improved Reordering.
Maryam Siahbani, Baskaran Sankaran and Anoop Sarkar.
EMNLP 2013. Oct 18-21, 2013. Seattle, USA.</div></blockquote>
<p>without cube pruning, but it is extended to an arbitrary number of
non-terminals as produced with ruleXtract.</p>
<dl class="method">
<dt>
<code class="descname">build_posterior</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/grammar.html#RuleXtractPredictor.build_posterior"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>We need to scan all hypotheses in <code class="docutils literal"><span class="pre">self.stacks</span></code> and add up
scores grouped by the symbol at the n_consumed+1-th position.
Then, we add end-of-sentence probability by checking
<code class="docutils literal"><span class="pre">self.finals[n_consumed]</span></code></p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">consume</code><span class="sig-paren">(</span><em>word</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/grammar.html#RuleXtractPredictor.consume"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Remove all hypotheses with translation prefixes which do not
match <code class="docutils literal"><span class="pre">word</span></code></p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">get_state</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/grammar.html#RuleXtractPredictor.get_state"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Predictor state consists of the stacks, the completed
hypotheses, and the number of consumed words.</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">get_unk_probability</code><span class="sig-paren">(</span><em>posterior</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/grammar.html#RuleXtractPredictor.get_unk_probability"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Returns negative infinity if the posterior is not empty as
words outside the grammar are not possible according this
predictor. If <code class="docutils literal"><span class="pre">posterior</span></code> is empty, return 0 (= log 1)</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">initialize</code><span class="sig-paren">(</span><em>src_sentence</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/grammar.html#RuleXtractPredictor.initialize"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Delete all bins and add the initial cell to the first bin</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">predict_next</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/grammar.html#RuleXtractPredictor.predict_next"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>For predicting the distribution of the next target tokens,
we need to empty the stack with the current history length
by expanding all hypotheses on it. Then, all hypotheses are
in larger bins, i.e. have a longer target prefix than the
current history. Thus, we can look up the possible next words
by iterating through all active hypotheses.</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">reset</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/grammar.html#RuleXtractPredictor.reset"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Empty the stack and delete history.</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">set_state</code><span class="sig-paren">(</span><em>state</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/grammar.html#RuleXtractPredictor.set_state"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Set the predictor state.</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt>
<em class="property">class </em><code class="descclassname">cam.sgnmt.predictors.grammar.</code><code class="descname">Span</code><span class="sig-paren">(</span><em>p</em>, <em>borders</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/grammar.html#Span"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Span is defined by the start and end position and the
corresponding sequence of terminal and non-terminal symbols p.
Normally, p is just a single NT symbol. However, if there is
ambiguity with how to apply a rule to a span (e.g.
rule X -&gt; X the X to span foo the bar the baz) we allow to resolve
them later on demand. In this case, p = X the X</p>
</dd></dl>

<dl class="class">
<dt>
<em class="property">class </em><code class="descclassname">cam.sgnmt.predictors.grammar.</code><code class="descname">Trie</code><span class="sig-paren">(</span><em>span_len_range</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/grammar.html#Trie"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>This trie implementation allows matching NT symbols with arbitrary
symbol sequences with certain lengths when searching.
Note: This trie does not implement edge collapsing - each edge is
labeled with exactly one word</p>
<dl class="method">
<dt>
<code class="descname">add</code><span class="sig-paren">(</span><em>seq</em>, <em>element</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/grammar.html#Trie.add"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Add an element to the trie data structure. The key sequence
<code class="docutils literal"><span class="pre">seq</span></code> can contain non-terminals with negative IDs. If a
element with the same key already exists in the data structure,
we do not delete it but store both items.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>seq</strong> (<em>list</em>) &#8211; Sequence of terminals and non-terminals used as
key in the trie</li>
<li><strong>element</strong> (<em>object</em>) &#8211; Object to associate with <code class="docutils literal"><span class="pre">seq</span></code></li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">get_all_elements</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/grammar.html#Trie.get_all_elements"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Retrieve all elements stored in the trie</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">get_elements</code><span class="sig-paren">(</span><em>src_seq</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/grammar.html#Trie.get_elements"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Get all elements (e.g. rules) which match the given sequence
of source tokens.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>seq</strong> (<em>list</em>) &#8211; Sequence of terminals and non-terminals used as
key in the trie</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><code class="docutils literal"><span class="pre">(rules,</span> <span class="pre">nt_span_lens)</span></code>. The first dictionary
contains all applying rules. <code class="docutils literal"><span class="pre">nt_span_lens</span></code> lists the
number of symbols each of the NTs on the source side
covers. Make sure that <code class="docutils literal"><span class="pre">self.span_len_range</span></code> is updated</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body">two dicts</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">replace</code><span class="sig-paren">(</span><em>seq</em>, <em>element</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/grammar.html#Trie.replace"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Replaces all elements stored at a <code class="docutils literal"><span class="pre">seq</span></code> with a new single
element <code class="docutils literal"><span class="pre">element</span></code>. This is equivalent to first removing all
items with key <code class="docutils literal"><span class="pre">seq</span></code>, and then add the new element with
<code class="docutils literal"><span class="pre">add(seq,</span> <span class="pre">element)</span></code></p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>seq</strong> (<em>list</em>) &#8211; Sequence of terminals and non-terminals used as
key in the trie</li>
<li><strong>element</strong> (<em>object</em>) &#8211; Object to associate with <code class="docutils literal"><span class="pre">seq</span></code></li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="cam-sgnmt-predictors-length-module">
<h3>cam.sgnmt.predictors.length module<a class="headerlink" href="#cam-sgnmt-predictors-length-module" title="Permalink to this headline">¶</a></h3>
<p>This module contains predictors that deal wit the length of the
target sentence. The <code class="docutils literal"><span class="pre">NBLengthPredictor</span></code> assumes a negative binomial
distribution on the target sentence lengths, where the parameters r and
p are linear combinations of features extracted from the source
sentence. The <code class="docutils literal"><span class="pre">WordCountPredictor</span></code> adds the number of words as cost,
which can be used to prevent hypotheses from getting to short when
using a language model.</p>
<dl class="class">
<dt>
<em class="property">class </em><code class="descclassname">cam.sgnmt.predictors.length.</code><code class="descname">NBLengthPredictor</code><span class="sig-paren">(</span><em>text_file</em>, <em>model_weights</em>, <em>use_point_probs</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/length.html#NBLengthPredictor"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Bases: <a class="reference internal" href="cam.sgnmt.decoding.html#cam.sgnmt.decoding.core.Predictor" title="cam.sgnmt.decoding.core.Predictor"><code class="xref py py-class docutils literal"><span class="pre">cam.sgnmt.decoding.core.Predictor</span></code></a></p>
<p>This predictor assumes that target sentence lengths are
distributed according a negative binomial distribution with
parameters r,p. r is linear in features, p is the logistic of a
linear function over the features. Weights can be trained using
the Matlab script <code class="docutils literal"><span class="pre">estimate_length_model.m</span></code></p>
<p>Let w be the model_weights. All features are extracted from the
src sentence:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="n">r</span> <span class="o">=</span> <span class="n">w0</span> <span class="o">*</span> <span class="c1">#char</span>
<span class="o">+</span> <span class="n">w1</span> <span class="o">*</span> <span class="c1">#words</span>
<span class="o">+</span> <span class="n">w2</span> <span class="o">*</span> <span class="c1">#punctuation</span>
<span class="o">+</span> <span class="n">w3</span> <span class="o">*</span> <span class="c1">#char/#words</span>
<span class="o">+</span> <span class="n">w4</span> <span class="o">*</span> <span class="c1">#punct/#words</span>
<span class="o">+</span> <span class="n">w10</span>

<span class="n">p</span> <span class="o">=</span> <span class="n">logistic</span><span class="p">(</span><span class="n">w5</span> <span class="o">*</span> <span class="c1">#char</span>
<span class="o">+</span> <span class="n">w6</span> <span class="o">*</span> <span class="c1">#words</span>
<span class="o">+</span> <span class="n">w7</span> <span class="o">*</span> <span class="c1">#punctuation</span>
<span class="o">+</span> <span class="n">w8</span> <span class="o">*</span> <span class="c1">#char/#words</span>
<span class="o">+</span> <span class="n">w9</span> <span class="o">*</span> <span class="c1">#punct/#words</span>
<span class="o">+</span> <span class="n">w11</span><span class="p">)</span>

<span class="n">target_length</span> <span class="o">~</span> <span class="n">NB</span><span class="p">(</span><span class="n">r</span><span class="p">,</span><span class="n">p</span><span class="p">)</span>
</pre></div>
</div>
<p>The biases w10 and w11 are optional.</p>
<p>The predictor predicts EOS with NB(#consumed_words,r,p)</p>
<dl class="method">
<dt>
<code class="descname">consume</code><span class="sig-paren">(</span><em>word</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/length.html#NBLengthPredictor.consume"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Increases the current history length</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>word</strong> (<em>int</em>) &#8211; Not used</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">get_state</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/length.html#NBLengthPredictor.get_state"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>State consists of the number of consumed words, and the
accumulator for previous EOS probability estimates if we
don&#8217;t use point estimates.</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">get_unk_probability</code><span class="sig-paren">(</span><em>posterior</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/length.html#NBLengthPredictor.get_unk_probability"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>If we use point estimates, return 0 (=1). Otherwise, return
the 1-p(EOS), with p(EOS) fetched from <code class="docutils literal"><span class="pre">posterior</span></code></p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">initialize</code><span class="sig-paren">(</span><em>src_sentence</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/length.html#NBLengthPredictor.initialize"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Extract features for the source sentence. Note that this
method does not use <code class="docutils literal"><span class="pre">src_sentence</span></code> as we need the string
representation of the source sentence to extract features.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>src_sentence</strong> (<em>list</em>) &#8211; Not used</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">predict_next</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/length.html#NBLengthPredictor.predict_next"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Returns a dictionary with single entry for EOS.</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">reset</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/length.html#NBLengthPredictor.reset"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Empty method.</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">set_state</code><span class="sig-paren">(</span><em>state</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/length.html#NBLengthPredictor.set_state"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Set the predictor state</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt>
<em class="property">class </em><code class="descclassname">cam.sgnmt.predictors.length.</code><code class="descname">WordCountPredictor</code><a class="reference internal" href="_modules/cam/sgnmt/predictors/length.html#WordCountPredictor"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Bases: <a class="reference internal" href="cam.sgnmt.decoding.html#cam.sgnmt.decoding.core.Predictor" title="cam.sgnmt.decoding.core.Predictor"><code class="xref py py-class docutils literal"><span class="pre">cam.sgnmt.decoding.core.Predictor</span></code></a></p>
<p>This predictor adds the number of words as feature</p>
<dl class="method">
<dt>
<code class="descname">consume</code><span class="sig-paren">(</span><em>word</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/length.html#WordCountPredictor.consume"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Increases word counter by one.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>word</strong> (<em>int</em>) &#8211; Not used</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">get_state</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/length.html#WordCountPredictor.get_state"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Returns the number of consumed words</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">get_unk_probability</code><span class="sig-paren">(</span><em>posterior</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/length.html#WordCountPredictor.get_unk_probability"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Always returns 0 (= log 1)</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">initialize</code><span class="sig-paren">(</span><em>src_sentence</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/length.html#WordCountPredictor.initialize"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Resets the internal counter for consumed words.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>src_sentence</strong> (<em>list</em>) &#8211; Not used</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">predict_next</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/length.html#WordCountPredictor.predict_next"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Set score for EOS to the number of consumed words</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">reset</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/length.html#WordCountPredictor.reset"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Empty method.</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">set_state</code><span class="sig-paren">(</span><em>state</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/length.html#WordCountPredictor.set_state"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Set the number of consumed words</p>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="cam-sgnmt-predictors-misc-module">
<h3>cam.sgnmt.predictors.misc module<a class="headerlink" href="#cam-sgnmt-predictors-misc-module" title="Permalink to this headline">¶</a></h3>
<p>This module provides helper predictors and predictor wrappers which
are not directly used for scoring. An example is the indexmap wrapper
predictor, which can be used if a predictor uses a different word map.</p>
<dl class="class">
<dt>
<em class="property">class </em><code class="descclassname">cam.sgnmt.predictors.misc.</code><code class="descname">IdxmapPredictor</code><span class="sig-paren">(</span><em>src_idxmap_path</em>, <em>trgt_idxmap_path</em>, <em>slave_predictor</em>, <em>slave_weight</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/misc.html#IdxmapPredictor"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Bases: <a class="reference internal" href="cam.sgnmt.decoding.html#cam.sgnmt.decoding.core.Predictor" title="cam.sgnmt.decoding.core.Predictor"><code class="xref py py-class docutils literal"><span class="pre">cam.sgnmt.decoding.core.Predictor</span></code></a></p>
<p>This wrapper predictor can be applied to slave predictors which
use different wmaps than SGNMT. It translates between SGNMT word
indices and predictors indices each time the predictor is called.
This mapping is transparent to both the decoder and the wrapped
slave predictor.</p>
<dl class="method">
<dt>
<code class="descname">consume</code><span class="sig-paren">(</span><em>word</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/misc.html#IdxmapPredictor.consume"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Pass through to slave predictor</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">estimate_future_cost</code><span class="sig-paren">(</span><em>hypo</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/misc.html#IdxmapPredictor.estimate_future_cost"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Pass through to slave predictor</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">get_state</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/misc.html#IdxmapPredictor.get_state"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Pass through to slave predictor</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">get_unk_probability</code><span class="sig-paren">(</span><em>posterior</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/misc.html#IdxmapPredictor.get_unk_probability"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>ATTENTION: Here we should translate the posterior array
back to slave predictor indices. However, the unk_id is
translated to the identical index, and others normally do not
matter when computing the UNK probability. Therefore, we
refrain from a complete conversion and pass through
<code class="docutils literal"><span class="pre">posterior</span></code> without changing its word indices.</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">initialize</code><span class="sig-paren">(</span><em>src_sentence</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/misc.html#IdxmapPredictor.initialize"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Pass through to slave predictor</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">initialize_heuristic</code><span class="sig-paren">(</span><em>src_sentence</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/misc.html#IdxmapPredictor.initialize_heuristic"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Pass through to slave predictor</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">load_map</code><span class="sig-paren">(</span><em>path</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/misc.html#IdxmapPredictor.load_map"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Load a index map file. Mappings should be bijections, but
there is no sanity check in place to verify this.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>path</strong> (<em>string</em>) &#8211; Path to the mapping file</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body">dict. Mapping from SGNMT index to slave predictor index</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">predict_next</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/misc.html#IdxmapPredictor.predict_next"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Pass through to slave predictor</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">reset</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/misc.html#IdxmapPredictor.reset"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Pass through to slave predictor</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">set_current_sen_id</code><span class="sig-paren">(</span><em>cur_sen_id</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/misc.html#IdxmapPredictor.set_current_sen_id"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>We need to override this method to propagate current_
sentence_id to the slave predictor</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">set_state</code><span class="sig-paren">(</span><em>state</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/misc.html#IdxmapPredictor.set_state"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Pass through to slave predictor</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt>
<em class="property">class </em><code class="descclassname">cam.sgnmt.predictors.misc.</code><code class="descname">UnboundedIdxmapPredictor</code><span class="sig-paren">(</span><em>src_idxmap_path</em>, <em>trgt_idxmap_path</em>, <em>slave_predictor</em>, <em>slave_weight</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/misc.html#UnboundedIdxmapPredictor"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Bases: <a class="reference internal" href="cam.sgnmt.predictors.html#cam.sgnmt.predictors.misc.IdxmapPredictor" title="cam.sgnmt.predictors.misc.IdxmapPredictor"><code class="xref py py-class docutils literal"><span class="pre">cam.sgnmt.predictors.misc.IdxmapPredictor</span></code></a>, <a class="reference internal" href="cam.sgnmt.decoding.html#cam.sgnmt.decoding.core.UnboundedVocabularyPredictor" title="cam.sgnmt.decoding.core.UnboundedVocabularyPredictor"><code class="xref py py-class docutils literal"><span class="pre">cam.sgnmt.decoding.core.UnboundedVocabularyPredictor</span></code></a></p>
<p>This class is a version of <code class="docutils literal"><span class="pre">IdxmapPredictor</span></code> for unbounded
vocabulary predictors. This needs an adjusted <code class="docutils literal"><span class="pre">predict_next</span></code>
method to pass through the set of target words to score correctly.</p>
<dl class="method">
<dt>
<code class="descname">predict_next</code><span class="sig-paren">(</span><em>trgt_words</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/misc.html#UnboundedIdxmapPredictor.predict_next"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Pass through to slave predictor</p>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="cam-sgnmt-predictors-ngram-module">
<h3>cam.sgnmt.predictors.ngram module<a class="headerlink" href="#cam-sgnmt-predictors-ngram-module" title="Permalink to this headline">¶</a></h3>
<p>This module contains predictors for n-gram (Kneser-Ney) language
modeling. This is a <code class="docutils literal"><span class="pre">UnboundedVocabularyPredictor</span></code> as the vocabulary
size ngram models normally do not permit complete enumeration of the
posterior.</p>
<p>This module is based on the swig-srilm package.</p>
<p><a class="reference external" href="https://github.com/desilinguist/swig-srilm">https://github.com/desilinguist/swig-srilm</a></p>
<dl class="class">
<dt>
<em class="property">class </em><code class="descclassname">cam.sgnmt.predictors.ngram.</code><code class="descname">SRILMPredictor</code><span class="sig-paren">(</span><em>path</em>, <em>ngram_order</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/ngram.html#SRILMPredictor"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Bases: <a class="reference internal" href="cam.sgnmt.decoding.html#cam.sgnmt.decoding.core.UnboundedVocabularyPredictor" title="cam.sgnmt.decoding.core.UnboundedVocabularyPredictor"><code class="xref py py-class docutils literal"><span class="pre">cam.sgnmt.decoding.core.UnboundedVocabularyPredictor</span></code></a></p>
<p>SRILM predictor based on swig
<a class="reference external" href="https://github.com/desilinguist/swig-srilm">https://github.com/desilinguist/swig-srilm</a></p>
<p>The predictor state is described by the n-gram history. The language
model has to use word indices rather than the string word
representations.</p>
<dl class="method">
<dt>
<code class="descname">consume</code><span class="sig-paren">(</span><em>word</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/ngram.html#SRILMPredictor.consume"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Extends the current history by <code class="docutils literal"><span class="pre">word</span></code></p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">get_state</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/ngram.html#SRILMPredictor.get_state"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Returns the current n-gram history</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">get_unk_probability</code><span class="sig-paren">(</span><em>posterior</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/ngram.html#SRILMPredictor.get_unk_probability"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Use the probability for &#8216;&lt;unk&gt;&#8217; in the language model</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">initialize</code><span class="sig-paren">(</span><em>src_sentence</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/ngram.html#SRILMPredictor.initialize"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Initializes the history with the start-of-sentence symbol.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>src_sentence</strong> (<em>list</em>) &#8211; Not used</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">predict_next</code><span class="sig-paren">(</span><em>words</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/ngram.html#SRILMPredictor.predict_next"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Score the set of target words with the n-gram language
model given the current history</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>words</strong> (<em>list</em>) &#8211; Set of words to score</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body">dict. Language model scores for the words in <code class="docutils literal"><span class="pre">words</span></code></td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">reset</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/ngram.html#SRILMPredictor.reset"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Resets the current history to &lt;S&gt;</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">set_state</code><span class="sig-paren">(</span><em>state</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/ngram.html#SRILMPredictor.set_state"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Sets the current n-gram history</p>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="cam-sgnmt-predictors-nnlm-module">
<h3>cam.sgnmt.predictors.nnlm module<a class="headerlink" href="#cam-sgnmt-predictors-nnlm-module" title="Permalink to this headline">¶</a></h3>
<p>This module integrates neural language models, for example feed-
forward language models like NPLM. It depends on the python interface
to NPLM.</p>
<p><a class="reference external" href="http://nlg.isi.edu/software/nplm/">http://nlg.isi.edu/software/nplm/</a></p>
<dl class="class">
<dt>
<em class="property">class </em><code class="descclassname">cam.sgnmt.predictors.nnlm.</code><code class="descname">NPLMPredictor</code><span class="sig-paren">(</span><em>path</em>, <em>normalize_scores</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/nnlm.html#NPLMPredictor"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Bases: <a class="reference internal" href="cam.sgnmt.decoding.html#cam.sgnmt.decoding.core.UnboundedVocabularyPredictor" title="cam.sgnmt.decoding.core.UnboundedVocabularyPredictor"><code class="xref py py-class docutils literal"><span class="pre">cam.sgnmt.decoding.core.UnboundedVocabularyPredictor</span></code></a></p>
<p>NPLM language model predictor. Even though NPLM normally has a
limited vocabulary size, we implement it as a unbounded vocabulary
predictor because it is more efficient to score only a subset of
the vocabulary. This predictor uses the python interface to NPLM
from</p>
<p><a class="reference external" href="http://nlg.isi.edu/software/nplm/">http://nlg.isi.edu/software/nplm/</a></p>
<dl class="method">
<dt>
<code class="descname">consume</code><span class="sig-paren">(</span><em>word</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/nnlm.html#NPLMPredictor.consume"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Extend current history by <code class="docutils literal"><span class="pre">word</span></code></p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">get_state</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/nnlm.html#NPLMPredictor.get_state"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Returns the current history</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">get_unk_probability</code><span class="sig-paren">(</span><em>posterior</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/nnlm.html#NPLMPredictor.get_unk_probability"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Use NPLM UNK score if exists</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">initialize</code><span class="sig-paren">(</span><em>src_sentence</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/nnlm.html#NPLMPredictor.initialize"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Set the n-gram history to initial value.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>src_sentence</strong> (<em>list</em>) &#8211; Not used</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">predict_next</code><span class="sig-paren">(</span><em>words</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/nnlm.html#NPLMPredictor.predict_next"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Scores the words in <code class="docutils literal"><span class="pre">words</span></code> using NPLM.</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">reset</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/nnlm.html#NPLMPredictor.reset"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Set the n-gram history to initial value.</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">set_state</code><span class="sig-paren">(</span><em>state</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/nnlm.html#NPLMPredictor.set_state"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Sets the current history</p>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="module-contents">
<h3>Module contents<a class="headerlink" href="#module-contents" title="Permalink to this headline">¶</a></h3>
<p>Predictors are the scoring modules used in SGNMT. They can be used
together to form a combined search space and scores. Note that the
configuration of predictors is not decoupled with the central
configuration (yet). Therefore, new predictors need to be referenced to
in <code class="docutils literal"><span class="pre">blocks.decode</span></code>, and their configuration parameters need to be
added to <code class="docutils literal"><span class="pre">blocks.ui</span></code>.</p>
</div>
</div>
</div>


           </div>
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="decoders.html" class="btn btn-neutral float-right" title="Decoders" accesskey="n">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="command_line.html" class="btn btn-neutral" title="Command-line reference" accesskey="p"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2016, University of Cambridge.

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/snide/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  

    <script type="text/javascript">
        var DOCUMENTATION_OPTIONS = {
            URL_ROOT:'./',
            VERSION:'0.1',
            COLLAPSE_INDEX:false,
            FILE_SUFFIX:'.html',
            HAS_SOURCE:  true
        };
    </script>
      <script type="text/javascript" src="_static/jquery.js"></script>
      <script type="text/javascript" src="_static/underscore.js"></script>
      <script type="text/javascript" src="_static/doctools.js"></script>

  

  
  
    <script type="text/javascript" src="_static/js/theme.js"></script>
  

  
  
  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.StickyNav.enable();
      });
  </script>
   

</body>
</html>