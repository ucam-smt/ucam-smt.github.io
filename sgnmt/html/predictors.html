

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Predictors &mdash; SGNMT 0.3.2 documentation</title>
  

  
  

  

  
  
    

  

  
  
    <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  

  
    <link rel="stylesheet" href="_static/custom.css" type="text/css" />
  

  
    <link rel="top" title="SGNMT 0.3.2 documentation" href="index.html"/>
        <link rel="next" title="Decoders" href="decoders.html"/>
        <link rel="prev" title="Command-line reference" href="command_line.html"/> 

  
  <script src="_static/js/modernizr.min.js"></script>

</head>

<body class="wy-body-for-nav" role="document">

  <div class="wy-grid-for-nav">

    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search">
          

          
            <a href="index.html" class="icon icon-home"> SGNMT
          

          
          </a>

          
            
            
              <div class="version">
                0.3.2
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
                <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="setup.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="tutorial.html">Tutorial: Basics</a></li>
<li class="toctree-l1"><a class="reference internal" href="adding_components.html">Tutorial: Adding new components</a></li>
<li class="toctree-l1"><a class="reference internal" href="kyoto_nmt.html">Tutorial:  NMT decoding strategies</a></li>
<li class="toctree-l1"><a class="reference internal" href="command_line.html">Command-line reference</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Predictors</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#available-predictors">Available predictors</a></li>
<li class="toctree-l2"><a class="reference internal" href="#predictor-modules">Predictor modules</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#cam-sgnmt-predictors-automata-module">cam.sgnmt.predictors.automata module</a></li>
<li class="toctree-l3"><a class="reference internal" href="#cam-sgnmt-predictors-blocks-nmt-module">cam.sgnmt.predictors.blocks_nmt module</a></li>
<li class="toctree-l3"><a class="reference internal" href="#cam-sgnmt-predictors-bow-module">cam.sgnmt.predictors.bow module</a></li>
<li class="toctree-l3"><a class="reference internal" href="#cam-sgnmt-predictors-core-module">cam.sgnmt.predictors.core module</a></li>
<li class="toctree-l3"><a class="reference internal" href="#cam-sgnmt-predictors-ffnnlm-module">cam.sgnmt.predictors.ffnnlm module</a></li>
<li class="toctree-l3"><a class="reference internal" href="#cam-sgnmt-predictors-forced-module">cam.sgnmt.predictors.forced module</a></li>
<li class="toctree-l3"><a class="reference internal" href="#cam-sgnmt-predictors-grammar-module">cam.sgnmt.predictors.grammar module</a></li>
<li class="toctree-l3"><a class="reference internal" href="#cam-sgnmt-predictors-length-module">cam.sgnmt.predictors.length module</a></li>
<li class="toctree-l3"><a class="reference internal" href="#cam-sgnmt-predictors-misc-module">cam.sgnmt.predictors.misc module</a></li>
<li class="toctree-l3"><a class="reference internal" href="#cam-sgnmt-predictors-ngram-module">cam.sgnmt.predictors.ngram module</a></li>
<li class="toctree-l3"><a class="reference internal" href="#cam-sgnmt-predictors-structure-module">cam.sgnmt.predictors.structure module</a></li>
<li class="toctree-l3"><a class="reference internal" href="#cam-sgnmt-predictors-tf-nizza-module">cam.sgnmt.predictors.tf_nizza module</a></li>
<li class="toctree-l3"><a class="reference internal" href="#cam-sgnmt-predictors-tf-nmt-module">cam.sgnmt.predictors.tf_nmt module</a></li>
<li class="toctree-l3"><a class="reference internal" href="#cam-sgnmt-predictors-tf-rnnlm-module">cam.sgnmt.predictors.tf_rnnlm module</a></li>
<li class="toctree-l3"><a class="reference internal" href="#cam-sgnmt-predictors-tf-t2t-module">cam.sgnmt.predictors.tf_t2t module</a></li>
<li class="toctree-l3"><a class="reference internal" href="#cam-sgnmt-predictors-tokenization-module">cam.sgnmt.predictors.tokenization module</a></li>
<li class="toctree-l3"><a class="reference internal" href="#cam-sgnmt-predictors-vocabulary-module">cam.sgnmt.predictors.vocabulary module</a></li>
<li class="toctree-l3"><a class="reference internal" href="#module-contents">Module contents</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="decoders.html">Decoders</a></li>
<li class="toctree-l1"><a class="reference internal" href="examples.html">Examples</a></li>
<li class="toctree-l1"><a class="reference internal" href="faq.html">Common issues</a></li>
<li class="toctree-l1"><a class="reference internal" href="publications.html">Publications</a></li>
<li class="toctree-l1"><a class="reference internal" href="cam.sgnmt.html">All modules</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" role="navigation" aria-label="top navigation">
        <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
        <a href="index.html">SGNMT</a>
      </nav>


      
      <div class="wy-nav-content">
        <div class="rst-content">
          

 



<div role="navigation" aria-label="breadcrumbs navigation">
  <ul class="wy-breadcrumbs">
    <li><a href="index.html">Docs</a> &raquo;</li>
      
    <li>Predictors</li>
      <li class="wy-breadcrumbs-aside">
        
          
            <a href="_sources/predictors.txt" rel="nofollow"> View page source</a>
          
        
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="predictors">
<h1>Predictors<a class="headerlink" href="#predictors" title="Permalink to this headline">¶</a></h1>
<p>Predictors are scoring modules which define a distribution over target words given the history and some side information like the source sentence.
If vocabulary sizes differ among predictors, we fill in gaps with predictor UNK scores.</p>
<p>Predictors are specified using the <code class="docutils literal"><span class="pre">--predictors</span></code> and <code class="docutils literal"><span class="pre">--predictor_weights</span></code> arguments, e.g.:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span>$ python decode.py --predictors nmt,fst,nplm --predictor_weights 0.7,0.1,0.2 ...
</pre></div>
</div>
<p>See the <a class="reference internal" href="tutorial.html#tutorial-label"><span class="std std-ref">Tutorial: Basics</span></a> page for examples how to use predictors for decoding.</p>
<div class="section" id="available-predictors">
<h2>Available predictors<a class="headerlink" href="#available-predictors" title="Permalink to this headline">¶</a></h2>
<p>The following predictors are available:</p>
<ul>
<li><p class="first"><strong>nmt</strong>: neural machine translation predictor. Requires Blocks/Theano or TensorFlow.</p>
<p>Options: <code class="docutils literal"><span class="pre">nmt_config</span></code>, <code class="docutils literal"><span class="pre">nmt_path</span></code>, <code class="docutils literal"><span class="pre">nmt_model_selector</span></code>, <code class="docutils literal"><span class="pre">cache_nmt_posteriors</span></code>, <code class="docutils literal"><span class="pre">nmt_engine</span></code></p>
</li>
<li><p class="first"><strong>t2t</strong>: Predictor for tensor2tensor models. Requires Tensor2Tensor.</p>
<p>Options: <code class="docutils literal"><span class="pre">t2t_usr_dir</span></code>, <code class="docutils literal"><span class="pre">t2t_model</span></code>, <code class="docutils literal"><span class="pre">t2t_problem</span></code>, <code class="docutils literal"><span class="pre">t2t_hparams_set</span></code>, <code class="docutils literal"><span class="pre">t2t_checkpoint_dir</span></code>, <code class="docutils literal"><span class="pre">pred_src_vocab_size</span></code>, <code class="docutils literal"><span class="pre">pred_trg_vocab_size</span></code></p>
</li>
<li><p class="first"><strong>nizza</strong>: Nizza alignment models. Requires Nizza.</p>
<p>Options: <code class="docutils literal"><span class="pre">nizza_model</span></code>, <code class="docutils literal"><span class="pre">nizza_hparams_set</span></code>, <code class="docutils literal"><span class="pre">nizza_checkpoint_dir</span></code>, <code class="docutils literal"><span class="pre">pred_src_vocab_size</span></code>, <code class="docutils literal"><span class="pre">pred_trg_vocab_size</span></code></p>
</li>
<li><p class="first"><strong>lexnizza</strong>: Uses Nizza lexical scores to check coverage. Requires Nizza.</p>
<p>Options: <code class="docutils literal"><span class="pre">nizza_model</span></code>, <code class="docutils literal"><span class="pre">nizza_hparams_set</span></code>, <code class="docutils literal"><span class="pre">nizza_checkpoint_dir</span></code>, <code class="docutils literal"><span class="pre">pred_src_vocab_size</span></code>, <code class="docutils literal"><span class="pre">pred_trg_vocab_size</span></code>, <code class="docutils literal"><span class="pre">lexnizza_alpha</span></code>, <code class="docutils literal"><span class="pre">lexnizza_beta</span></code>, <code class="docutils literal"><span class="pre">lexnizza_shortlist_strategies</span></code>, <code class="docutils literal"><span class="pre">lexnizza_max_shortlist_length</span></code></p>
</li>
<li><p class="first"><strong>srilm</strong>: n-gram language model. Requires swig-srilm.</p>
<p>Options: <code class="docutils literal"><span class="pre">srilm_path</span></code>, <code class="docutils literal"><span class="pre">srilm_order</span></code></p>
</li>
<li><p class="first"><strong>nplm</strong>: neural n-gram language model. Requires nplm.</p>
<p>Options: <code class="docutils literal"><span class="pre">nplm_path</span></code>, <code class="docutils literal"><span class="pre">normalize_nplm_probs</span></code></p>
</li>
<li><p class="first"><strong>rnnlm</strong>: RNN language model following Zaremba et al. (2014). Requires TensorFlow.</p>
<p>Options: <code class="docutils literal"><span class="pre">rnnlm_config,</span> <span class="pre">rnnlm_path</span></code></p>
</li>
<li><p class="first"><strong>forced</strong>: Forced decoding with one reference</p>
<p>Options: <code class="docutils literal"><span class="pre">trg_test</span></code></p>
</li>
<li><p class="first"><strong>bracket</strong>: Enforces well-formed bracket expressions</p>
<p>Options: <code class="docutils literal"><span class="pre">syntax_pop_id</span></code> , <code class="docutils literal"><span class="pre">syntax_max_terminal_id</span></code>, <code class="docutils literal"><span class="pre">syntax_max_depth</span></code>, <code class="docutils literal"><span class="pre">extlength_path</span></code></p>
</li>
<li><p class="first"><strong>osm</strong>: Constraints output to valid OSM sequences</p>
<p>Options: None</p>
</li>
<li><p class="first"><strong>forcedosm</strong>: Forced alignment with an OSM model</p>
<p>Options: <code class="docutils literal"><span class="pre">trg_test</span></code></p>
</li>
<li><p class="first"><strong>forcedlst</strong>: Forced decoding with a Moses n-best list (n-best list rescoring)</p>
<p>Options: <code class="docutils literal"><span class="pre">trg_test</span></code>, <code class="docutils literal"><span class="pre">forcedlst_match_unk</span></code>, <code class="docutils literal"><span class="pre">forcedlst_sparse_feat</span></code>, <code class="docutils literal"><span class="pre">use_nbest_weights</span></code></p>
</li>
<li><p class="first"><strong>bow</strong>: Forced decoding with one bag-of-words ref.</p>
<p>Options: <code class="docutils literal"><span class="pre">trg_test</span></code>, <code class="docutils literal"><span class="pre">heuristic_scores_file</span></code>, <code class="docutils literal"><span class="pre">bow_heuristic_strategies</span></code>, <code class="docutils literal"><span class="pre">bow_accept_subsets</span></code>, <code class="docutils literal"><span class="pre">bow_accept_duplicates</span></code>, <code class="docutils literal"><span class="pre">pred_trg_vocab_size</span></code></p>
</li>
<li><p class="first"><strong>bowsearch</strong>: Forced decoding with one bag-of-words ref.</p>
<p>Options: <code class="docutils literal"><span class="pre">hypo_recombination</span></code>, <code class="docutils literal"><span class="pre">trg_test</span></code>, <code class="docutils literal"><span class="pre">heuristic_scores_file</span></code>, <code class="docutils literal"><span class="pre">bow_heuristic_strategies</span></code>, <code class="docutils literal"><span class="pre">bow_accept_subsets</span></code>, <code class="docutils literal"><span class="pre">bow_accept_duplicates</span></code>, <code class="docutils literal"><span class="pre">pred_trg_vocab_size</span></code></p>
</li>
<li><p class="first"><strong>fst</strong>: Deterministic translation lattices</p>
<p>Options: <code class="docutils literal"><span class="pre">fst_path</span></code>, <code class="docutils literal"><span class="pre">use_fst_weights</span></code>, <code class="docutils literal"><span class="pre">normalize_fst_weights</span></code>, <code class="docutils literal"><span class="pre">fst_to_log</span></code>, <code class="docutils literal"><span class="pre">fst_skip_bos_weight</span></code></p>
</li>
<li><p class="first"><strong>nfst</strong>: Non-deterministic translation lattices</p>
<p>Options: <code class="docutils literal"><span class="pre">fst_path</span></code>, <code class="docutils literal"><span class="pre">use_fst_weights</span></code>, <code class="docutils literal"><span class="pre">normalize_fst_weights</span></code>, <code class="docutils literal"><span class="pre">fst_to_log</span></code>, <code class="docutils literal"><span class="pre">fst_skip_bos_weight</span></code></p>
</li>
<li><p class="first"><strong>rtn</strong>: Recurrent transition networks as created by HiFST with late expansion.</p>
<p>Options: <code class="docutils literal"><span class="pre">rtn_path</span></code>, <code class="docutils literal"><span class="pre">use_rtn_weights</span></code>, <code class="docutils literal"><span class="pre">minimize_rtns</span></code>, <code class="docutils literal"><span class="pre">remove_epsilon_in_rtns</span></code>, <code class="docutils literal"><span class="pre">normalize_rtn_weights</span></code></p>
</li>
<li><p class="first"><strong>lrhiero</strong>: Direct Hiero (left-to-right Hiero). This is an EXPERIMENTAL implementation of LRHiero.</p>
<p>Options: <code class="docutils literal"><span class="pre">rules_path</span></code>, <code class="docutils literal"><span class="pre">grammar_feature_weights</span></code>, <code class="docutils literal"><span class="pre">use_grammar_weights</span></code></p>
</li>
<li><p class="first"><strong>wc</strong>: Number of words feature.</p>
<p>Options: <code class="docutils literal"><span class="pre">wc_word</span></code></p>
</li>
<li><p class="first"><strong>unkc</strong>: Poisson model for number of UNKs.</p>
<p>Options: <code class="docutils literal"><span class="pre">unk_count_lambdas</span></code>, <code class="docutils literal"><span class="pre">pred_trg_vocab_size</span></code></p>
</li>
<li><p class="first"><strong>ngramc</strong>: For using MBR n-gram posteriors.</p>
<p>Options: <code class="docutils literal"><span class="pre">ngramc_path</span></code>, <code class="docutils literal"><span class="pre">ngramc_order</span></code></p>
</li>
<li><p class="first"><strong>length</strong>: Target sentence length model.</p>
<p>Options: <code class="docutils literal"><span class="pre">src_test_raw</span></code>, <code class="docutils literal"><span class="pre">length_model_weights</span></code>, <code class="docutils literal"><span class="pre">use_length_point_probs</span></code></p>
</li>
<li><p class="first"><strong>extlength</strong>: External target sentence lengths.</p>
<p>Options: <code class="docutils literal"><span class="pre">extlength_path</span></code></p>
</li>
</ul>
<p>All predictors can be combined with one or more wrapper predictors by adding the wrapper name separated by a _ symbol. Following wrappers are available:</p>
<ul>
<li><p class="first"><strong>idxmap</strong>: Add this wrapper to predictors which use an alternative word map.</p>
<p>Options: <code class="docutils literal"><span class="pre">src_idxmap</span></code>, <code class="docutils literal"><span class="pre">trg_idxmap</span></code></p>
</li>
<li><p class="first"><strong>altsrc</strong>: This wrapper loads source sentences from an alternative source.</p>
<p>Options: <code class="docutils literal"><span class="pre">altsrc_test</span></code></p>
</li>
<li><p class="first"><strong>ngramize</strong>: Extracts n-gram posteriors from a predictor without feedback loop.</p>
<p>Options: <code class="docutils literal"><span class="pre">min_ngram_order</span></code>, <code class="docutils literal"><span class="pre">max_ngram_order</span></code>, <code class="docutils literal"><span class="pre">max_len_factor</span></code></p>
</li>
<li><p class="first"><strong>skipvocab</strong>: Uses internal beam search to skip a subset of the predictor vocabulary.</p>
<p>Options: <code class="docutils literal"><span class="pre">beam</span></code>, <code class="docutils literal"><span class="pre">skipvocab_max_id</span></code>, <code class="docutils literal"><span class="pre">skipvocab_stop_size</span></code></p>
</li>
<li><p class="first"><strong>unkvocab</strong>: This wrapper explicitly excludes matching word indices higher than <code class="docutils literal"><span class="pre">pred_trg_vocab_size</span></code> with UNK scores.</p>
<p>Options: <code class="docutils literal"><span class="pre">pred_trg_vocab_size</span></code></p>
</li>
<li><p class="first"><strong>fsttok</strong>: Uses an FST to transduce SGNMT tokens to predictor tokens.</p>
<p>Options: <code class="docutils literal"><span class="pre">fsttok_path</span></code>, <code class="docutils literal"><span class="pre">fsttok_max_pending_score</span></code>, <code class="docutils literal"><span class="pre">fst_unk_id</span></code></p>
</li>
<li><p class="first"><strong>word2char</strong>: Wraps word-level predictors when SGNMT is running on character level.</p>
<p>Options: <code class="docutils literal"><span class="pre">word2char_map</span></code></p>
</li>
</ul>
<p>Note that you can use multiple instances of the same predictor. For example, &#8216;nmt,nmt,nmt&#8217; can be used for ensembling three NMT systems.
You can often override parts of the predictor configurations for subsequent predictors by adding the predictor number (e.g. see <code class="docutils literal"><span class="pre">--nmt_config2</span></code> or <code class="docutils literal"><span class="pre">--fst_path2</span></code>)</p>
<p>Detailed descriptions are available below in the modules.</p>
</div>
<div class="section" id="predictor-modules">
<h2>Predictor modules<a class="headerlink" href="#predictor-modules" title="Permalink to this headline">¶</a></h2>
<div class="section" id="cam-sgnmt-predictors-automata-module">
<h3>cam.sgnmt.predictors.automata module<a class="headerlink" href="#cam-sgnmt-predictors-automata-module" title="Permalink to this headline">¶</a></h3>
<p>This module encapsulates the predictor interface to OpenFST. This
module depends on OpenFST. To enable Python support in OpenFST, use a
recent version (&gt;=1.5.4) and compile with <code class="docutils literal"><span class="pre">--enable_python</span></code>.
Further information can be found here:</p>
<p><a class="reference external" href="http://www.openfst.org/twiki/bin/view/FST/PythonExtension">http://www.openfst.org/twiki/bin/view/FST/PythonExtension</a></p>
<p>This file includes the fst, nfst, and rtn predictors.</p>
<p>Note: If we use arc weights in FSTs, we multiply them by -1 as
everything in SGNMT is logprob, not -logprob as in FSTs log
or tropical semirings. You can disable this behavior with &#8211;fst_to_log</p>
<p>Note2: The FSTs and RTNs are assumed to have both &lt;S&gt; and &lt;/S&gt;. This
has compatibility reasons, as lattices generated by HiFST have these
symbols.</p>
<dl class="data">
<dt>
<code class="descclassname">cam.sgnmt.predictors.automata.</code><code class="descname">EPS_ID</code><em class="property"> = 0</em></dt>
<dd><p>OpenFST&#8217;s reserved ID for epsilon arcs.</p>
</dd></dl>

<dl class="class">
<dt>
<em class="property">class </em><code class="descclassname">cam.sgnmt.predictors.automata.</code><code class="descname">FstPredictor</code><span class="sig-paren">(</span><em>fst_path</em>, <em>use_weights</em>, <em>normalize_scores</em>, <em>skip_bos_weight=True</em>, <em>to_log=True</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/automata.html#FstPredictor"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Bases: <a class="reference internal" href="cam.sgnmt.predictors.html#cam.sgnmt.predictors.core.Predictor" title="cam.sgnmt.predictors.core.Predictor"><code class="xref py py-class docutils literal"><span class="pre">cam.sgnmt.predictors.core.Predictor</span></code></a></p>
<p>This predictor can read determinized translation lattices. The
predictor state consists of the current node. This is unique as the
lattices are determinized.</p>
<p>Creates a new fst predictor.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>fst_path</strong> (<em>string</em>) &#8211; Path to the FST file</li>
<li><strong>use_weights</strong> (<em>bool</em>) &#8211; If false, replace all arc weights with
0 (=log 1).</li>
<li><strong>normalize_scores</strong> (<em>bool</em>) &#8211; If true, we normalize the weights
on all outgoing arcs such that
they sum up to 1</li>
<li><strong>skip_bos_weight</strong> (<em>bool</em>) &#8211; Add the score at the &lt;S&gt; arc to the
&lt;/S&gt; arc if this is false. This results
in scores consistent with
OpenFST&#8217;s replace operation,
as &lt;S&gt; scores are normally
ignored by SGNMT.</li>
<li><strong>to_log</strong> (<em>bool</em>) &#8211; SGNMT uses normal log probs (scores) while
arc weights in FSTs normally have cost (i.e.
neg. log values) semantics. Therefore, if
true, we multiply arc weights by -1.</li>
</ul>
</td>
</tr>
</tbody>
</table>
<dl class="method">
<dt>
<code class="descname">consume</code><span class="sig-paren">(</span><em>word</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/automata.html#FstPredictor.consume"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Updates the current node by following the arc labelled with
<code class="docutils literal"><span class="pre">word</span></code>. If there is no such arc, we set <code class="docutils literal"><span class="pre">cur_node</span></code> to -1,
indicating that the predictor is in an invalid state. In this
case, all subsequent <code class="docutils literal"><span class="pre">predict_next</span></code> calls will return the
empty set.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>word</strong> (<em>int</em>) &#8211; Word on an outgoing arc from the current node</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body">float. Weight on the traversed arc</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">estimate_future_cost</code><span class="sig-paren">(</span><em>hypo</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/automata.html#FstPredictor.estimate_future_cost"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>The FST predictor comes with its own heuristic function. We
use the shortest path in the fst as future cost estimator.</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">get_state</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/automata.html#FstPredictor.get_state"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Returns the current node.</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">get_unk_probability</code><span class="sig-paren">(</span><em>posterior</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/automata.html#FstPredictor.get_unk_probability"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Always returns negative infinity: Words outside the
translation lattice are not possible according to this
predictor.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body">float. Negative infinity</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">initialize</code><span class="sig-paren">(</span><em>src_sentence</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/automata.html#FstPredictor.initialize"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Loads the FST from the file system and consumes the start
of sentence symbol.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>src_sentence</strong> (<em>list</em>) &#8211; Not used</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">initialize_heuristic</code><span class="sig-paren">(</span><em>src_sentence</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/automata.html#FstPredictor.initialize_heuristic"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Creates a matrix of shortest distances between nodes.</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">is_equal</code><span class="sig-paren">(</span><em>state1</em>, <em>state2</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/automata.html#FstPredictor.is_equal"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Returns true if the current node is the same</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">predict_next</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/automata.html#FstPredictor.predict_next"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Uses the outgoing arcs from the current node to build up the
scores for the next word.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body">dict. Set of words on outgoing arcs from the current node
together with their scores, or an empty set if we currently
have no active node or fst.</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">reset</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/automata.html#FstPredictor.reset"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Resets the loaded FST object and current node.</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">set_state</code><span class="sig-paren">(</span><em>state</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/automata.html#FstPredictor.set_state"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Sets the current node.</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt>
<em class="property">class </em><code class="descclassname">cam.sgnmt.predictors.automata.</code><code class="descname">NondeterministicFstPredictor</code><span class="sig-paren">(</span><em>fst_path</em>, <em>use_weights</em>, <em>normalize_scores</em>, <em>skip_bos_weight=True</em>, <em>to_log=True</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/automata.html#NondeterministicFstPredictor"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Bases: <a class="reference internal" href="cam.sgnmt.predictors.html#cam.sgnmt.predictors.core.Predictor" title="cam.sgnmt.predictors.core.Predictor"><code class="xref py py-class docutils literal"><span class="pre">cam.sgnmt.predictors.core.Predictor</span></code></a></p>
<p>This predictor can handle non-deterministic translation
lattices. In contrast to the fst predictor for deterministic
lattices, we store a set of nodes which are all reachable from
the start node through the current history.</p>
<p>Creates a new nfst predictor.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>fst_path</strong> (<em>string</em>) &#8211; Path to the FST file</li>
<li><strong>use_weights</strong> (<em>bool</em>) &#8211; If false, replace all arc weights with
0 (=log 1).</li>
<li><strong>normalize_scores</strong> (<em>bool</em>) &#8211; If true, we normalize the weights
on all outgoing arcs such that
they sum up to 1</li>
<li><strong>skip_bos_weight</strong> (<em>bool</em>) &#8211; If true, set weights on &lt;S&gt; arcs
to 0 (= log1)</li>
<li><strong>to_log</strong> (<em>bool</em>) &#8211; SGNMT uses normal log probs (scores) while
arc weights in FSTs normally have cost (i.e.
neg. log values) semantics. Therefore, if
true, we multiply arc weights by -1.</li>
</ul>
</td>
</tr>
</tbody>
</table>
<dl class="method">
<dt>
<code class="descname">consume</code><span class="sig-paren">(</span><em>word</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/automata.html#NondeterministicFstPredictor.consume"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Updates the current nodes by searching for all nodes which
are reachable from the current nodes by a path consisting of
any number of epsilons and exactly one <code class="docutils literal"><span class="pre">word</span></code> label. If there
is no such arc, we set the predictor in an invalid state. In
this case, all subsequent <code class="docutils literal"><span class="pre">predict_next</span></code> calls will return
the empty set.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>word</strong> (<em>int</em>) &#8211; Word on an outgoing arc from the current node</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">estimate_future_cost</code><span class="sig-paren">(</span><em>hypo</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/automata.html#NondeterministicFstPredictor.estimate_future_cost"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>The FST predictor comes with its own heuristic function. We
use the shortest path in the fst as future cost estimator.</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">get_state</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/automata.html#NondeterministicFstPredictor.get_state"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Returns the set of current nodes</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">get_unk_probability</code><span class="sig-paren">(</span><em>posterior</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/automata.html#NondeterministicFstPredictor.get_unk_probability"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Always returns negative infinity: Words outside the
translation lattice are not possible according to this
predictor.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body">float. Negative infinity</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">initialize</code><span class="sig-paren">(</span><em>src_sentence</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/automata.html#NondeterministicFstPredictor.initialize"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Loads the FST from the file system and consumes the start
of sentence symbol.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>src_sentence</strong> (<em>list</em>) &#8211; Not used</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">initialize_heuristic</code><span class="sig-paren">(</span><em>src_sentence</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/automata.html#NondeterministicFstPredictor.initialize_heuristic"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Creates a matrix of shortest distances between all nodes</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">is_equal</code><span class="sig-paren">(</span><em>state1</em>, <em>state2</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/automata.html#NondeterministicFstPredictor.is_equal"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Returns true if the current nodes are the same</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">predict_next</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/automata.html#NondeterministicFstPredictor.predict_next"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Uses the outgoing arcs from all current node to build up the
scores for the next word. This method does not follow epsilon
arcs: <code class="docutils literal"><span class="pre">consume</span></code> updates <code class="docutils literal"><span class="pre">cur_nodes</span></code> such that all reachable
arcs with word ids are connected directly with a node in
<code class="docutils literal"><span class="pre">cur_nodes</span></code>. If there are multiple arcs with the same word,
we use the log sum of the arc weights as score.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body">dict. Set of words on outgoing arcs from the current node
together with their scores, or an empty set if we currently
have no active nodes or fst.</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">reset</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/automata.html#NondeterministicFstPredictor.reset"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Resets the FST and empties the set of current nodes</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">set_state</code><span class="sig-paren">(</span><em>state</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/automata.html#NondeterministicFstPredictor.set_state"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Sets the set of current nodes</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt>
<em class="property">class </em><code class="descclassname">cam.sgnmt.predictors.automata.</code><code class="descname">RtnPredictor</code><span class="sig-paren">(</span><em>rtn_path</em>, <em>use_weights</em>, <em>normalize_scores</em>, <em>to_log=True</em>, <em>minimize_rtns=False</em>, <em>rmeps=True</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/automata.html#RtnPredictor"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Bases: <a class="reference internal" href="cam.sgnmt.predictors.html#cam.sgnmt.predictors.core.Predictor" title="cam.sgnmt.predictors.core.Predictor"><code class="xref py py-class docutils literal"><span class="pre">cam.sgnmt.predictors.core.Predictor</span></code></a></p>
<p>Predictor for RTNs (recurrent transition networks). This
predictor assumes a directory structure as produced by HiFST. You
can use this predictor for non-deterministic lattices too. This
implementation supports late expansion: RTNs are only expanded as
far as necessary to retrieve all currently reachable states.</p>
<p><code class="docutils literal"><span class="pre">cur_nodes</span></code> contains the accumulated weights from the last
consumed word (if ambiguous, the largest)</p>
<p>This implementation does not maintain a list of active nodes like
the other automata predictors. Instead, we store the current
history and search for the active nodes at each expansion. This is
more expensive, but fstreplace might change state IDs so a list of
active nodes might get corrupted.</p>
<p>Note that this predictor does not support FSTs in gzip format.</p>
<p>Creates a new RTN predictor.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>rtn_path</strong> (<em>string</em>) &#8211; Path to the RTN directory</li>
<li><strong>use_weights</strong> (<em>bool</em>) &#8211; If false, replace all arc weights with
0 (=log 1).</li>
<li><strong>normalize_scores</strong> (<em>bool</em>) &#8211; If true, we normalize the weights
on all outgoing arcs such that
they sum up to 1</li>
<li><strong>to_log</strong> (<em>bool</em>) &#8211; SGNMT uses normal log probs (scores) while
arc weights in FSTs normally have cost (i.e.
neg. log values) semantics. Therefore, if
true, we multiply arc weights by -1.</li>
<li><strong>minimize_rtns</strong> (<em>bool</em>) &#8211; Minimize the FST after each replace
operation</li>
<li><strong>rmeps</strong> (<em>bool</em>) &#8211; Remove epsilons in the FST after each replace
operation</li>
</ul>
</td>
</tr>
</tbody>
</table>
<dl class="method">
<dt>
<code class="descname">add_to_label_fst_map_recursive</code><span class="sig-paren">(</span><em>label_fst_map</em>, <em>visited_nodes</em>, <em>root_node</em>, <em>acc_weight</em>, <em>history</em>, <em>func</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/automata.html#RtnPredictor.add_to_label_fst_map_recursive"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Adds arcs to <code class="docutils literal"><span class="pre">label_fst_map</span></code> if they are labeled with an
NT symbol and reachable from <code class="docutils literal"><span class="pre">root_node</span></code> via <code class="docutils literal"><span class="pre">history</span></code>.</p>
<p>Note: visited_nodes is maintained for each history separately</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">consume</code><span class="sig-paren">(</span><em>word</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/automata.html#RtnPredictor.consume"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Adds <code class="docutils literal"><span class="pre">word</span></code> to the current history.</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">expand_rtn</code><span class="sig-paren">(</span><em>func</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/automata.html#RtnPredictor.expand_rtn"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>This method expands the RTN as far as necessary. This means
that the RTN is expanded s.t. we can build the posterior for
<code class="docutils literal"><span class="pre">cur_history</span></code>. In practice, this means that we follow all
epsilon edges and replaces all NT edges until all paths with
the prefix <code class="docutils literal"><span class="pre">cur_history</span></code> in the RTN have at least one more
terminal token. Then, we apply <code class="docutils literal"><span class="pre">func</span></code> to all reachable nodes.</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">get_state</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/automata.html#RtnPredictor.get_state"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Returns the current history.</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">get_sub_fst</code><span class="sig-paren">(</span><em>fst_id</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/automata.html#RtnPredictor.get_sub_fst"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Load sub fst from the file system or the cache</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">get_unk_probability</code><span class="sig-paren">(</span><em>posterior</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/automata.html#RtnPredictor.get_unk_probability"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Always returns negative infinity: Words outside the
RTN are not possible according to this predictor.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body">float. Negative infinity</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">initialize</code><span class="sig-paren">(</span><em>src_sentence</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/automata.html#RtnPredictor.initialize"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Loads the root RTN and consumes the start of sentence
symbol.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>src_sentence</strong> (<em>list</em>) &#8211; Not used</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">is_nt_label</code><span class="sig-paren">(</span><em>label</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/automata.html#RtnPredictor.is_nt_label"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Returns true if <code class="docutils literal"><span class="pre">label</span></code> is a non-terminal.</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">predict_next</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/automata.html#RtnPredictor.predict_next"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Expands RTN as far as possible and uses the outgoing edges
from nodes reachable by the current history to build up
the posterior for the next word. If there are no such nodes
or arcs, or no root FST is loaded, return the empty set.</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">reset</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/automata.html#RtnPredictor.reset"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Unloads the current RTN</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">set_state</code><span class="sig-paren">(</span><em>state</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/automata.html#RtnPredictor.set_state"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Sets the current history.</p>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="cam-sgnmt-predictors-blocks-nmt-module">
<h3>cam.sgnmt.predictors.blocks_nmt module<a class="headerlink" href="#cam-sgnmt-predictors-blocks-nmt-module" title="Permalink to this headline">¶</a></h3>
<p>This is the only module outside the <code class="docutils literal"><span class="pre">blocks</span></code> package with
dependency on the Blocks framework. It contains the neural machine
translation predictor nmt. Code is partially taken from the neural
machine translation example in blocks.</p>
<p><a class="reference external" href="https://github.com/mila-udem/blocks-examples/tree/master/machine_translation">https://github.com/mila-udem/blocks-examples/tree/master/machine_translation</a></p>
<p>Note that using this predictor slows down decoding compared to the
original NMT decoding because search cannot be parallelized. However,
it is much more flexible as it can be combined with other predictors.</p>
<dl class="class">
<dt>
<em class="property">class </em><code class="descclassname">cam.sgnmt.predictors.blocks_nmt.</code><code class="descname">BlocksNMTPredictor</code><span class="sig-paren">(</span><em>nmt_model_path</em>, <em>gnmt_beta</em>, <em>enable_cache</em>, <em>config</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/blocks_nmt.html#BlocksNMTPredictor"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Bases: <a class="reference internal" href="cam.sgnmt.predictors.html#cam.sgnmt.predictors.core.Predictor" title="cam.sgnmt.predictors.core.Predictor"><code class="xref py py-class docutils literal"><span class="pre">cam.sgnmt.predictors.core.Predictor</span></code></a></p>
<p>This is the neural machine translation predictor. The predicted
posteriors are equal to the distribution generated by the decoder
network in NMT. This predictor heavily relies on the NMT example in
blocks. Note that this predictor cannot be used in combination with
a target side sparse feature map. See
<code class="docutils literal"><span class="pre">BlocksUnboundedNMTPredictor</span></code> for that case.</p>
<p>Creates a new NMT predictor.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>nmt_model_path</strong> (<em>string</em>) &#8211; Path to the NMT model file (.npz)</li>
<li><strong>gnmt_beta</strong> (<em>float</em>) &#8211; If greater than 0.0, add a Google NMT
style coverage penalization term (Wu et
al., 2016) to the predictive scores</li>
<li><strong>enable_cache</strong> (<em>bool</em>) &#8211; The NMT predictor usually has a very
limited vocabulary size, and a large
number of UNKs in hypotheses. This
enables reusing already computed
predictor states for hypotheses which
differ only by NMT OOV words.</li>
<li><strong>config</strong> (<em>dict</em>) &#8211; NMT configuration</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Raises:</th><td class="field-body"><p class="first last">ValueError. If a target sparse feature map is defined</p>
</td>
</tr>
</tbody>
</table>
<dl class="method">
<dt>
<code class="descname">consume</code><span class="sig-paren">(</span><em>word</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/blocks_nmt.html#BlocksNMTPredictor.consume"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Feeds back <code class="docutils literal"><span class="pre">word</span></code> to the decoder network. This includes
embedding of <code class="docutils literal"><span class="pre">word</span></code>, running the attention network and update
the recurrent decoder layer.</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">get_state</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/blocks_nmt.html#BlocksNMTPredictor.get_state"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>The NMT predictor state consists of the decoder network
state, and (for caching) the current history of consumed words</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">get_unk_probability</code><span class="sig-paren">(</span><em>posterior</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/blocks_nmt.html#BlocksNMTPredictor.get_unk_probability"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Returns the UNK probability defined by NMT.</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">initialize</code><span class="sig-paren">(</span><em>src_sentence</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/blocks_nmt.html#BlocksNMTPredictor.initialize"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Runs the encoder network to create the source annotations
for the source sentence. If the cache is enabled, empty the
cache.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>src_sentence</strong> (<em>list</em>) &#8211; List of word ids without &lt;S&gt; and &lt;/S&gt;
which represent the source sentence.</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">is_equal</code><span class="sig-paren">(</span><em>state1</em>, <em>state2</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/blocks_nmt.html#BlocksNMTPredictor.is_equal"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Returns true if the history is the same</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">is_history_cachable</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/blocks_nmt.html#BlocksNMTPredictor.is_history_cachable"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Returns true if cache is enabled and history contains UNK</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">predict_next</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/blocks_nmt.html#BlocksNMTPredictor.predict_next"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Uses cache or runs the decoder network to get the
distribution over the next target words.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body">np array. Full distribution over the entire NMT vocabulary
for the next target token.</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">reset</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/blocks_nmt.html#BlocksNMTPredictor.reset"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Deletes the source side annotations and decoder state.</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">set_state</code><span class="sig-paren">(</span><em>state</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/blocks_nmt.html#BlocksNMTPredictor.set_state"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Set the NMT predictor state.</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">set_up_predictor</code><span class="sig-paren">(</span><em>nmt_model_path</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/blocks_nmt.html#BlocksNMTPredictor.set_up_predictor"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Initializes the predictor with the given NMT model. Code
following <code class="docutils literal"><span class="pre">blocks.machine_translation.main</span></code>.</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt>
<em class="property">class </em><code class="descclassname">cam.sgnmt.predictors.blocks_nmt.</code><code class="descname">BlocksUnboundedNMTPredictor</code><span class="sig-paren">(</span><em>nmt_model_path</em>, <em>gnmt_beta</em>, <em>config</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/blocks_nmt.html#BlocksUnboundedNMTPredictor"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Bases: <a class="reference internal" href="cam.sgnmt.predictors.html#cam.sgnmt.predictors.blocks_nmt.BlocksNMTPredictor" title="cam.sgnmt.predictors.blocks_nmt.BlocksNMTPredictor"><code class="xref py py-class docutils literal"><span class="pre">cam.sgnmt.predictors.blocks_nmt.BlocksNMTPredictor</span></code></a>, <a class="reference internal" href="cam.sgnmt.predictors.html#cam.sgnmt.predictors.core.UnboundedVocabularyPredictor" title="cam.sgnmt.predictors.core.UnboundedVocabularyPredictor"><code class="xref py py-class docutils literal"><span class="pre">cam.sgnmt.predictors.core.UnboundedVocabularyPredictor</span></code></a></p>
<p>This is a version of the NMT predictor which assumes an
unbounded vocabulary. Therefore, this predictor can only be used
when other predictors (like fst) define the words to score. Using
this predictor is mandatory when a target sparse feature map is
provided.</p>
<p>Creates a new NMT predictor with unbounded vocabulary.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>nmt_model_path</strong> (<em>string</em>) &#8211; Path to the NMT model file (.npz)</li>
<li><strong>config</strong> (<em>dict</em>) &#8211; NMT configuration,</li>
</ul>
</td>
</tr>
</tbody>
</table>
<dl class="method">
<dt>
<code class="descname">consume</code><span class="sig-paren">(</span><em>word</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/blocks_nmt.html#BlocksUnboundedNMTPredictor.consume"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Feeds back <code class="docutils literal"><span class="pre">word</span></code> to the decoder network. This includes
embedding of <code class="docutils literal"><span class="pre">word</span></code>, running the attention network and update
the recurrent decoder layer.</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">get_unk_probability</code><span class="sig-paren">(</span><em>posterior</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/blocks_nmt.html#BlocksUnboundedNMTPredictor.get_unk_probability"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Returns negative inf as this is a unbounded predictor.</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">is_equal</code><span class="sig-paren">(</span><em>state1</em>, <em>state2</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/blocks_nmt.html#BlocksUnboundedNMTPredictor.is_equal"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Returns true if the history is the same</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">predict_next</code><span class="sig-paren">(</span><em>words</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/blocks_nmt.html#BlocksUnboundedNMTPredictor.predict_next"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Uses cache or runs the decoder network to get the
distribution over the next target words.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body">np array. Full distribution over the entire NMT vocabulary
for the next target token.</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">set_up_predictor</code><span class="sig-paren">(</span><em>nmt_model_path</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/blocks_nmt.html#BlocksUnboundedNMTPredictor.set_up_predictor"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Initializes the predictor with the given NMT model. Code
following <code class="docutils literal"><span class="pre">blocks.machine_translation.main</span></code>.</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt>
<em class="property">class </em><code class="descclassname">cam.sgnmt.predictors.blocks_nmt.</code><code class="descname">MyopticSearch</code><span class="sig-paren">(</span><em>samples</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/blocks_nmt.html#MyopticSearch"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal"><span class="pre">blocks.search.BeamSearch</span></code></p>
<p>This class hacks into blocks beam search to leverage off the
initialization routines. Note that this has nothing to do with
SGNMTs high level decoding in <code class="docutils literal"><span class="pre">cam.sgnmt.decoding</span></code>. We basically
replace the <code class="docutils literal"><span class="pre">search()</span></code> with single_step_``decoding()`` which
generates the posteriors for the next word. Thus, it fits in the
predictor framework. We try to use <code class="docutils literal"><span class="pre">BeamSearch</span></code> functionality
wherever possible.</p>
<p>Calls the <code class="docutils literal"><span class="pre">BeamSearch</span></code> constructor</p>
</dd></dl>

<dl class="class">
<dt>
<em class="property">class </em><code class="descclassname">cam.sgnmt.predictors.blocks_nmt.</code><code class="descname">MyopticSparseSearch</code><span class="sig-paren">(</span><em>samples</em>, <em>trg_sparse_feat_map</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/blocks_nmt.html#MyopticSparseSearch"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Bases: <a class="reference internal" href="cam.sgnmt.blocks.html#cam.sgnmt.blocks.sparse_search.SparseBeamSearch" title="cam.sgnmt.blocks.sparse_search.SparseBeamSearch"><code class="xref py py-class docutils literal"><span class="pre">cam.sgnmt.blocks.sparse_search.SparseBeamSearch</span></code></a></p>
<p>Variant of <code class="docutils literal"><span class="pre">MyopticSearch</span></code> for target side sparse features.</p>
<p>Calls the <code class="docutils literal"><span class="pre">SparseBeamSearch</span></code> constructor</p>
</dd></dl>

</div>
<div class="section" id="cam-sgnmt-predictors-bow-module">
<h3>cam.sgnmt.predictors.bow module<a class="headerlink" href="#cam-sgnmt-predictors-bow-module" title="Permalink to this headline">¶</a></h3>
<p>This module contains predictors for bag of words experiments. This
is the standard bow predictor and the bowsearch predictor which first
does an unrestricted search to construct a skeleton and then restricts
the order of words by that skeleton (in addition to the bag
restriction).</p>
<dl class="class">
<dt>
<em class="property">class </em><code class="descclassname">cam.sgnmt.predictors.bow.</code><code class="descname">BagOfWordsPredictor</code><span class="sig-paren">(</span><em>trg_test_file</em>, <em>accept_subsets=False</em>, <em>accept_duplicates=False</em>, <em>heuristic_scores_file=''</em>, <em>collect_stats_strategy='best'</em>, <em>heuristic_add_consumed=False</em>, <em>heuristic_add_remaining=True</em>, <em>diversity_heuristic_factor=-1.0</em>, <em>equivalence_vocab=-1</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/bow.html#BagOfWordsPredictor"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Bases: <a class="reference internal" href="cam.sgnmt.predictors.html#cam.sgnmt.predictors.core.Predictor" title="cam.sgnmt.predictors.core.Predictor"><code class="xref py py-class docutils literal"><span class="pre">cam.sgnmt.predictors.core.Predictor</span></code></a></p>
<p>This predictor is similar to the forced predictor, but it does
not enforce the word order in the reference. Therefore, it assigns
1 to all hypotheses which have the words in the reference in any
order, and -inf to all other hypos.</p>
<p>Creates a new bag-of-words predictor.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>trg_test_file</strong> (<em>string</em>) &#8211; Path to the plain text file with
the target sentences. Must have the
same number of lines as the number
of source sentences to decode. The
word order in the target sentences
is not relevant for this predictor.</li>
<li><strong>accept_subsets</strong> (<em>bool</em>) &#8211; If true, this predictor permits
EOS even if the bag is not fully
consumed yet</li>
<li><strong>accept_duplicates</strong> (<em>bool</em>) &#8211; If true, counts are not updated
when a word is consumed. This
means that we allow a word in a
bag to appear multiple times</li>
<li><strong>heuristic_scores_file</strong> (<em>string</em>) &#8211; Path to the unigram scores
which are used if this
predictor estimates future
costs</li>
<li><strong>collect_stats_strategy</strong> (<em>string</em>) &#8211; best, full, or all. Defines
how unigram estimates are
collected for heuristic</li>
<li><strong>heuristic_add_consumed</strong> (<em>bool</em>) &#8211; Set to true to add the
difference between actual
partial score and unigram
estimates of consumed words
to the predictor heuristic</li>
<li><strong>heuristic_add_remaining</strong> (<em>bool</em>) &#8211; Set to true to add the sum
of unigram scores of words
remaining in the bag to the
predictor heuristic</li>
<li><strong>diversity_heuristic_factor</strong> (<em>float</em>) &#8211; Factor for diversity
heuristic which
penalizes hypotheses
with the same bag as
full hypos</li>
<li><strong>equivalence_vocab</strong> (<em>int</em>) &#8211; If positive, predictor states are
considered equal if the the
remaining words within that vocab
and OOVs regarding this vocab are
the same. Only relevant when using
hypothesis recombination</li>
</ul>
</td>
</tr>
</tbody>
</table>
<dl class="method">
<dt>
<code class="descname">consume</code><span class="sig-paren">(</span><em>word</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/bow.html#BagOfWordsPredictor.consume"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Updates the bag by deleting the consumed word.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>word</strong> (<em>int</em>) &#8211; Next word to consume</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">estimate_future_cost</code><span class="sig-paren">(</span><em>hypo</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/bow.html#BagOfWordsPredictor.estimate_future_cost"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>The bow predictor comes with its own heuristic function. We
use the sum of scores of the remaining words as future cost
estimator.</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">get_state</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/bow.html#BagOfWordsPredictor.get_state"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>State of this predictor is the current bag</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">get_unk_probability</code><span class="sig-paren">(</span><em>posterior</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/bow.html#BagOfWordsPredictor.get_unk_probability"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Returns negative infinity unconditionally: Words which are
not in the target sentence have assigned probability 0 by
this predictor.</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">initialize</code><span class="sig-paren">(</span><em>src_sentence</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/bow.html#BagOfWordsPredictor.initialize"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Creates a new bag for the current target sentence..</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>src_sentence</strong> (<em>list</em>) &#8211; Not used</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">initialize_heuristic</code><span class="sig-paren">(</span><em>src_sentence</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/bow.html#BagOfWordsPredictor.initialize_heuristic"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Calls <code class="docutils literal"><span class="pre">reset</span></code> of the used unigram table with estimates
<code class="docutils literal"><span class="pre">self.estimates</span></code> to clear all statistics from the previous
sentence</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>src_sentence</strong> (<em>list</em>) &#8211; Not used</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">is_equal</code><span class="sig-paren">(</span><em>state1</em>, <em>state2</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/bow.html#BagOfWordsPredictor.is_equal"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Returns true if the bag is the same</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">notify</code><span class="sig-paren">(</span><em>message</em>, <em>message_type=1</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/bow.html#BagOfWordsPredictor.notify"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>This gets called if this predictor observes the decoder. It
updates unigram heuristic estimates via passing through this
message to the unigram table <code class="docutils literal"><span class="pre">self.estimates</span></code>.</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">predict_next</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/bow.html#BagOfWordsPredictor.predict_next"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>If the bag is empty, the only allowed symbol is EOS.
Otherwise, return the list of keys in the bag.</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">reset</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/bow.html#BagOfWordsPredictor.reset"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Empty method.</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">set_state</code><span class="sig-paren">(</span><em>state</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/bow.html#BagOfWordsPredictor.set_state"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>State of this predictor is the current bag</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt>
<em class="property">class </em><code class="descclassname">cam.sgnmt.predictors.bow.</code><code class="descname">BagOfWordsSearchPredictor</code><span class="sig-paren">(</span><em>main_decoder</em>, <em>hypo_recombination</em>, <em>trg_test_file</em>, <em>accept_subsets=False</em>, <em>accept_duplicates=False</em>, <em>heuristic_scores_file=''</em>, <em>collect_stats_strategy='best'</em>, <em>heuristic_add_consumed=False</em>, <em>heuristic_add_remaining=True</em>, <em>diversity_heuristic_factor=-1.0</em>, <em>equivalence_vocab=-1</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/bow.html#BagOfWordsSearchPredictor"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Bases: <a class="reference internal" href="cam.sgnmt.predictors.html#cam.sgnmt.predictors.bow.BagOfWordsPredictor" title="cam.sgnmt.predictors.bow.BagOfWordsPredictor"><code class="xref py py-class docutils literal"><span class="pre">cam.sgnmt.predictors.bow.BagOfWordsPredictor</span></code></a></p>
<p>Combines the bag-of-words predictor with a proxy decoding pass
which creates a skeleton translation.</p>
<p>Creates a new bag-of-words predictor with pre search</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>main_decoder</strong> (<a class="reference internal" href="cam.sgnmt.decoding.html#cam.sgnmt.decoding.core.Decoder" title="cam.sgnmt.decoding.core.Decoder"><em>Decoder</em></a>) &#8211; Reference to the main decoder
instance, used to fetch the predictors</li>
<li><strong>hypo_recombination</strong> (<em>bool</em>) &#8211; Activates hypo recombination for the
pre decoder</li>
<li><strong>trg_test_file</strong> (<em>string</em>) &#8211; Path to the plain text file with
the target sentences. Must have the
same number of lines as the number
of source sentences to decode. The
word order in the target sentences
is not relevant for this predictor.</li>
<li><strong>accept_subsets</strong> (<em>bool</em>) &#8211; If true, this predictor permits
EOS even if the bag is not fully
consumed yet</li>
<li><strong>accept_duplicates</strong> (<em>bool</em>) &#8211; If true, counts are not updated
when a word is consumed. This
means that we allow a word in a
bag to appear multiple times</li>
<li><strong>heuristic_scores_file</strong> (<em>string</em>) &#8211; Path to the unigram scores
which are used if this
predictor estimates future
costs</li>
<li><strong>collect_stats_strategy</strong> (<em>string</em>) &#8211; best, full, or all. Defines
how unigram estimates are
collected for heuristic</li>
<li><strong>heuristic_add_consumed</strong> (<em>bool</em>) &#8211; Set to true to add the
difference between actual
partial score and unigram
estimates of consumed words
to the predictor heuristic</li>
<li><strong>heuristic_add_remaining</strong> (<em>bool</em>) &#8211; Set to true to add the sum
of unigram scores of words
remaining in the bag to the
predictor heuristic</li>
<li><strong>equivalence_vocab</strong> (<em>int</em>) &#8211; If positive, predictor states are
considered equal if the the
remaining words within that vocab
and OOVs regarding this vocab are
the same. Only relevant when using
hypothesis recombination</li>
</ul>
</td>
</tr>
</tbody>
</table>
<dl class="method">
<dt>
<code class="descname">consume</code><span class="sig-paren">(</span><em>word</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/bow.html#BagOfWordsSearchPredictor.consume"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Calls super class <code class="docutils literal"><span class="pre">consume</span></code>. If not in <code class="docutils literal"><span class="pre">pre_mode</span></code>,
update skeleton info.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>word</strong> (<em>int</em>) &#8211; Next word to consume</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">get_state</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/bow.html#BagOfWordsSearchPredictor.get_state"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>If in pre_mode, state of this predictor is the current bag
Otherwise, its the bag plus skeleton state</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">initialize</code><span class="sig-paren">(</span><em>src_sentence</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/bow.html#BagOfWordsSearchPredictor.initialize"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>If in <code class="docutils literal"><span class="pre">pre_mode</span></code>, pass through to super class. Otherwise,
initialize skeleton.</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">is_equal</code><span class="sig-paren">(</span><em>state1</em>, <em>state2</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/bow.html#BagOfWordsSearchPredictor.is_equal"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Returns true if the bag and the skeleton states are the same</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">predict_next</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/bow.html#BagOfWordsSearchPredictor.predict_next"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>If in <code class="docutils literal"><span class="pre">pre_mode</span></code>, pass through to super class. Otherwise,
scan skeleton</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">set_state</code><span class="sig-paren">(</span><em>state</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/bow.html#BagOfWordsSearchPredictor.set_state"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>If in pre_mode, state of this predictor is the current bag
Otherwise, its the bag plus skeleton state</p>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="cam-sgnmt-predictors-core-module">
<h3>cam.sgnmt.predictors.core module<a class="headerlink" href="#cam-sgnmt-predictors-core-module" title="Permalink to this headline">¶</a></h3>
<p>This module contains the two basic predictor interfaces
for bounded and unbounded vocabulary predictors.</p>
<dl class="class">
<dt>
<em class="property">class </em><code class="descclassname">cam.sgnmt.predictors.core.</code><code class="descname">Predictor</code><a class="reference internal" href="_modules/cam/sgnmt/predictors/core.html#Predictor"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Bases: <a class="reference internal" href="cam.sgnmt.html#cam.sgnmt.utils.Observer" title="cam.sgnmt.utils.Observer"><code class="xref py py-class docutils literal"><span class="pre">cam.sgnmt.utils.Observer</span></code></a></p>
<p>A predictor produces the predictive probability distribution of
the next word given the state of the predictor. The state may
change during <code class="docutils literal"><span class="pre">predict_next()</span></code> and <code class="docutils literal"><span class="pre">consume()</span></code>. The functions
<code class="docutils literal"><span class="pre">get_state()</span></code> and <code class="docutils literal"><span class="pre">set_state()</span></code> can be used for non-greedy
decoding. Note: The state describes the predictor with the current
history. It does not encapsulate the current source sentence, i.e.
you cannot recover a predictor state if <code class="docutils literal"><span class="pre">initialize()</span></code> was called
in between. <code class="docutils literal"><span class="pre">predict_next()</span></code> and <code class="docutils literal"><span class="pre">consume()</span></code> must be called
alternately. This holds even when using <code class="docutils literal"><span class="pre">get_state()</span></code> and
<code class="docutils literal"><span class="pre">set_state()</span></code>: Loading/saving states is transparent to the
predictor instance.</p>
<p>Initializes <code class="docutils literal"><span class="pre">current_sen_id</span></code> with 0.</p>
<dl class="method">
<dt>
<code class="descname">consume</code><span class="sig-paren">(</span><em>word</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/core.html#Predictor.consume"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Expand the current history by <code class="docutils literal"><span class="pre">word</span></code> and update the
internal predictor state accordingly. Two calls of <code class="docutils literal"><span class="pre">consume()</span></code>
must be separated by a <code class="docutils literal"><span class="pre">predict_next()</span></code> call.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>word</strong> (<em>int</em>) &#8211; Word to add to the current history</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">estimate_future_cost</code><span class="sig-paren">(</span><em>hypo</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/core.html#Predictor.estimate_future_cost"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Predictors can implement their own look-ahead cost functions.
They are used in A* if the &#8211;heuristics parameter is set to
predictor. This function should return the future log <em>cost</em>
(i.e. the lower the better) given the current predictor state,
assuming that the last word in the partial hypothesis &#8216;hypo&#8217; is
consumed next. This function must not change the internal
predictor state.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>hypo</strong> (<a class="reference internal" href="cam.sgnmt.decoding.html#cam.sgnmt.decoding.core.PartialHypothesis" title="cam.sgnmt.decoding.core.PartialHypothesis"><em>PartialHypothesis</em></a>) &#8211; Hypothesis for which to estimate
the future cost given the current
predictor state</td>
</tr>
</tbody>
</table>
<dl class="docutils">
<dt>Returns</dt>
<dd>float. Future cost</dd>
</dl>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">finalize_posterior</code><span class="sig-paren">(</span><em>scores</em>, <em>use_weights</em>, <em>normalize_scores</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/core.html#Predictor.finalize_posterior"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>This method can be used to enforce the parameters use_weights
normalize_scores in predictors with dict posteriors.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>scores</strong> (<em>dict</em>) &#8211; unnormalized log valued scores</li>
<li><strong>use_weights</strong> (<em>bool</em>) &#8211; Set to false to replace all values in
<code class="docutils literal"><span class="pre">scores</span></code> with 0 (= log 1)</li>
<li><strong>normalize_scores</strong> &#8211; Set to true to make the exp of elements
in <code class="docutils literal"><span class="pre">scores</span></code> sum up to 1</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">get_state</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/core.html#Predictor.get_state"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Get the current predictor state. The state can be any object
or tuple of objects which makes it possible to return to the
predictor state with the current history.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body">object. Predictor state</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">get_unk_probability</code><span class="sig-paren">(</span><em>posterior</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/core.html#Predictor.get_unk_probability"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>This function defines the probability of all words which are
not in <code class="docutils literal"><span class="pre">posterior</span></code>. This is usually used to combine open and
closed vocabulary predictors. The argument <code class="docutils literal"><span class="pre">posterior</span></code> should
have been produced with <code class="docutils literal"><span class="pre">predict_next()</span></code></p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>posterior</strong> (<em>list,array,dict</em>) &#8211; Return value of the last call
of <code class="docutils literal"><span class="pre">predict_next</span></code></td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body">Score to use for words outside <code class="docutils literal"><span class="pre">posterior</span></code></td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body">float</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">initialize</code><span class="sig-paren">(</span><em>src_sentence</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/core.html#Predictor.initialize"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Initialize the predictor with the given source sentence.
This resets the internal predictor state and loads everything
which is constant throughout the processing of a single source
sentence. For example, the NMT decoder runs the encoder network
and stores the source annotations.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>src_sentence</strong> (<em>list</em>) &#8211; List of word IDs which form the source
sentence without &lt;S&gt; or &lt;/S&gt;</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">initialize_heuristic</code><span class="sig-paren">(</span><em>src_sentence</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/core.html#Predictor.initialize_heuristic"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>This is called after <code class="docutils literal"><span class="pre">initialize()</span></code> if the predictor is
registered as heuristic predictor (i.e.
<code class="docutils literal"><span class="pre">estimate_future_cost()</span></code> will be called in the future).
Predictors can implement this function for initialization of
their own heuristic mechanisms.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>src_sentence</strong> (<em>list</em>) &#8211; List of word IDs which form the source
sentence without &lt;S&gt; or &lt;/S&gt;</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">is_equal</code><span class="sig-paren">(</span><em>state1</em>, <em>state2</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/core.html#Predictor.is_equal"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Returns true if two predictor states are equal, i.e. both
states will always result in the same scores. This is used for
hypothesis recombination</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>state1</strong> (<em>object</em>) &#8211; First predictor state</li>
<li><strong>state2</strong> (<em>object</em>) &#8211; Second predictor state</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first last">bool. True if both states are equal, false if not</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">notify</code><span class="sig-paren">(</span><em>message</em>, <em>message_type=1</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/core.html#Predictor.notify"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>We implement the <code class="docutils literal"><span class="pre">notify</span></code> method from the <code class="docutils literal"><span class="pre">Observer</span></code>
super class with an empty method here s.t. predictors do not
need to implement it.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>message</strong> (<em>object</em>) &#8211; The posterior sent by the decoder</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">predict_next</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/core.html#Predictor.predict_next"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Returns the predictive distribution over the target
vocabulary for the next word given the predictor state. Note
that the prediction itself can change the state of the
predictor. For example, the neural predictor updates the
decoder network state and its attention to predict the next
word. Two calls of <code class="docutils literal"><span class="pre">predict_next()</span></code> must be separated by a
<code class="docutils literal"><span class="pre">consume()</span></code> call.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body">dictionary,array,list. Word log probabilities for the next
target token. All ids which are not set are assumed to have
probability <code class="docutils literal"><span class="pre">get_unk_probability()</span></code></td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">reset</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/core.html#Predictor.reset"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Reset the predictor state to the initial configuration. This
is required when a new set of sentences is to be decoded, e.g.
to reset the sentence counter in the fst predictor to load the
correct lattice. This function is NOT called each time before
decoding a single sentence. See <code class="docutils literal"><span class="pre">initialize()</span></code> for this.</p>
<p>The default implementation is an empty method.</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">set_current_sen_id</code><span class="sig-paren">(</span><em>cur_sen_id</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/core.html#Predictor.set_current_sen_id"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>This function is called between <code class="docutils literal"><span class="pre">initialize()</span></code> calls to
increment the sentence id counter. It can also be used to skip
sentences for the &#8211;range argument.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>cur_sen_id</strong> (<em>int</em>) &#8211; Sentence id for the next call of
<code class="docutils literal"><span class="pre">initialize()</span></code></td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">set_state</code><span class="sig-paren">(</span><em>state</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/core.html#Predictor.set_state"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Loads a predictor state from an object created with
<code class="docutils literal"><span class="pre">get_state()</span></code>. Note that this does not copy the argument but
just references the given state. If <code class="docutils literal"><span class="pre">state</span></code> is going to be
used in the future to return to that point again, you should
copy the state with <code class="docutils literal"><span class="pre">copy.deepcopy()</span></code> before.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>state</strong> (<em>object</em>) &#8211; Predictor state as returned by
<code class="docutils literal"><span class="pre">get_state()</span></code></td>
</tr>
</tbody>
</table>
</dd></dl>

</dd></dl>

<dl class="class">
<dt>
<em class="property">class </em><code class="descclassname">cam.sgnmt.predictors.core.</code><code class="descname">UnboundedVocabularyPredictor</code><a class="reference internal" href="_modules/cam/sgnmt/predictors/core.html#UnboundedVocabularyPredictor"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Bases: <a class="reference internal" href="cam.sgnmt.predictors.html#cam.sgnmt.predictors.core.Predictor" title="cam.sgnmt.predictors.core.Predictor"><code class="xref py py-class docutils literal"><span class="pre">cam.sgnmt.predictors.core.Predictor</span></code></a></p>
<p>Predictors under this class implement models with very large
target vocabularies, for which it is too inefficient to list the
entire posterior. Instead, they are evaluated only for a given list
of target words. This list is usually created by taking all non-zero
probability words from the bounded vocabulary predictors. An
example of a unbounded vocabulary predictor is the ngram predictor:
Instead of listing the entire ngram vocabulary, we run srilm only
on the words which are possible according other predictor (e.g. fst
or nmt). This is realized by introducing the <code class="docutils literal"><span class="pre">trgt_words</span></code>
argument to <code class="docutils literal"><span class="pre">predict_next</span></code>.</p>
<p>Initializes <code class="docutils literal"><span class="pre">current_sen_id</span></code> with 0.</p>
<dl class="method">
<dt>
<code class="descname">predict_next</code><span class="sig-paren">(</span><em>trgt_words</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/core.html#UnboundedVocabularyPredictor.predict_next"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Like in <code class="docutils literal"><span class="pre">Predictor</span></code>, returns the predictive distribution
over target words given the predictor state. Note
that the prediction itself can change the state of the
predictor. For example, the neural predictor updates the
decoder network state and its attention to predict the next
word. Two calls of <code class="docutils literal"><span class="pre">predict_next()</span></code> must be separated by a
<code class="docutils literal"><span class="pre">consume()</span></code> call.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>trgt_words</strong> (<em>list</em>) &#8211; List of target word ids.</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body">dictionary,array,list. Word log probabilities for the next
target token. All ids which are not set are assumed to have
probability <code class="docutils literal"><span class="pre">get_unk_probability()</span></code>. The returned set should
not contain any ids which are not in <code class="docutils literal"><span class="pre">trgt_words</span></code>, but it
does not have to score all of them</td>
</tr>
</tbody>
</table>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="cam-sgnmt-predictors-ffnnlm-module">
<h3>cam.sgnmt.predictors.ffnnlm module<a class="headerlink" href="#cam-sgnmt-predictors-ffnnlm-module" title="Permalink to this headline">¶</a></h3>
<p>This module integrates neural language models, for example feed-
forward language models like NPLM. It depends on the Python interface
to NPLM.</p>
<p><a class="reference external" href="http://nlg.isi.edu/software/nplm/">http://nlg.isi.edu/software/nplm/</a></p>
<dl class="class">
<dt>
<em class="property">class </em><code class="descclassname">cam.sgnmt.predictors.ffnnlm.</code><code class="descname">NPLMPredictor</code><span class="sig-paren">(</span><em>path</em>, <em>normalize_scores</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/ffnnlm.html#NPLMPredictor"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Bases: <a class="reference internal" href="cam.sgnmt.predictors.html#cam.sgnmt.predictors.core.UnboundedVocabularyPredictor" title="cam.sgnmt.predictors.core.UnboundedVocabularyPredictor"><code class="xref py py-class docutils literal"><span class="pre">cam.sgnmt.predictors.core.UnboundedVocabularyPredictor</span></code></a></p>
<p>NPLM language model predictor. Even though NPLM normally has a
limited vocabulary size, we implement it as a unbounded vocabulary
predictor because it is more efficient to score only a subset of
the vocabulary. This predictor uses the python interface to NPLM
from</p>
<p><a class="reference external" href="http://nlg.isi.edu/software/nplm/">http://nlg.isi.edu/software/nplm/</a></p>
<p>Creates a new NPLM predictor instance.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>path</strong> (<em>string</em>) &#8211; Path to the NPLM model file</li>
<li><strong>normalize_scores</strong> (<em>bool</em>) &#8211; Whether to renormalize scores s.t.
scores returned by <code class="docutils literal"><span class="pre">predict_next</span></code>
sum up to 1</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Raises:</th><td class="field-body"><p class="first last">NameError. If NPLM is not installed</p>
</td>
</tr>
</tbody>
</table>
<dl class="method">
<dt>
<code class="descname">consume</code><span class="sig-paren">(</span><em>word</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/ffnnlm.html#NPLMPredictor.consume"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Extend current history by <code class="docutils literal"><span class="pre">word</span></code></p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">get_state</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/ffnnlm.html#NPLMPredictor.get_state"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Returns the current history</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">get_unk_probability</code><span class="sig-paren">(</span><em>posterior</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/ffnnlm.html#NPLMPredictor.get_unk_probability"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Use NPLM UNK score if exists</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">initialize</code><span class="sig-paren">(</span><em>src_sentence</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/ffnnlm.html#NPLMPredictor.initialize"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Set the n-gram history to initial value.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>src_sentence</strong> (<em>list</em>) &#8211; Not used</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">is_equal</code><span class="sig-paren">(</span><em>state1</em>, <em>state2</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/ffnnlm.html#NPLMPredictor.is_equal"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Returns true if the ngram history is the same</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">predict_next</code><span class="sig-paren">(</span><em>words</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/ffnnlm.html#NPLMPredictor.predict_next"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Scores the words in <code class="docutils literal"><span class="pre">words</span></code> using NPLM.</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">reset</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/ffnnlm.html#NPLMPredictor.reset"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Set the n-gram history to initial value.</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">set_state</code><span class="sig-paren">(</span><em>state</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/ffnnlm.html#NPLMPredictor.set_state"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Sets the current history</p>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="cam-sgnmt-predictors-forced-module">
<h3>cam.sgnmt.predictors.forced module<a class="headerlink" href="#cam-sgnmt-predictors-forced-module" title="Permalink to this headline">¶</a></h3>
<p>This module contains predictors for forced decoding. This can be
done either with one reference (forced <code class="docutils literal"><span class="pre">ForcedPredictor</span></code>), or with
multiple references in form of a n-best list (forcedlst
<code class="docutils literal"><span class="pre">ForcedLstPredictor</span></code>).</p>
<dl class="class">
<dt>
<em class="property">class </em><code class="descclassname">cam.sgnmt.predictors.forced.</code><code class="descname">ForcedLstPredictor</code><span class="sig-paren">(</span><em>trg_test_file</em>, <em>use_scores=True</em>, <em>match_unk=False</em>, <em>feat_name=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/forced.html#ForcedLstPredictor"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Bases: <a class="reference internal" href="cam.sgnmt.predictors.html#cam.sgnmt.predictors.core.Predictor" title="cam.sgnmt.predictors.core.Predictor"><code class="xref py py-class docutils literal"><span class="pre">cam.sgnmt.predictors.core.Predictor</span></code></a></p>
<p>This predictor can be used for direct n-best list rescoring. In
contrast to the <code class="docutils literal"><span class="pre">ForcedPredictor</span></code>, it reads an n-best list in
Moses format and uses its scores as predictive probabilities of the
&lt;/S&gt; symbol. Everywhere else it gives the predictive probability 1
if the history corresponds to at least one n-best list entry, 0
otherwise. From the n-best list we use
First column: Sentence id
Second column: Hypothesis in integer format
Last column: score</p>
<p>Note: Behavior is undefined if you have duplicates in the n-best
list</p>
<p>TODO: Would be much more efficient to use Tries for
cur_trgt_sentences instead of a flat list.</p>
<p>Creates a new n-best rescoring predictor instance.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>trg_test_file</strong> (<em>string</em>) &#8211; Path to the n-best list</li>
<li><strong>use_scores</strong> (<em>bool</em>) &#8211; Whether to use the scores from the
n-best list. If false, use uniform
scores of 0 (=log 1).</li>
<li><strong>match_unk</strong> (<em>bool</em>) &#8211; If true, allow any word where the n-best
list contains UNK.</li>
<li><strong>feat_name</strong> (<em>string</em>) &#8211; Instead of the combined score in the
last column of the Moses n-best list,
we can use one of the sparse features.
Set this to the name of the feature
(denoted as &lt;name&gt;= in the n-best list)
if you wish to do that.</li>
</ul>
</td>
</tr>
</tbody>
</table>
<dl class="method">
<dt>
<code class="descname">consume</code><span class="sig-paren">(</span><em>word</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/forced.html#ForcedLstPredictor.consume"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Extends the current history by <code class="docutils literal"><span class="pre">word</span></code>.</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">get_state</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/forced.html#ForcedLstPredictor.get_state"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Returns the current history.</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">get_unk_probability</code><span class="sig-paren">(</span><em>posterior</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/forced.html#ForcedLstPredictor.get_unk_probability"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Return negative infinity unconditionally - words outside the
n-best list are not possible according to this predictor.</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">initialize</code><span class="sig-paren">(</span><em>src_sentence</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/forced.html#ForcedLstPredictor.initialize"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Resets the history and loads the n-best list entries for the
next source sentence</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>src_sentence</strong> (<em>list</em>) &#8211; Not used</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">is_equal</code><span class="sig-paren">(</span><em>state1</em>, <em>state2</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/forced.html#ForcedLstPredictor.is_equal"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Returns true if the history is the same</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">predict_next</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/forced.html#ForcedLstPredictor.predict_next"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Outputs 0.0 (i.e. prob=1) for all words for which there is
an entry <code class="docutils literal"><span class="pre">in</span> <span class="pre">cur_trg_sentences</span></code>, and the score in
<code class="docutils literal"><span class="pre">cur_trg_sentences</span></code> if the current history is by itself equal
to an entry in <code class="docutils literal"><span class="pre">cur_trg_sentences</span></code>.</p>
<p>TODO: The implementation here is fairly inefficient as it scans
through all target sentences linearly. Would be better to
organize the target sentences in a Trie</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">reset</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/forced.html#ForcedLstPredictor.reset"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Empty method.</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">set_state</code><span class="sig-paren">(</span><em>state</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/forced.html#ForcedLstPredictor.set_state"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Sets the current history.</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt>
<em class="property">class </em><code class="descclassname">cam.sgnmt.predictors.forced.</code><code class="descname">ForcedPredictor</code><span class="sig-paren">(</span><em>trg_test_file</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/forced.html#ForcedPredictor"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Bases: <a class="reference internal" href="cam.sgnmt.predictors.html#cam.sgnmt.predictors.core.Predictor" title="cam.sgnmt.predictors.core.Predictor"><code class="xref py py-class docutils literal"><span class="pre">cam.sgnmt.predictors.core.Predictor</span></code></a></p>
<p>This predictor realizes forced decoding. It stores one target
sentence for each source sentence and outputs predictive probability
1 along this path, and 0 otherwise.</p>
<p>Creates a new forced decoding predictor.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>trg_test_file</strong> (<em>string</em>) &#8211; Path to the plain text file with
the target sentences. Must have the
same number of lines as the number
of source sentences to decode</td>
</tr>
</tbody>
</table>
<dl class="method">
<dt>
<code class="descname">consume</code><span class="sig-paren">(</span><em>word</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/forced.html#ForcedPredictor.consume"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>If <code class="docutils literal"><span class="pre">word</span></code> matches the target sentence, we increase the
current history by one. Otherwise, we set this predictor in
an invalid state, in which it always predicts &lt;/S&gt;</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>word</strong> (<em>int</em>) &#8211; Next word to consume</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">get_state</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/forced.html#ForcedPredictor.get_state"><span class="viewcode-link">[source]</span></a></dt>
<dd><p><code class="docutils literal"><span class="pre">cur_trg_sentence</span></code> can be changed so its part of the
predictor state</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">get_unk_probability</code><span class="sig-paren">(</span><em>posterior</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/forced.html#ForcedPredictor.get_unk_probability"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Returns negative infinity unconditionally: Words which are
not in the target sentence have assigned probability 0 by
this predictor.</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">initialize</code><span class="sig-paren">(</span><em>src_sentence</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/forced.html#ForcedPredictor.initialize"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Fetches the corresponding target sentence and resets the
current history.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>src_sentence</strong> (<em>list</em>) &#8211; Not used</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">is_equal</code><span class="sig-paren">(</span><em>state1</em>, <em>state2</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/forced.html#ForcedPredictor.is_equal"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Returns true if the state is the same</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">predict_next</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/forced.html#ForcedPredictor.predict_next"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Returns a dictionary with one entry and value 0 (=log 1). The
key is either the next word in the target sentence or (if the
target sentence has no more words) the end-of-sentence symbol.</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">reset</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/forced.html#ForcedPredictor.reset"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Empty method.</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">set_state</code><span class="sig-paren">(</span><em>state</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/forced.html#ForcedPredictor.set_state"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Set the predictor state.</p>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="cam-sgnmt-predictors-grammar-module">
<h3>cam.sgnmt.predictors.grammar module<a class="headerlink" href="#cam-sgnmt-predictors-grammar-module" title="Permalink to this headline">¶</a></h3>
<p>This module contains everything related to the hiero predictor. This
predictor allows applying rules from a syntactical SMT system directly
in SGNMT. The main interface is <code class="docutils literal"><span class="pre">RuleXtractPredictor</span></code> which can be
used like other predictors during decoding.
The Hiero predictor follows are the LRHiero implementation from</p>
<p><a class="reference external" href="https://github.com/sfu-natlang/lrhiero">https://github.com/sfu-natlang/lrhiero</a></p>
<blockquote>
<div>Efficient Left-to-Right Hierarchical Phrase-based Translation with
Improved Reordering.
Maryam Siahbani, Baskaran Sankaran and Anoop Sarkar.
EMNLP 2013. Oct 18-21, 2013. Seattle, USA.</div></blockquote>
<p>However, note that we modified the code to
a) deal with an arbitrary number of non-terminals
b) work with ruleXtract
c) allow spurious ambiguity</p>
<p>ATTENTION: This implementation is experimental!!</p>
<dl class="class">
<dt>
<em class="property">class </em><code class="descclassname">cam.sgnmt.predictors.grammar.</code><code class="descname">Cell</code><span class="sig-paren">(</span><em>init_hypo=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/grammar.html#Cell"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Comparable to a CYK cell: A set of hypotheses. If duplicates are
added, we do hypo combination by combining the costs and retraining
only one of them. Internally, the hypotheses are stored in a list
sorted by the sum of the translation prefix</p>
<p>Creates a new <code class="docutils literal"><span class="pre">Cell</span></code> with only one hypothesis.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>init_hypo</strong> (<a class="reference internal" href="cam.sgnmt.predictors.html#cam.sgnmt.predictors.grammar.LRHieroHypothesis" title="cam.sgnmt.predictors.grammar.LRHieroHypothesis"><em>LRHieroHypothesis</em></a>) &#8211; Initial hypothesis</td>
</tr>
</tbody>
</table>
<dl class="method">
<dt>
<code class="descname">add</code><span class="sig-paren">(</span><em>hypo</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/grammar.html#Cell.add"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Add a new hypothesis to the cell. If an equivalent
hypothesis already exists, combine both hypotheses.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>hypo</strong> (<a class="reference internal" href="cam.sgnmt.predictors.html#cam.sgnmt.predictors.grammar.LRHieroHypothesis" title="cam.sgnmt.predictors.grammar.LRHieroHypothesis"><em>LRHieroHypothesis</em></a>) &#8211; Hypothesis to add under the key
<code class="docutils literal"><span class="pre">hypo.key</span></code></td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">filter</code><span class="sig-paren">(</span><em>pos</em>, <em>symb</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/grammar.html#Cell.filter"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Remove all hypotheses which do not have <code class="docutils literal"><span class="pre">symb</span></code> at <code class="docutils literal"><span class="pre">pos</span></code>
in their <code class="docutils literal"><span class="pre">trgt_prefix</span></code>. Breaks if <code class="docutils literal"><span class="pre">pos</span></code> is out of range for
some <code class="docutils literal"><span class="pre">trgt_prefix</span></code></p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">findIdx</code><span class="sig-paren">(</span><em>key</em>, <em>a</em>, <em>b</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/grammar.html#Cell.findIdx"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Find index of first element with given key. If there is no
such key, return last element with largest key smaller than key
This is a recursive function which only searches in the
interval [a,b]</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">pop</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/grammar.html#Cell.pop"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Removes a hypothesis from the cell.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body">LRHieroHypothesis. The removed hypothesis</td>
</tr>
</tbody>
</table>
</dd></dl>

</dd></dl>

<dl class="class">
<dt>
<em class="property">class </em><code class="descclassname">cam.sgnmt.predictors.grammar.</code><code class="descname">LRHieroHypothesis</code><span class="sig-paren">(</span><em>trgt_prefix</em>, <em>spans</em>, <em>cost</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/grammar.html#LRHieroHypothesis"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Represents a LRHiero hypothesis, which is defined by the
accumulated cost, the target prefix, and open source spans.</p>
<p>Creates a new LRHiero hypothesis</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>trgt_prefix</strong> (<em>list</em>) &#8211; Target side translation prefix, i.e.
the partial target sentence which is
translated so far</li>
<li><strong>spans</strong> (<em>list</em>) &#8211; List of spans which are not covered yet, in
left-to-right order on target side</li>
<li><strong>cost</strong> (<em>float</em>) &#8211; Cost of this partial hypothesis</li>
</ul>
</td>
</tr>
</tbody>
</table>
<dl class="method">
<dt>
<code class="descname">is_final</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/grammar.html#LRHieroHypothesis.is_final"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Returns true if this hypothesis has no open spans</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt>
<em class="property">class </em><code class="descclassname">cam.sgnmt.predictors.grammar.</code><code class="descname">Node</code><a class="reference internal" href="_modules/cam/sgnmt/predictors/grammar.html#Node"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Represents a node in the Trie.</p>
</dd></dl>

<dl class="class">
<dt>
<em class="property">class </em><code class="descclassname">cam.sgnmt.predictors.grammar.</code><code class="descname">Rule</code><span class="sig-paren">(</span><em>rhs_src</em>, <em>rhs_trgt</em>, <em>trgt_src_map</em>, <em>cost</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/grammar.html#Rule"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>A rule consists of <code class="docutils literal"><span class="pre">rhs_src</span></code> and <code class="docutils literal"><span class="pre">rhs_trgt</span></code>, both are
sequences of integers. NTs are indicated with negative sign. The
<code class="docutils literal"><span class="pre">trgt_src_map</span></code> defines which NT on the target side belongs to
which NT on the source side.</p>
<p>Creates a new rule.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>rhs_src</strong> (<em>list</em>) &#8211; Source on the right hand side of the rule</li>
<li><strong>rhs_trgt</strong> (<em>list</em>) &#8211; Target on the right hand side of the rule</li>
<li><strong>trgt_src_map</strong> (<em>dict</em>) &#8211; Defines which NT on the target side
belongs to which NT on the source side</li>
</ul>
</td>
</tr>
</tbody>
</table>
<dl class="attribute">
<dt>
<code class="descname">last_id</code><em class="property"> = 0</em></dt>
<dd></dd></dl>

</dd></dl>

<dl class="class">
<dt>
<em class="property">class </em><code class="descclassname">cam.sgnmt.predictors.grammar.</code><code class="descname">RuleSet</code><a class="reference internal" href="_modules/cam/sgnmt/predictors/grammar.html#RuleSet"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>This class stores the set of rules and provides efficient retrieval and
matching functionality</p>
<p>Initializes the set by setting up the trie data structure
for storing the rules.</p>
<dl class="attribute">
<dt>
<code class="descname">INF</code><em class="property"> = 10000</em></dt>
<dd></dd></dl>

<dl class="method">
<dt>
<code class="descname">create_rule</code><span class="sig-paren">(</span><em>rhs_src</em>, <em>rhs_trgt</em>, <em>weight</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/grammar.html#RuleSet.create_rule"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Creates a rule object (factory method)</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>rhs_src</strong> (<em>list</em>) &#8211; String sequence describing the source of
the right-hand-side of the rule</li>
<li><strong>rhs_trgt</strong> (<em>list</em>) &#8211; String sequence describing the target of
the right-hand-side of the rule</li>
<li><strong>weight</strong> (<em>float</em>) &#8211; Rule weight</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first last"><code class="docutils literal"><span class="pre">Rule</span></code> or <code class="docutils literal"><span class="pre">None</span></code> if something went wrong</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">expand_hypo</code><span class="sig-paren">(</span><em>hypo</em>, <em>src_seq</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/grammar.html#RuleSet.expand_hypo"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Similar to <code class="docutils literal"><span class="pre">getSpanRules()</span></code> and <code class="docutils literal"><span class="pre">GrowHypothesis()</span></code> in
Alg. 1 in (Siahbani, 2013) combined. Gets all rules which match
the given span.</p>
<ul class="simple">
<li>If the p parameter of the span is a single non-terminal, we
return hypotheses resulting from productions of this non-
terminal. Note that rules might be applicable in many different
ways: X-&gt; A the B can be applied to foo the bar the baz in two
ways. In this case, we add the translation prefix, but leave the
borders of the span untouched, and change the <code class="docutils literal"><span class="pre">p</span></code> value to
<code class="docutils literal"><span class="pre">thr</span> <span class="pre">rhs</span></code> of the production (i.e. &#8220;A the B&#8221;). If p consists
of multiple characters, the spans store the minimum and maximum
<em>length</em>, not the begin and end since the exact begin and end
positions are variable.</li>
<li>If the p parameter of the span has length &gt; 1, we return a
set of hypotheses in which the first subspan has a single NT
as p parameter.</li>
</ul>
<p>Through this contract we can e.g. handle spurious ambiguity, if
two NT are on the source side. However, resolving this
ambiguity is implemented in a lazy fashion: we delay fixing the
span boundaries until we need to expand the hypothesis once
more, and then we fix only the first boundaries for the first
span.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>hypo</strong> (<a class="reference internal" href="cam.sgnmt.predictors.html#cam.sgnmt.predictors.grammar.LRHieroHypothesis" title="cam.sgnmt.predictors.grammar.LRHieroHypothesis"><em>LRHieroHypothesis</em></a>) &#8211; Hypothesis to expand</li>
<li><strong>src_seq</strong> (<em>list</em>) &#8211; Source sequence to match</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">parse</code><span class="sig-paren">(</span><em>line</em>, <em>feature_weights=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/grammar.html#RuleSet.parse"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Parse a line in a rule file from ruleXtract and add the rule
to the set.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>line</strong> (<em>string</em>) &#8211; </li>
<li><strong>feature_weights</strong> (<em>list</em>) &#8211; score or <code class="docutils literal"><span class="pre">None</span></code> to use uniform
weights</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">update_span_len_range</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/grammar.html#RuleSet.update_span_len_range"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>This method updates the <code class="docutils literal"><span class="pre">span_len_range</span></code> variable by
finding boundaries for the spans each non terminal can cover.
This is done iteratively: First, guess the range for each NT to
(0, inf). Then, iterate through all rules for a specific NT and
adjust the boundaries given the ranges for all other NTs. Do
this until ranges do not change anymore. This is an expensive
operation should be done after adding all rules. Note also that
the tries store a reference to <code class="docutils literal"><span class="pre">self.span_len_range</span></code>, i.e.
the variable is propagated to all tries automatically.</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt>
<em class="property">class </em><code class="descclassname">cam.sgnmt.predictors.grammar.</code><code class="descname">RuleXtractPredictor</code><span class="sig-paren">(</span><em>ruleXtract_path</em>, <em>use_weights</em>, <em>feature_weights=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/grammar.html#RuleXtractPredictor"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Bases: <a class="reference internal" href="cam.sgnmt.predictors.html#cam.sgnmt.predictors.core.Predictor" title="cam.sgnmt.predictors.core.Predictor"><code class="xref py py-class docutils literal"><span class="pre">cam.sgnmt.predictors.core.Predictor</span></code></a></p>
<p>Predictor based on ruleXtract rules. Bins are organized
according the number of target words. We assume that no rule
produces the empty word on the source side (but possibly on the
target side). Hypotheses are produced iteratively s.t. the
following invariant holds: The bins contain a set of (partial)
hypotheses from which we can derive all full hypotheses which are
consistent with the current target prefix (i.e. the prefix of the
target sentence which has already been translated). This set is
updated when calling either consume_word or predict_next: consume_
word deletes all hypotheses which become inconsistent with the new
word. <code class="docutils literal"><span class="pre">predict_next</span></code> requires all hypotheses to have a target_
prefix length of at least one plus the number of consumed words.
Therefore, <code class="docutils literal"><span class="pre">predict_next</span></code> expands hypotheses as long as they are
shorter. This fits nicely with grouping hypotheses in bins of same
target prefix length: we expand until all low rank bins are empty.
We predict the next target word by using the cost of the best
hypothesis with the word at the right position.</p>
<p>Note that this predictor is similar to the decoding algorithm in</p>
<blockquote>
<div>Efficient Left-to-Right Hierarchical Phrase-based Translation with
Improved Reordering.
Maryam Siahbani, Baskaran Sankaran and Anoop Sarkar.
EMNLP 2013. Oct 18-21, 2013. Seattle, USA.</div></blockquote>
<p>without cube pruning, but it is extended to an arbitrary number of
non-terminals as produced with ruleXtract.</p>
<p>Creates a new hiero predictor.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>ruleXtract_path</strong> (<em>string</em>) &#8211; Path to the rules file</li>
<li><strong>use_weights</strong> (<em>bool</em>) &#8211; If false, set all hypothesis scores
uniformly to 0 (= log 1). If true,
use the rule weights to compute
hypothesis scores</li>
<li><strong>feature_weights</strong> (<em>list</em>) &#8211; Rule feature weights to compute
the rule scores. If this is none
we use uniform weights</li>
</ul>
</td>
</tr>
</tbody>
</table>
<dl class="method">
<dt>
<code class="descname">build_posterior</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/grammar.html#RuleXtractPredictor.build_posterior"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>We need to scan all hypotheses in <code class="docutils literal"><span class="pre">self.stacks</span></code> and add up
scores grouped by the symbol at the n_consumed+1-th position.
Then, we add end-of-sentence probability by checking
<code class="docutils literal"><span class="pre">self.finals[n_consumed]</span></code></p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">consume</code><span class="sig-paren">(</span><em>word</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/grammar.html#RuleXtractPredictor.consume"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Remove all hypotheses with translation prefixes which do not
match <code class="docutils literal"><span class="pre">word</span></code></p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">get_state</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/grammar.html#RuleXtractPredictor.get_state"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Predictor state consists of the stacks, the completed
hypotheses, and the number of consumed words.</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">get_unk_probability</code><span class="sig-paren">(</span><em>posterior</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/grammar.html#RuleXtractPredictor.get_unk_probability"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Returns negative infinity if the posterior is not empty as
words outside the grammar are not possible according this
predictor. If <code class="docutils literal"><span class="pre">posterior</span></code> is empty, return 0 (= log 1)</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">initialize</code><span class="sig-paren">(</span><em>src_sentence</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/grammar.html#RuleXtractPredictor.initialize"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Delete all bins and add the initial cell to the first bin</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">predict_next</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/grammar.html#RuleXtractPredictor.predict_next"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>For predicting the distribution of the next target tokens,
we need to empty the stack with the current history length
by expanding all hypotheses on it. Then, all hypotheses are
in larger bins, i.e. have a longer target prefix than the
current history. Thus, we can look up the possible next words
by iterating through all active hypotheses.</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">reset</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/grammar.html#RuleXtractPredictor.reset"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Empty the stack and delete history.</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">set_state</code><span class="sig-paren">(</span><em>state</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/grammar.html#RuleXtractPredictor.set_state"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Set the predictor state.</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt>
<em class="property">class </em><code class="descclassname">cam.sgnmt.predictors.grammar.</code><code class="descname">Span</code><span class="sig-paren">(</span><em>p</em>, <em>borders</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/grammar.html#Span"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Span is defined by the start and end position and the
corresponding sequence of terminal and non-terminal symbols p.
Normally, p is just a single NT symbol. However, if there is
ambiguity with how to apply a rule to a span (e.g.
rule X -&gt; X the X to span foo the bar the baz) we allow to resolve
them later on demand. In this case, p = X the X</p>
<p>Fully initializes a new <code class="docutils literal"><span class="pre">Span</span></code> instance.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>p</strong> (<em>list</em>) &#8211; See class docstring for <code class="docutils literal"><span class="pre">Span</span></code></li>
<li><strong>borders</strong> (<em>tuple</em>) &#8211; (begin, end) with begin inclusive and end
exclusive</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="class">
<dt>
<em class="property">class </em><code class="descclassname">cam.sgnmt.predictors.grammar.</code><code class="descname">Trie</code><span class="sig-paren">(</span><em>span_len_range</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/grammar.html#Trie"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>This trie implementation allows matching NT symbols with arbitrary
symbol sequences with certain lengths when searching.
Note: This trie does not implement edge collapsing - each edge is
labeled with exactly one word</p>
<p>Creates an empty trie data structure.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>span_len_range</strong> (<em>tuple</em>) &#8211; minimum and maximum span lengths
for non-terminal symbols</td>
</tr>
</tbody>
</table>
<dl class="method">
<dt>
<code class="descname">add</code><span class="sig-paren">(</span><em>seq</em>, <em>element</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/grammar.html#Trie.add"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Add an element to the trie data structure. The key sequence
<code class="docutils literal"><span class="pre">seq</span></code> can contain non-terminals with negative IDs. If a
element with the same key already exists in the data structure,
we do not delete it but store both items.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>seq</strong> (<em>list</em>) &#8211; Sequence of terminals and non-terminals used as
key in the trie</li>
<li><strong>element</strong> (<em>object</em>) &#8211; Object to associate with <code class="docutils literal"><span class="pre">seq</span></code></li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">get_all_elements</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/grammar.html#Trie.get_all_elements"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Retrieve all elements stored in the trie</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">get_elements</code><span class="sig-paren">(</span><em>src_seq</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/grammar.html#Trie.get_elements"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Get all elements (e.g. rules) which match the given sequence
of source tokens.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>seq</strong> (<em>list</em>) &#8211; Sequence of terminals and non-terminals used as
key in the trie</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><code class="docutils literal"><span class="pre">(rules,</span> <span class="pre">nt_span_lens)</span></code>. The first dictionary
contains all applying rules. <code class="docutils literal"><span class="pre">nt_span_lens</span></code> lists the
number of symbols each of the NTs on the source side
covers. Make sure that <code class="docutils literal"><span class="pre">self.span_len_range</span></code> is updated</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body">two dicts</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">replace</code><span class="sig-paren">(</span><em>seq</em>, <em>element</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/grammar.html#Trie.replace"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Replaces all elements stored at a <code class="docutils literal"><span class="pre">seq</span></code> with a new single
element <code class="docutils literal"><span class="pre">element</span></code>. This is equivalent to first removing all
items with key <code class="docutils literal"><span class="pre">seq</span></code>, and then add the new element with
<code class="docutils literal"><span class="pre">add(seq,</span> <span class="pre">element)</span></code></p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>seq</strong> (<em>list</em>) &#8211; Sequence of terminals and non-terminals used as
key in the trie</li>
<li><strong>element</strong> (<em>object</em>) &#8211; Object to associate with <code class="docutils literal"><span class="pre">seq</span></code></li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="cam-sgnmt-predictors-length-module">
<h3>cam.sgnmt.predictors.length module<a class="headerlink" href="#cam-sgnmt-predictors-length-module" title="Permalink to this headline">¶</a></h3>
<p>This module contains predictors that deal wit the length of the
target sentence. The <code class="docutils literal"><span class="pre">NBLengthPredictor</span></code> assumes a negative binomial
distribution on the target sentence lengths, where the parameters r and
p are linear combinations of features extracted from the source
sentence. The <code class="docutils literal"><span class="pre">WordCountPredictor</span></code> adds the number of words as cost,
which can be used to prevent hypotheses from getting to short when
using a language model.</p>
<dl class="class">
<dt>
<em class="property">class </em><code class="descclassname">cam.sgnmt.predictors.length.</code><code class="descname">ExternalLengthPredictor</code><span class="sig-paren">(</span><em>path</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/length.html#ExternalLengthPredictor"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Bases: <a class="reference internal" href="cam.sgnmt.predictors.html#cam.sgnmt.predictors.core.Predictor" title="cam.sgnmt.predictors.core.Predictor"><code class="xref py py-class docutils literal"><span class="pre">cam.sgnmt.predictors.core.Predictor</span></code></a></p>
<p>This predictor loads the distribution over target sentence
lengths from an external file. The file contains blank separated
length:score pairs in each line which define the length
distribution. The predictor adds the specified scores directly
to the EOS score.</p>
<p>Creates a external length distribution predictor.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>path</strong> (<em>string</em>) &#8211; Path to the file with target sentence length
distributions.</td>
</tr>
</tbody>
</table>
<dl class="method">
<dt>
<code class="descname">consume</code><span class="sig-paren">(</span><em>word</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/length.html#ExternalLengthPredictor.consume"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Increases word counter by one.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>word</strong> (<em>int</em>) &#8211; Not used</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">get_state</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/length.html#ExternalLengthPredictor.get_state"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Returns the number of consumed words</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">get_unk_probability</code><span class="sig-paren">(</span><em>posterior</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/length.html#ExternalLengthPredictor.get_unk_probability"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Returns 0=log 1 if the partial hypothesis does not exceed
max length. Otherwise, predict next returns an empty set,
and we set everything else to -inf.</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">initialize</code><span class="sig-paren">(</span><em>src_sentence</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/length.html#ExternalLengthPredictor.initialize"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Fetches the corresponding target sentence length
distribution and resets the word counter.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>src_sentence</strong> (<em>list</em>) &#8211; Not used</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">is_equal</code><span class="sig-paren">(</span><em>state1</em>, <em>state2</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/length.html#ExternalLengthPredictor.is_equal"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Returns true if the number of consumed words is the same</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">predict_next</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/length.html#ExternalLengthPredictor.predict_next"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Returns a dictionary with one entry and value 0 (=log 1). The
key is either the next word in the target sentence or (if the
target sentence has no more words) the end-of-sentence symbol.</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">reset</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/length.html#ExternalLengthPredictor.reset"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Empty method.</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">set_state</code><span class="sig-paren">(</span><em>state</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/length.html#ExternalLengthPredictor.set_state"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Set the number of consumed words</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt>
<em class="property">class </em><code class="descclassname">cam.sgnmt.predictors.length.</code><code class="descname">NBLengthPredictor</code><span class="sig-paren">(</span><em>text_file</em>, <em>model_weights</em>, <em>use_point_probs</em>, <em>offset=0</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/length.html#NBLengthPredictor"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Bases: <a class="reference internal" href="cam.sgnmt.predictors.html#cam.sgnmt.predictors.core.Predictor" title="cam.sgnmt.predictors.core.Predictor"><code class="xref py py-class docutils literal"><span class="pre">cam.sgnmt.predictors.core.Predictor</span></code></a></p>
<p>This predictor assumes that target sentence lengths are
distributed according a negative binomial distribution with
parameters r,p. r is linear in features, p is the logistic of a
linear function over the features. Weights can be trained using
the Matlab script <code class="docutils literal"><span class="pre">estimate_length_model.m</span></code></p>
<p>Let w be the model_weights. All features are extracted from the
src sentence:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="n">r</span> <span class="o">=</span> <span class="n">w0</span> <span class="o">*</span> <span class="c1">#char</span>
<span class="o">+</span> <span class="n">w1</span> <span class="o">*</span> <span class="c1">#words</span>
<span class="o">+</span> <span class="n">w2</span> <span class="o">*</span> <span class="c1">#punctuation</span>
<span class="o">+</span> <span class="n">w3</span> <span class="o">*</span> <span class="c1">#char/#words</span>
<span class="o">+</span> <span class="n">w4</span> <span class="o">*</span> <span class="c1">#punct/#words</span>
<span class="o">+</span> <span class="n">w10</span>

<span class="n">p</span> <span class="o">=</span> <span class="n">logistic</span><span class="p">(</span><span class="n">w5</span> <span class="o">*</span> <span class="c1">#char</span>
<span class="o">+</span> <span class="n">w6</span> <span class="o">*</span> <span class="c1">#words</span>
<span class="o">+</span> <span class="n">w7</span> <span class="o">*</span> <span class="c1">#punctuation</span>
<span class="o">+</span> <span class="n">w8</span> <span class="o">*</span> <span class="c1">#char/#words</span>
<span class="o">+</span> <span class="n">w9</span> <span class="o">*</span> <span class="c1">#punct/#words</span>
<span class="o">+</span> <span class="n">w11</span><span class="p">)</span>

<span class="n">target_length</span> <span class="o">~</span> <span class="n">NB</span><span class="p">(</span><span class="n">r</span><span class="p">,</span><span class="n">p</span><span class="p">)</span>
</pre></div>
</div>
<p>The biases w10 and w11 are optional.</p>
<p>The predictor predicts EOS with NB(#consumed_words,r,p)</p>
<p>Creates a new target sentence length model predictor.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>text_file</strong> (<em>string</em>) &#8211; Path to the text file with the
unindexed source sentences, i.e. not
using word ids</li>
<li><strong>model_weights</strong> (<em>list</em>) &#8211; Weights w0 to w11 of the length
model. See class docstring for more
information</li>
<li><strong>use_point_probs</strong> (<em>bool</em>) &#8211; Use point estimates for EOS token,
0.0 otherwise</li>
<li><strong>offset</strong> (<em>int</em>) &#8211; Subtract this from hypothesis length before
applying the NB model</li>
</ul>
</td>
</tr>
</tbody>
</table>
<dl class="method">
<dt>
<code class="descname">consume</code><span class="sig-paren">(</span><em>word</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/length.html#NBLengthPredictor.consume"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Increases the current history length</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>word</strong> (<em>int</em>) &#8211; Not used</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">get_state</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/length.html#NBLengthPredictor.get_state"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>State consists of the number of consumed words, and the
accumulator for previous EOS probability estimates if we
don&#8217;t use point estimates.</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">get_unk_probability</code><span class="sig-paren">(</span><em>posterior</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/length.html#NBLengthPredictor.get_unk_probability"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>If we use point estimates, return 0 (=1). Otherwise, return
the 1-p(EOS), with p(EOS) fetched from <code class="docutils literal"><span class="pre">posterior</span></code></p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">initialize</code><span class="sig-paren">(</span><em>src_sentence</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/length.html#NBLengthPredictor.initialize"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Extract features for the source sentence. Note that this
method does not use <code class="docutils literal"><span class="pre">src_sentence</span></code> as we need the string
representation of the source sentence to extract features.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>src_sentence</strong> (<em>list</em>) &#8211; Not used</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">is_equal</code><span class="sig-paren">(</span><em>state1</em>, <em>state2</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/length.html#NBLengthPredictor.is_equal"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Returns true if the number of consumed words is the same</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">predict_next</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/length.html#NBLengthPredictor.predict_next"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Returns a dictionary with single entry for EOS.</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">reset</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/length.html#NBLengthPredictor.reset"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Empty method.</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">set_state</code><span class="sig-paren">(</span><em>state</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/length.html#NBLengthPredictor.set_state"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Set the predictor state</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt>
<em class="property">class </em><code class="descclassname">cam.sgnmt.predictors.length.</code><code class="descname">NgramCountPredictor</code><span class="sig-paren">(</span><em>path</em>, <em>order=0</em>, <em>discount_factor=-1.0</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/length.html#NgramCountPredictor"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Bases: <a class="reference internal" href="cam.sgnmt.predictors.html#cam.sgnmt.predictors.core.Predictor" title="cam.sgnmt.predictors.core.Predictor"><code class="xref py py-class docutils literal"><span class="pre">cam.sgnmt.predictors.core.Predictor</span></code></a></p>
<p>This predictor counts the number of n-grams in hypotheses. n-gram
posteriors are loaded from a file. The predictor score is the sum of
all n-gram posteriors in a hypothesis.</p>
<p>Creates a new ngram count predictor instance.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>path</strong> (<em>string</em>) &#8211; Path to the n-gram posteriors. File format:
&lt;ngram&gt; : &lt;score&gt; (one ngram per line). Use
placeholder %d for sentence id.</li>
<li><strong>order</strong> (<em>int</em>) &#8211; If positive, count n-grams of the specified
order. Otherwise, count all n-grams</li>
<li><strong>discount_factor</strong> (<em>float</em>) &#8211; If non-negative, discount n-gram
posteriors by this factor each time
they are consumed</li>
</ul>
</td>
</tr>
</tbody>
</table>
<dl class="method">
<dt>
<code class="descname">consume</code><span class="sig-paren">(</span><em>word</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/length.html#NgramCountPredictor.consume"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Adds <code class="docutils literal"><span class="pre">word</span></code> to the current history. Shorten if the extended
history exceeds <code class="docutils literal"><span class="pre">max_history_len</span></code>.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>word</strong> (<em>int</em>) &#8211; Word to add to the history.</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">get_state</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/length.html#NgramCountPredictor.get_state"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Current history is the predictor state</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">get_unk_probability</code><span class="sig-paren">(</span><em>posterior</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/length.html#NgramCountPredictor.get_unk_probability"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Always return 0.0</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">initialize</code><span class="sig-paren">(</span><em>src_sentence</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/length.html#NgramCountPredictor.initialize"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Loads n-gram posteriors and resets history.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>src_sentence</strong> (<em>list</em>) &#8211; not used</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">is_equal</code><span class="sig-paren">(</span><em>state1</em>, <em>state2</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/length.html#NgramCountPredictor.is_equal"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Hypothesis recombination is
not supported if discounting is enabled.</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">predict_next</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/length.html#NgramCountPredictor.predict_next"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Composes the posterior vector by collecting all ngrams which
are consistent with the current history.</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">reset</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/length.html#NgramCountPredictor.reset"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Empty method.</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">set_state</code><span class="sig-paren">(</span><em>state</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/length.html#NgramCountPredictor.set_state"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Current history is the predictor state</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt>
<em class="property">class </em><code class="descclassname">cam.sgnmt.predictors.length.</code><code class="descname">NgramizePredictor</code><span class="sig-paren">(</span><em>min_order</em>, <em>max_order</em>, <em>max_len_factor</em>, <em>slave_predictor</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/length.html#NgramizePredictor"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Bases: <a class="reference internal" href="cam.sgnmt.predictors.html#cam.sgnmt.predictors.core.Predictor" title="cam.sgnmt.predictors.core.Predictor"><code class="xref py py-class docutils literal"><span class="pre">cam.sgnmt.predictors.core.Predictor</span></code></a></p>
<p>This wrapper extracts n-gram posteriors from a predictor which
does not depend on the particular argument of <cite>consume()</cite>. In that
case, we can build a lookup mechanism for all possible n-grams in
a single forward pass through the predictor search space: We record
all posteriors (predict_next() return values) of the slave
predictor during a greedy pass in <cite>initialize()</cite>. The wrapper
predictor state is the current n-gram history. We use the
(semiring) sum over all possible positions of the current n-gram
history in the recorded slave predictor posteriors to form the
n-gram scores returned by this predictor.</p>
<p>Note that this wrapper does not work correctly if the slave
predictor feeds back the selected token in the history, ie. depends
on the particular token which is provided via <cite>consume()</cite>.</p>
<p>TODO: Make this wrapper work with slaves which return dicts.</p>
<p>Creates a new ngramize wrapper predictor.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>min_order</strong> (<em>int</em>) &#8211; Minimum n-gram order</li>
<li><strong>max_order</strong> (<em>int</em>) &#8211; Maximum n-gram order</li>
<li><strong>max_len_factor</strong> (<em>int</em>) &#8211; Stop the forward pass through the
slave predictor after src_length
times this factor</li>
<li><strong>slave_predictor</strong> (<a class="reference internal" href="cam.sgnmt.predictors.html#cam.sgnmt.predictors.core.Predictor" title="cam.sgnmt.predictors.core.Predictor"><em>Predictor</em></a>) &#8211; Instance of the predictor which
uses the source sentences in
<code class="docutils literal"><span class="pre">src_test</span></code></li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Raises:</th><td class="field-body"><p class="first last">AttributeError if order is not positive.</p>
</td>
</tr>
</tbody>
</table>
<dl class="method">
<dt>
<code class="descname">consume</code><span class="sig-paren">(</span><em>word</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/length.html#NgramizePredictor.consume"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Pass through to slave predictor</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">get_state</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/length.html#NgramizePredictor.get_state"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>State is the current n-gram history.</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">get_unk_probability</code><span class="sig-paren">(</span><em>posterior</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/length.html#NgramizePredictor.get_unk_probability"><span class="viewcode-link">[source]</span></a></dt>
<dd></dd></dl>

<dl class="method">
<dt>
<code class="descname">initialize</code><span class="sig-paren">(</span><em>src_sentence</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/length.html#NgramizePredictor.initialize"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Runs greedy decoding on the slave predictor to populate
self.scores and self.unk_scores, resets the history.</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">initialize_heuristic</code><span class="sig-paren">(</span><em>src_sentence</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/length.html#NgramizePredictor.initialize_heuristic"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Pass through to slave predictor</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">is_equal</code><span class="sig-paren">(</span><em>state1</em>, <em>state2</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/length.html#NgramizePredictor.is_equal"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Pass through to slave predictor</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">predict_next</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/length.html#NgramizePredictor.predict_next"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Looks up ngram scores via self.scores.</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">reset</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/length.html#NgramizePredictor.reset"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Pass through to slave predictor</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">set_current_sen_id</code><span class="sig-paren">(</span><em>cur_sen_id</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/length.html#NgramizePredictor.set_current_sen_id"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>We need to override this method to propagate current_
sentence_id to the slave predictor</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">set_state</code><span class="sig-paren">(</span><em>state</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/length.html#NgramizePredictor.set_state"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>State is the current n-gram history.</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt>
<em class="property">class </em><code class="descclassname">cam.sgnmt.predictors.length.</code><code class="descname">UnkCountPredictor</code><span class="sig-paren">(</span><em>src_vocab_size</em>, <em>lambdas</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/length.html#UnkCountPredictor"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Bases: <a class="reference internal" href="cam.sgnmt.predictors.html#cam.sgnmt.predictors.core.Predictor" title="cam.sgnmt.predictors.core.Predictor"><code class="xref py py-class docutils literal"><span class="pre">cam.sgnmt.predictors.core.Predictor</span></code></a></p>
<p>This predictor regulates the number of UNKs in the output. We
assume that the number of UNKs in the target sentence is Poisson
distributed. This predictor is configured with n lambdas for
0,1,...,&gt;=n-1 UNKs in the source sentence.</p>
<p>Initializes the UNK count predictor.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>src_vocab_size</strong> (<em>int</em>) &#8211; Size of source language vocabulary.
Indices greater than this are
considered as UNK.</li>
<li><strong>lambdas</strong> (<em>list</em>) &#8211; List of floats. The first entry is the
lambda parameter given that the number of
unks in the source sentence is 0 etc. The
last float is lambda given that the source
sentence has more than n-1 unks.</li>
</ul>
</td>
</tr>
</tbody>
</table>
<dl class="method">
<dt>
<code class="descname">consume</code><span class="sig-paren">(</span><em>word</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/length.html#UnkCountPredictor.consume"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Increases unk counter by one if <code class="docutils literal"><span class="pre">word</span></code> is unk.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>word</strong> (<em>int</em>) &#8211; Increase counter if <code class="docutils literal"><span class="pre">word</span></code> is UNK</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">get_state</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/length.html#UnkCountPredictor.get_state"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Returns the number of consumed words</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">get_unk_probability</code><span class="sig-paren">(</span><em>posterior</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/length.html#UnkCountPredictor.get_unk_probability"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Always returns 0 (= log 1) except for the first time</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">initialize</code><span class="sig-paren">(</span><em>src_sentence</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/length.html#UnkCountPredictor.initialize"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Count UNKs in <code class="docutils literal"><span class="pre">src_sentence</span></code> and reset counters.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>src_sentence</strong> (<em>list</em>) &#8211; Count UNKs in this list</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">is_equal</code><span class="sig-paren">(</span><em>state1</em>, <em>state2</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/length.html#UnkCountPredictor.is_equal"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Returns true if the state is the same</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">predict_next</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/length.html#UnkCountPredictor.predict_next"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Set score for EOS to the number of consumed words</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">reset</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/length.html#UnkCountPredictor.reset"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Empty method.</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">set_state</code><span class="sig-paren">(</span><em>state</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/length.html#UnkCountPredictor.set_state"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Set the number of consumed words</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt>
<em class="property">class </em><code class="descclassname">cam.sgnmt.predictors.length.</code><code class="descname">WordCountPredictor</code><span class="sig-paren">(</span><em>word=-1</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/length.html#WordCountPredictor"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Bases: <a class="reference internal" href="cam.sgnmt.predictors.html#cam.sgnmt.predictors.core.Predictor" title="cam.sgnmt.predictors.core.Predictor"><code class="xref py py-class docutils literal"><span class="pre">cam.sgnmt.predictors.core.Predictor</span></code></a></p>
<p>This predictor adds the (negative) number of words as feature.</p>
<p>Creates a new word count predictor instance.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>word</strong> (<em>int</em>) &#8211; If this is non-negative we count only the
number of the specified word. If its
negative, count all words</td>
</tr>
</tbody>
</table>
<dl class="method">
<dt>
<code class="descname">consume</code><span class="sig-paren">(</span><em>word</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/length.html#WordCountPredictor.consume"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Empty</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">get_state</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/length.html#WordCountPredictor.get_state"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Returns true</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">get_unk_probability</code><span class="sig-paren">(</span><em>posterior</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/length.html#WordCountPredictor.get_unk_probability"><span class="viewcode-link">[source]</span></a></dt>
<dd></dd></dl>

<dl class="method">
<dt>
<code class="descname">initialize</code><span class="sig-paren">(</span><em>src_sentence</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/length.html#WordCountPredictor.initialize"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Empty</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">is_equal</code><span class="sig-paren">(</span><em>state1</em>, <em>state2</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/length.html#WordCountPredictor.is_equal"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Returns true</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">predict_next</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/length.html#WordCountPredictor.predict_next"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Set score for EOS to the number of consumed words</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">reset</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/length.html#WordCountPredictor.reset"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Empty method.</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">set_state</code><span class="sig-paren">(</span><em>state</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/length.html#WordCountPredictor.set_state"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Empty</p>
</dd></dl>

</dd></dl>

<dl class="function">
<dt>
<code class="descclassname">cam.sgnmt.predictors.length.</code><code class="descname">load_external_lengths</code><span class="sig-paren">(</span><em>path</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/length.html#load_external_lengths"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Loads a length distribution from a plain text file. The file
must contain blank separated &lt;length&gt;:&lt;score&gt; pairs in each line.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>path</strong> (<em>string</em>) &#8211; Path to the length file.</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body">list of dicts mapping a length to its scores, one dict for each
sentence.</td>
</tr>
</tbody>
</table>
</dd></dl>

</div>
<div class="section" id="cam-sgnmt-predictors-misc-module">
<h3>cam.sgnmt.predictors.misc module<a class="headerlink" href="#cam-sgnmt-predictors-misc-module" title="Permalink to this headline">¶</a></h3>
<p>This module provides helper predictors and predictor wrappers which
are not directly used for scoring. An example is the altsrc predictor
wrapper which loads source sentences from a different file.</p>
<dl class="class">
<dt>
<em class="property">class </em><code class="descclassname">cam.sgnmt.predictors.misc.</code><code class="descname">AltsrcPredictor</code><span class="sig-paren">(</span><em>src_test</em>, <em>slave_predictor</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/misc.html#AltsrcPredictor"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Bases: <a class="reference internal" href="cam.sgnmt.predictors.html#cam.sgnmt.predictors.core.Predictor" title="cam.sgnmt.predictors.core.Predictor"><code class="xref py py-class docutils literal"><span class="pre">cam.sgnmt.predictors.core.Predictor</span></code></a></p>
<p>This wrapper loads the source sentences from an alternative
source file. The <code class="docutils literal"><span class="pre">src_sentence</span></code> arguments of <code class="docutils literal"><span class="pre">initialize</span></code> and
<code class="docutils literal"><span class="pre">initialize_heuristic</span></code> are overridden with sentences loaded from
the file specified via the argument <code class="docutils literal"><span class="pre">--altsrc_test</span></code>. All other
methods are pass through calls to the slave predictor.</p>
<p>Creates a new altsrc wrapper predictor.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>src_test</strong> (<em>string</em>) &#8211; Path to the text file with source
sentences</li>
<li><strong>slave_predictor</strong> (<a class="reference internal" href="cam.sgnmt.predictors.html#cam.sgnmt.predictors.core.Predictor" title="cam.sgnmt.predictors.core.Predictor"><em>Predictor</em></a>) &#8211; Instance of the predictor which
uses the source sentences in
<code class="docutils literal"><span class="pre">src_test</span></code></li>
</ul>
</td>
</tr>
</tbody>
</table>
<dl class="method">
<dt>
<code class="descname">consume</code><span class="sig-paren">(</span><em>word</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/misc.html#AltsrcPredictor.consume"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Pass through to slave predictor</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">estimate_future_cost</code><span class="sig-paren">(</span><em>hypo</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/misc.html#AltsrcPredictor.estimate_future_cost"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Pass through to slave predictor</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">get_state</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/misc.html#AltsrcPredictor.get_state"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Pass through to slave predictor</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">get_unk_probability</code><span class="sig-paren">(</span><em>posterior</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/misc.html#AltsrcPredictor.get_unk_probability"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Pass through to slave predictor</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">initialize</code><span class="sig-paren">(</span><em>src_sentence</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/misc.html#AltsrcPredictor.initialize"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Pass through to slave predictor but replace
<code class="docutils literal"><span class="pre">src_sentence</span></code> with a sentence from <code class="docutils literal"><span class="pre">self.altsens</span></code></p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">initialize_heuristic</code><span class="sig-paren">(</span><em>src_sentence</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/misc.html#AltsrcPredictor.initialize_heuristic"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Pass through to slave predictor but replace
<code class="docutils literal"><span class="pre">src_sentence</span></code> with a sentence from <code class="docutils literal"><span class="pre">self.altsens</span></code></p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">is_equal</code><span class="sig-paren">(</span><em>state1</em>, <em>state2</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/misc.html#AltsrcPredictor.is_equal"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Pass through to slave predictor</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">predict_next</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/misc.html#AltsrcPredictor.predict_next"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Pass through to slave predictor</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">reset</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/misc.html#AltsrcPredictor.reset"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Pass through to slave predictor</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">set_current_sen_id</code><span class="sig-paren">(</span><em>cur_sen_id</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/misc.html#AltsrcPredictor.set_current_sen_id"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>We need to override this method to propagate current_
sentence_id to the slave predictor</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">set_state</code><span class="sig-paren">(</span><em>state</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/misc.html#AltsrcPredictor.set_state"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Pass through to slave predictor</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt>
<em class="property">class </em><code class="descclassname">cam.sgnmt.predictors.misc.</code><code class="descname">UnboundedAltsrcPredictor</code><span class="sig-paren">(</span><em>src_test</em>, <em>slave_predictor</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/misc.html#UnboundedAltsrcPredictor"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Bases: <a class="reference internal" href="cam.sgnmt.predictors.html#cam.sgnmt.predictors.misc.AltsrcPredictor" title="cam.sgnmt.predictors.misc.AltsrcPredictor"><code class="xref py py-class docutils literal"><span class="pre">cam.sgnmt.predictors.misc.AltsrcPredictor</span></code></a>, <a class="reference internal" href="cam.sgnmt.predictors.html#cam.sgnmt.predictors.core.UnboundedVocabularyPredictor" title="cam.sgnmt.predictors.core.UnboundedVocabularyPredictor"><code class="xref py py-class docutils literal"><span class="pre">cam.sgnmt.predictors.core.UnboundedVocabularyPredictor</span></code></a></p>
<p>This class is a version of <code class="docutils literal"><span class="pre">AltsrcPredictor</span></code> for unbounded
vocabulary predictors. This needs an adjusted <code class="docutils literal"><span class="pre">predict_next</span></code>
method to pass through the set of target words to score correctly.</p>
<p>Pass through to <code class="docutils literal"><span class="pre">AltsrcPredictor.__init__</span></code></p>
<dl class="method">
<dt>
<code class="descname">predict_next</code><span class="sig-paren">(</span><em>trgt_words</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/misc.html#UnboundedAltsrcPredictor.predict_next"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Pass through to slave predictor</p>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="cam-sgnmt-predictors-ngram-module">
<h3>cam.sgnmt.predictors.ngram module<a class="headerlink" href="#cam-sgnmt-predictors-ngram-module" title="Permalink to this headline">¶</a></h3>
<p>This module contains predictors for n-gram (Kneser-Ney) language
modeling. This is a <code class="docutils literal"><span class="pre">UnboundedVocabularyPredictor</span></code> as the vocabulary
size ngram models normally do not permit complete enumeration of the
posterior.</p>
<p>This module is based on the swig-srilm package.</p>
<p><a class="reference external" href="https://github.com/desilinguist/swig-srilm">https://github.com/desilinguist/swig-srilm</a></p>
<dl class="class">
<dt>
<em class="property">class </em><code class="descclassname">cam.sgnmt.predictors.ngram.</code><code class="descname">SRILMPredictor</code><span class="sig-paren">(</span><em>path</em>, <em>ngram_order</em>, <em>convert_to_ln=False</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/ngram.html#SRILMPredictor"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Bases: <a class="reference internal" href="cam.sgnmt.predictors.html#cam.sgnmt.predictors.core.UnboundedVocabularyPredictor" title="cam.sgnmt.predictors.core.UnboundedVocabularyPredictor"><code class="xref py py-class docutils literal"><span class="pre">cam.sgnmt.predictors.core.UnboundedVocabularyPredictor</span></code></a></p>
<p>SRILM predictor based on swig
<a class="reference external" href="https://github.com/desilinguist/swig-srilm">https://github.com/desilinguist/swig-srilm</a></p>
<p>The predictor state is described by the n-gram history. The language
model has to use word indices rather than the string word
representations.</p>
<p>Creates a new n-gram language model predictor.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>path</strong> (<em>string</em>) &#8211; Path to the ARPA language model file</li>
<li><strong>ngram_order</strong> (<em>int</em>) &#8211; Order of the language model</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Raises:</th><td class="field-body"><p class="first last">NameError. If srilm-swig is not installed</p>
</td>
</tr>
</tbody>
</table>
<dl class="method">
<dt>
<code class="descname">consume</code><span class="sig-paren">(</span><em>word</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/ngram.html#SRILMPredictor.consume"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Extends the current history by <code class="docutils literal"><span class="pre">word</span></code></p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">get_state</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/ngram.html#SRILMPredictor.get_state"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Returns the current n-gram history</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">get_unk_probability</code><span class="sig-paren">(</span><em>posterior</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/ngram.html#SRILMPredictor.get_unk_probability"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Use the probability for &#8216;&lt;unk&gt;&#8217; in the language model</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">initialize</code><span class="sig-paren">(</span><em>src_sentence</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/ngram.html#SRILMPredictor.initialize"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Initializes the history with the start-of-sentence symbol.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>src_sentence</strong> (<em>list</em>) &#8211; Not used</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">is_equal</code><span class="sig-paren">(</span><em>state1</em>, <em>state2</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/ngram.html#SRILMPredictor.is_equal"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Returns true if the ngram history is the same</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">predict_next</code><span class="sig-paren">(</span><em>words</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/ngram.html#SRILMPredictor.predict_next"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Score the set of target words with the n-gram language
model given the current history</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>words</strong> (<em>list</em>) &#8211; Set of words to score</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body">dict. Language model scores for the words in <code class="docutils literal"><span class="pre">words</span></code></td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">reset</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/ngram.html#SRILMPredictor.reset"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Resets the current history to &lt;S&gt;</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">set_state</code><span class="sig-paren">(</span><em>state</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/ngram.html#SRILMPredictor.set_state"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Sets the current n-gram history</p>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="cam-sgnmt-predictors-structure-module">
<h3>cam.sgnmt.predictors.structure module<a class="headerlink" href="#cam-sgnmt-predictors-structure-module" title="Permalink to this headline">¶</a></h3>
<p>This module implements constraints which assure that highly structured
output is well-formatted. For example, the bracket predictor checks for
balanced bracket expressions, and the OSM predictor prevents any sequence
of operations which cannot be compiled to a string.</p>
<dl class="class">
<dt>
<em class="property">class </em><code class="descclassname">cam.sgnmt.predictors.structure.</code><code class="descname">BracketPredictor</code><span class="sig-paren">(</span><em>max_terminal_id</em>, <em>closing_bracket_id</em>, <em>max_depth=-1</em>, <em>extlength_path=''</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/structure.html#BracketPredictor"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Bases: <a class="reference internal" href="cam.sgnmt.predictors.html#cam.sgnmt.predictors.core.UnboundedVocabularyPredictor" title="cam.sgnmt.predictors.core.UnboundedVocabularyPredictor"><code class="xref py py-class docutils literal"><span class="pre">cam.sgnmt.predictors.core.UnboundedVocabularyPredictor</span></code></a></p>
<p>This predictor constrains the output to well-formed bracket
expressions. It also allows to specify the number of terminals with
an external length distribution file.</p>
<p>Creates a new bracket predictor.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>max_terminal_id</strong> (<em>int</em>) &#8211; All IDs greater than this are
brackets</li>
<li><strong>closing_bracket_id</strong> (<em>string</em>) &#8211; All brackets except these ones are
opening. Comma-separated list of integers.</li>
<li><strong>max_depth</strong> (<em>int</em>) &#8211; If positive, restrict the maximum depth</li>
<li><strong>extlength_path</strong> (<em>string</em>) &#8211; If this is set, restrict the
number of terminals to the distribution specified in
the referenced file. Terminals can be implicit: We
count a single terminal between each adjacent opening
and closing bracket.</li>
</ul>
</td>
</tr>
</tbody>
</table>
<dl class="method">
<dt>
<code class="descname">consume</code><span class="sig-paren">(</span><em>word</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/structure.html#BracketPredictor.consume"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Updates current depth and the number of consumed terminals.</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">get_state</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/structure.html#BracketPredictor.get_state"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Returns the current depth and number of consumed terminals</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">get_unk_probability</code><span class="sig-paren">(</span><em>posterior</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/structure.html#BracketPredictor.get_unk_probability"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Always returns 0.0</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">initialize</code><span class="sig-paren">(</span><em>src_sentence</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/structure.html#BracketPredictor.initialize"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Sets the current depth to 0.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>src_sentence</strong> (<em>list</em>) &#8211; Not used</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">is_equal</code><span class="sig-paren">(</span><em>state1</em>, <em>state2</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/structure.html#BracketPredictor.is_equal"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Trivial implementation</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">predict_next</code><span class="sig-paren">(</span><em>words</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/structure.html#BracketPredictor.predict_next"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>If the maximum depth is reached, exclude all opening
brackets. If history is not balanced, exclude EOS. If the
current depth is zero, exclude closing brackets.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>words</strong> (<em>list</em>) &#8211; Set of words to score</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body">dict.</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">reset</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/structure.html#BracketPredictor.reset"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Empty.</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">set_state</code><span class="sig-paren">(</span><em>state</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/structure.html#BracketPredictor.set_state"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Sets the current depth and number of consumed terminals</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt>
<em class="property">class </em><code class="descclassname">cam.sgnmt.predictors.structure.</code><code class="descname">ForcedOSMPredictor</code><span class="sig-paren">(</span><em>trg_test_file</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/structure.html#ForcedOSMPredictor"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Bases: <a class="reference internal" href="cam.sgnmt.predictors.html#cam.sgnmt.predictors.core.Predictor" title="cam.sgnmt.predictors.core.Predictor"><code class="xref py py-class docutils literal"><span class="pre">cam.sgnmt.predictors.core.Predictor</span></code></a></p>
<p>This predictor allows forced decoding with an OSM output, which
essentially means running the OSM in alignment mode. This predictor
assumes well-formed operation sequences. Please combine this
predictor with the osm constraint predictor to satisfy this
requirement. The state of this predictor is the compiled version of
the current history. It allows terminal symbols which are
consistent with the reference. The end-of-sentence symbol is
supressed until all words in the reference have been consumed.</p>
<p>Creates a new forcedosm predictor.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>trg_test_file</strong> (<em>string</em>) &#8211; Path to the plain text file with
the target sentences. Must have the
same number of lines as the number
of source sentences to decode</td>
</tr>
</tbody>
</table>
<dl class="method">
<dt>
<code class="descname">consume</code><span class="sig-paren">(</span><em>word</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/structure.html#ForcedOSMPredictor.consume"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Updates the compiled string and the head position.</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">get_state</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/structure.html#ForcedOSMPredictor.get_state"><span class="viewcode-link">[source]</span></a></dt>
<dd></dd></dl>

<dl class="method">
<dt>
<code class="descname">get_unk_probability</code><span class="sig-paren">(</span><em>posterior</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/structure.html#ForcedOSMPredictor.get_unk_probability"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Always returns -inf.</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">initialize</code><span class="sig-paren">(</span><em>src_sentence</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/structure.html#ForcedOSMPredictor.initialize"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Resets compiled and head.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>src_sentence</strong> (<em>list</em>) &#8211; Not used</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">is_equal</code><span class="sig-paren">(</span><em>state1</em>, <em>state2</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/structure.html#ForcedOSMPredictor.is_equal"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Trivial implementation</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">predict_next</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/structure.html#ForcedOSMPredictor.predict_next"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Apply word reference constraints.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body">dict.</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">set_state</code><span class="sig-paren">(</span><em>state</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/structure.html#ForcedOSMPredictor.set_state"><span class="viewcode-link">[source]</span></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="class">
<dt>
<em class="property">class </em><code class="descclassname">cam.sgnmt.predictors.structure.</code><code class="descname">OSMPredictor</code><a class="reference internal" href="_modules/cam/sgnmt/predictors/structure.html#OSMPredictor"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Bases: <a class="reference internal" href="cam.sgnmt.predictors.html#cam.sgnmt.predictors.core.Predictor" title="cam.sgnmt.predictors.core.Predictor"><code class="xref py py-class docutils literal"><span class="pre">cam.sgnmt.predictors.core.Predictor</span></code></a></p>
<p>This predictor applies the following constraints to an OSM output:</p>
<ul class="simple">
<li>The number of EOP (end-of-phrase) tokens must not exceed the number
of source tokens.</li>
<li>JUMP_FWD and JUMP_BWD tokens are constraint to avoid jumping out of
bounds.</li>
</ul>
<p>Creates a new osm predictor.</p>
<dl class="method">
<dt>
<code class="descname">consume</code><span class="sig-paren">(</span><em>word</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/structure.html#OSMPredictor.consume"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Updates the number of holes, EOPs, and the head position.</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">get_state</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/structure.html#OSMPredictor.get_state"><span class="viewcode-link">[source]</span></a></dt>
<dd></dd></dl>

<dl class="method">
<dt>
<code class="descname">get_unk_probability</code><span class="sig-paren">(</span><em>posterior</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/structure.html#OSMPredictor.get_unk_probability"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Always returns 0.0</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">initialize</code><span class="sig-paren">(</span><em>src_sentence</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/structure.html#OSMPredictor.initialize"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Sets the number of source tokens.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>src_sentence</strong> (<em>list</em>) &#8211; Not used</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">is_equal</code><span class="sig-paren">(</span><em>state1</em>, <em>state2</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/structure.html#OSMPredictor.is_equal"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Trivial implementation</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">predict_next</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/structure.html#OSMPredictor.predict_next"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Apply OSM constraints.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body">dict.</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">reset</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/structure.html#OSMPredictor.reset"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Empty.</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">set_state</code><span class="sig-paren">(</span><em>state</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/structure.html#OSMPredictor.set_state"><span class="viewcode-link">[source]</span></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="function">
<dt>
<code class="descclassname">cam.sgnmt.predictors.structure.</code><code class="descname">load_external_lengths</code><span class="sig-paren">(</span><em>path</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/structure.html#load_external_lengths"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Loads a length distribution from a plain text file. The file
must contain blank separated &lt;length&gt;:&lt;score&gt; pairs in each line.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>path</strong> (<em>string</em>) &#8211; Path to the length file.</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body">list of dicts mapping a length to its scores, one dict for each
sentence.</td>
</tr>
</tbody>
</table>
</dd></dl>

</div>
<div class="section" id="cam-sgnmt-predictors-tf-nizza-module">
<h3>cam.sgnmt.predictors.tf_nizza module<a class="headerlink" href="#cam-sgnmt-predictors-tf-nizza-module" title="Permalink to this headline">¶</a></h3>
<p>This module integrates Nizza alignment models.</p>
<p><a class="reference external" href="https://github.com/fstahlberg/nizza">https://github.com/fstahlberg/nizza</a></p>
<dl class="class">
<dt>
<em class="property">class </em><code class="descclassname">cam.sgnmt.predictors.tf_nizza.</code><code class="descname">BaseNizzaPredictor</code><span class="sig-paren">(</span><em>src_vocab_size</em>, <em>trg_vocab_size</em>, <em>model_name</em>, <em>hparams_set_name</em>, <em>checkpoint_dir</em>, <em>single_cpu_thread</em>, <em>nizza_unk_id=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/tf_nizza.html#BaseNizzaPredictor"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Bases: <a class="reference internal" href="cam.sgnmt.predictors.html#cam.sgnmt.predictors.core.Predictor" title="cam.sgnmt.predictors.core.Predictor"><code class="xref py py-class docutils literal"><span class="pre">cam.sgnmt.predictors.core.Predictor</span></code></a></p>
<p>Common functionality for Nizza based predictors. This includes
loading checkpoints, creating sessions, and creating computation
graphs.</p>
<p>Initializes a nizza predictor.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>src_vocab_size</strong> (<em>int</em>) &#8211; Source vocabulary size (called inputs_vocab_size
in nizza)</li>
<li><strong>trg_vocab_size</strong> (<em>int</em>) &#8211; Target vocabulary size (called targets_vocab_size
in nizza)</li>
<li><strong>model_name</strong> (<em>string</em>) &#8211; Name of the nizza model</li>
<li><strong>hparams_set_name</strong> (<em>string</em>) &#8211; Name of the nizza hyper-parameter set</li>
<li><strong>checkpoint_dir</strong> (<em>string</em>) &#8211; Path to the Nizza checkpoint directory. The
predictor will load the top most checkpoint in
the <cite>checkpoints</cite> file.</li>
<li><strong>single_cpu_thread</strong> (<em>bool</em>) &#8211; If true, prevent tensorflow from
doing multithreading.</li>
<li><strong>nizza_unk_id</strong> (<em>int</em>) &#8211; If set, use this as UNK id. Otherwise, the
nizza is assumed to have no UNKs</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Raises:</th><td class="field-body"><p class="first last">IOError if checkpoint file not found.</p>
</td>
</tr>
</tbody>
</table>
<dl class="method">
<dt>
<code class="descname">create_session</code><span class="sig-paren">(</span><em>checkpoint_dir</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/tf_nizza.html#BaseNizzaPredictor.create_session"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Creates a MonitoredSession for this predictor.</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">get_unk_probability</code><span class="sig-paren">(</span><em>posterior</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/tf_nizza.html#BaseNizzaPredictor.get_unk_probability"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Fetch posterior[t2t_unk_id] or return NEG_INF if None.</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt>
<em class="property">class </em><code class="descclassname">cam.sgnmt.predictors.tf_nizza.</code><code class="descname">LexNizzaPredictor</code><span class="sig-paren">(</span><em>src_vocab_size</em>, <em>trg_vocab_size</em>, <em>model_name</em>, <em>hparams_set_name</em>, <em>checkpoint_dir</em>, <em>single_cpu_thread</em>, <em>alpha</em>, <em>beta</em>, <em>shortlist_strategies</em>, <em>trg2src_model_name=''</em>, <em>trg2src_hparams_set_name=''</em>, <em>trg2src_checkpoint_dir=''</em>, <em>max_shortlist_length=0</em>, <em>min_id=0</em>, <em>nizza_unk_id=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/tf_nizza.html#LexNizzaPredictor"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Bases: <a class="reference internal" href="cam.sgnmt.predictors.html#cam.sgnmt.predictors.tf_nizza.BaseNizzaPredictor" title="cam.sgnmt.predictors.tf_nizza.BaseNizzaPredictor"><code class="xref py py-class docutils literal"><span class="pre">cam.sgnmt.predictors.tf_nizza.BaseNizzaPredictor</span></code></a></p>
<p>This predictor is only compatible to Model1-like Nizza models
which return lexical translation probabilities in precompute(). The
predictor keeps a list of the same length as the source sentence
and initializes it with zeros. At each timestep it updates this list
by the lexical scores Model1 assigned to the last consumed token.
The predictor score aims to bring up all entries in the list, and
thus serves as a coverage mechanism over the source sentence.</p>
<p>Initializes a nizza predictor.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>src_vocab_size</strong> (<em>int</em>) &#8211; Source vocabulary size (called inputs_vocab_size
in nizza)</li>
<li><strong>trg_vocab_size</strong> (<em>int</em>) &#8211; Target vocabulary size (called targets_vocab_size
in nizza)</li>
<li><strong>model_name</strong> (<em>string</em>) &#8211; Name of the nizza model</li>
<li><strong>hparams_set_name</strong> (<em>string</em>) &#8211; Name of the nizza hyper-parameter set</li>
<li><strong>checkpoint_dir</strong> (<em>string</em>) &#8211; Path to the Nizza checkpoint directory. The
predictor will load the top most checkpoint in
the <cite>checkpoints</cite> file.</li>
<li><strong>single_cpu_thread</strong> (<em>bool</em>) &#8211; If true, prevent tensorflow from
doing multithreading.</li>
<li><strong>alpha</strong> (<em>float</em>) &#8211; Score for each matching word</li>
<li><strong>beta</strong> (<em>float</em>) &#8211; Penalty for each uncovered word at the end</li>
<li><strong>shortlist_strategies</strong> (<em>string</em>) &#8211; Comma-separated list of shortlist
strategies.</li>
<li><strong>trg2src_model_name</strong> (<em>string</em>) &#8211; Name of the target2source nizza model</li>
<li><strong>trg2src_hparams_set_name</strong> (<em>string</em>) &#8211; Name of the nizza hyper-parameter set
for the target2source model</li>
<li><strong>trg2src_checkpoint_dir</strong> (<em>string</em>) &#8211; Path to the Nizza checkpoint directory
for the target2source model. The
predictor will load the top most checkpoint in
the <cite>checkpoints</cite> file.</li>
<li><strong>max_shortlist_length</strong> (<em>int</em>) &#8211; If a shortlist exceeds this limit,
initialize the initial coverage with 1 at this position. If
zero, do not apply any limit</li>
<li><strong>min_id</strong> (<em>int</em>) &#8211; Do not use IDs below this threshold (filters out most
frequent words).</li>
<li><strong>nizza_unk_id</strong> (<em>int</em>) &#8211; If set, use this as UNK id. Otherwise, the
nizza is assumed to have no UNKs</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Raises:</th><td class="field-body"><p class="first last">IOError if checkpoint file not found.</p>
</td>
</tr>
</tbody>
</table>
<dl class="method">
<dt>
<code class="descname">consume</code><span class="sig-paren">(</span><em>word</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/tf_nizza.html#LexNizzaPredictor.consume"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Update coverage.</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">estimate_future_cost</code><span class="sig-paren">(</span><em>hypo</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/tf_nizza.html#LexNizzaPredictor.estimate_future_cost"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>We use the number of uncovered words times beta as heuristic
estimate.</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">get_state</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/tf_nizza.html#LexNizzaPredictor.get_state"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>The predictor state is the coverage vector.</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">get_unk_probability</code><span class="sig-paren">(</span><em>posterior</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/tf_nizza.html#LexNizzaPredictor.get_unk_probability"><span class="viewcode-link">[source]</span></a></dt>
<dd></dd></dl>

<dl class="method">
<dt>
<code class="descname">initialize</code><span class="sig-paren">(</span><em>src_sentence</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/tf_nizza.html#LexNizzaPredictor.initialize"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Set src_sentence, reset consumed.</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">predict_next</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/tf_nizza.html#LexNizzaPredictor.predict_next"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Predict record scores.</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">set_state</code><span class="sig-paren">(</span><em>state</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/tf_nizza.html#LexNizzaPredictor.set_state"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>The predictor state is the coverage vector.</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt>
<em class="property">class </em><code class="descclassname">cam.sgnmt.predictors.tf_nizza.</code><code class="descname">NizzaPredictor</code><span class="sig-paren">(</span><em>src_vocab_size</em>, <em>trg_vocab_size</em>, <em>model_name</em>, <em>hparams_set_name</em>, <em>checkpoint_dir</em>, <em>single_cpu_thread</em>, <em>nizza_unk_id=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/tf_nizza.html#NizzaPredictor"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Bases: <a class="reference internal" href="cam.sgnmt.predictors.html#cam.sgnmt.predictors.tf_nizza.BaseNizzaPredictor" title="cam.sgnmt.predictors.tf_nizza.BaseNizzaPredictor"><code class="xref py py-class docutils literal"><span class="pre">cam.sgnmt.predictors.tf_nizza.BaseNizzaPredictor</span></code></a></p>
<p>This predictor uses Nizza alignment models to derive a posterior over
the target vocabulary for the next position. It mainly relies on the
predict_next_word() implementation of Nizza models.</p>
<p>Initializes a nizza predictor.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>src_vocab_size</strong> (<em>int</em>) &#8211; Source vocabulary size (called inputs_vocab_size
in nizza)</li>
<li><strong>trg_vocab_size</strong> (<em>int</em>) &#8211; Target vocabulary size (called targets_vocab_size
in nizza)</li>
<li><strong>model_name</strong> (<em>string</em>) &#8211; Name of the nizza model</li>
<li><strong>hparams_set_name</strong> (<em>string</em>) &#8211; Name of the nizza hyper-parameter set</li>
<li><strong>checkpoint_dir</strong> (<em>string</em>) &#8211; Path to the Nizza checkpoint directory. The
predictor will load the top most checkpoint in
the <cite>checkpoints</cite> file.</li>
<li><strong>single_cpu_thread</strong> (<em>bool</em>) &#8211; If true, prevent tensorflow from
doing multithreading.</li>
<li><strong>nizza_unk_id</strong> (<em>int</em>) &#8211; If set, use this as UNK id. Otherwise, the
nizza is assumed to have no UNKs</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Raises:</th><td class="field-body"><p class="first last">IOError if checkpoint file not found.</p>
</td>
</tr>
</tbody>
</table>
<dl class="method">
<dt>
<code class="descname">consume</code><span class="sig-paren">(</span><em>word</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/tf_nizza.html#NizzaPredictor.consume"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Append <code class="docutils literal"><span class="pre">word</span></code> to the current history.</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">get_state</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/tf_nizza.html#NizzaPredictor.get_state"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>The predictor state is the complete history.</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">initialize</code><span class="sig-paren">(</span><em>src_sentence</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/tf_nizza.html#NizzaPredictor.initialize"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Set src_sentence, reset consumed.</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">is_equal</code><span class="sig-paren">(</span><em>state1</em>, <em>state2</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/tf_nizza.html#NizzaPredictor.is_equal"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Returns true if the history is the same</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">predict_next</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/tf_nizza.html#NizzaPredictor.predict_next"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Call the T2T model in self.mon_sess.</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">set_state</code><span class="sig-paren">(</span><em>state</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/tf_nizza.html#NizzaPredictor.set_state"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>The predictor state is the complete history.</p>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="cam-sgnmt-predictors-tf-nmt-module">
<h3>cam.sgnmt.predictors.tf_nmt module<a class="headerlink" href="#cam-sgnmt-predictors-tf-nmt-module" title="Permalink to this headline">¶</a></h3>
</div>
<div class="section" id="cam-sgnmt-predictors-tf-rnnlm-module">
<h3>cam.sgnmt.predictors.tf_rnnlm module<a class="headerlink" href="#cam-sgnmt-predictors-tf-rnnlm-module" title="Permalink to this headline">¶</a></h3>
</div>
<div class="section" id="cam-sgnmt-predictors-tf-t2t-module">
<h3>cam.sgnmt.predictors.tf_t2t module<a class="headerlink" href="#cam-sgnmt-predictors-tf-t2t-module" title="Permalink to this headline">¶</a></h3>
<p>This is the interface to the tensor2tensor library.</p>
<p><a class="reference external" href="https://github.com/tensorflow/tensor2tensor">https://github.com/tensorflow/tensor2tensor</a></p>
<p>Alternatively, you may use the following fork which has been tested in
combination with SGNMT:</p>
<p><a class="reference external" href="https://github.com/fstahlberg/tensor2tensor">https://github.com/fstahlberg/tensor2tensor</a></p>
<p>The t2t predictor can read any model trained with tensor2tensor which
includes the transformer model, convolutional models, and RNN-based
sequence models.</p>
<dl class="class">
<dt>
<em class="property">class </em><code class="descclassname">cam.sgnmt.predictors.tf_t2t.</code><code class="descname">FertilityT2TPredictor</code><span class="sig-paren">(</span><em>src_vocab_size</em>, <em>trg_vocab_size</em>, <em>model_name</em>, <em>problem_name</em>, <em>hparams_set_name</em>, <em>t2t_usr_dir</em>, <em>checkpoint_dir</em>, <em>t2t_unk_id=None</em>, <em>single_cpu_thread=False</em>, <em>max_terminal_id=-1</em>, <em>pop_id=-1</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/tf_t2t.html#FertilityT2TPredictor"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Bases: <a class="reference internal" href="cam.sgnmt.predictors.html#cam.sgnmt.predictors.tf_t2t.T2TPredictor" title="cam.sgnmt.predictors.tf_t2t.T2TPredictor"><code class="xref py py-class docutils literal"><span class="pre">cam.sgnmt.predictors.tf_t2t.T2TPredictor</span></code></a></p>
<p>Use this predictor to integrate fertility models trained with
T2T. Fertility models output the fertility for each source word
instead of target words. We define the fertility of the i-th
source word in a hypothesis as the number of tokens between the
(i-1)-th and the i-th POP token.</p>
<p>TODO: This is not SOLID (violates substitution principle)</p>
<p>Creates a new T2T predictor. The constructor prepares the
TensorFlow session for predict_next() calls. This includes:
- Load hyper parameters from the given set (hparams)
- Update registry, load T2T model
- Create TF placeholders for source sequence and target prefix
- Create computation graph for computing log probs.
- Create a MonitoredSession object, which also handles</p>
<blockquote>
<div>restoring checkpoints.</div></blockquote>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>src_vocab_size</strong> (<em>int</em>) &#8211; Source vocabulary size.</li>
<li><strong>trg_vocab_size</strong> (<em>int</em>) &#8211; Target vocabulary size.</li>
<li><strong>model_name</strong> (<em>string</em>) &#8211; T2T model name.</li>
<li><strong>problem_name</strong> (<em>string</em>) &#8211; T2T problem name.</li>
<li><strong>hparams_set_name</strong> (<em>string</em>) &#8211; T2T hparams set name.</li>
<li><strong>t2t_usr_dir</strong> (<em>string</em>) &#8211; See &#8211;t2t_usr_dir in tensor2tensor.</li>
<li><strong>checkpoint_dir</strong> (<em>string</em>) &#8211; Path to the T2T checkpoint
directory. The predictor will load
the top most checkpoint in the
<cite>checkpoints</cite> file.</li>
<li><strong>t2t_unk_id</strong> (<em>int</em>) &#8211; If set, use this ID to get UNK scores. If
None, UNK is always scored with -inf.</li>
<li><strong>single_cpu_thread</strong> (<em>bool</em>) &#8211; If true, prevent tensorflow from
doing multithreading.</li>
<li><strong>max_terminal_id</strong> (<em>int</em>) &#8211; If positive, maximum terminal ID. Needs to
be set for syntax-based T2T models.</li>
<li><strong>pop_id</strong> (<em>int</em>) &#8211; If positive, ID of the POP or closing bracket symbol.
Needs to be set for syntax-based T2T models.</li>
</ul>
</td>
</tr>
</tbody>
</table>
<dl class="method">
<dt>
<code class="descname">consume</code><span class="sig-paren">(</span><em>word</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/tf_t2t.html#FertilityT2TPredictor.consume"><span class="viewcode-link">[source]</span></a></dt>
<dd></dd></dl>

<dl class="method">
<dt>
<code class="descname">get_state</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/tf_t2t.html#FertilityT2TPredictor.get_state"><span class="viewcode-link">[source]</span></a></dt>
<dd></dd></dl>

<dl class="method">
<dt>
<code class="descname">get_unk_probability</code><span class="sig-paren">(</span><em>posterior</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/tf_t2t.html#FertilityT2TPredictor.get_unk_probability"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Returns self.other_scores[n_aligned_words].</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">initialize</code><span class="sig-paren">(</span><em>src_sentence</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/tf_t2t.html#FertilityT2TPredictor.initialize"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Set src_sentence, compute fertilities for first src word.</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">is_equal</code><span class="sig-paren">(</span><em>state1</em>, <em>state2</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/tf_t2t.html#FertilityT2TPredictor.is_equal"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Returns true if the history is the same</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">predict_next</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/tf_t2t.html#FertilityT2TPredictor.predict_next"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Returns self.pop_scores[n_aligned_words] for POP and EOS.</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">reset</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/tf_t2t.html#FertilityT2TPredictor.reset"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Empty method.</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">set_state</code><span class="sig-paren">(</span><em>state</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/tf_t2t.html#FertilityT2TPredictor.set_state"><span class="viewcode-link">[source]</span></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="data">
<dt>
<code class="descclassname">cam.sgnmt.predictors.tf_t2t.</code><code class="descname">POP</code><em class="property"> = '##POP##'</em></dt>
<dd><p>Textual representation of the POP symbol.</p>
</dd></dl>

<dl class="class">
<dt>
<em class="property">class </em><code class="descclassname">cam.sgnmt.predictors.tf_t2t.</code><code class="descname">T2TPredictor</code><span class="sig-paren">(</span><em>src_vocab_size</em>, <em>trg_vocab_size</em>, <em>model_name</em>, <em>problem_name</em>, <em>hparams_set_name</em>, <em>t2t_usr_dir</em>, <em>checkpoint_dir</em>, <em>t2t_unk_id=None</em>, <em>single_cpu_thread=False</em>, <em>max_terminal_id=-1</em>, <em>pop_id=-1</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/tf_t2t.html#T2TPredictor"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal"><span class="pre">cam.sgnmt.predictors.tf_t2t._BaseTensor2TensorPredictor</span></code></p>
<p>This predictor implements scoring with Tensor2Tensor models. We
follow the decoder implementation in T2T and do not reuse network
states in decoding. We rather compute the full forward pass along
the current history. Therefore, the decoder state is simply the
the full history of consumed words.</p>
<p>Creates a new T2T predictor. The constructor prepares the
TensorFlow session for predict_next() calls. This includes:
- Load hyper parameters from the given set (hparams)
- Update registry, load T2T model
- Create TF placeholders for source sequence and target prefix
- Create computation graph for computing log probs.
- Create a MonitoredSession object, which also handles</p>
<blockquote>
<div>restoring checkpoints.</div></blockquote>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>src_vocab_size</strong> (<em>int</em>) &#8211; Source vocabulary size.</li>
<li><strong>trg_vocab_size</strong> (<em>int</em>) &#8211; Target vocabulary size.</li>
<li><strong>model_name</strong> (<em>string</em>) &#8211; T2T model name.</li>
<li><strong>problem_name</strong> (<em>string</em>) &#8211; T2T problem name.</li>
<li><strong>hparams_set_name</strong> (<em>string</em>) &#8211; T2T hparams set name.</li>
<li><strong>t2t_usr_dir</strong> (<em>string</em>) &#8211; See &#8211;t2t_usr_dir in tensor2tensor.</li>
<li><strong>checkpoint_dir</strong> (<em>string</em>) &#8211; Path to the T2T checkpoint
directory. The predictor will load
the top most checkpoint in the
<cite>checkpoints</cite> file.</li>
<li><strong>t2t_unk_id</strong> (<em>int</em>) &#8211; If set, use this ID to get UNK scores. If
None, UNK is always scored with -inf.</li>
<li><strong>single_cpu_thread</strong> (<em>bool</em>) &#8211; If true, prevent tensorflow from
doing multithreading.</li>
<li><strong>max_terminal_id</strong> (<em>int</em>) &#8211; If positive, maximum terminal ID. Needs to
be set for syntax-based T2T models.</li>
<li><strong>pop_id</strong> (<em>int</em>) &#8211; If positive, ID of the POP or closing bracket symbol.
Needs to be set for syntax-based T2T models.</li>
</ul>
</td>
</tr>
</tbody>
</table>
<dl class="method">
<dt>
<code class="descname">consume</code><span class="sig-paren">(</span><em>word</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/tf_t2t.html#T2TPredictor.consume"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Append <code class="docutils literal"><span class="pre">word</span></code> to the current history.</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">get_state</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/tf_t2t.html#T2TPredictor.get_state"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>The predictor state is the complete history.</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">initialize</code><span class="sig-paren">(</span><em>src_sentence</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/tf_t2t.html#T2TPredictor.initialize"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Set src_sentence, reset consumed.</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">is_equal</code><span class="sig-paren">(</span><em>state1</em>, <em>state2</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/tf_t2t.html#T2TPredictor.is_equal"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Returns true if the history is the same</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">predict_next</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/tf_t2t.html#T2TPredictor.predict_next"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Call the T2T model in self.mon_sess.</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">reset</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/tf_t2t.html#T2TPredictor.reset"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Empty method.</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">set_state</code><span class="sig-paren">(</span><em>state</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/tf_t2t.html#T2TPredictor.set_state"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>The predictor state is the complete history.</p>
</dd></dl>

</dd></dl>

<dl class="data">
<dt>
<code class="descclassname">cam.sgnmt.predictors.tf_t2t.</code><code class="descname">T2T_INITIALIZED</code><em class="property"> = False</em></dt>
<dd><p>Set to true by _initialize_t2t() after first constructor call.</p>
</dd></dl>

<dl class="function">
<dt>
<code class="descclassname">cam.sgnmt.predictors.tf_t2t.</code><code class="descname">expand_input_dims_for_t2t</code><span class="sig-paren">(</span><em>t</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/tf_t2t.html#expand_input_dims_for_t2t"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Expands a plain input tensor for using it in a T2T graph.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>t</strong> &#8211; Tensor</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body">Tensor <cite>t</cite> expanded by 1 dimension on the left and two dimensions
on the right.</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt>
<code class="descclassname">cam.sgnmt.predictors.tf_t2t.</code><code class="descname">log_prob_from_logits</code><span class="sig-paren">(</span><em>logits</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/tf_t2t.html#log_prob_from_logits"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Softmax function.</p>
</dd></dl>

</div>
<div class="section" id="cam-sgnmt-predictors-tokenization-module">
<h3>cam.sgnmt.predictors.tokenization module<a class="headerlink" href="#cam-sgnmt-predictors-tokenization-module" title="Permalink to this headline">¶</a></h3>
<p>This module contains wrapper predictors which support decoding with
diverse tokenization. The <code class="docutils literal"><span class="pre">Word2charPredictor</span></code> can be used if the
decoder operates on fine-grained tokens such as characters, but the
tokenization of a predictor is coarse-grained (e.g. words or subwords).</p>
<p>The <code class="docutils literal"><span class="pre">word2char</span></code> predictor maintains an explicit list of word boundary
characters and applies consume and predict_next whenever a word boundary
character is consumed.</p>
<p>The <code class="docutils literal"><span class="pre">fsttok</span></code> predictor also masks coarse grained predictors when SGNMT
uses fine-grained tokens such as characters. This wrapper loads an FST
which transduces character to predictor-unit sequences.</p>
<dl class="class">
<dt>
<em class="property">class </em><code class="descclassname">cam.sgnmt.predictors.tokenization.</code><code class="descname">CombinedState</code><span class="sig-paren">(</span><em>fst_node</em>, <em>pred_state</em>, <em>posterior</em>, <em>unconsumed=[]</em>, <em>pending_score=0.0</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/tokenization.html#CombinedState"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal"><span class="pre">object</span></code></p>
<p>Combines an FST state with predictor state. Use by the fsttok
predictor.</p>
<dl class="method">
<dt>
<code class="descname">consume_all</code><span class="sig-paren">(</span><em>predictor</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/tokenization.html#CombinedState.consume_all"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Consume all unconsumed tokens and update pred_state,
pending_score, and posterior accordingly.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>predictor</strong> (<a class="reference internal" href="cam.sgnmt.predictors.html#cam.sgnmt.predictors.core.Predictor" title="cam.sgnmt.predictors.core.Predictor"><em>Predictor</em></a>) &#8211; Predictor instance</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">consume_single</code><span class="sig-paren">(</span><em>predictor</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/tokenization.html#CombinedState.consume_single"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Consume a single token in <code class="docutils literal"><span class="pre">self.unconsumed</span></code>.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>predictor</strong> (<a class="reference internal" href="cam.sgnmt.predictors.html#cam.sgnmt.predictors.core.Predictor" title="cam.sgnmt.predictors.core.Predictor"><em>Predictor</em></a>) &#8211; Predictor instance</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">score</code><span class="sig-paren">(</span><em>token</em>, <em>predictor</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/tokenization.html#CombinedState.score"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Returns a score which can be added if <code class="docutils literal"><span class="pre">token</span></code> is consumed
next. This is not necessarily the full score but an upper bound
on it: Continuations will have a score lower or equal than
this. We only use the current posterior vector and do not
consume tokens with the wrapped predictor.</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">traverse_fst</code><span class="sig-paren">(</span><em>trans_fst</em>, <em>char</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/tokenization.html#CombinedState.traverse_fst"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Returns a list of <code class="docutils literal"><span class="pre">CombinedState``s</span> <span class="pre">with</span> <span class="pre">the</span> <span class="pre">same</span> <span class="pre">predictor</span>
<span class="pre">state</span> <span class="pre">and</span> <span class="pre">posterior,</span> <span class="pre">but</span> <span class="pre">an</span> <span class="pre">``fst_node</span></code> which is reachable
via the input label <code class="docutils literal"><span class="pre">char</span></code>. If the output tabe contains
symbols, add them to <code class="docutils literal"><span class="pre">unconsumed</span></code>.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>trans_fst</strong> (<em>Fst</em>) &#8211; FST to traverse</li>
<li><strong>char</strong> (<em>int</em>) &#8211; Index of character</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first last">list. List of combined states reachable via <code class="docutils literal"><span class="pre">char</span></code></p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">update_posterior</code><span class="sig-paren">(</span><em>predictor</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/tokenization.html#CombinedState.update_posterior"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>If <code class="docutils literal"><span class="pre">self.posterior</span></code> is None, call <code class="docutils literal"><span class="pre">predict_next</span></code> to
be able to score the next tokens.</p>
</dd></dl>

</dd></dl>

<dl class="data">
<dt>
<code class="descclassname">cam.sgnmt.predictors.tokenization.</code><code class="descname">EPS_ID</code><em class="property"> = 0</em></dt>
<dd><p>OpenFST&#8217;s reserved ID for epsilon arcs.</p>
</dd></dl>

<dl class="class">
<dt>
<em class="property">class </em><code class="descclassname">cam.sgnmt.predictors.tokenization.</code><code class="descname">FSTTokPredictor</code><span class="sig-paren">(</span><em>path</em>, <em>fst_unk_id</em>, <em>max_pending_score</em>, <em>slave_predictor</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/tokenization.html#FSTTokPredictor"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Bases: <a class="reference internal" href="cam.sgnmt.predictors.html#cam.sgnmt.predictors.core.Predictor" title="cam.sgnmt.predictors.core.Predictor"><code class="xref py py-class docutils literal"><span class="pre">cam.sgnmt.predictors.core.Predictor</span></code></a></p>
<p>This wrapper can be used if the SGNMT decoder operates on the
character level, but a predictor uses a more coarse grained
tokenization. The mapping is defined by an FST which transduces
character to predictor unit sequences. This wrapper maintains a
list of <code class="docutils literal"><span class="pre">CombinedState</span></code> objects which are tuples of an FST node
and a predictor state for which holds:</p>
<ul class="simple">
<li>The input labels on the path to the node are consistent with the
consumed characters</li>
<li>The output labels on the path to the node are consistent with the
predictor states</li>
</ul>
<p>Constructor for the fsttok wrapper</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>path</strong> (<em>string</em>) &#8211; Path to an FST which transduces characters
to predictor tokens</li>
<li><strong>fst_unk_id</strong> (<em>int</em>) &#8211; ID used to represent UNK in the FSTs
(usually 999999998)</li>
<li><strong>max_pending_score</strong> (<em>float</em>) &#8211; Maximum pending score in a
<code class="docutils literal"><span class="pre">CombinedState</span></code> instance.</li>
<li><strong>slave_predictor</strong> (<a class="reference internal" href="cam.sgnmt.predictors.html#cam.sgnmt.predictors.core.Predictor" title="cam.sgnmt.predictors.core.Predictor"><em>Predictor</em></a>) &#8211; Wrapped predictor</li>
</ul>
</td>
</tr>
</tbody>
</table>
<dl class="method">
<dt>
<code class="descname">consume</code><span class="sig-paren">(</span><em>word</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/tokenization.html#FSTTokPredictor.consume"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Update <code class="docutils literal"><span class="pre">self.states</span></code> to be consistent with <code class="docutils literal"><span class="pre">word</span></code> and
consumes all the predictor tokens.</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">estimate_future_cost</code><span class="sig-paren">(</span><em>hypo</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/tokenization.html#FSTTokPredictor.estimate_future_cost"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Not implemented yet</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">get_state</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/tokenization.html#FSTTokPredictor.get_state"><span class="viewcode-link">[source]</span></a></dt>
<dd></dd></dl>

<dl class="method">
<dt>
<code class="descname">get_unk_probability</code><span class="sig-paren">(</span><em>posterior</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/tokenization.html#FSTTokPredictor.get_unk_probability"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Always returns negative infinity. Handling UNKs needs to be
realized by the FST.</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">initialize</code><span class="sig-paren">(</span><em>src_sentence</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/tokenization.html#FSTTokPredictor.initialize"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Pass through to slave predictor. The source sentence is not
modified. <code class="docutils literal"><span class="pre">states</span></code> is updated to the initial FST node and
predictor posterior and state.</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">initialize_heuristic</code><span class="sig-paren">(</span><em>src_sentence</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/tokenization.html#FSTTokPredictor.initialize_heuristic"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Pass through to slave predictor. The source sentence is not
modified</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">is_equal</code><span class="sig-paren">(</span><em>state1</em>, <em>state2</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/tokenization.html#FSTTokPredictor.is_equal"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Not implemented yet</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">predict_next</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/tokenization.html#FSTTokPredictor.predict_next"><span class="viewcode-link">[source]</span></a></dt>
<dd></dd></dl>

<dl class="method">
<dt>
<code class="descname">reset</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/tokenization.html#FSTTokPredictor.reset"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Pass through to slave predictor</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">set_current_sen_id</code><span class="sig-paren">(</span><em>cur_sen_id</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/tokenization.html#FSTTokPredictor.set_current_sen_id"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>We need to override this method to propagate current_
sentence_id to the slave predictor</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">set_state</code><span class="sig-paren">(</span><em>state</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/tokenization.html#FSTTokPredictor.set_state"><span class="viewcode-link">[source]</span></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="class">
<dt>
<em class="property">class </em><code class="descclassname">cam.sgnmt.predictors.tokenization.</code><code class="descname">Word2charPredictor</code><span class="sig-paren">(</span><em>map_path</em>, <em>slave_predictor</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/tokenization.html#Word2charPredictor"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Bases: <a class="reference internal" href="cam.sgnmt.predictors.html#cam.sgnmt.predictors.core.UnboundedVocabularyPredictor" title="cam.sgnmt.predictors.core.UnboundedVocabularyPredictor"><code class="xref py py-class docutils literal"><span class="pre">cam.sgnmt.predictors.core.UnboundedVocabularyPredictor</span></code></a></p>
<p>This predictor wraps word level predictors when SGNMT is running
on the character level. The mapping between word ID and character
ID sequence is loaded from the file system. All characters which
do not appear in that mapping are treated as word boundary
makers. The wrapper blocks consume and predict_next calls until a
word boundary marker is consumed, and updates the slave predictor
according the word between the last two word boundaries. The
mapping is done only on the target side, and the source sentences
are passed through as they are. To use alternative tokenization on
the source side, see the altsrc predictor wrapper. The word2char
wrapper is always an <code class="docutils literal"><span class="pre">UnboundedVocabularyPredictor</span></code>.</p>
<p>Creates a new word2char wrapper predictor. The map_path
file has to be plain text files, each line containing the
mapping from a word index to the character index sequence
(format: word char1 char2... charn).</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>map_path</strong> (<em>string</em>) &#8211; Path to the mapping file</li>
<li><strong>slave_predictor</strong> (<a class="reference internal" href="cam.sgnmt.predictors.html#cam.sgnmt.predictors.core.Predictor" title="cam.sgnmt.predictors.core.Predictor"><em>Predictor</em></a>) &#8211; Instance of the predictor with
a different wmap than SGNMT</li>
</ul>
</td>
</tr>
</tbody>
</table>
<dl class="method">
<dt>
<code class="descname">consume</code><span class="sig-paren">(</span><em>word</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/tokenization.html#Word2charPredictor.consume"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>If <code class="docutils literal"><span class="pre">word</span></code> is a word boundary marker, truncate <code class="docutils literal"><span class="pre">word_stub</span></code>
and let the slave predictor consume word_stub. Otherwise,
extend <code class="docutils literal"><span class="pre">word_stub</span></code> by the character.</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">estimate_future_cost</code><span class="sig-paren">(</span><em>hypo</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/tokenization.html#Word2charPredictor.estimate_future_cost"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Not supported</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">get_state</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/tokenization.html#Word2charPredictor.get_state"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Pass through to slave predictor</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">get_unk_probability</code><span class="sig-paren">(</span><em>posterior</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/tokenization.html#Word2charPredictor.get_unk_probability"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>This is about the unkown character, not word. Since the word
level slave predictor has no notion of the unknown character,
we return NEG_INF unconditionally.</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">initialize</code><span class="sig-paren">(</span><em>src_sentence</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/tokenization.html#Word2charPredictor.initialize"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Pass through to slave predictor. The source sentence is not
modified</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">initialize_heuristic</code><span class="sig-paren">(</span><em>src_sentence</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/tokenization.html#Word2charPredictor.initialize_heuristic"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Pass through to slave predictor. The source sentence is not
modified</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">is_equal</code><span class="sig-paren">(</span><em>state1</em>, <em>state2</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/tokenization.html#Word2charPredictor.is_equal"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Pass through to slave predictor</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">predict_next</code><span class="sig-paren">(</span><em>trgt_words</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/tokenization.html#Word2charPredictor.predict_next"><span class="viewcode-link">[source]</span></a></dt>
<dd></dd></dl>

<dl class="method">
<dt>
<code class="descname">reset</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/tokenization.html#Word2charPredictor.reset"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Pass through to slave predictor</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">set_current_sen_id</code><span class="sig-paren">(</span><em>cur_sen_id</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/tokenization.html#Word2charPredictor.set_current_sen_id"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>We need to override this method to propagate current_
sentence_id to the slave predictor</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">set_state</code><span class="sig-paren">(</span><em>state</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/tokenization.html#Word2charPredictor.set_state"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Pass through to slave predictor</p>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="cam-sgnmt-predictors-vocabulary-module">
<h3>cam.sgnmt.predictors.vocabulary module<a class="headerlink" href="#cam-sgnmt-predictors-vocabulary-module" title="Permalink to this headline">¶</a></h3>
<p>Predictor wrappers in this module work with the vocabulary of the
wrapped predictor. An example is the idxmap wrapper which makes it
possible to use an alternative word map.</p>
<dl class="class">
<dt>
<em class="property">class </em><code class="descclassname">cam.sgnmt.predictors.vocabulary.</code><code class="descname">IdxmapPredictor</code><span class="sig-paren">(</span><em>src_idxmap_path</em>, <em>trgt_idxmap_path</em>, <em>slave_predictor</em>, <em>slave_weight</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/vocabulary.html#IdxmapPredictor"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Bases: <a class="reference internal" href="cam.sgnmt.predictors.html#cam.sgnmt.predictors.core.Predictor" title="cam.sgnmt.predictors.core.Predictor"><code class="xref py py-class docutils literal"><span class="pre">cam.sgnmt.predictors.core.Predictor</span></code></a></p>
<p>This wrapper predictor can be applied to slave predictors which
use different wmaps than SGNMT. It translates between SGNMT word
indices and predictors indices each time the predictor is called.
This mapping is transparent to both the decoder and the wrapped
slave predictor.</p>
<p>Creates a new idxmap wrapper predictor. The index maps have
to be plain text files, each line containing the mapping from
a SGNMT word index to the slave predictor word index.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>src_idxmap_path</strong> (<em>string</em>) &#8211; Path to the source index map</li>
<li><strong>trgt_idxmap_path</strong> (<em>string</em>) &#8211; Path to the target index map</li>
<li><strong>slave_predictor</strong> (<a class="reference internal" href="cam.sgnmt.predictors.html#cam.sgnmt.predictors.core.Predictor" title="cam.sgnmt.predictors.core.Predictor"><em>Predictor</em></a>) &#8211; Instance of the predictor with
a different wmap than SGNMT</li>
<li><strong>slave_weight</strong> (<em>float</em>) &#8211; Slave predictor weight</li>
</ul>
</td>
</tr>
</tbody>
</table>
<dl class="method">
<dt>
<code class="descname">consume</code><span class="sig-paren">(</span><em>word</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/vocabulary.html#IdxmapPredictor.consume"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Pass through to slave predictor</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">estimate_future_cost</code><span class="sig-paren">(</span><em>hypo</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/vocabulary.html#IdxmapPredictor.estimate_future_cost"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Pass through to slave predictor</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">get_state</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/vocabulary.html#IdxmapPredictor.get_state"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Pass through to slave predictor</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">get_unk_probability</code><span class="sig-paren">(</span><em>posterior</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/vocabulary.html#IdxmapPredictor.get_unk_probability"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>ATTENTION: We should translate the posterior array
back to slave predictor indices. However, the unk_id is
translated to the identical index, and others normally do not
matter when computing the UNK probability. Therefore, we
refrain from a complete conversion and pass through
<code class="docutils literal"><span class="pre">posterior</span></code> without changing its word indices.</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">initialize</code><span class="sig-paren">(</span><em>src_sentence</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/vocabulary.html#IdxmapPredictor.initialize"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Pass through to slave predictor</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">initialize_heuristic</code><span class="sig-paren">(</span><em>src_sentence</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/vocabulary.html#IdxmapPredictor.initialize_heuristic"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Pass through to slave predictor</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">is_equal</code><span class="sig-paren">(</span><em>state1</em>, <em>state2</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/vocabulary.html#IdxmapPredictor.is_equal"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Pass through to slave predictor</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">load_map</code><span class="sig-paren">(</span><em>path</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/vocabulary.html#IdxmapPredictor.load_map"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Load a index map file. Mappings should be bijections, but
there is no sanity check in place to verify this.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>path</strong> (<em>string</em>) &#8211; Path to the mapping file</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body">dict. Mapping from SGNMT index to slave predictor index</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">predict_next</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/vocabulary.html#IdxmapPredictor.predict_next"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Pass through to slave predictor</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">reset</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/vocabulary.html#IdxmapPredictor.reset"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Pass through to slave predictor</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">set_current_sen_id</code><span class="sig-paren">(</span><em>cur_sen_id</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/vocabulary.html#IdxmapPredictor.set_current_sen_id"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>We need to override this method to propagate current_
sentence_id to the slave predictor</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">set_state</code><span class="sig-paren">(</span><em>state</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/vocabulary.html#IdxmapPredictor.set_state"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Pass through to slave predictor</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt>
<em class="property">class </em><code class="descclassname">cam.sgnmt.predictors.vocabulary.</code><code class="descname">SkipvocabInternalHypothesis</code><span class="sig-paren">(</span><em>score</em>, <em>predictor_state</em>, <em>word_to_consume</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/vocabulary.html#SkipvocabInternalHypothesis"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal"><span class="pre">object</span></code></p>
<p>Helper class for internal beam search in skipvocab.</p>
</dd></dl>

<dl class="class">
<dt>
<em class="property">class </em><code class="descclassname">cam.sgnmt.predictors.vocabulary.</code><code class="descname">SkipvocabPredictor</code><span class="sig-paren">(</span><em>max_id</em>, <em>stop_size</em>, <em>beam</em>, <em>slave_predictor</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/vocabulary.html#SkipvocabPredictor"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Bases: <a class="reference internal" href="cam.sgnmt.predictors.html#cam.sgnmt.predictors.core.Predictor" title="cam.sgnmt.predictors.core.Predictor"><code class="xref py py-class docutils literal"><span class="pre">cam.sgnmt.predictors.core.Predictor</span></code></a></p>
<p>This predictor wrapper masks predictors with a larger vocabulary
than the SGNMT vocabulary. The SGNMT OOV words are not scored with
UNK scores from the other predictors like usual, but are hidden by
this wrapper. Therefore, this wrapper does not produce any word
from the larger vocabulary, but searches internally until enough
in-vocabulary word scores are collected from the wrapped predictor.</p>
<p>Creates a new skipvocab wrapper predictor.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>max_id</strong> (<em>int</em>) &#8211; All words greater than this are skipped</li>
<li><strong>stop_size</strong> (<em>int</em>) &#8211; Stop internal beam search when the best
stop_size words are in-vocabulary</li>
<li><strong>beam</strong> (<em>int</em>) &#8211; Beam size of internal beam search</li>
<li><strong>slave_predictor</strong> (<a class="reference internal" href="cam.sgnmt.predictors.html#cam.sgnmt.predictors.core.Predictor" title="cam.sgnmt.predictors.core.Predictor"><em>Predictor</em></a>) &#8211; Wrapped predictor.</li>
</ul>
</td>
</tr>
</tbody>
</table>
<dl class="method">
<dt>
<code class="descname">consume</code><span class="sig-paren">(</span><em>word</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/vocabulary.html#SkipvocabPredictor.consume"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Pass through to slave predictor</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">estimate_future_cost</code><span class="sig-paren">(</span><em>hypo</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/vocabulary.html#SkipvocabPredictor.estimate_future_cost"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Pass through to slave predictor</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">get_state</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/vocabulary.html#SkipvocabPredictor.get_state"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Pass through to slave predictor</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">get_unk_probability</code><span class="sig-paren">(</span><em>posterior</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/vocabulary.html#SkipvocabPredictor.get_unk_probability"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Pass through to slave predictor</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">initialize</code><span class="sig-paren">(</span><em>src_sentence</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/vocabulary.html#SkipvocabPredictor.initialize"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Pass through to slave predictor</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">initialize_heuristic</code><span class="sig-paren">(</span><em>src_sentence</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/vocabulary.html#SkipvocabPredictor.initialize_heuristic"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Pass through to slave predictor</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">is_equal</code><span class="sig-paren">(</span><em>state1</em>, <em>state2</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/vocabulary.html#SkipvocabPredictor.is_equal"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Pass through to slave predictor</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">predict_next</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/vocabulary.html#SkipvocabPredictor.predict_next"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>This method first performs beam search internally to update
the slave predictor state to a point where the best stop_size
entries in the predict_next() return value are in-vocabulary
(bounded by max_id). Then, it returns the slave posterior in
that state.</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">reset</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/vocabulary.html#SkipvocabPredictor.reset"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Pass through to slave predictor</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">set_current_sen_id</code><span class="sig-paren">(</span><em>cur_sen_id</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/vocabulary.html#SkipvocabPredictor.set_current_sen_id"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>We need to override this method to propagate current_
sentence_id to the slave predictor</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">set_state</code><span class="sig-paren">(</span><em>state</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/vocabulary.html#SkipvocabPredictor.set_state"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Pass through to slave predictor</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt>
<em class="property">class </em><code class="descclassname">cam.sgnmt.predictors.vocabulary.</code><code class="descname">UnboundedIdxmapPredictor</code><span class="sig-paren">(</span><em>src_idxmap_path</em>, <em>trgt_idxmap_path</em>, <em>slave_predictor</em>, <em>slave_weight</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/vocabulary.html#UnboundedIdxmapPredictor"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Bases: <a class="reference internal" href="cam.sgnmt.predictors.html#cam.sgnmt.predictors.vocabulary.IdxmapPredictor" title="cam.sgnmt.predictors.vocabulary.IdxmapPredictor"><code class="xref py py-class docutils literal"><span class="pre">cam.sgnmt.predictors.vocabulary.IdxmapPredictor</span></code></a>, <a class="reference internal" href="cam.sgnmt.predictors.html#cam.sgnmt.predictors.core.UnboundedVocabularyPredictor" title="cam.sgnmt.predictors.core.UnboundedVocabularyPredictor"><code class="xref py py-class docutils literal"><span class="pre">cam.sgnmt.predictors.core.UnboundedVocabularyPredictor</span></code></a></p>
<p>This class is a version of <code class="docutils literal"><span class="pre">IdxmapPredictor</span></code> for unbounded
vocabulary predictors. This needs an adjusted <code class="docutils literal"><span class="pre">predict_next</span></code>
method to pass through the set of target words to score correctly.</p>
<p>Pass through to <code class="docutils literal"><span class="pre">IdxmapPredictor.__init__</span></code></p>
<dl class="method">
<dt>
<code class="descname">predict_next</code><span class="sig-paren">(</span><em>trgt_words</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/vocabulary.html#UnboundedIdxmapPredictor.predict_next"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Pass through to slave predictor</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt>
<em class="property">class </em><code class="descclassname">cam.sgnmt.predictors.vocabulary.</code><code class="descname">UnkvocabPredictor</code><span class="sig-paren">(</span><em>trg_vocab_size</em>, <em>slave_predictor</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/vocabulary.html#UnkvocabPredictor"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Bases: <a class="reference internal" href="cam.sgnmt.predictors.html#cam.sgnmt.predictors.core.Predictor" title="cam.sgnmt.predictors.core.Predictor"><code class="xref py py-class docutils literal"><span class="pre">cam.sgnmt.predictors.core.Predictor</span></code></a></p>
<p>If the predictor wrapped by the unkvocab wrapper produces an UNK
with predict next, this wrapper adds explicit NEG_INF scores to all
in-vocabulary words not in its posterior. This can control which
words are matched by the UNK scores of other predictors.</p>
<p>Creates a new unkvocab wrapper predictor.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>trg_vocab_size</strong> (<em>int</em>) &#8211; Size of the target vocabulary</td>
</tr>
</tbody>
</table>
<dl class="method">
<dt>
<code class="descname">consume</code><span class="sig-paren">(</span><em>word</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/vocabulary.html#UnkvocabPredictor.consume"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Pass through to slave predictor</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">estimate_future_cost</code><span class="sig-paren">(</span><em>hypo</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/vocabulary.html#UnkvocabPredictor.estimate_future_cost"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Pass through to slave predictor</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">get_state</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/vocabulary.html#UnkvocabPredictor.get_state"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Pass through to slave predictor</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">get_unk_probability</code><span class="sig-paren">(</span><em>posterior</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/vocabulary.html#UnkvocabPredictor.get_unk_probability"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Pass through to slave predictor</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">initialize</code><span class="sig-paren">(</span><em>src_sentence</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/vocabulary.html#UnkvocabPredictor.initialize"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Pass through to slave predictor</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">initialize_heuristic</code><span class="sig-paren">(</span><em>src_sentence</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/vocabulary.html#UnkvocabPredictor.initialize_heuristic"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Pass through to slave predictor</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">is_equal</code><span class="sig-paren">(</span><em>state1</em>, <em>state2</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/vocabulary.html#UnkvocabPredictor.is_equal"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Pass through to slave predictor</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">predict_next</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/vocabulary.html#UnkvocabPredictor.predict_next"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Pass through to slave predictor. If the posterior from the
slave predictor contains util.UNK_ID, add NEG_INF for all
word ids lower than trg_vocab_size that are not already
defined</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">reset</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/vocabulary.html#UnkvocabPredictor.reset"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Pass through to slave predictor</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">set_current_sen_id</code><span class="sig-paren">(</span><em>cur_sen_id</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/vocabulary.html#UnkvocabPredictor.set_current_sen_id"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>We need to override this method to propagate current_
sentence_id to the slave predictor</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">set_state</code><span class="sig-paren">(</span><em>state</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/cam/sgnmt/predictors/vocabulary.html#UnkvocabPredictor.set_state"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Pass through to slave predictor</p>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="module-contents">
<h3>Module contents<a class="headerlink" href="#module-contents" title="Permalink to this headline">¶</a></h3>
<p>Predictors are the scoring modules used in SGNMT. They can be used
together to form a combined search space and scores. Note that the
configuration of predictors is not decoupled with the central
configuration (yet). Therefore, new predictors need to be referenced to
in <code class="docutils literal"><span class="pre">blocks.decode</span></code>, and their configuration parameters need to be
added to <code class="docutils literal"><span class="pre">blocks.ui</span></code>.</p>
</div>
</div>
</div>


           </div>
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="decoders.html" class="btn btn-neutral float-right" title="Decoders" accesskey="n">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="command_line.html" class="btn btn-neutral" title="Command-line reference" accesskey="p"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2018, University of Cambridge.

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/snide/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  

    <script type="text/javascript">
        var DOCUMENTATION_OPTIONS = {
            URL_ROOT:'./',
            VERSION:'0.3.2',
            COLLAPSE_INDEX:false,
            FILE_SUFFIX:'.html',
            HAS_SOURCE:  true
        };
    </script>
      <script type="text/javascript" src="_static/jquery.js"></script>
      <script type="text/javascript" src="_static/underscore.js"></script>
      <script type="text/javascript" src="_static/doctools.js"></script>

  

  
  
    <script type="text/javascript" src="_static/js/theme.js"></script>
  

  
  
  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.StickyNav.enable();
      });
  </script>
   

</body>
</html>